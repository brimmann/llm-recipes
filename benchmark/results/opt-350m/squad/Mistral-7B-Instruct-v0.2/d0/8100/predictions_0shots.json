{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Carolina Panthers", "Carolina Panthers", "Carolina Panthers"], "answer_start": [249, 249, 249]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Santa Clara, California", "Levi's Stadium", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California."], "answer_start": [403, 355, 355]}, "prediction_text": "San Francisco Bay Area"}
{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["gold", "gold", "gold"], "answer_start": [488, 488, 521]}, "prediction_text": "Gold"}
{"answers": {"text": ["\"golden anniversary\"", "gold-themed", "\"golden anniversary"], "answer_start": [487, 521, 487]}, "prediction_text": "Golden anniversary"}
{"answers": {"text": ["February 7, 2016", "February 7", "February 7, 2016"], "answer_start": [334, 334, 334]}, "prediction_text": "February 7, 2016"}
{"answers": {"text": ["American Football Conference", "American Football Conference", "American Football Conference"], "answer_start": [133, 133, 133]}, "prediction_text": "American Football Conference"}
{"answers": {"text": ["\"golden anniversary\"", "gold-themed", "gold"], "answer_start": [487, 521, 521]}, "prediction_text": "Golden anniversary"}
{"answers": {"text": ["American Football Conference", "American Football Conference", "American Football Conference"], "answer_start": [133, 133, 133]}, "prediction_text": "American Football Conference"}
{"answers": {"text": ["February 7, 2016", "February 7", "February 7, 2016"], "answer_start": [334, 334, 334]}, "prediction_text": "February 7, 2016"}
{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Levi's Stadium", "Levi's Stadium", "Levi's Stadium in the San Francisco Bay Area at Santa Clara"], "answer_start": [355, 355, 355]}, "prediction_text": "Levi's Stadium in San Francisco Bay Area"}
{"answers": {"text": ["Santa Clara", "Santa Clara", "Santa Clara"], "answer_start": [403, 403, 403]}, "prediction_text": "San Francisco Bay Area"}
{"answers": {"text": ["Super Bowl L", "L", "Super Bowl L"], "answer_start": [693, 704, 693]}, "prediction_text": "\"Super Bowl L\""}
{"answers": {"text": ["2015", "the 2015 season", "2015"], "answer_start": [116, 112, 116]}, "prediction_text": "2015"}
{"answers": {"text": ["2015", "2016", "2015"], "answer_start": [116, 346, 116]}, "prediction_text": "2015"}
{"answers": {"text": ["Santa Clara", "Santa Clara", "Santa Clara"], "answer_start": [403, 403, 403]}, "prediction_text": "San Francisco Bay Area"}
{"answers": {"text": ["Levi's Stadium", "Levi's Stadium", "Levi's Stadium"], "answer_start": [355, 355, 355]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["24\u201310", "24\u201310", "24\u201310"], "answer_start": [267, 267, 267]}, "prediction_text": "Denver Broncos defeated Carolina Panthers 24-10."}
{"answers": {"text": ["February 7, 2016", "February 7, 2016", "February 7, 2016"], "answer_start": [334, 334, 334]}, "prediction_text": "February 7, 2016"}
{"answers": {"text": ["2015", "2016", "2016"], "answer_start": [116, 346, 346]}, "prediction_text": "2015"}
{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Carolina Panthers", "Carolina Panthers", "Carolina Panthers"], "answer_start": [249, 249, 249]}, "prediction_text": "Carolina Panthers"}
{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["2015", "the 2015 season", "2015"], "answer_start": [116, 112, 116]}, "prediction_text": "2015"}
{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Santa Clara, California.", "Levi's Stadium", "Levi's Stadium"], "answer_start": [403, 355, 355]}, "prediction_text": "Levi's Stadium in San Francisco Bay Area"}
{"answers": {"text": ["Super Bowl", "Super Bowl", "Super Bowl"], "answer_start": [0, 0, 0]}, "prediction_text": "Super Bowl 50"}
{"answers": {"text": ["Denver Broncos", "Denver Broncos", "Denver Broncos"], "answer_start": [177, 177, 177]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [77, 77, 77]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["8", "eight", "eight"], "answer_start": [467, 601, 601]}, "prediction_text": "Eight appearances"}
{"answers": {"text": ["1995", "1995", "1995"], "answer_start": [291, 291, 291]}, "prediction_text": "1995"}
{"answers": {"text": ["Arizona Cardinals", "the Arizona Cardinals", "Arizona Cardinals"], "answer_start": [152, 148, 152]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["New England Patriots", "the New England Patriots", "New England Patriots"], "answer_start": [372, 368, 372]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["Arizona Cardinals", "the Arizona Cardinals", "Arizona Cardinals"], "answer_start": [152, 148, 152]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["New England Patriots", "the New England Patriots", "New England Patriots"], "answer_start": [372, 368, 372]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["New England Patriots", "the New England Patriots", "New England Patriots"], "answer_start": [372, 368, 372]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [575, 575, 575]}, "prediction_text": "Four teams"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [77, 77, 77]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["15\u20131", "15\u20131", "15\u20131"], "answer_start": [48, 48, 48]}, "prediction_text": "15\u20131"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [77, 77, 77]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["12\u20134", "12\u20134", "12\u20134"], "answer_start": [344, 344, 344]}, "prediction_text": "12\u20134 record"}
{"answers": {"text": ["4", "four", "four"], "answer_start": [170, 575, 575]}, "prediction_text": "Four teams"}
{"answers": {"text": ["New England Patriots", "the New England Patriots", "New England Patriots"], "answer_start": [372, 368, 372]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [77, 77, 77]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["Arizona Cardinals", "the Arizona Cardinals", "Arizona Cardinals"], "answer_start": [152, 148, 152]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["2", "second", "second"], "answer_start": [345, 227, 227]}, "prediction_text": "Eight times"}
{"answers": {"text": ["New England Patriots", "the New England Patriots", "New England Patriots"], "answer_start": [372, 368, 372]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [77, 77, 77]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["New England Patriots", "the New England Patriots", "New England Patriots"], "answer_start": [372, 368, 372]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["Arizona Cardinals", "the Arizona Cardinals", "Arizona Cardinals"], "answer_start": [152, 148, 152]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [77, 77, 77]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["Arizona Cardinals", "the Arizona Cardinals", "Arizona Cardinals"], "answer_start": [152, 148, 152]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["1995.", "1995", "1995"], "answer_start": [291, 291, 291]}, "prediction_text": "1995"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [248, 248, 252]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["2", "two", "two"], "answer_start": [314, 328, 328]}, "prediction_text": "Two fumbles"}
{"answers": {"text": ["Broncos", "The Broncos", "Broncos"], "answer_start": [4, 0, 4]}, "prediction_text": "Denver"}
{"answers": {"text": ["linebacker Von Miller", "Von Miller", "Miller"], "answer_start": [237, 248, 252]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["five solo tackles", "five", "five"], "answer_start": [295, 295, 295]}, "prediction_text": "Five solo tackles"}
{"answers": {"text": ["Newton was limited by Denver's defense", "Newton", "Newton"], "answer_start": [67, 67, 67]}, "prediction_text": "Newton"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [124, 124, 124]}, "prediction_text": "Seven times"}
{"answers": {"text": ["Von Miller", "The Broncos", "Miller"], "answer_start": [248, 0, 252]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [156, 156, 156]}, "prediction_text": "Three"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [328, 328, 328]}, "prediction_text": "Two fumbles"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [248, 248, 252]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["linebacker", "linebacker", "linebacker"], "answer_start": [237, 237, 237]}, "prediction_text": "Defensive end"}
{"answers": {"text": ["5", "five", "five"], "answer_start": [45, 295, 295]}, "prediction_text": "Five solo tackles"}
{"answers": {"text": ["2", "two", "two"], "answer_start": [314, 328, 328]}, "prediction_text": "Two"}
{"answers": {"text": ["Von Miller", "Von Miller", "Von Miller"], "answer_start": [248, 248, 248]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["5", "five", "five"], "answer_start": [45, 295, 295]}, "prediction_text": "Five"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [124, 124, 124]}, "prediction_text": "Seven times"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [156, 156, 156]}, "prediction_text": "Three times"}
{"answers": {"text": ["a fumble", "a fumble", "fumble"], "answer_start": [183, 183, 185]}, "prediction_text": "A fumble"}
{"answers": {"text": ["Von Miller", "Von Miller", "Von Miller"], "answer_start": [248, 248, 248]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["linebacker", "linebacker", "linebacker"], "answer_start": [237, 237, 237]}, "prediction_text": "Defensive end"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [124, 124, 124]}, "prediction_text": "Seven times"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [156, 156, 156]}, "prediction_text": "Three times"}
{"answers": {"text": ["Von Miller", "Von Miller", "Von Miller"], "answer_start": [248, 248, 248]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["five", "five", "five"], "answer_start": [295, 295, 295]}, "prediction_text": "Five"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [0, 0, 0]}, "prediction_text": "CBS"}
{"answers": {"text": ["$5 million", "$5 million", "$5 million"], "answer_start": [67, 67, 67]}, "prediction_text": "$5 million"}
{"answers": {"text": ["Coldplay", "Coldplay", "Coldplay"], "answer_start": [194, 194, 194]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars"], "answer_start": [233, 233, 233]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["Super Bowl XLVII", "Super Bowl XLVII", "XLVII"], "answer_start": [275, 275, 286]}, "prediction_text": "Super Bowl XLVIII"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [0, 0, 0]}, "prediction_text": "CBS"}
{"answers": {"text": ["$5 million", "$5 million", "$5 million"], "answer_start": [67, 67, 67]}, "prediction_text": "$5 million"}
{"answers": {"text": ["Beyonc\u00e9", "Beyonc\u00e9", "Beyonc\u00e9"], "answer_start": [233, 233, 233]}, "prediction_text": "Bruno Mars"}
{"answers": {"text": ["Bruno Mars", "Bruno Mars", "Mars"], "answer_start": [245, 245, 251]}, "prediction_text": "Bruno Mars"}
{"answers": {"text": ["Coldplay", "Coldplay", "Coldplay"], "answer_start": [194, 194, 194]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [0, 0, 0]}, "prediction_text": "CBS"}
{"answers": {"text": ["$5 million", "$5 million", "$5 million"], "answer_start": [67, 67, 67]}, "prediction_text": "$5 million"}
{"answers": {"text": ["Bruno Mars", "Bruno Mars", "Bruno Mars,"], "answer_start": [245, 245, 245]}, "prediction_text": "Bruno Mars"}
{"answers": {"text": ["third", "third", "third"], "answer_start": [355, 355, 355]}, "prediction_text": "Third-most watched"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [0, 0, 0]}, "prediction_text": "CBS"}
{"answers": {"text": ["$5 million", "$5 million", "$5 million"], "answer_start": [67, 67, 67]}, "prediction_text": "$5 million"}
{"answers": {"text": ["Coldplay", "Coldplay", "Coldplay"], "answer_start": [194, 194, 194]}, "prediction_text": "Coldplay"}
{"answers": {"text": ["Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars"], "answer_start": [233, 233, 233]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [0, 0, 0]}, "prediction_text": "CBS"}
{"answers": {"text": ["Coldplay", "Coldplay", "Coldplay"], "answer_start": [194, 194, 194]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars"], "answer_start": [233, 233, 233]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["Super Bowl XLVII", "Super Bowl XLVII", "Super Bowl XLVII"], "answer_start": [275, 275, 275]}, "prediction_text": "Super Bowl XLVIII"}
{"answers": {"text": ["$5 million", "$5 million", "$5 million for a 30-second"], "answer_start": [67, 67, 67]}, "prediction_text": "$5 million"}
{"answers": {"text": ["Coldplay", "Coldplay", "Coldplay"], "answer_start": [194, 194, 194]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars", "Beyonc\u00e9 and Bruno Mars"], "answer_start": [233, 233, 233]}, "prediction_text": "Beyonc\u00e9 and Bruno Mars"}
{"answers": {"text": ["Bruno Mars", "Coldplay", "Coldplay"], "answer_start": [245, 194, 194]}, "prediction_text": "Bruno Mars"}
{"answers": {"text": ["Roger Goodell", "Roger Goodell", "Goodell"], "answer_start": [32, 32, 38]}, "prediction_text": "Roger Goodell"}
{"answers": {"text": ["the 50th Super Bowl", "the 50th", "50th"], "answer_start": [85, 85, 89]}, "prediction_text": "50th Super Bowl"}
{"answers": {"text": ["2012", "2012", "2012"], "answer_start": [9, 9, 9]}, "prediction_text": "2012"}
{"answers": {"text": ["Roger Goodell", "Roger Goodell", "Goodell"], "answer_start": [32, 32, 38]}, "prediction_text": "Roger Goodell"}
{"answers": {"text": ["early 2012", "In early 2012", "2012"], "answer_start": [3, 0, 9]}, "prediction_text": "Early 2012"}
{"answers": {"text": ["Roger Goodell", "Roger Goodell", "Goodell"], "answer_start": [32, 32, 38]}, "prediction_text": "Roger Goodell"}
{"answers": {"text": ["Roger Goodell", "Roger Goodell", "Goodell"], "answer_start": [32, 32, 38]}, "prediction_text": "Roger Goodell"}
{"answers": {"text": ["Roger Goodell", "Roger Goodell", "Goodell"], "answer_start": [32, 32, 38]}, "prediction_text": "Roger Goodell"}
{"answers": {"text": ["spectacular", "an important game for us as a league", "spectacular"], "answer_start": [106, 141, 106]}, "prediction_text": "\"an important game for us as a league\""}
{"answers": {"text": ["spectacular", "spectacular", "spectacular"], "answer_start": [106, 106, 106]}, "prediction_text": "\"Spectacular\""}
{"answers": {"text": ["2012", "2012", "2012"], "answer_start": [9, 9, 9]}, "prediction_text": "2012"}
{"answers": {"text": ["New Orleans' Mercedes-Benz Superdome", "New Orleans' Mercedes-Benz Superdome", "Mercedes-Benz Superdome"], "answer_start": [56, 56, 69]}, "prediction_text": "Mercedes-Benz Superdome"}
{"answers": {"text": ["Miami's Sun Life Stadium", "Miami's Sun Life Stadium", "Sun Life Stadium"], "answer_start": [94, 94, 102]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["San Francisco Bay Area's Levi's Stadium", "San Francisco Bay Area's Levi's Stadium", "Levi's Stadium"], "answer_start": [128, 128, 153]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["Sun Life Stadium", "Sun Life Stadium", "Sun Life Stadium"], "answer_start": [102, 102, 102]}, "prediction_text": "Sun Life Stadium"}
{"answers": {"text": ["Levi's Stadium", "Levi's Stadium", "Levi's Stadium"], "answer_start": [153, 153, 153]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["Levi's Stadium", "Levi's Stadium", "Levi's Stadium."], "answer_start": [153, 153, 153]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["Mercedes-Benz Superdome", "Mercedes-Benz Superdome", "Mercedes-Benz Superdome"], "answer_start": [69, 69, 69]}, "prediction_text": "Mercedes-Benz Superdome"}
{"answers": {"text": ["Sun Life Stadium", "Sun Life Stadium", "Sun Life Stadium"], "answer_start": [102, 102, 102]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium.", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium."], "answer_start": [56, 56, 56]}, "prediction_text": "Mercedes-Benz Superdome, Miami's Sun Life Stadium, and Levi's Stadium."}
{"answers": {"text": ["three", "three", "three"], "answer_start": [43, 43, 43]}, "prediction_text": "Three sites"}
{"answers": {"text": ["New Orleans", "New Orleans", "New Orleans'"], "answer_start": [56, 56, 56]}, "prediction_text": "New Orleans"}
{"answers": {"text": ["Sun Life Stadium", "Sun Life Stadium", "Sun Life Stadium"], "answer_start": [102, 102, 102]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["San Francisco", "San Francisco", "San Francisco Bay Area's"], "answer_start": [128, 128, 128]}, "prediction_text": "San Francisco Bay Area"}
{"answers": {"text": ["Levi's Stadium.", "Levi's Stadium", "Levi's Stadium."], "answer_start": [153, 153, 153]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["Sun Life Stadium", "Sun Life Stadium", "Sun Life Stadium"], "answer_start": [102, 102, 102]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["Mercedes-Benz Superdome", "Mercedes-Benz Superdome", "Mercedes-Benz Superdome,"], "answer_start": [69, 69, 69]}, "prediction_text": "Mercedes-Benz Superdome"}
{"answers": {"text": ["Levi's Stadium.", "Levi's Stadium", "Levi's Stadium."], "answer_start": [153, 153, 153]}, "prediction_text": "Levi's Stadium"}
{"answers": {"text": ["October 16, 2012", "October 16, 2012,", "October 16, 2012"], "answer_start": [24, 24, 24]}, "prediction_text": "October 16, 2012"}
{"answers": {"text": ["10", "10", "10"], "answer_start": [168, 168, 168]}, "prediction_text": "10 times"}
{"answers": {"text": ["Super Bowl XLIV", "Super Bowl XLIV", "2010"], "answer_start": [242, 242, 261]}, "prediction_text": "Super Bowl XLIV (2010)"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [261, 261, 261]}, "prediction_text": "2010"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [309, 309, 309]}, "prediction_text": "1985 (Super Bowl XIX)"}
{"answers": {"text": ["Sun Life Stadium", "Sun Life Stadium", "Sun Life Stadium"], "answer_start": [70, 70, 70]}, "prediction_text": "New Orleans Saints (in 2010)"}
{"answers": {"text": ["October 16, 2012", "October 16, 2012", "October 16, 2012,"], "answer_start": [24, 24, 24]}, "prediction_text": "October 16, 2012"}
{"answers": {"text": ["Stanford Stadium", "Stanford Stadium", "Stanford Stadium"], "answer_start": [340, 340, 340]}, "prediction_text": "Stanford Stadium"}
{"answers": {"text": ["May 3, 2013", "May 3, 2013", "May 3, 2013"], "answer_start": [491, 491, 491]}, "prediction_text": "May 3, 2013"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [261, 261, 261]}, "prediction_text": "2010"}
{"answers": {"text": ["two", "10", "10"], "answer_start": [51, 168, 168]}, "prediction_text": "10 times"}
{"answers": {"text": ["Super Bowl XLIV", "Super Bowl XLIV", "2010"], "answer_start": [242, 242, 261]}, "prediction_text": "Super Bowl XLIV (2010)"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [51, 51, 51]}, "prediction_text": "Two stadiums"}
{"answers": {"text": ["Florida legislature", "the Florida legislature", "Florida legislature"], "answer_start": [508, 504, 508]}, "prediction_text": "Florida legislature"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [309, 309, 309]}, "prediction_text": "1985"}
{"answers": {"text": ["New Orleans", "New Orleans", "New Orleans"], "answer_start": [197, 197, 197]}, "prediction_text": "New Orleans"}
{"answers": {"text": ["October 16, 2012", "October 16, 2012", "October 16, 2012,"], "answer_start": [24, 24, 24]}, "prediction_text": "October 16, 2012"}
{"answers": {"text": ["10.", "10", "10 times"], "answer_start": [263, 168, 168]}, "prediction_text": "10 times"}
{"answers": {"text": ["New Orleans", "New Orleans", "New Orleans"], "answer_start": [197, 197, 197]}, "prediction_text": "New Orleans"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [309, 309, 309]}, "prediction_text": "1985 (Super Bowl XIX)"}
{"answers": {"text": ["Florida legislature", "the Florida legislature", "Florida legislature"], "answer_start": [508, 504, 508]}, "prediction_text": "Florida legislature"}
{"answers": {"text": ["May 21, 2013", "May 21, 2013", "May 21, 2013,"], "answer_start": [3, 3, 3]}, "prediction_text": "May 21, 2013"}
{"answers": {"text": ["NFL owners", "NFL owners", "NFL owners"], "answer_start": [17, 17, 17]}, "prediction_text": "NFL owners"}
{"answers": {"text": ["2014", "in 2014", "2014"], "answer_start": [144, 141, 144]}, "prediction_text": "2014"}
{"answers": {"text": ["$1.2 billion", "$1.2 billion", "$1.2 billion"], "answer_start": [113, 113, 113]}, "prediction_text": "$1.2 billion"}
{"answers": {"text": ["San Diego", "San Diego", "San Diego"], "answer_start": [308, 308, 308]}, "prediction_text": "San Diego"}
{"answers": {"text": ["Boston", "in Boston", "May 21, 2013"], "answer_start": [56, 53, 3]}, "prediction_text": "Boston"}
{"answers": {"text": ["May 21, 2013", "May 21, 2013", "May 21, 2013,"], "answer_start": [3, 3, 3]}, "prediction_text": "May 21, 2013"}
{"answers": {"text": ["$1.2 billion", "$1.2 billion", "$1.2 billion"], "answer_start": [113, 113, 113]}, "prediction_text": "$1.2 billion"}
{"answers": {"text": ["Super Bowl XXXVII", "Super Bowl XXXVII", "XXXVII"], "answer_start": [276, 276, 287]}, "prediction_text": "Super Bowl XXXVII"}
{"answers": {"text": ["San Diego", "San Diego", "San Diego"], "answer_start": [308, 308, 308]}, "prediction_text": "San Diego"}
{"answers": {"text": ["2013", "2013", "2013"], "answer_start": [11, 11, 11]}, "prediction_text": "2013"}
{"answers": {"text": ["2014", "2014", "2014"], "answer_start": [144, 144, 144]}, "prediction_text": "2014"}
{"answers": {"text": ["$1.2 billion", "$1.2 billion", "$1.2 billion"], "answer_start": [113, 113, 113]}, "prediction_text": "$1.2 billion"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [236, 236, 236]}, "prediction_text": "1985"}
{"answers": {"text": ["Super Bowl XXXVII", "Super Bowl XXXVII", "XXXVII"], "answer_start": [276, 276, 287]}, "prediction_text": "Super Bowl XXXVII"}
{"answers": {"text": ["May 21, 2013", "May 21, 2013,", "May 21, 2013"], "answer_start": [3, 3, 3]}, "prediction_text": "May 21, 2013"}
{"answers": {"text": ["2014", "in 2014", "2014"], "answer_start": [144, 141, 144]}, "prediction_text": "2014"}
{"answers": {"text": ["2003", "in 2003", "2003"], "answer_start": [321, 318, 321]}, "prediction_text": "2003"}
{"answers": {"text": ["Boston", "in Boston", "Boston"], "answer_start": [56, 53, 56]}, "prediction_text": "Boston"}
{"answers": {"text": ["May 21, 2013", "May 21, 2013", "May 21, 2013"], "answer_start": [3, 3, 3]}, "prediction_text": "May 21, 2013"}
{"answers": {"text": ["2014.", "in 2014", "2014"], "answer_start": [144, 141, 144]}, "prediction_text": "2014"}
{"answers": {"text": ["$1.2 billion", "$1.2 billion", "$1.2 billion"], "answer_start": [113, 113, 113]}, "prediction_text": "$1.2 billion"}
{"answers": {"text": ["2003.", "2003", "2003"], "answer_start": [321, 321, 321]}, "prediction_text": "2003"}
{"answers": {"text": ["John Fox", "John Fox", "Fox"], "answer_start": [636, 636, 641]}, "prediction_text": "John Fox"}
{"answers": {"text": ["ten", "ten", "six"], "answer_start": [138, 138, 219]}, "prediction_text": "Ten teams"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [219, 219, 219]}, "prediction_text": "One team"}
{"answers": {"text": ["Carolina Panthers", "The Carolina Panthers", "Panthers"], "answer_start": [101, 97, 110]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["Super Bowl XLVIII", "Super Bowl XLVIII", "XLVIII"], "answer_start": [444, 444, 455]}, "prediction_text": "Super Bowl XXXVIII"}
{"answers": {"text": ["John Fox", "John Fox", "Fox"], "answer_start": [636, 636, 641]}, "prediction_text": "John Fox"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [324, 324, 324]}, "prediction_text": "Four times"}
{"answers": {"text": ["ten", "ten", "ten"], "answer_start": [138, 138, 138]}, "prediction_text": "Ten teams"}
{"answers": {"text": ["Super Bowl XXXVIII", "Super Bowl XXXVIII", "XXXVIII"], "answer_start": [573, 573, 584]}, "prediction_text": "Super Bowl XLVIII"}
{"answers": {"text": ["six", "ten", "ten"], "answer_start": [219, 138, 138]}, "prediction_text": "One team"}
{"answers": {"text": ["number one", "number one", "one"], "answer_start": [35, 35, 42]}, "prediction_text": "No. 1 seed"}
{"answers": {"text": ["number one", "number one", "one"], "answer_start": [35, 35, 42]}, "prediction_text": "Super Bowl XXXVIII seed"}
{"answers": {"text": ["Super Bowl XLVIII", "Super Bowl XLVIII", "Super Bowl XLVIII"], "answer_start": [444, 444, 444]}, "prediction_text": "Super Bowl XXXVIII"}
{"answers": {"text": ["Super Bowl XXXVIII.", "Super Bowl XXXVIII", "Super Bowl XXXVIII"], "answer_start": [573, 573, 573]}, "prediction_text": "Last Super Bowl appearance prior to Super Bowl 50."}
{"answers": {"text": ["six", "ten", "ten"], "answer_start": [219, 138, 138]}, "prediction_text": "Six teams"}
{"answers": {"text": ["one", "1", "1"], "answer_start": [42, 251, 251]}, "prediction_text": "One game"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [300, 300, 300]}, "prediction_text": "Four teams"}
{"answers": {"text": ["John Fox", "John Fox", "John Fox"], "answer_start": [636, 636, 636]}, "prediction_text": "John Fox"}
{"answers": {"text": ["DeAngelo Williams", "DeAngelo Williams", "Williams"], "answer_start": [38, 38, 47]}, "prediction_text": "DeAngelo Williams"}
{"answers": {"text": ["Kelvin Benjamin", "Kelvin Benjamin", "Benjamin"], "answer_start": [85, 85, 92]}, "prediction_text": "Kelvin Benjamin"}
{"answers": {"text": ["7", "seventh", "seventh"], "answer_start": [326, 220, 220]}, "prediction_text": "Seven teams"}
{"answers": {"text": ["1978", "1978", "1978"], "answer_start": [324, 324, 324]}, "prediction_text": "1978"}
{"answers": {"text": ["Carolina Panthers", "the Panthers", "Carolina"], "answer_start": [137, 695, 330]}, "prediction_text": "Carolina Panthers (14\u20130)"}
{"answers": {"text": ["Ten", "Ten", "Ten"], "answer_start": [807, 807, 807]}, "prediction_text": "Ten players"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [892, 892, 892]}, "prediction_text": "Eight"}
{"answers": {"text": ["Kelvin Benjamin", "Kelvin Benjamin", "Benjamin"], "answer_start": [85, 85, 92]}, "prediction_text": "DeAngelo Williams"}
{"answers": {"text": ["1978", "1978", "1978"], "answer_start": [324, 324, 324]}, "prediction_text": "1978"}
{"answers": {"text": ["2009", "2009", "2009"], "answer_start": [591, 591, 591]}, "prediction_text": "2009"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [623, 623, 623]}, "prediction_text": "2011"}
{"answers": {"text": ["torn ACL", "a torn ACL", "torn ACL"], "answer_start": [106, 104, 106]}, "prediction_text": "Torn ACL"}
{"answers": {"text": ["Kelvin Benjamin", "Kelvin Benjamin", "Benjamin"], "answer_start": [85, 85, 92]}, "prediction_text": "Kelvin Benjamin"}
{"answers": {"text": ["DeAngelo Williams", "DeAngelo Williams", "Williams"], "answer_start": [38, 38, 47]}, "prediction_text": "DeAngelo Williams"}
{"answers": {"text": ["1978", "1978", "1978"], "answer_start": [324, 324, 324]}, "prediction_text": "1978"}
{"answers": {"text": ["Ten", "Ten", "Ten"], "answer_start": [807, 807, 807]}, "prediction_text": "Ten players"}
{"answers": {"text": ["Carolina Panthers", "the Panthers", "Carolina"], "answer_start": [137, 695, 330]}, "prediction_text": "Carolina Panthers"}
{"answers": {"text": ["1978.", "1978", "1978"], "answer_start": [324, 324, 324]}, "prediction_text": "1978"}
{"answers": {"text": ["Carolina Panthers", "the Panthers", "Carolina"], "answer_start": [137, 695, 330]}, "prediction_text": "Carolina Panthers"}
{"answers": {"text": ["Ten", "Ten", "Ten"], "answer_start": [807, 807, 807]}, "prediction_text": "Ten players"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [98, 98, 98]}, "prediction_text": "Six Pro Bowlers"}
{"answers": {"text": ["45", "45", "45"], "answer_start": [279, 279, 279]}, "prediction_text": "35"}
{"answers": {"text": ["10", "10", "10"], "answer_start": [312, 338, 338]}, "prediction_text": "45"}
{"answers": {"text": ["27", "27", "27"], "answer_start": [659, 659, 659]}, "prediction_text": "27 punts"}
{"answers": {"text": ["Greg Olsen", "Greg Olsen", "Olsen"], "answer_start": [444, 444, 449]}, "prediction_text": "Greg Olsen"}
{"answers": {"text": ["45", "45", "45"], "answer_start": [279, 279, 279]}, "prediction_text": "35"}
{"answers": {"text": ["99.4", "99.4", "99.4."], "answer_start": [396, 396, 396]}, "prediction_text": "99.4"}
{"answers": {"text": ["77 passes", "77", "77"], "answer_start": [481, 481, 481]}, "prediction_text": "77 passes"}
{"answers": {"text": ["receivers", "receivers", "receivers"], "answer_start": [419, 693, 693]}, "prediction_text": "Center"}
{"answers": {"text": ["Jonathan Stewart", "Jonathan Stewart", "Jonathan Stewart"], "answer_start": [964, 964, 964]}, "prediction_text": "Jonathan Stewart"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [98, 98, 98]}, "prediction_text": "Six players were selected."}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Cam Newton"], "answer_start": [144, 144, 144]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["3,837", "3,837", "3,837"], "answer_start": [197, 197, 197]}, "prediction_text": "3,837 yards"}
{"answers": {"text": ["45", "45", "45"], "answer_start": [279, 279, 279]}, "prediction_text": "35"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [98, 1026, 1026]}, "prediction_text": "989"}
{"answers": {"text": ["500", "500", "500"], "answer_start": [52, 52, 52]}, "prediction_text": "500 points"}
{"answers": {"text": ["3,837", "3,837", "3,837"], "answer_start": [197, 197, 197]}, "prediction_text": "3,837 yards"}
{"answers": {"text": ["45", "45", "45"], "answer_start": [279, 279, 279]}, "prediction_text": "35"}
{"answers": {"text": ["99.4.", "99.4", "99.4."], "answer_start": [396, 396, 396]}, "prediction_text": "99.4"}
{"answers": {"text": ["39", "39", "39"], "answer_start": [588, 739, 739]}, "prediction_text": "81"}
{"answers": {"text": ["308", "308", "308"], "answer_start": [34, 34, 34]}, "prediction_text": "308 points"}
{"answers": {"text": ["136", "136", "136"], "answer_start": [470, 470, 470]}, "prediction_text": "5\u00bd"}
{"answers": {"text": ["118", "118", "118"], "answer_start": [789, 789, 789]}, "prediction_text": "88 tackles"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [140, 1104, 1104]}, "prediction_text": "Four balls"}
{"answers": {"text": ["Kawann Short", "Kawann Short", "Short"], "answer_start": [192, 192, 199]}, "prediction_text": "Kawann Short (12)"}
{"answers": {"text": ["24", "24", "24"], "answer_start": [124, 124, 124]}, "prediction_text": "Four interceptions"}
{"answers": {"text": ["Kawann Short", "Kawann Short", "Short"], "answer_start": [192, 192, 199]}, "prediction_text": "Kawann Short"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [140, 140, 140]}, "prediction_text": "Three Panthers players were selected."}
{"answers": {"text": ["four", "5\u00bd", "four"], "answer_start": [140, 695, 705]}, "prediction_text": "Eight"}
{"answers": {"text": ["Kurt Coleman", "Kurt Coleman", "Coleman"], "answer_start": [900, 900, 905]}, "prediction_text": "Josh Norman"}
{"answers": {"text": ["24", "24", "24"], "answer_start": [124, 124, 124]}, "prediction_text": "Eight"}
{"answers": {"text": ["Kony Ealy", "Kony Ealy"], "answer_start": [500, 500]}, "prediction_text": "Mario Addison"}
{"answers": {"text": ["Luke Kuechly.", "Luke Kuechly", "Short"], "answer_start": [666, 666, 199]}, "prediction_text": "Mario Addison"}
{"answers": {"text": ["two.", "two", "24"], "answer_start": [284, 1124, 124]}, "prediction_text": "Four"}
{"answers": {"text": ["Gary Kubiak", "Gary Kubiak", "Kubiak"], "answer_start": [291, 291, 332]}, "prediction_text": "Gary Kubiak"}
{"answers": {"text": ["Brock Osweiler", "Brock Osweiler", "Osweiler"], "answer_start": [1157, 1157, 1163]}, "prediction_text": "Brock Osweiler"}
{"answers": {"text": ["Indianapolis Colts", "the Indianapolis Colts", "Colts"], "answer_start": [641, 637, 654]}, "prediction_text": "Indianapolis Colts"}
{"answers": {"text": ["San Diego Chargers", "San Diego Chargers", "Chargers"], "answer_start": [1404, 1404, 1414]}, "prediction_text": "San Diego Chargers"}
{"answers": {"text": ["Wade Phillips", "Wade Phillips", "Phillips"], "answer_start": [1640, 1640, 1645]}, "prediction_text": "Wade Phillips"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [201, 238, 238]}, "prediction_text": "Four years"}
{"answers": {"text": ["Gary Kubiak", "Gary Kubiak", "Kubiak"], "answer_start": [291, 291, 332]}, "prediction_text": "Gary Kubiak"}
{"answers": {"text": ["Indianapolis Colts", "the Indianapolis Colts", "1998"], "answer_start": [641, 637, 663]}, "prediction_text": "Indianapolis Colts"}
{"answers": {"text": ["39", "39", "39"], "answer_start": [817, 817, 817]}, "prediction_text": "39 years old."}
{"answers": {"text": ["plantar fasciitis", "a partial tear of the plantar fasciitis"], "answer_start": [678, 946]}, "prediction_text": "Plantar fasciitis injury"}
{"answers": {"text": ["Gary Kubiak", "Gary Kubiak", "Kubiak"], "answer_start": [291, 291, 332]}, "prediction_text": "Gary Kubiak"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning"], "answer_start": [442, 442, 566]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["a plantar fasciitis injury", "a plantar fasciitis injury", "plantar fasciitis"], "answer_start": [676, 676, 678]}, "prediction_text": "Plantar fasciitis injury"}
{"answers": {"text": ["39", "39", "39"], "answer_start": [817, 817, 817]}, "prediction_text": "39 years old."}
{"answers": {"text": ["four", "4", "4"], "answer_start": [201, 1991, 1991]}, "prediction_text": "7 games"}
{"answers": {"text": ["John Fox", "John Fox", "Fox"], "answer_start": [179, 179, 184]}, "prediction_text": "John Fox"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning"], "answer_start": [442, 442, 566]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["Gary Kubiak", "Gary Kubiak", "Kubiak"], "answer_start": [291, 291, 296]}, "prediction_text": "John Fox"}
{"answers": {"text": ["left foot.", "left", "left"], "answer_start": [993, 993, 993]}, "prediction_text": "The plantar fasciitis injury was on Manning's left foot."}
{"answers": {"text": ["Wade Phillips", "Wade Phillips", "Phillips"], "answer_start": [1640, 1640, 1645]}, "prediction_text": "Wade Phillips"}
{"answers": {"text": ["67.9", "67.9", "67.9"], "answer_start": [44, 44, 44]}, "prediction_text": "67.9"}
{"answers": {"text": ["17", "17", "17"], "answer_start": [115, 115, 115]}, "prediction_text": "17 picks"}
{"answers": {"text": ["Demaryius Thomas", "Demaryius Thomas", "Thomas"], "answer_start": [253, 253, 263]}, "prediction_text": "Ronnie Hillman"}
{"answers": {"text": ["C. J. Anderson", "C. J. Anderson", "Anderson"], "answer_start": [572, 572, 578]}, "prediction_text": "Ronnie Hillman"}
{"answers": {"text": ["10", "10", "10"], "answer_start": [178, 178, 178]}, "prediction_text": "17"}
{"answers": {"text": ["67.9", "67.9", "67.9"], "answer_start": [44, 44, 44]}, "prediction_text": "67.9"}
{"answers": {"text": ["2,249", "2,249", "2,249"], "answer_start": [77, 77, 77]}, "prediction_text": "2,249"}
{"answers": {"text": ["nine", "17", "career-low 67.9 passer rating,"], "answer_start": [93, 115, 33]}, "prediction_text": "17 interceptions"}
{"answers": {"text": ["Demaryius Thomas", "Demaryius Thomas", "Thomas"], "answer_start": [253, 253, 263]}, "prediction_text": "Ronnie Hillman"}
{"answers": {"text": ["receiver", "receiver", "Thomas"], "answer_start": [244, 244, 263]}, "prediction_text": "Receiver"}
{"answers": {"text": ["67.9", "67.9", "67.9"], "answer_start": [44, 44, 44]}, "prediction_text": "67.9"}
{"answers": {"text": ["17", "17", "17"], "answer_start": [115, 115, 115]}, "prediction_text": "17 times"}
{"answers": {"text": ["Demaryius Thomas", "Demaryius Thomas", "Thomas"], "answer_start": [253, 253, 263]}, "prediction_text": "Demaryius Thomas"}
{"answers": {"text": ["5", "five", "five"], "answer_start": [290, 761, 761]}, "prediction_text": "24"}
{"answers": {"text": ["67.9", "67.9", "67.9"], "answer_start": [44, 44, 44]}, "prediction_text": "67.9"}
{"answers": {"text": ["17", "17", "17"], "answer_start": [115, 115, 115]}, "prediction_text": "17"}
{"answers": {"text": ["Emmanuel Sanders", "Emmanuel Sanders", "Sanders"], "answer_start": [345, 345, 354]}, "prediction_text": "Emmanuel Sanders"}
{"answers": {"text": ["C. J. Anderson", "C. J. Anderson", "Anderson"], "answer_start": [572, 572, 578]}, "prediction_text": "Ronnie Hillman"}
{"answers": {"text": ["4.7", "4.7", "4.7"], "answer_start": [799, 799, 799]}, "prediction_text": "4.7"}
{"answers": {"text": ["4,530", "4,530", "4,530"], "answer_start": [60, 60, 60]}, "prediction_text": "4,530"}
{"answers": {"text": ["5\u00bd", "5\u00bd", "5\u00bd"], "answer_start": [198, 198, 198]}, "prediction_text": "5\u00bd"}
{"answers": {"text": ["Brandon Marshall", "Brandon Marshall", "Marshall"], "answer_start": [458, 458, 466]}, "prediction_text": "Linebacker DeMarcus Ware"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [302, 585, 585]}, "prediction_text": "Three picks"}
{"answers": {"text": ["Linebacker", "Linebacker", "Linebacker"], "answer_start": [309, 309, 309]}, "prediction_text": "Linebacker"}
{"answers": {"text": ["Linebacker", "Linebacker", "Linebacker"], "answer_start": [309, 447, 447]}, "prediction_text": "Cornerback"}
{"answers": {"text": ["Defensive ends", "Defensive ends", "Defensive ends"], "answer_start": [144, 144, 144]}, "prediction_text": "Defensive end"}
{"answers": {"text": ["296", "296", "296"], "answer_start": [138, 138, 138]}, "prediction_text": "296 points"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [228, 228, 232]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["Brandon Marshall", "Brandon Marshall", "Marshall"], "answer_start": [458, 458, 466]}, "prediction_text": "DeMarcus Ware"}
{"answers": {"text": ["three.", "three", "three"], "answer_start": [302, 585, 585]}, "prediction_text": "Two"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [228, 228, 232]}, "prediction_text": "Malik Jackson"}
{"answers": {"text": ["Linebacker Brandon Marshall", "Brandon Marshall", "Marshall"], "answer_start": [447, 458, 466]}, "prediction_text": "DeMarcus Ware"}
{"answers": {"text": ["Derek Wolfe and Malik Jackson", "Derek Wolfe and Malik Jackson"], "answer_start": [159, 159]}, "prediction_text": "Derek Wolfe and Malik Jackson"}
{"answers": {"text": ["Seattle Seahawks", "the Seattle Seahawks", "Seahawks"], "answer_start": [22, 18, 30]}, "prediction_text": "Seattle Seahawks"}
{"answers": {"text": ["Arizona Cardinals", "Arizona Cardinals", "Cardinals"], "answer_start": [249, 249, 257]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["487", "487", "487"], "answer_start": [315, 315, 315]}, "prediction_text": "487"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [337, 337, 337]}, "prediction_text": "Seven times"}
{"answers": {"text": ["31\u201324", "31\u201324", "31\u201324"], "answer_start": [163, 163, 163]}, "prediction_text": "31\u201324 Panthers"}
{"answers": {"text": ["Seattle Seahawks", "the Seattle Seahawks", "Seahawks"], "answer_start": [22, 18, 30]}, "prediction_text": "Arizona Cardinals"}
{"answers": {"text": ["31\u201324", "31\u201324", "31\u201324,"], "answer_start": [163, 163, 163]}, "prediction_text": "49\u201315"}
{"answers": {"text": ["487", "487", "487"], "answer_start": [315, 315, 315]}, "prediction_text": "487"}
{"answers": {"text": ["Seattle Seahawks", "the Seattle Seahawks", "Seahawks"], "answer_start": [22, 18, 30]}, "prediction_text": "Seattle Seahawks"}
{"answers": {"text": ["Arizona Cardinals", "the Arizona Cardinals", "Cardinals"], "answer_start": [249, 245, 257]}, "prediction_text": "Seattle Seahawks"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [337, 337, 337]}, "prediction_text": "Seven turnovers"}
{"answers": {"text": ["Seattle Seahawks", "the Seattle Seahawks", "Seahawks"], "answer_start": [22, 18, 30]}, "prediction_text": "Seattle Seahawks"}
{"answers": {"text": ["49\u201315", "49\u201315", "49\u201315,"], "answer_start": [297, 297, 297]}, "prediction_text": "49\u201315"}
{"answers": {"text": ["Arizona Cardinals", "the Seattle Seahawks", "Cardinals"], "answer_start": [249, 18, 257]}, "prediction_text": "Seattle Seahawks"}
{"answers": {"text": ["487", "487"], "answer_start": [315, 315]}, "prediction_text": "487"}
{"answers": {"text": ["Pittsburgh Steelers", "the Pittsburgh Steelers", "Steelers"], "answer_start": [25, 21, 36]}, "prediction_text": "Pittsburgh Steelers"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [88, 88, 88]}, "prediction_text": "11 points"}
{"answers": {"text": ["New England Patriots", "New England Patriots", "Patriots"], "answer_start": [192, 192, 204]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["20\u201318", "20\u201318", "20\u201318,"], "answer_start": [243, 243, 243]}, "prediction_text": "20\u201318"}
{"answers": {"text": ["17 seconds", "17 seconds", "17"], "answer_start": [322, 322, 322]}, "prediction_text": "17 seconds"}
{"answers": {"text": ["Broncos", "The Broncos", "Broncos"], "answer_start": [4, 0, 4]}, "prediction_text": "Pittsburgh Steelers"}
{"answers": {"text": ["23\u201316", "23\u201316", ", 23\u201316,"], "answer_start": [70, 70, 68]}, "prediction_text": "11 points"}
{"answers": {"text": ["New England Patriots", "New England Patriots", "Patriots"], "answer_start": [192, 192, 204]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["17", "17 seconds", "17"], "answer_start": [322, 322, 322]}, "prediction_text": "17 seconds"}
{"answers": {"text": ["Manning", "Manning"], "answer_start": [360, 360]}, "prediction_text": "Manning"}
{"answers": {"text": ["Pittsburgh Steelers", "the Pittsburgh Steelers", "Steelers"], "answer_start": [25, 21, 36]}, "prediction_text": "Pittsburgh Steelers"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [88, 88, 88]}, "prediction_text": "11 points"}
{"answers": {"text": ["New England Patriots", "New England Patriots", "Patriots"], "answer_start": [192, 192, 204]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["Pittsburgh Steelers", "Pittsburgh Steelers", "Steelers"], "answer_start": [25, 25, 36]}, "prediction_text": "Pittsburgh Steelers"}
{"answers": {"text": ["New England Patriots", "New England Patriots", "Patriots"], "answer_start": [192, 192, 204]}, "prediction_text": "New England Patriots"}
{"answers": {"text": ["17", "17", "17"], "answer_start": [322, 322, 322]}, "prediction_text": "17 seconds"}
{"answers": {"text": ["Thomas Davis", "Thomas Davis,", "Davis"], "answer_start": [39, 39, 46]}, "prediction_text": "Thomas Davis"}
{"answers": {"text": ["a broken arm", "a broken arm", "broken arm"], "answer_start": [143, 143, 145]}, "prediction_text": "Broken arm"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [97, 97, 97]}, "prediction_text": "Three times"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [56, 56, 56]}, "prediction_text": "11 years"}
{"answers": {"text": ["ACL tears", "ACL tears", "ACL"], "answer_start": [103, 103, 103]}, "prediction_text": "ACL tears"}
{"answers": {"text": ["arm", "arm", "arm"], "answer_start": [152, 152, 152]}, "prediction_text": "Arm"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [56, 56, 56]}, "prediction_text": "11 years"}
{"answers": {"text": ["Super Bowl", "the Super Bowl", "Super Bowl"], "answer_start": [253, 249, 253]}, "prediction_text": "Super Bowl"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [97, 97, 97]}, "prediction_text": "Three ACL tears"}
{"answers": {"text": ["broken arm", "a broken arm", "broken arm"], "answer_start": [145, 143, 145]}, "prediction_text": "Broken arm"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [56, 56, 56]}, "prediction_text": "11 years"}
{"answers": {"text": ["Thomas Davis", "Thomas Davis", "Davis"], "answer_start": [39, 39, 46]}, "prediction_text": "Thomas Davis"}
{"answers": {"text": ["39", "39", "39", "39"], "answer_start": [172, 172, 172, 172]}, "prediction_text": "Age 39"}
{"answers": {"text": ["John Elway", "John Elway", "Elway", "Elway"], "answer_start": [204, 204, 209, 209]}, "prediction_text": "John Elway"}
{"answers": {"text": ["38", "38", "38", "38"], "answer_start": [275, 275, 275, 275]}, "prediction_text": "38 years old"}
{"answers": {"text": ["Executive Vice President of Football Operations and General Manager", "Executive Vice President of Football Operations and General Manager", "Executive Vice President of Football Operations and General Manager.", "Executive Vice President of Football Operations and General Manager."], "answer_start": [304, 304, 304, 304]}, "prediction_text": "Executive Vice President of Football Operations and General Manager"}
{"answers": {"text": ["Broncos", "the Broncos", "Broncos", "Broncos"], "answer_start": [228, 224, 228, 228]}, "prediction_text": "Broncos"}
{"answers": {"text": ["Broncos", "the Broncos", "Broncos", "Broncos"], "answer_start": [228, 224, 228, 228]}, "prediction_text": "Denver Broncos"}
{"answers": {"text": ["John Elway", "John Elway", "Elway", "Elway"], "answer_start": [204, 204, 209, 209]}, "prediction_text": "John Elway"}
{"answers": {"text": ["38", "38", "38", "38"], "answer_start": [275, 275, 275, 275]}, "prediction_text": "38 years old"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning", "Manning"], "answer_start": [0, 0, 7, 7]}, "prediction_text": "John Elway"}
{"answers": {"text": ["two", "two", "two", "two"], "answer_start": [57, 57, 57, 57]}, "prediction_text": "Two teams"}
{"answers": {"text": ["two", "two", "two", "two"], "answer_start": [57, 57, 57, 57]}, "prediction_text": "Two teams"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning", "Manning"], "answer_start": [0, 0, 7, 7]}, "prediction_text": "John Elway"}
{"answers": {"text": ["John Elway", "John Elway", "Elway", "Elway"], "answer_start": [204, 204, 209, 209]}, "prediction_text": "John Elway"}
{"answers": {"text": ["Super Bowl XXXIII", "Super Bowl XXXIII", "XXXIII", "XXXIII"], "answer_start": [250, 250, 261, 261]}, "prediction_text": "Super Bowl XXXIII"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning", "Manning"], "answer_start": [0, 0, 7, 7]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["39.", "39", "39", "39"], "answer_start": [172, 172, 172, 172]}, "prediction_text": "Age 39"}
{"answers": {"text": ["John Elway", "John Elway", "Elway", "Elway"], "answer_start": [204, 204, 209, 209]}, "prediction_text": "John Elway"}
{"answers": {"text": ["1998", "1998", "1998"], "answer_start": [149, 149, 149]}, "prediction_text": "1998"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [198, 198, 198]}, "prediction_text": "2011"}
{"answers": {"text": ["26", "26", "26"], "answer_start": [492, 492, 492]}, "prediction_text": "26 years old"}
{"answers": {"text": ["13 years and 48 days", "13 years and 48 days", "13 years"], "answer_start": [443, 443, 443]}, "prediction_text": "Newton was 26 years old."}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [306, 306, 310]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["Manning", "Manning", "Manning"], "answer_start": [113, 113, 113]}, "prediction_text": "Manning"}
{"answers": {"text": ["Newton", "Newton", "Newton"], "answer_start": [171, 171, 171]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["26", "26", "26"], "answer_start": [492, 492, 492]}, "prediction_text": "26 years old"}
{"answers": {"text": ["quarterback", "quarterbacks", "quarterback"], "answer_start": [43, 427, 43]}, "prediction_text": "Quarterback"}
{"answers": {"text": ["1998", "1998", "1998"], "answer_start": [149, 149, 149]}, "prediction_text": "1998 NFL draft"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [198, 198, 198]}, "prediction_text": "2011"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [306, 306, 310]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["2011.", "2011", "2011"], "answer_start": [198, 198, 198]}, "prediction_text": "2011"}
{"answers": {"text": ["26", "26", "26"], "answer_start": [492, 492, 492]}, "prediction_text": "26 years old"}
{"answers": {"text": ["13 years and 48 days", "13 years and 48 days", "13 years and 48 days"], "answer_start": [443, 443, 443]}, "prediction_text": "26 years and 48 days"}
{"answers": {"text": ["Super Bowl XX", "Super Bowl XX", "XX"], "answer_start": [63, 63, 74]}, "prediction_text": "Super Bowl XXI"}
{"answers": {"text": ["Chicago Bears", "the Chicago Bears", "Bears"], "answer_start": [46, 42, 54]}, "prediction_text": "Chicago Bears"}
{"answers": {"text": ["linebacker", "linebacker", "linebacker"], "answer_start": [26, 26, 26]}, "prediction_text": "linebacker"}
{"answers": {"text": ["Elway", "Elway", "Elway"], "answer_start": [99, 99, 99]}, "prediction_text": "Elway"}
{"answers": {"text": ["Broncos", "the Broncos", "Broncos"], "answer_start": [123, 119, 123]}, "prediction_text": "Chicago Bears"}
{"answers": {"text": ["linebacker", "linebacker", "linebacker"], "answer_start": [26, 26, 26]}, "prediction_text": "linebacker"}
{"answers": {"text": ["Elway", "Elway", "Elway"], "answer_start": [99, 99, 99]}, "prediction_text": "Elway"}
{"answers": {"text": ["Rivera", "Rivera", "Rivera"], "answer_start": [5, 5, 5]}, "prediction_text": "Mike Rivera"}
{"answers": {"text": ["Super Bowl XX", "Super Bowl XX", "XX"], "answer_start": [63, 63, 74]}, "prediction_text": "Super Bowl XXI"}
{"answers": {"text": ["Justin Tucker", "Justin Tucker", "Tucker"], "answer_start": [320, 320, 327]}, "prediction_text": "Justin Tucker"}
{"answers": {"text": ["Bermuda 419", "Bermuda 419", "hybrid Bermuda 419"], "answer_start": [569, 569, 562]}, "prediction_text": "Bermuda 419 turf"}
{"answers": {"text": ["Ed Mangan", "Ed Mangan", "Mangan"], "answer_start": [625, 625, 628]}, "prediction_text": "Ed Mangan"}
{"answers": {"text": ["Baltimore Ravens", "Baltimore Ravens", "Ravens"], "answer_start": [296, 296, 306]}, "prediction_text": "Baltimore Ravens"}
{"answers": {"text": ["kicker", "kicker", "kicker"], "answer_start": [313, 313, 313]}, "prediction_text": "Kicker"}
{"answers": {"text": ["Justin Tucker", "Justin Tucker", "Tucker"], "answer_start": [320, 320, 327]}, "prediction_text": "Justin Tucker"}
{"answers": {"text": ["kicker", "kicker", "kicker"], "answer_start": [313, 313, 313]}, "prediction_text": "Kicker"}
{"answers": {"text": ["hybrid Bermuda 419 turf", "Bermuda 419 turf", "hybrid Bermuda 419"], "answer_start": [562, 569, 562]}, "prediction_text": "Bermuda 419 turf"}
{"answers": {"text": ["Justin Tucker", "Justin Tucker", "Tucker"], "answer_start": [320, 320, 327]}, "prediction_text": "Justin Tucker"}
{"answers": {"text": ["a new playing surface", "re-sodded", "re-sodded"], "answer_start": [537, 512, 157]}, "prediction_text": "Re-sodded the field with a new playing surface."}
{"answers": {"text": ["a hybrid Bermuda 419 turf.", "Bermuda 419 turf", "hybrid Bermuda 419 turf"], "answer_start": [560, 569, 562]}, "prediction_text": "Bermuda 419 turf"}
{"answers": {"text": ["their cleats", "cleats", "cleats"], "answer_start": [788, 794, 794]}, "prediction_text": "Cleats"}
{"answers": {"text": ["Justin Tucker", "Tucker"], "answer_start": [320, 327]}, "prediction_text": "Justin Tucker"}
{"answers": {"text": ["natural grass", "natural grass", "grass"], "answer_start": [480, 480, 488]}, "prediction_text": "Natural grass"}
{"answers": {"text": ["Broncos", "the Broncos", "Broncos"], "answer_start": [82, 78, 82]}, "prediction_text": "The Broncos"}
{"answers": {"text": ["34\u201319", "34\u201319", "34\u201319"], "answer_start": [392, 392, 392]}, "prediction_text": "34\u201319"}
{"answers": {"text": ["Atlanta Falcons", "the Atlanta Falcons", "Falcons"], "answer_start": [376, 372, 384]}, "prediction_text": "Atlanta Falcons"}
{"answers": {"text": ["white", "white", "white"], "answer_start": [117, 145, 145]}, "prediction_text": "White pants"}
{"answers": {"text": ["Super Bowl XXXIII", "Super Bowl XXXIII", "Super Bowl XXXIII"], "answer_start": [302, 302, 302]}, "prediction_text": "Super Bowl XXXIII"}
{"answers": {"text": ["Super Bowl XXXIII", "Super Bowl XXXIII", "Super Bowl XXXIII"], "answer_start": [302, 302, 302]}, "prediction_text": "Super Bowl XXXIII"}
{"answers": {"text": ["34\u201319", "34\u201319", "34\u201319"], "answer_start": [392, 392, 392]}, "prediction_text": "Atlanta Falcons 34\u201319."}
{"answers": {"text": ["Atlanta Falcons", "the Atlanta Falcons", "Falcons"], "answer_start": [376, 372, 384]}, "prediction_text": "Atlanta Falcons"}
{"answers": {"text": ["white", "matching white jerseys", "white"], "answer_start": [117, 248, 209]}, "prediction_text": "White"}
{"answers": {"text": ["road white jerseys", "matching white", "white"], "answer_start": [112, 136, 117]}, "prediction_text": "White jersey"}
{"answers": {"text": ["Pittsburgh Steelers", "the Pittsburgh Steelers", "Steelers"], "answer_start": [801, 797, 812]}, "prediction_text": "Pittsburgh Steelers"}
{"answers": {"text": ["Super Bowl XXXIII", "Super Bowl XXXIII", "XXXIII"], "answer_start": [302, 302, 313]}, "prediction_text": "Super Bowl XXXIII"}
{"answers": {"text": ["blue", "blue", "white"], "answer_start": [467, 467, 209]}, "prediction_text": "Blue"}
{"answers": {"text": ["orange", "orange", "orange"], "answer_start": [629, 629, 629]}, "prediction_text": "Orange jersey"}
{"answers": {"text": ["black jerseys with silver pants.", "black jerseys with silver pants", "black"], "answer_start": [993, 993, 993]}, "prediction_text": "Black jerseys with silver pants."}
{"answers": {"text": ["San Jose State", "San Jose State", "San Jose State"], "answer_start": [22, 22, 22]}, "prediction_text": "Stanford University"}
{"answers": {"text": ["Stanford University", "Stanford University", "Stanford"], "answer_start": [117, 117, 117]}, "prediction_text": "Stanford University"}
{"answers": {"text": ["San Jose", "San Jose", "San Jose"], "answer_start": [22, 73, 73]}, "prediction_text": "Santa Clara"}
{"answers": {"text": ["Santa Clara", "Santa Clara", "Santa Clara"], "answer_start": [155, 155, 155]}, "prediction_text": "Santa Clara"}
{"answers": {"text": ["San Jose Marriott", "the San Jose Marriott", "San Jose State practice facility and stayed at the San Jose Marriott."], "answer_start": [73, 69, 22]}, "prediction_text": "Santa Clara Marriott"}
{"answers": {"text": ["Santa Clara Marriott", "the San Jose Marriott", "Marriott"], "answer_start": [155, 69, 82]}, "prediction_text": "Santa Clara Marriott"}
{"answers": {"text": ["San Jose State practice facility", "the San Jose State practice facility", "San Jose State"], "answer_start": [22, 18, 22]}, "prediction_text": "San Jose State practice facility"}
{"answers": {"text": ["Stanford University", "at Stanford University", "Stanford"], "answer_start": [117, 114, 117]}, "prediction_text": "Stanford University"}
{"answers": {"text": ["San Jose State practice facility", "the San Jose State practice facility", "San Jose State"], "answer_start": [22, 18, 22]}, "prediction_text": "San Jose State practice facility"}
{"answers": {"text": ["San Jose Marriott.", "the San Jose Marriott", "San Jose Marriott"], "answer_start": [73, 69, 73]}, "prediction_text": "Santa Clara Marriott"}
{"answers": {"text": ["Stanford University", "at Stanford University", "Stanford"], "answer_start": [117, 114, 117]}, "prediction_text": "Stanford University"}
{"answers": {"text": ["Santa Clara Marriott.", "the Santa Clara Marriott", "Santa Clara Marriott."], "answer_start": [155, 151, 155]}, "prediction_text": "Santa Clara Marriott"}
{"answers": {"text": ["San Jose", "the San Jose State practice facility", "San Jose State"], "answer_start": [22, 18, 22]}, "prediction_text": "San Jose State practice facility"}
{"answers": {"text": ["San Jose Marriott.", "the San Jose Marriott", "San Jose Marriott."], "answer_start": [73, 69, 73]}, "prediction_text": "San Jose Marriott"}
{"answers": {"text": ["Stanford University", "at Stanford University", "Stanford"], "answer_start": [117, 114, 117]}, "prediction_text": "Stanford University"}
{"answers": {"text": ["Santa Clara Marriott.", "the Santa Clara Marriott", "Santa Clara Marriott."], "answer_start": [155, 151, 155]}, "prediction_text": "Santa Clara Marriott"}
{"answers": {"text": ["June 4, 2014", "On June 4, 2014", "2014"], "answer_start": [3, 0, 11]}, "prediction_text": "June 4, 2014"}
{"answers": {"text": ["Super Bowl V", "Super Bowl V", "V"], "answer_start": [129, 129, 140]}, "prediction_text": "Super Bowl V"}
{"answers": {"text": ["Jaime Weston", "Jaime Weston", "Weston"], "answer_start": [339, 339, 345]}, "prediction_text": "Jaime Weston"}
{"answers": {"text": ["Super Bowl XLV", "Super Bowl XLV", "V"], "answer_start": [585, 585, 140]}, "prediction_text": "Super Bowl XLV"}
{"answers": {"text": ["Vince Lombardi", "Vince Lombardi Trophy", "Lombardi"], "answer_start": [699, 699, 705]}, "prediction_text": "Vince Lombardi Trophy"}
{"answers": {"text": ["2014", "2014", "2014"], "answer_start": [11, 11, 11]}, "prediction_text": "2014"}
{"answers": {"text": ["Super Bowl LI", "LI", "LI"], "answer_start": [324, 335, 335]}, "prediction_text": "Super Bowl LI"}
{"answers": {"text": ["L", "L", "L"], "answer_start": [23, 272, 272]}, "prediction_text": "Super Bowl L"}
{"answers": {"text": ["gold", "gold", "gold"], "answer_start": [682, 682, 682]}, "prediction_text": "Gold"}
{"answers": {"text": ["June 4, 2014", "On June 4, 2014", "2014"], "answer_start": [3, 0, 11]}, "prediction_text": "June 4, 2014"}
{"answers": {"text": ["Arabic numerals", "Arabic numerals", "Arabic"], "answer_start": [214, 214, 214]}, "prediction_text": "Arabic numerals"}
{"answers": {"text": ["L.", "L", "L"], "answer_start": [272, 272, 272]}, "prediction_text": "Super Bowl"}
{"answers": {"text": ["gold", "gold", "gold"], "answer_start": [682, 682, 682]}, "prediction_text": "Silver"}
{"answers": {"text": ["Super Bowl LI.", "Super Bowl LI", "Super Bowl LI"], "answer_start": [324, 324, 324]}, "prediction_text": "June 4, 2014"}
{"answers": {"text": ["Arabic", "Arabic numerals", "Arabic"], "answer_start": [214, 214, 214]}, "prediction_text": "Roman numerals"}
{"answers": {"text": ["LI.", "LI", "LI"], "answer_start": [335, 335, 335]}, "prediction_text": "Roman numerals"}
{"answers": {"text": ["gold", "gold", "gold"], "answer_start": [8, 8, 267]}, "prediction_text": "Gold"}
{"answers": {"text": ["week 7", "2015", "week 7,"], "answer_start": [290, 72, 290]}, "prediction_text": "Week 7"}
{"answers": {"text": ["50", "50-yard line", "50"], "answer_start": [232, 232, 232]}, "prediction_text": "50-yard line"}
{"answers": {"text": ["gold", "gold", "gold"], "answer_start": [8, 8, 267]}, "prediction_text": "Gold"}
{"answers": {"text": ["gold", "gold", "Gold"], "answer_start": [8, 8, 357]}, "prediction_text": "Gold"}
{"answers": {"text": ["Golden Super Bowl", "the \"Golden Super Bowl\"", "Golden Super Bowl"], "answer_start": [105, 100, 105]}, "prediction_text": "\"Golden Super Bowl\""}
{"answers": {"text": ["Gold footballs", "Gold footballs", "Gold footballs"], "answer_start": [357, 357, 357]}, "prediction_text": "Gold footballs"}
{"answers": {"text": ["the 50-yard line", "the 50", "50"], "answer_start": [228, 228, 232]}, "prediction_text": "50-yard line"}
{"answers": {"text": ["gold", "gold", "gold"], "answer_start": [8, 8, 8]}, "prediction_text": "Gold"}
{"answers": {"text": ["Moscone Center", "the Moscone Center", "Moscone Center"], "answer_start": [42, 38, 42]}, "prediction_text": "Moscone Center"}
{"answers": {"text": ["San Francisco", "San Francisco", "San Francisco"], "answer_start": [60, 60, 60]}, "prediction_text": "San Francisco"}
{"answers": {"text": ["Ed Lee", "Ed Lee", "Lee"], "answer_start": [419, 419, 422]}, "prediction_text": "Jane Kim"}
{"answers": {"text": ["Jane Kim", "Jane Kim", "Kim"], "answer_start": [549, 549, 554]}, "prediction_text": "Jane Kim"}
{"answers": {"text": ["January 30", "January 30", "January 30"], "answer_start": [116, 116, 116]}, "prediction_text": "January 30, 2019"}
{"answers": {"text": ["1 million", "More than 1 million", "1 million"], "answer_start": [302, 292, 302]}, "prediction_text": "Over 1 million"}
{"answers": {"text": ["Ed Lee", "Ed Lee", "Lee"], "answer_start": [419, 419, 422]}, "prediction_text": "Jane Kim"}
{"answers": {"text": ["Moscone Center", "the Moscone Center", "Moscone Center"], "answer_start": [42, 38, 42]}, "prediction_text": "Moscone Center"}
{"answers": {"text": ["Super Bowl City", "Super Bowl City", "Super Bowl City"], "answer_start": [89, 89, 89]}, "prediction_text": "\"Super Bowl City\""}
{"answers": {"text": ["Moscone Center", "at the Moscone Center", "Moscone Center"], "answer_start": [42, 35, 42]}, "prediction_text": "Moscone Center in San Francisco"}
{"answers": {"text": ["Super Bowl City", "Super Bowl City\" opened", "\"Super Bowl City"], "answer_start": [89, 89, 88]}, "prediction_text": "Super Bowl City"}
{"answers": {"text": ["Ed Lee", "Ed Lee", "Lee"], "answer_start": [419, 419, 422]}, "prediction_text": "Jane Kim"}
{"answers": {"text": ["Super Bowl City", "\"Super Bowl City\"", "Super Bowl City"], "answer_start": [89, 88, 89]}, "prediction_text": "Super Bowl City"}
{"answers": {"text": ["More than 1 million", "More than 1 million", "1 million"], "answer_start": [292, 292, 302]}, "prediction_text": "Over 1 million"}
{"answers": {"text": ["mayor Ed Lee", "Ed Lee", "mayor Ed Lee"], "answer_start": [413, 419, 413]}, "prediction_text": "San Francisco mayor Ed Lee"}
{"answers": {"text": ["$5 million.", "0", "$5 million"], "answer_start": [655, 125, 655]}, "prediction_text": "$5 million"}
{"answers": {"text": ["The annual NFL Experience", "The annual NFL Experience", "NFL Experience"], "answer_start": [0, 0, 11]}, "prediction_text": "NFL Experience"}
{"answers": {"text": ["Santa Clara University", "Santa Clara University", "Santa Clara University"], "answer_start": [184, 184, 184]}, "prediction_text": "Santa Clara University"}
{"answers": {"text": ["$2 million", "$2 million", "$2 million"], "answer_start": [23, 23, 23]}, "prediction_text": "$2 million"}
{"answers": {"text": ["a week", "a week", "week"], "answer_start": [77, 77, 79]}, "prediction_text": "Week-long event"}
{"answers": {"text": ["$2 million", "$2 million", "$2 million"], "answer_start": [23, 23, 23]}, "prediction_text": "$2 million"}
{"answers": {"text": ["pep rally", "pep", "pep"], "answer_start": [214, 214, 214]}, "prediction_text": "Pep rally"}
{"answers": {"text": ["city council", "the city council", "city council"], "answer_start": [335, 411, 415]}, "prediction_text": "Santa Clara University"}
{"answers": {"text": ["Bellomy Field", "Bellomy Field", "Santa Clara Convention Center"], "answer_start": [167, 167, 102]}, "prediction_text": "Santa Clara University"}
{"answers": {"text": ["A professional fundraiser", "A professional fundraiser", "professional fundraiser"], "answer_start": [225, 225, 227]}, "prediction_text": "City council"}
{"answers": {"text": ["city council", "the city council", "city council"], "answer_start": [335, 411, 415]}, "prediction_text": "The city council"}
{"answers": {"text": ["$2 million", "$2 million", "$2 million"], "answer_start": [23, 23, 23]}, "prediction_text": "$2 million"}
{"answers": {"text": ["city council", "the city council", "city council"], "answer_start": [335, 411, 335]}, "prediction_text": "City council"}
{"answers": {"text": ["Monday", "February 1, 2016", "Monday"], "answer_start": [108, 189, 108]}, "prediction_text": "Monday evening"}
{"answers": {"text": ["Tuesday", "Tuesday afternoon prior to the game", "Tuesday"], "answer_start": [54, 54, 54]}, "prediction_text": "Monday evening"}
{"answers": {"text": ["SAP Center", "SAP Center", "SAP Center"], "answer_start": [209, 209, 209]}, "prediction_text": "SAP Center"}
{"answers": {"text": ["San Jose", "San Jose", "San Jose."], "answer_start": [223, 223, 223]}, "prediction_text": "San Jose"}
{"answers": {"text": ["the Golden Gate Bridge", "the Golden Gate Bridge", "Golden Gate Bridge."], "answer_start": [362, 362, 366]}, "prediction_text": "Golden Gate Bridge"}
{"answers": {"text": ["Tuesday", "Tuesday afternoon prior to the game", "Tuesday"], "answer_start": [54, 54, 54]}, "prediction_text": "Tuesday"}
{"answers": {"text": ["Monday", "Monday", "Monday"], "answer_start": [108, 108, 108]}, "prediction_text": "Monday"}
{"answers": {"text": ["Super Bowl Opening Night", "Super Bowl Opening Night", "Super Bowl Opening Night."], "answer_start": [141, 141, 141]}, "prediction_text": "Opening Night"}
{"answers": {"text": ["SAP Center", "SAP Center", "SAP Center"], "answer_start": [209, 209, 209]}, "prediction_text": "SAP Center"}
{"answers": {"text": ["San Jose", "San Jose", "San Jose."], "answer_start": [223, 223, 223]}, "prediction_text": "San Jose"}
{"answers": {"text": ["the Tuesday afternoon prior to the game", "Tuesday afternoon prior to the game", "Tuesday"], "answer_start": [50, 54, 54]}, "prediction_text": "Monday evening"}
{"answers": {"text": ["Super Bowl Opening Night.", "Super Bowl Opening Night", "Super Bowl Opening Night."], "answer_start": [141, 141, 141]}, "prediction_text": "Super Bowl Opening Night"}
{"answers": {"text": ["SAP Center in San Jose.", "at SAP Center in San Jose", "San Jose"], "answer_start": [209, 206, 223]}, "prediction_text": "SAP Center in San Jose"}
{"answers": {"text": ["the Golden Gate Bridge.", "the Golden Gate Bridge", "Golden Gate Bridge."], "answer_start": [362, 362, 366]}, "prediction_text": "Golden Gate Bridge replica"}
{"answers": {"text": ["Monday", "Monday", "Monday"], "answer_start": [108, 108, 108]}, "prediction_text": "Monday evening"}
{"answers": {"text": ["Super Bowl Opening Night.", "Super Bowl Opening Night", "Super Bowl Opening Night"], "answer_start": [141, 141, 141]}, "prediction_text": "Opening night"}
{"answers": {"text": ["SAP Center in San Jose.", "SAP Center", "SAP Center"], "answer_start": [209, 209, 209]}, "prediction_text": "SAP Center in San Jose"}
{"answers": {"text": ["Golden Gate Bridge.", "the Golden Gate", "Golden Gate Bridge."], "answer_start": [366, 362, 366]}, "prediction_text": "Golden Gate Bridge"}
{"answers": {"text": ["February 1, 2016", "February 1, 2016", "February 1, 2016"], "answer_start": [189, 189, 189]}, "prediction_text": "February 1, 2016"}
{"answers": {"text": ["Business Connect", "Business Connect", "Business Connect"], "answer_start": [164, 164, 164]}, "prediction_text": "Business Connect"}
{"answers": {"text": ["$40 million", "over $40 million", "$40 million"], "answer_start": [339, 334, 339]}, "prediction_text": "Over $40 million"}
{"answers": {"text": ["Dignity Health", "Dignity Health", "Dignity"], "answer_start": [426, 426, 426]}, "prediction_text": "Dignity Health"}
{"answers": {"text": ["Gap", "Gap", "Gap"], "answer_start": [408, 408, 408]}, "prediction_text": "Apple"}
{"answers": {"text": ["Chevron", "Chevron", "Chevron"], "answer_start": [413, 413, 413]}, "prediction_text": "Chevron"}
{"answers": {"text": ["Super Bowl 50 Host Committee", "the Super Bowl 50 Host Committee", "Super Bowl 50 Host Committee"], "answer_start": [24, 20, 24]}, "prediction_text": "Super Bowl Host Committee"}
{"answers": {"text": ["over $40 million", "over $40 million", "over $40 million"], "answer_start": [334, 334, 334]}, "prediction_text": "Over $40 million"}
{"answers": {"text": ["sponsors", "through sponsors", "sponsors"], "answer_start": [359, 351, 359]}, "prediction_text": "Through sponsors"}
{"answers": {"text": ["Business Connect", "Business Connect", "Business Connect"], "answer_start": [164, 164, 164]}, "prediction_text": "Business Connect"}
{"answers": {"text": ["Business Connect", "Business Connect", "Business Connect"], "answer_start": [164, 164, 164]}, "prediction_text": "Business Connect"}
{"answers": {"text": ["over $40 million", "over $40 million", "$40 million"], "answer_start": [334, 334, 339]}, "prediction_text": "Over $40 million"}
{"answers": {"text": ["25", "25 percent", "25"], "answer_start": [102, 102, 102]}, "prediction_text": "25 percent"}
{"answers": {"text": ["the 50 fund", "the 50 fund", "50 fund"], "answer_start": [200, 200, 204]}, "prediction_text": "50 fund"}
{"answers": {"text": ["25 percent", "25 percent", "25"], "answer_start": [102, 102, 102]}, "prediction_text": "25 percent"}
{"answers": {"text": ["50 fund", "the 50 fund", "50 fund"], "answer_start": [204, 200, 204]}, "prediction_text": "50 fund"}
{"answers": {"text": ["the most giving Super Bowl ever", "giving Super Bowl", "giving"], "answer_start": [50, 59, 59]}, "prediction_text": "Giving Super Bowl ever"}
{"answers": {"text": ["25 percent", "25 percent of all money", "25"], "answer_start": [102, 102, 102]}, "prediction_text": "25 percent"}
{"answers": {"text": ["the 50 fund", "the 50 fund", "50 fund"], "answer_start": [200, 200, 204]}, "prediction_text": "50 fund"}
{"answers": {"text": ["25 percent", "25 percent", "25"], "answer_start": [102, 102, 102]}, "prediction_text": "25 percent"}
{"answers": {"text": ["50 fund", "the 50 fund", "50 fund"], "answer_start": [204, 200, 204]}, "prediction_text": "50 fund"}
{"answers": {"text": ["Vince Lombardi", "Vince Lombardi", "Lombardi"], "answer_start": [19, 19, 25]}, "prediction_text": "Vince Lombardi"}
{"answers": {"text": ["18", "18", "18"], "answer_start": [135, 135, 135]}, "prediction_text": "18 karats"}
{"answers": {"text": ["66", "66 lb", "33"], "answer_start": [213, 213, 184]}, "prediction_text": "33 lb (15 kg)"}
{"answers": {"text": ["Tiffany & Co.", "Tiffany & Co", "Tiffany & Co."], "answer_start": [283, 283, 283]}, "prediction_text": "Tiffany & Co."}
{"answers": {"text": ["Tiffany & Co.", "Tiffany & Co", "Tiffany & Co"], "answer_start": [283, 283, 283]}, "prediction_text": "Tiffany & Co."}
{"answers": {"text": ["Vince Lombardi Trophy", "the Vince Lombardi Trophy", "Vince Lombardi Trophy"], "answer_start": [19, 15, 19]}, "prediction_text": "Vince Lombardi Trophy"}
{"answers": {"text": ["18-karat gold-plated", "18-karat gold", "gold"], "answer_start": [135, 135, 144]}, "prediction_text": "Gold"}
{"answers": {"text": ["Tiffany & Co", "Tiffany & Co", "Tiffany & Co"], "answer_start": [283, 283, 283]}, "prediction_text": "Tiffany & Co."}
{"answers": {"text": ["the Vince Lombardi Trophy", "the Vince Lombardi Trophy", "Vince Lombardi Trophy"], "answer_start": [15, 15, 19]}, "prediction_text": "Vince Lombardi Trophy"}
{"answers": {"text": ["Tiffany & Co.", "Tiffany & Co", "Tiffany & Co."], "answer_start": [283, 283, 283]}, "prediction_text": "Tiffany & Co."}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [48, 48, 48]}, "prediction_text": "CBS"}
{"answers": {"text": ["Phil Simms", "Phil Simms", "Phil Simms"], "answer_start": [188, 188, 188]}, "prediction_text": "Phil Simms"}
{"answers": {"text": ["Tracy Wolfson", "Tracy Wolfson", "Tracy Wolfson"], "answer_start": [224, 224, 224]}, "prediction_text": "Tracy Wolfson"}
{"answers": {"text": ["36", "36", "36"], "answer_start": [384, 400, 400]}, "prediction_text": "36 cameras"}
{"answers": {"text": ["5K", "5K", "5K"], "answer_start": [629, 629, 629]}, "prediction_text": "5K resolution"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [84, 84, 84]}, "prediction_text": "CBS, NBC, and Fox"}
{"answers": {"text": ["sidelines", "the sidelines", "sidelines"], "answer_start": [263, 259, 263]}, "prediction_text": "On the sidelines"}
{"answers": {"text": ["360-degree", "360", "360"], "answer_start": [462, 384, 462]}, "prediction_text": "360-degree view"}
{"answers": {"text": ["5K resolution", "5K", "5K"], "answer_start": [629, 629, 629]}, "prediction_text": "5K resolution"}
{"answers": {"text": ["sidelines", "the sidelines", "sidelines"], "answer_start": [263, 259, 263]}, "prediction_text": "On the sidelines"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [48, 48, 48]}, "prediction_text": "CBS"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [84, 84, 84]}, "prediction_text": "Three main broadcast partners"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [48, 48, 48]}, "prediction_text": "CBS"}
{"answers": {"text": ["Jim Nantz and Phil Simms", "Jim Nantz and Phil Simms", "Jim Nantz and Phil Simms"], "answer_start": [174, 174, 174]}, "prediction_text": "Phil Simms and Jim Nantz"}
{"answers": {"text": ["Tracy Wolfson and Evan Washburn", "Tracy Wolfson and Evan Washburn", "Tracy Wolfson and Evan Washburn"], "answer_start": [224, 224, 224]}, "prediction_text": "Jim Nantz and Phil Simms"}
{"answers": {"text": ["5K", "5K", "5K"], "answer_start": [629, 629, 629]}, "prediction_text": "5K resolution"}
{"answers": {"text": ["cameras", "cameras", "cameras"], "answer_start": [339, 339, 339]}, "prediction_text": "New features"}
{"answers": {"text": ["ESPN Deportes", "ESPN Deportes", "ESPN Deportes"], "answer_start": [22, 22, 22]}, "prediction_text": "CBS"}
{"answers": {"text": ["John Sutcliffe", "John Sutcliffe", "Sutcliffe"], "answer_start": [617, 617, 622]}, "prediction_text": "John Sutcliffe"}
{"answers": {"text": ["Alvaro Martin", "Alvaro Martin", "Alvaro Martin"], "answer_start": [563, 563, 563]}, "prediction_text": "Alvaro Martin and Raul Allegre"}
{"answers": {"text": ["December 28, 2015", "December 28, 2015", "December 28, 2015,"], "answer_start": [3, 3, 3]}, "prediction_text": "December 28, 2015"}
{"answers": {"text": ["Spanish", "Spanish", "Spanish"], "answer_start": [122, 122, 122]}, "prediction_text": "Spanish"}
{"answers": {"text": ["CBS", "ESPN Deportes", "ESPN Deportes"], "answer_start": [86, 22, 22]}, "prediction_text": "ESPN Deportes"}
{"answers": {"text": ["ESPN Deportes", "ESPN Deportes", "ESPN Deportes"], "answer_start": [22, 22, 22]}, "prediction_text": "ESPN Deportes"}
{"answers": {"text": ["John Sutcliffe.", "John Sutcliffe", "Sutcliffe"], "answer_start": [617, 617, 622]}, "prediction_text": "John Sutcliffe"}
{"answers": {"text": ["ESPN Deportes", "ESPN Deportes", "ESPN Deportes"], "answer_start": [22, 22, 22]}, "prediction_text": "ESPN Deportes"}
{"answers": {"text": ["Alvaro Martin and Raul Allegre", "Alvaro Martin and Raul Allegre", "Alvaro Martin and Raul Allegre"], "answer_start": [563, 563, 563]}, "prediction_text": "Alvaro Martin, Raul Allegre, John Sutcliffe."}
{"answers": {"text": ["John Sutcliffe.", "John Sutcliffe", "Sutcliffe"], "answer_start": [617, 617, 622]}, "prediction_text": "John Sutcliffe"}
{"answers": {"text": ["NFL Mobile", "NFL Mobile", "NFL Mobile service."], "answer_start": [304, 304, 304]}, "prediction_text": "NFL Mobile service"}
{"answers": {"text": ["WatchESPN", "WatchESPN", "WatchESPN"], "answer_start": [387, 387, 387]}, "prediction_text": "NFL Mobile"}
{"answers": {"text": ["CBSSports.com", "CBSSports.com", "CBSSports"], "answer_start": [45, 45, 45]}, "prediction_text": "CBSSports.com"}
{"answers": {"text": ["Xbox One", "Xbox One", "Xbox One"], "answer_start": [108, 108, 108]}, "prediction_text": "CBS Sports app on tablets"}
{"answers": {"text": ["10", "10", "10"], "answer_start": [104, 104, 104]}, "prediction_text": "Windows 10"}
{"answers": {"text": ["CBSSports.com", "CBSSports.com", "CBSSports.com"], "answer_start": [45, 45, 45]}, "prediction_text": "CBSSports.com"}
{"answers": {"text": ["Xbox One", "Xbox One", "Xbox"], "answer_start": [108, 108, 108]}, "prediction_text": "Verizon Wireless"}
{"answers": {"text": ["Verizon Wireless customers", "Verizon", "Verizon"], "answer_start": [269, 187, 187]}, "prediction_text": "Verizon Wireless customers"}
{"answers": {"text": ["NFL Mobile service", "the CBS Sports apps", "NFL"], "answer_start": [304, 64, 304]}, "prediction_text": "WatchESPN"}
{"answers": {"text": ["Verizon", "Verizon", "Verizon"], "answer_start": [187, 187, 187]}, "prediction_text": "Verizon Communications"}
{"answers": {"text": ["NFL Mobile service.", "NFL Mobile", "NFL"], "answer_start": [304, 304, 304]}, "prediction_text": "NFL Mobile"}
{"answers": {"text": ["digital streams of the game", "digital streams", "digital streams"], "answer_start": [13, 13, 13]}, "prediction_text": "Digital streams of the game"}
{"answers": {"text": ["Verizon", "Verizon", "Verizon"], "answer_start": [187, 187, 187]}, "prediction_text": "Verizon Communications"}
{"answers": {"text": ["WatchESPN.", "through WatchESPN", "WatchESPN"], "answer_start": [387, 379, 387]}, "prediction_text": "WatchESPN"}
{"answers": {"text": ["The Late Show with Stephen Colbert", "The Late Show with Stephen Colbert", "Late Show with Stephen Colbert"], "answer_start": [186, 186, 190]}, "prediction_text": "The Late Late Show with James Corden"}
{"answers": {"text": ["The Late Late Show with James Corden", "The Late Late Show with James Corden", "Late Late Show with James Corden"], "answer_start": [323, 323, 327]}, "prediction_text": "The Late Late Show with James Corden"}
{"answers": {"text": ["The Late Show with Stephen Colbert", "The Late Show with Stephen Colbert", "Colbert"], "answer_start": [186, 186, 213]}, "prediction_text": "The Late Late Show with James Corden"}
{"answers": {"text": ["The Late Late Show with James Corden", "The Late Late Show with James Corden", "Late Late Show with James Corden"], "answer_start": [323, 323, 327]}, "prediction_text": "The Late Late Show with James Corden"}
{"answers": {"text": ["The Late Show with Stephen Colbert", "The Late Show with Stephen Colbert", "Late Show with Stephen Colbert"], "answer_start": [186, 186, 190]}, "prediction_text": "The Late Late Show with James Corden"}
{"answers": {"text": ["late local programming", "late local programming", "late local programming"], "answer_start": [263, 263, 263]}, "prediction_text": "A special episode of The Late Late Show with James Corden."}
{"answers": {"text": ["The Late Late Show with James Corden.", "The Late Late Show with James Corden", "The Late Late Show with James Corden."], "answer_start": [323, 323, 323]}, "prediction_text": "A special episode of The Late Late Show with James Corden."}
{"answers": {"text": ["$5,000,000", "$5,000,000", "$5,000,000,"], "answer_start": [55, 55, 55]}, "prediction_text": "$5,000,000"}
{"answers": {"text": ["Anheuser-Busch InBev", "Anheuser-Busch InBev", "Anheuser-Busch InBev"], "answer_start": [492, 492, 492]}, "prediction_text": "Anheuser-Busch InBev"}
{"answers": {"text": ["Doritos", "Doritos", "Doritos"], "answer_start": [648, 770, 648]}, "prediction_text": "Nintendo"}
{"answers": {"text": ["20th", "the 20th", "20th"], "answer_start": [910, 906, 910]}, "prediction_text": "20th anniversary"}
{"answers": {"text": ["$5,000,000", "$5,000,000", "$5,000,000"], "answer_start": [55, 55, 55]}, "prediction_text": "$5,000,000"}
{"answers": {"text": ["Anheuser-Busch InBev", "Anheuser-Busch InBev", "Anheuser-Busch InBev"], "answer_start": [492, 492, 492]}, "prediction_text": "Anheuser-Busch InBev"}
{"answers": {"text": ["Doritos", "Doritos", "Doritos"], "answer_start": [648, 770, 648]}, "prediction_text": "Nintendo"}
{"answers": {"text": ["Nintendo", "Nintendo", "Nintendo"], "answer_start": [829, 829, 829]}, "prediction_text": "Nintendo"}
{"answers": {"text": ["The Pok\u00e9mon Company", "The Pok\u00e9mon Company", "The Pok\u00e9mon Company"], "answer_start": [842, 842, 842]}, "prediction_text": "Nintendo"}
{"answers": {"text": ["Anheuser-Busch InBev", "Anheuser-Busch InBev", "Anheuser-Busch InBev"], "answer_start": [492, 492, 492]}, "prediction_text": "Anheuser-Busch InBev"}
{"answers": {"text": ["Doritos", "Doritos", "Doritos"], "answer_start": [648, 648, 648]}, "prediction_text": "Nintendo"}
{"answers": {"text": ["Anheuser-Busch InBev", "Anheuser-Busch InBev", "Anheuser-Busch InBev"], "answer_start": [492, 492, 492]}, "prediction_text": "Anheuser-Busch InBev"}
{"answers": {"text": ["Doritos", "Doritos", "Doritos"], "answer_start": [648, 648, 648]}, "prediction_text": "Anheuser-Busch InBev"}
{"answers": {"text": ["Crash the Super Bowl", "Crash the Super Bowl", "Crash the Super Bowl"], "answer_start": [699, 699, 699]}, "prediction_text": "\"Crash the Super Bowl\""}
{"answers": {"text": ["\"Small Business Big Game\"", "Small Business Big Game", "Small Business Big Game"], "answer_start": [23, 24, 24]}, "prediction_text": "\"Small Business Big Game\""}
{"answers": {"text": ["Death Wish Coffee", "Death Wish Coffee", "Death Wish Coffee"], "answer_start": [67, 67, 157]}, "prediction_text": "Death Wish Coffee"}
{"answers": {"text": ["30-second", "30-second", "30-second"], "answer_start": [91, 91, 91]}, "prediction_text": "30 seconds"}
{"answers": {"text": ["nine", "nine", "nine"], "answer_start": [184, 184, 184]}, "prediction_text": "Nine competitors"}
{"answers": {"text": ["Death Wish Coffee", "Death Wish Coffee", "Death Wish Coffee"], "answer_start": [67, 67, 157]}, "prediction_text": "Death Wish Coffee"}
{"answers": {"text": ["nine", "nine", "nine"], "answer_start": [184, 184, 184]}, "prediction_text": "Nine other contestants"}
{"answers": {"text": ["QuickBooks.", "QuickBooks", "QuickBooks"], "answer_start": [145, 0, 0]}, "prediction_text": "Death Wish Coffee"}
{"answers": {"text": ["Death Wish Coffee", "Death Wish Coffee", "Death Wish Coffee"], "answer_start": [67, 67, 157]}, "prediction_text": "Death Wish Coffee"}
{"answers": {"text": ["ten", "nine", "nine"], "answer_start": [198, 184, 184]}, "prediction_text": "Nine companies"}
{"answers": {"text": ["QuickBooks.", "QuickBooks", "QuickBooks"], "answer_start": [145, 0, 0]}, "prediction_text": "Death Wish Coffee"}
{"answers": {"text": ["Death Wish Coffee", "Death Wish Coffee", "Death Wish Coffee"], "answer_start": [67, 67, 157]}, "prediction_text": "Death Wish Coffee"}
{"answers": {"text": ["Jason Bourne", "Jason Bourne", "Jason Bourne"], "answer_start": [438, 438, 438]}, "prediction_text": "Gods of Egypt"}
{"answers": {"text": ["Gods of Egypt", "Gods of Egypt", "Gods of Egypt,"], "answer_start": [261, 261, 261]}, "prediction_text": "Lionsgate's trailer for The Secret Life of Pets."}
{"answers": {"text": ["Teenage Mutant Ninja Turtles: Out of the Shadows", "Teenage Mutant Ninja Turtles: Out of the Shadows", "Teenage Mutant Ninja Turtles: Out of the Shadows"], "answer_start": [295, 295, 295]}, "prediction_text": "The Jungle Book"}
{"answers": {"text": ["Resurgence", "Resurgence", "Resurgence"], "answer_start": [210, 210, 210]}, "prediction_text": "Independence Day: Resurgence"}
{"answers": {"text": ["Gods of Egypt", "Gods of Egypt", "Gods of Egypt"], "answer_start": [261, 261, 261]}, "prediction_text": "Gods of Egypt"}
{"answers": {"text": ["Teenage Mutant Ninja Turtles: Out of the Shadows", "Teenage Mutant Ninja Turtles: Out of the Shadows", "Teenage Mutant Ninja Turtles"], "answer_start": [295, 295, 295]}, "prediction_text": "The Secret Life of Pets"}
{"answers": {"text": ["Jason Bourne", "Jason Bourne", "Jason Bourne"], "answer_start": [438, 438, 438]}, "prediction_text": "10 Cloverfield Lane"}
{"answers": {"text": ["Captain America: Civil War", "Captain America: Civil War", "Captain America: Civil War"], "answer_start": [471, 471, 471]}, "prediction_text": "The Secret Life of Pets"}
{"answers": {"text": ["Independence Day", "Independence Day", "Independence Day: Resurgence"], "answer_start": [192, 192, 192]}, "prediction_text": "Deadpool"}
{"answers": {"text": ["Universal", "Universal", "Universal"], "answer_start": [49, 369, 369]}, "prediction_text": "Lionsgate"}
{"answers": {"text": ["Fox", "Fox", "Disney"], "answer_start": [13, 150, 455]}, "prediction_text": "Fox"}
{"answers": {"text": ["Westwood One", "Westwood One", "Westwood One"], "answer_start": [0, 0, 0]}, "prediction_text": "Westwood One"}
{"answers": {"text": ["Kevin Harlan", "Kevin Harlan", "Kevin Harlan"], "answer_start": [64, 64, 64]}, "prediction_text": "Kevin Harlan"}
{"answers": {"text": ["Jim Gray", "Jim Gray", ". Jim Gray"], "answer_start": [208, 208, 206]}, "prediction_text": "Jim Gray"}
{"answers": {"text": ["Boomer Esiason", "Boomer Esiason", "Boomer Esiason"], "answer_start": [104, 104, 104]}, "prediction_text": "Boomer Esiason"}
{"answers": {"text": ["James Lofton", "James Lofton", "James Lofton and Mark Malone"], "answer_start": [156, 156, 156]}, "prediction_text": "James Lofton"}
{"answers": {"text": ["two", "Boomer Esiason and Dan Fouts"], "answer_start": [3, 104]}, "prediction_text": "Boomer Esiason, Dan Fouts, James Lofton, Mark Malone."}
{"answers": {"text": ["Kevin Harlan", "Kevin Harlan", "Kevin Harlan"], "answer_start": [64, 64, 64]}, "prediction_text": "Kevin Harlan"}
{"answers": {"text": ["Westwood One", "Westwood One", "Westwood One"], "answer_start": [0, 0, 0]}, "prediction_text": "Westwood One"}
{"answers": {"text": ["Kevin Harlan", "Kevin Harlan", "Kevin Harlan"], "answer_start": [64, 64, 64]}, "prediction_text": "Kevin Harlan"}
{"answers": {"text": ["Jim Gray", "Jim Gray", "Jim Gray"], "answer_start": [208, 208, 208]}, "prediction_text": "Jim Gray"}
{"answers": {"text": ["Kevin Harlan", "Kevin Harlan", "Kevin Harlan"], "answer_start": [64, 64, 64]}, "prediction_text": "Kevin Harlan"}
{"answers": {"text": ["Boomer Esiason and Dan Fouts", "Boomer Esiason and Dan Fouts", "Boomer Esiason and Dan Fouts"], "answer_start": [104, 104, 104]}, "prediction_text": "Boomer Esiason, Dan Fouts, James Lofton, Mark Malone."}
{"answers": {"text": ["James Lofton and Mark Malone", "James Lofton and Mark Malone", "James Lofton and Mark Malone"], "answer_start": [156, 156, 156]}, "prediction_text": "Boomer Esiason, Dan Fouts, James Lofton, Mark Malone."}
{"answers": {"text": ["pre-game and halftime coverage.", "halftime", "anchor the pre-game and halftime coverage"], "answer_start": [233, 246, 222]}, "prediction_text": "Pre-game and halftime coverage"}
{"answers": {"text": ["North America", "North America", "North America"], "answer_start": [44, 44, 44]}, "prediction_text": "North America"}
{"answers": {"text": ["KRFX", "KRFX", "KRFX"], "answer_start": [137, 137, 137]}, "prediction_text": "WBT"}
{"answers": {"text": ["Dave Logan", "KOA (850 AM) and KRFX (103.5 FM)", "Dave Logan"], "answer_start": [179, 120, 179]}, "prediction_text": "Dave Logan"}
{"answers": {"text": ["1110 AM", "1110 AM", "(1110 AM)"], "answer_start": [268, 268, 267]}, "prediction_text": "1110 AM"}
{"answers": {"text": ["Chester, South Carolina", "Chester", "Chester, South Carolina"], "answer_start": [476, 476, 476]}, "prediction_text": "Chester, South Carolina"}
{"answers": {"text": ["Mick Mixon", "Mick Mixon", "Mick Mixon"], "answer_start": [303, 303, 303]}, "prediction_text": "Mick Mixon"}
{"answers": {"text": ["Dave Logan", "Dave Logan", "Dave Logan"], "answer_start": [179, 179, 179]}, "prediction_text": "Dave Logan"}
{"answers": {"text": ["Ed McCaffrey", "Ed McCaffrey", "Ed McCaffrey"], "answer_start": [210, 210, 210]}, "prediction_text": "Ed McCaffrey"}
{"answers": {"text": ["WBT", "WBT (1110 AM)", "WBT (1110 AM)"], "answer_start": [263, 263, 263]}, "prediction_text": "WBT-FM (99.3 FM)"}
{"answers": {"text": ["Mick Mixon", "Mick Mixon", "Mick Mixon"], "answer_start": [303, 303, 303]}, "prediction_text": "Mick Mixon"}
{"answers": {"text": ["KOA (850 AM) and KRFX (103.5 FM)", "KOA (850 AM) and KRFX (103.5 FM)", "KOA (850 AM) and KRFX (103.5 FM)"], "answer_start": [120, 120, 120]}, "prediction_text": "KOA and KRFX"}
{"answers": {"text": ["WBT-FM (99.3 FM)", "WBT (1110 AM)", "WBT-FM"], "answer_start": [440, 263, 440]}, "prediction_text": "WBT-FM (99.3 FM)"}
{"answers": {"text": ["BBC Radio 5", "Radio 5 Live", "BBC Radio 5 Live"], "answer_start": [23, 27, 23]}, "prediction_text": "BBC Radio 5 Live"}
{"answers": {"text": ["5 Live Sports Extra", "5 Live Sports Extra", "5 Live Sports Extra"], "answer_start": [44, 44, 44]}, "prediction_text": "5 Live Sports Extra"}
{"answers": {"text": ["Darren Fletcher", "Darren Fletcher", "Darren Fletcher"], "answer_start": [159, 159, 159]}, "prediction_text": "Greg Brady and Rocky Boiman"}
{"answers": {"text": ["BBC", "BBC", "BBC"], "answer_start": [23, 23, 92]}, "prediction_text": "BBC"}
{"answers": {"text": ["Greg Brady", "Greg Brady", "Greg Brady"], "answer_start": [147, 147, 147]}, "prediction_text": "Greg Brady"}
{"answers": {"text": ["Bart Starr", "Bart Starr", "Starr"], "answer_start": [148, 148, 153]}, "prediction_text": "Bart Starr"}
{"answers": {"text": ["Chuck Howley", "Chuck Howley", "Howley"], "answer_start": [193, 193, 199]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning"], "answer_start": [254, 254, 261]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [484, 484, 484]}, "prediction_text": "2001"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning"], "answer_start": [254, 254, 261]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["39", "39", "39"], "answer_start": [92, 92, 92]}, "prediction_text": "39 players"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning"], "answer_start": [254, 254, 261]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["Harvey Martin", "Harvey Martin", "Martin"], "answer_start": [431, 431, 438]}, "prediction_text": "Harvey Martin"}
{"answers": {"text": ["43", "43", "43"], "answer_start": [102, 102, 102]}, "prediction_text": "39 players"}
{"answers": {"text": ["39", "39", "39"], "answer_start": [92, 92, 92]}, "prediction_text": "39"}
{"answers": {"text": ["Bart Starr", "Bart Starr", "Starr"], "answer_start": [148, 148, 153]}, "prediction_text": "Bart Starr"}
{"answers": {"text": ["Peyton Manning", "Peyton Manning", "Manning"], "answer_start": [254, 254, 261]}, "prediction_text": "Peyton Manning"}
{"answers": {"text": ["Harvey Martin", "Harvey Martin", "Harvey Martin"], "answer_start": [431, 431, 431]}, "prediction_text": "Harvey Martin"}
{"answers": {"text": ["Six", "Six", "Six"], "answer_start": [0, 0, 0]}, "prediction_text": "Six Grammys"}
{"answers": {"text": ["the national anthem", "the national anthem", "national anthem"], "answer_start": [69, 69, 73]}, "prediction_text": "National anthem"}
{"answers": {"text": ["Academy Award", "Academy Award", "Academy Award"], "answer_start": [27, 96, 96]}, "prediction_text": "Academy Award"}
{"answers": {"text": ["the national anthem", "the national anthem", "national anthem"], "answer_start": [69, 69, 73]}, "prediction_text": "American Sign Language (ASL)"}
{"answers": {"text": ["American Sign Language", "American Sign Language", "American Sign Language"], "answer_start": [140, 140, 140]}, "prediction_text": "American Sign Language (ASL)"}
{"answers": {"text": ["Lady Gaga", "Lady Gaga", "Lady Gaga"], "answer_start": [49, 49, 49]}, "prediction_text": "Lady Gaga"}
{"answers": {"text": ["Marlee Matlin", "Marlee Matlin", "Marlee Matlin"], "answer_start": [117, 117, 117]}, "prediction_text": "Marlee Matlin"}
{"answers": {"text": ["Lady Gaga", "Lady Gaga", "Lady Gaga"], "answer_start": [49, 49, 49]}, "prediction_text": "Lady Gaga"}
{"answers": {"text": ["Marlee Matlin", "Marlee Matlin", "Marlee Matlin"], "answer_start": [117, 117, 117]}, "prediction_text": "Marlee Matlin"}
{"answers": {"text": ["Lady Gaga", "Lady Gaga", "Lady Gaga"], "answer_start": [49, 49, 49]}, "prediction_text": "Lady Gaga"}
{"answers": {"text": ["Six", "Six", "Six"], "answer_start": [0, 0, 0]}, "prediction_text": "Six Grammy Awards"}
{"answers": {"text": ["Marlee Matlin", "Marlee Matlin", "Marlee Matlin"], "answer_start": [117, 117, 117]}, "prediction_text": "Lady Gaga"}
{"answers": {"text": ["December 3", "December 3", "December 3"], "answer_start": [112, 112, 112]}, "prediction_text": "December 3"}
{"answers": {"text": ["British", "British", "British"], "answer_start": [185, 185, 185]}, "prediction_text": "British"}
{"answers": {"text": ["Super Bowl XLVII", "Super Bowl XLVII", "XLVII"], "answer_start": [306, 306, 317]}, "prediction_text": "Super Bowl XLVIII"}
{"answers": {"text": ["\"Hymn for the Weekend\"", "Hymn for the Weekend", "Hymn for the Weekend"], "answer_start": [382, 383, 383]}, "prediction_text": "\"Hymn for the Weekend\""}
{"answers": {"text": ["Super Bowl XLVIII", "Super Bowl XLVIII", "XLVIII"], "answer_start": [467, 467, 478]}, "prediction_text": "Super Bowl XLVIII"}
{"answers": {"text": ["Coldplay.", "Coldplay", "Coldplay"], "answer_start": [204, 204, 204]}, "prediction_text": "Beyonc\u00e9"}
{"answers": {"text": ["Pepsi", "Pepsi", "Pepsi"], "answer_start": [234, 234, 234]}, "prediction_text": "Pepsi"}
{"answers": {"text": ["\"Hymn for the Weekend\"", "Hymn for the Weekend", "Hymn for the Weekend"], "answer_start": [382, 383, 383]}, "prediction_text": "\"Hymn for the Weekend\""}
{"answers": {"text": ["Coldplay.", "Coldplay", "Coldplay"], "answer_start": [204, 204, 204]}, "prediction_text": "Beyonc\u00e9"}
{"answers": {"text": ["Beyonc\u00e9", "Beyonc\u00e9", "Beyonc\u00e9"], "answer_start": [279, 279, 279]}, "prediction_text": "Bruno Mars"}
{"answers": {"text": ["Hymn for the Weekend", "Hymn for the Weekend", "Mars"], "answer_start": [383, 383, 443]}, "prediction_text": "\"Hymn for the Weekend\""}
{"answers": {"text": ["Bruno Mars", "Bruno Mars", "Bruno Mars,"], "answer_start": [437, 437, 437]}, "prediction_text": "Mark Ronson"}
{"answers": {"text": ["Denver", "Denver", "Denver"], "answer_start": [0, 0, 0]}, "prediction_text": "Denver"}
{"answers": {"text": ["Andre Caldwell", "Andre Caldwell", "Caldwell"], "answer_start": [160, 160, 166]}, "prediction_text": "Andre Caldwell"}
{"answers": {"text": ["Ronnie Hillman", "Ronnie Hillman", "Hillman"], "answer_start": [366, 366, 373]}, "prediction_text": "Ronnie Hillman"}
{"answers": {"text": ["Brandon McManus", "Brandon McManus", "McManus"], "answer_start": [536, 536, 544]}, "prediction_text": "Brandon McManus"}
{"answers": {"text": ["C. J. Anderson", "C. J. Anderson", "Anderson"], "answer_start": [197, 197, 203]}, "prediction_text": "C. J. Anderson"}
{"answers": {"text": ["18", "18", "22-yard"], "answer_start": [89, 89, 134]}, "prediction_text": "18 yards"}
{"answers": {"text": ["Shaq Thompson", "Shaq Thompson", "Thompson"], "answer_start": [344, 344, 349]}, "prediction_text": "Thomas Davis"}
{"answers": {"text": ["Brandon McManus", "Brandon McManus", "McManus"], "answer_start": [536, 536, 544]}, "prediction_text": "Brandon McManus"}
{"answers": {"text": ["a deficit.", "a deficit", "deficit"], "answer_start": [654, 654, 656]}, "prediction_text": "A deficit"}
{"answers": {"text": ["Denver", "Carolina", "Denver"], "answer_start": [0, 634, 0]}, "prediction_text": "Denver"}
{"answers": {"text": ["Owen Daniels", "Owen Daniels", "Daniels"], "answer_start": [115, 115, 120]}, "prediction_text": "Owen Daniels"}
{"answers": {"text": ["C. J. Anderson", "C. J. Anderson", "Anderson"], "answer_start": [197, 197, 203]}, "prediction_text": "C. J. Anderson"}
{"answers": {"text": ["Brandon McManus", "Brandon McManus", "McManus"], "answer_start": [536, 536, 544]}, "prediction_text": "C. J. Anderson scored the first points for Carolina."}
{"answers": {"text": ["a deficit.", "a deficit", "deficit"], "answer_start": [654, 654, 656]}, "prediction_text": "A deficit"}
{"answers": {"text": ["Mike Carey", "Mike Carey", "Carey"], "answer_start": [219, 219, 224]}, "prediction_text": "Mike Carey"}
{"answers": {"text": ["Cam Newton", "Cam Newton", "Newton"], "answer_start": [45, 45, 49]}, "prediction_text": "Cam Newton's pass to Jerricho Cotchery"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [389, 389, 393]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["Malik Jackson", "Malik Jackson", "Jackson"], "answer_start": [462, 462, 468]}, "prediction_text": "Malik Jackson"}
{"answers": {"text": ["Super Bowl XXVIII", "Super Bowl XXVIII", "XXVIII"], "answer_start": [624, 624, 635]}, "prediction_text": "Super Bowl XXVIII"}
{"answers": {"text": ["Jerricho Cotchery", "Jerricho Cotchery", "Cotchery"], "answer_start": [92, 92, 101]}, "prediction_text": "Cam Newton"}
{"answers": {"text": ["Mike Carey", "Mike Carey", "Carey"], "answer_start": [219, 219, 224]}, "prediction_text": "Mike Carey"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [389, 389, 393]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["Malik Jackson", "Malik Jackson", "Jackson"], "answer_start": [462, 462, 468]}, "prediction_text": "Malik Jackson"}
{"answers": {"text": ["1993", "1993", "1993"], "answer_start": [660, 660, 660]}, "prediction_text": "1993"}
{"answers": {"text": ["Mike Carey", "Mike Carey", "Carey"], "answer_start": [219, 219, 224]}, "prediction_text": "Mike Carey"}
{"answers": {"text": ["Von Miller", "Von Miller", "Miller"], "answer_start": [389, 389, 393]}, "prediction_text": "Von Miller"}
{"answers": {"text": ["Malik Jackson", "Malik Jackson", "Jackson"], "answer_start": [462, 462, 468]}, "prediction_text": "Malik Jackson"}
{"answers": {"text": ["Super Bowl XXVIII", "the end of the 1993 season", "1993"], "answer_start": [624, 645, 660]}, "prediction_text": "1993"}
{"answers": {"text": ["Jonathan Stewart", "Jonathan Stewart", "Stewart"], "answer_start": [171, 171, 180]}, "prediction_text": "Jonathan Stewart"}
{"answers": {"text": ["Brad Nortman", "Brad Nortman", "Nortman"], "answer_start": [352, 352, 357]}, "prediction_text": "Brad Nortman"}
{"answers": {"text": ["28", "28", "28"], "answer_start": [270, 373, 373]}, "prediction_text": "51 yards"}
{"answers": {"text": ["61", "61", "61"], "answer_start": [612, 612, 612]}, "prediction_text": "61 yards"}
{"answers": {"text": ["33", "33", "33"], "answer_start": [805, 805, 805]}, "prediction_text": "33 yards"}
{"answers": {"text": ["51", "51", "51"], "answer_start": [125, 125, 125]}, "prediction_text": "51 yards"}
{"answers": {"text": ["Jonathan Stewart", "Jonathan Stewart", "Stewart"], "answer_start": [171, 171, 180]}, "prediction_text": "Jordan Norwood"}
{"answers": {"text": ["11:28", "11:28", "11:28"], "answer_start": [267, 267, 267]}, "prediction_text": "11:28 left in the second quarter."}
{"answers": {"text": ["Jordan Norwood", "Jordan Norwood", "Norwood"], "answer_start": [328, 328, 516]}, "prediction_text": "Jordan Norwood"}
{"answers": {"text": ["33", "33", "33"], "answer_start": [805, 805, 805]}, "prediction_text": "33 yards"}
{"answers": {"text": ["Jonathan Stewart", "Jonathan Stewart", "Stewart"], "answer_start": [171, 171, 180]}, "prediction_text": "Newton"}
{"answers": {"text": ["field goal", "field goal", "field goal"], "answer_start": [813, 813, 813]}, "prediction_text": "Denver scored at the end of the drive."}
{"answers": {"text": ["Darian Stewart", "Darian Stewart", "Stewart"], "answer_start": [96, 96, 103]}, "prediction_text": "Darian Stewart"}
{"answers": {"text": ["linebacker", "linebacker", "linebacker"], "answer_start": [118, 118, 118]}, "prediction_text": "Defensive end"}
{"answers": {"text": ["Kony Ealy", "Kony Ealy", "Ealy"], "answer_start": [249, 249, 254]}, "prediction_text": "Kony Ealy"}
{"answers": {"text": ["Newton", "Newton", "Newton"], "answer_start": [571, 571, 571]}, "prediction_text": "DeMarcus Ware"}
{"answers": {"text": ["DeMarcus Ware", "DeMarcus Ware", "Ware"], "answer_start": [592, 592, 601]}, "prediction_text": "DeMarcus Ware"}
{"answers": {"text": ["Mike Tolbert", "Mike Tolbert", "Tolbert"], "answer_start": [39, 39, 44]}, "prediction_text": "Mike Tolbert"}
{"answers": {"text": ["Kony Ealy", "Kony Ealy", "Ealy"], "answer_start": [249, 249, 254]}, "prediction_text": "Kony Ealy"}
{"answers": {"text": ["19", "19", "19"], "answer_start": [336, 336, 336]}, "prediction_text": "19 yards"}
{"answers": {"text": ["DeMarcus Ware", "DeMarcus Ware", "Ware"], "answer_start": [592, 592, 601]}, "prediction_text": "Danny Trevathan"}
{"answers": {"text": ["Mike Tolbert", "Mike Tolbert", "Tolbert"], "answer_start": [39, 39, 44]}, "prediction_text": "Mike Tolbert"}
{"answers": {"text": ["Danny Trevathan", "Danny Trevathan", "Stewart"], "answer_start": [129, 129, 103]}, "prediction_text": "Danny Trevathan"}
{"answers": {"text": ["Kony Ealy", "Kony Ealy", "Ealy"], "answer_start": [249, 249, 254]}, "prediction_text": "Danny Trevathan"}
{"answers": {"text": ["punt", "Newton was sacked", "sacked"], "answer_start": [474, 571, 582]}, "prediction_text": "They lost the possession."}
{"answers": {"text": ["DeMarcus Ware", "DeMarcus Ware", "Ware"], "answer_start": [592, 592, 601]}, "prediction_text": "DeMarcus Ware"}
{"answers": {"text": ["Ted Ginn Jr.", "Ted Ginn Jr", "Ted Ginn Jr"], "answer_start": [118, 118, 118]}, "prediction_text": "Ted Ginn Jr."}
{"answers": {"text": ["Graham Gano", "Graham Gano", "Gano"], "answer_start": [285, 285, 292]}, "prediction_text": "Graham Gano"}
{"answers": {"text": ["44", "44", "44"], "answer_start": [319, 319, 319]}, "prediction_text": "No points"}
{"answers": {"text": ["McManus", "McManus", "McManus"], "answer_start": [459, 459, 459]}, "prediction_text": "T.J. Ward"}
{"answers": {"text": ["T. J. Ward", "T. J. Ward", "Ward"], "answer_start": [775, 775, 781]}, "prediction_text": "Trevathan recovered the fumble."}
{"answers": {"text": ["Ted Ginn Jr.", "Ted Ginn Jr.", "Ted Ginn Jr"], "answer_start": [118, 118, 118]}, "prediction_text": "Ted Ginn Jr."}
{"answers": {"text": ["the uprights", "the uprights", "uprights"], "answer_start": [301, 301, 305]}, "prediction_text": "Uprights"}
{"answers": {"text": ["T. J. Ward.", "T. J. Ward", "Ward"], "answer_start": [775, 775, 781]}, "prediction_text": "T. J. Ward"}
{"answers": {"text": ["Trevathan", "Trevathan", "Trevathan"], "answer_start": [832, 832, 832]}, "prediction_text": "Trevathan"}
{"answers": {"text": ["Ted Ginn Jr.", "Ted Ginn Jr"], "answer_start": [118, 118]}, "prediction_text": "Ted Ginn Jr."}
{"answers": {"text": ["26-yard line", "26"], "answer_start": [238, 238]}, "prediction_text": "26-yard line"}
{"answers": {"text": ["Graham Gano", "Graham Gano", "Gano"], "answer_start": [285, 285, 292]}, "prediction_text": "Graham Gano"}
{"answers": {"text": ["Emmanuel Sanders", "Emmanuel Sanders", "Sanders"], "answer_start": [401, 401, 410]}, "prediction_text": "Ted Ginn Jr."}
{"answers": {"text": ["Ealy", "Ealy", "Ealy"], "answer_start": [144, 144, 144]}, "prediction_text": "Ealy"}
{"answers": {"text": ["39", "39", "39"], "answer_start": [363, 363, 363]}, "prediction_text": "39 yards"}
{"answers": {"text": ["Devin Funchess", "Devin Funchess", "Funchess"], "answer_start": [300, 300, 306]}, "prediction_text": "Devin Funchess"}
{"answers": {"text": ["Stewart", "Stewart", "Stewart"], "answer_start": [336, 336, 336]}, "prediction_text": "Stewart"}
{"answers": {"text": ["41-yard line.", "41", "41"], "answer_start": [112, 112, 112]}, "prediction_text": "41-yard line"}
{"answers": {"text": ["Ealy", "Ealy", "Ealy"], "answer_start": [144, 144, 144]}, "prediction_text": "Ealy"}
{"answers": {"text": ["50-yard line.", "on the 50-yard line", "50"], "answer_start": [263, 256, 263]}, "prediction_text": "Panthers 50-yard line"}
{"answers": {"text": ["punts.", "punts", "punts"], "answer_start": [482, 482, 482]}, "prediction_text": "Punts"}
{"answers": {"text": ["Ealy", "Ealy", "Ealy"], "answer_start": [144, 144, 144]}, "prediction_text": "Devin Funchess"}
{"answers": {"text": ["50-yard line.", "41", "50"], "answer_start": [263, 112, 263]}, "prediction_text": "41-yard line"}
{"answers": {"text": ["39-yard", "39", "39"], "answer_start": [363, 363, 363]}, "prediction_text": "39 yards"}
{"answers": {"text": ["three", "three", "The next three drives"], "answer_start": [444, 444, 435]}, "prediction_text": "Three drives"}
{"answers": {"text": ["24", "their own 24", "24"], "answer_start": [65, 55, 65]}, "prediction_text": "Their own 24-yard line"}
{"answers": {"text": ["Newton", "Newton", "Newton"], "answer_start": [202, 202, 434]}, "prediction_text": "Miller"}
{"answers": {"text": ["Josh Norman", "Josh Norman", "Norman"], "answer_start": [620, 620, 625]}, "prediction_text": "Josh Norman"}
{"answers": {"text": ["Anderson", "Anderson", "Anderson"], "answer_start": [674, 674, 674]}, "prediction_text": "Miller punched the ball in from the 2."}
{"answers": {"text": ["Bennie Fowler", "Bennie Fowler", "Fowler"], "answer_start": [748, 748, 755]}, "prediction_text": "Bennie Fowler"}
{"answers": {"text": ["Miller", "Miller", "Miller"], "answer_start": [167, 167, 167]}, "prediction_text": "Miller"}
{"answers": {"text": ["wards", "Ward", "Ward"], "answer_start": [275, 302, 302]}, "prediction_text": "Ward"}
{"answers": {"text": ["Newton", "Newton", "Newton"], "answer_start": [202, 434, 434]}, "prediction_text": "Newton"}
{"answers": {"text": ["Josh Norman", "Josh Norman", "Norman"], "answer_start": [620, 620, 625]}, "prediction_text": "Josh Norman"}
{"answers": {"text": ["3:08", "3:08", "3:08"], "answer_start": [820, 820, 820]}, "prediction_text": "3:08 left"}
{"answers": {"text": ["4:51", "4:51", "4:51"], "answer_start": [5, 5, 5]}, "prediction_text": "4:51 left"}
{"answers": {"text": ["Miller", "Miller", "Miller"], "answer_start": [167, 167, 167]}, "prediction_text": "Miller"}
{"answers": {"text": ["wards", "Ward", "Ward"], "answer_start": [275, 302, 302]}, "prediction_text": "Ward"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [571, 571, 571]}, "prediction_text": "Three plays"}
{"answers": {"text": ["Anderson", "Anderson", "Anderson"], "answer_start": [674, 674, 674]}, "prediction_text": "Bennie Fowler"}
{"answers": {"text": ["five", "2\u00bd", "2"], "answer_start": [296, 308, 308]}, "prediction_text": "Two"}
{"answers": {"text": ["zero", "zero", "zero"], "answer_start": [75, 75, 75]}, "prediction_text": "One touchdown"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [236, 472, 472]}, "prediction_text": "Four field goals"}
{"answers": {"text": ["Thomas Davis", "Thomas Davis", "Davis"], "answer_start": [1056, 1056, 1063]}, "prediction_text": "Luke Kuechly"}
{"answers": {"text": ["one", "one", "one"], "answer_start": [54, 612, 612]}, "prediction_text": "One pick"}
{"answers": {"text": ["one", "one", "one"], "answer_start": [54, 54, 54]}, "prediction_text": "One interception"}
{"answers": {"text": ["zero", "zero", "zero"], "answer_start": [75, 75, 75]}, "prediction_text": "One touchdown"}
{"answers": {"text": ["Anderson", "Anderson", "Anderson"], "answer_start": [155, 155, 155]}, "prediction_text": "Sanders"}
{"answers": {"text": ["Sanders", "Sanders", "Sanders"], "answer_start": [92, 92, 92]}, "prediction_text": "Manning"}
{"answers": {"text": ["Thomas Davis", "Thomas Davis", "Davis"], "answer_start": [1056, 1056, 1063]}, "prediction_text": "Charles Johnson"}
{"answers": {"text": ["Sanders", "Sanders", "Sanders"], "answer_start": [92, 92, 92]}, "prediction_text": "Sanders"}
{"answers": {"text": ["Anderson", "Anderson", "Anderson"], "answer_start": [155, 155, 155]}, "prediction_text": "Sanders"}
{"answers": {"text": ["all four", "all four", "four"], "answer_start": [468, 468, 472]}, "prediction_text": "Four field goals"}
{"answers": {"text": ["one", "one", "one"], "answer_start": [54, 612, 612]}, "prediction_text": "Four intercpetions"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [236, 955, 955]}, "prediction_text": "Four total tackles"}
{"answers": {"text": ["194", "194", "194"], "answer_start": [136, 136, 136]}, "prediction_text": "315 to 194"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [164, 164, 164]}, "prediction_text": "21 first downs"}
{"answers": {"text": ["Baltimore Ravens", "the Baltimore Ravens", "Ravens"], "answer_start": [308, 304, 318]}, "prediction_text": "Baltimore Ravens"}
{"answers": {"text": ["Jordan Norwood", "Jordan Norwood", "Norwood"], "answer_start": [593, 593, 600]}, "prediction_text": "Kony Ealy"}
{"answers": {"text": ["Manning", "Manning", "Manning"], "answer_start": [897, 1069, 1069]}, "prediction_text": "Gary Kubiak"}
{"answers": {"text": ["194", "194", "194"], "answer_start": [136, 136, 136]}, "prediction_text": "315 to 194 yards"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [164, 164, 164]}, "prediction_text": "21 first downs"}
{"answers": {"text": ["Chicago Bears", "the Chicago Bears", "Bears"], "answer_start": [508, 504, 516]}, "prediction_text": "Kony Ealy"}
{"answers": {"text": ["Broncos", "Denver", "Denver"], "answer_start": [451, 726, 68]}, "prediction_text": "Carolina"}
{"answers": {"text": ["21", "21", "21"], "answer_start": [158, 158, 158]}, "prediction_text": "21 first downs"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [164, 164, 164]}, "prediction_text": "21 first downs"}
{"answers": {"text": ["The Broncos", "Denver", "Denver"], "answer_start": [447, 68, 68]}, "prediction_text": "Denver (in total yards)"}
{"answers": {"text": ["Chicago Bears", "the Chicago Bears", "Bears"], "answer_start": [508, 504, 516]}, "prediction_text": "Denver"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [814, 1199, 1199]}, "prediction_text": "Two teams"}
{"answers": {"text": ["Nobel Prize", "Nobel Prize", "Nobel Prize"], "answer_start": [188, 188, 188]}, "prediction_text": "Nobel Prize"}
{"answers": {"text": ["1745", "1745", "1745"], "answer_start": [517, 517, 517]}, "prediction_text": "1745"}
{"answers": {"text": ["Maria Sk\u0142odowska-Curie", "Maria Sk\u0142odowska-Curie", "Maria Sk\u0142odowska-Curie"], "answer_start": [49, 49, 49]}, "prediction_text": "Maria Sk\u0142odowska-Curie"}
{"answers": {"text": ["Famous musicians", "musicians", "Famous musicians"], "answer_start": [201, 208, 201]}, "prediction_text": "Fr\u00e9d\u00e9ric Chopin was born in Warsaw."}
{"answers": {"text": ["seven months old", "seven months old", "seven months old"], "answer_start": [404, 404, 404]}, "prediction_text": "Seven months old"}
{"answers": {"text": ["100", "over 100", "100"], "answer_start": [92, 87, 92]}, "prediction_text": "Over 100 species"}
{"answers": {"text": ["Krasi\u0144ski Palace Garden", "Krasi\u0144ski Palace Garden", "Krasi\u0144ski Palace Garden"], "answer_start": [579, 579, 579]}, "prediction_text": "Krasi\u0144ski Palace Garden"}
{"answers": {"text": ["The Saxon Garden", "Saxon Garden", "The Saxon Garden"], "answer_start": [0, 4, 0]}, "prediction_text": "Saxon Garden"}
{"answers": {"text": ["east end", "east", "east"], "answer_start": [176, 176, 176]}, "prediction_text": "East end"}
{"answers": {"text": ["\u0141azienki", "\u0141azienki Park", "\u0141azienki Park"], "answer_start": [728, 728, 728]}, "prediction_text": "The \u0141azienki Park"}
{"answers": {"text": ["15 kilometres", "15 kilometres", "About 15 kilometres"], "answer_start": [109, 109, 103]}, "prediction_text": "About 15 kilometres (9 miles)"}
{"answers": {"text": ["otter, beaver and hundreds of bird species", "otter, beaver and hundreds of bird species", "otter, beaver and hundreds of bird species."], "answer_start": [287, 287, 287]}, "prediction_text": "Otter, beaver, bird species."}
{"answers": {"text": ["13", "13", "13"], "answer_start": [10, 10, 10]}, "prediction_text": "13 natural reserves"}
{"answers": {"text": ["several", "several", "several"], "answer_start": [346, 346, 346]}, "prediction_text": "Few lakes"}
{"answers": {"text": ["to clean them", "clean them", "to clean them of plants and sediments"], "answer_start": [590, 593, 590]}, "prediction_text": "To clean them of plants and sediments."}
{"answers": {"text": ["city", "Demographically", "city"], "answer_start": [41, 0, 41]}, "prediction_text": "Polish majority"}
{"answers": {"text": ["833,500", "833,500", "833,500"], "answer_start": [476, 476, 476]}, "prediction_text": "833,500"}
{"answers": {"text": ["around 34%", "34", "34%"], "answer_start": [301, 308, 308]}, "prediction_text": "About 30%"}
{"answers": {"text": ["Jewish", "Jewish", "Jewish"], "answer_start": [171, 171, 171]}, "prediction_text": "Jews"}
{"answers": {"text": ["migration and urbanisation", "internal migration and urbanisation", "internal migration and urbanisation."], "answer_start": [731, 722, 722]}, "prediction_text": "Internal migration and urbanisation."}
{"answers": {"text": ["Warsaw University of Technology", "Warsaw University of Technology", "Warsaw University of Technology"], "answer_start": [169, 169, 169]}, "prediction_text": "University of Technology"}
{"answers": {"text": ["2,000", "2,000", "2,000"], "answer_start": [318, 318, 318]}, "prediction_text": "2,000 professors"}
{"answers": {"text": ["Medical University of Warsaw", "National Defence University", "Medical University of Warsaw"], "answer_start": [388, 492, 388]}, "prediction_text": "Warsaw University of Music"}
{"answers": {"text": ["1816", "1816", "1816"], "answer_start": [44, 44, 44]}, "prediction_text": "1816"}
{"answers": {"text": ["Fryderyk Chopin University of Music", "Fryderyk Chopin University of Music", "Fryderyk Chopin University of Music"], "answer_start": [574, 574, 574]}, "prediction_text": "Warsaw School of Economics"}
{"answers": {"text": ["1816", "1816", "1816"], "answer_start": [63, 63, 63]}, "prediction_text": "1816"}
{"answers": {"text": ["over two million", "over two million", "over two million"], "answer_start": [80, 80, 80]}, "prediction_text": "Over two million items"}
{"answers": {"text": ["architects", "architects", "architects"], "answer_start": [133, 133, 133]}, "prediction_text": "Zbigniew Badowski is a professor at the University Library."}
{"answers": {"text": ["Irena Bajerska", "Irena Bajerska", "Irena Bajerska"], "answer_start": [284, 284, 284]}, "prediction_text": "Irena Bajerska"}
{"answers": {"text": ["10,000 m2", "more than 10,000 m2", "10,000 m2"], "answer_start": [421, 411, 421]}, "prediction_text": "107,639.10 sq ft"}
{"answers": {"text": ["infrastructure", "infrastructure", "infrastructure"], "answer_start": [48, 48, 48]}, "prediction_text": "Infrastructure"}
{"answers": {"text": ["Three-Year Plan", "Three-Year Plan", "Three-Year Plan"], "answer_start": [187, 187, 187]}, "prediction_text": "Three-Year Plan"}
{"answers": {"text": ["solid economic growth", "solid economic growth", "economic growth"], "answer_start": [379, 379, 385]}, "prediction_text": "Solid economic growth, increase in foreign investment, European Union funding."}
{"answers": {"text": ["improved markedly", "improved markedly", "improved markedly"], "answer_start": [585, 585, 585]}, "prediction_text": "Improved significantly."}
{"answers": {"text": ["Warsaw", "Warsaw", "Warsaw"], "answer_start": [7, 7, 7]}, "prediction_text": "Warsaw"}
{"answers": {"text": ["Children's Memorial Health Institute", "Children's Memorial Health Institute", "Children's Memorial Health Institute"], "answer_start": [113, 113, 113]}, "prediction_text": "Children's Memorial Health Institute (CMHI)"}
{"answers": {"text": ["Maria Sk\u0142odowska-Curie Institute of Oncology", "Maria Sk\u0142odowska-Curie Institute of Oncology", "Maria Sk\u0142odowska-Curie Institute of Oncology"], "answer_start": [269, 269, 269]}, "prediction_text": "Maria Sk\u0142odowska-Curie Institute of Oncology"}
{"answers": {"text": ["700", "700", "700"], "answer_start": [451, 451, 451]}, "prediction_text": "700 beds"}
{"answers": {"text": ["developed", "developed", "developed"], "answer_start": [595, 595, 595]}, "prediction_text": "Developed a lot of infrastructure"}
{"answers": {"text": ["musical", "musical", "musical"], "answer_start": [19, 19, 19]}, "prediction_text": "Polish National Opera"}
{"answers": {"text": ["events and festivals", "events and festivals", "events and festivals"], "answer_start": [289, 289, 289]}, "prediction_text": "Events and festivals"}
{"answers": {"text": ["in the Palace of Culture and Science", "Palace of Culture and Science", "Palace of Culture and Science"], "answer_start": [233, 240, 240]}, "prediction_text": "Palace of Culture and Science, Warsaw"}
{"answers": {"text": ["Warsaw", "Warsaw", "Warsaw"], "answer_start": [271, 271, 271]}, "prediction_text": "Warsaw Summer Jazz Days"}
{"answers": {"text": ["festivals", "events"], "answer_start": [300, 321]}, "prediction_text": "International Stanis\u0142aw Moniuszko Vocal Competition"}
{"answers": {"text": ["Ogr\u00f3d Saski", "Ogr\u00f3d Saski", "Ogr\u00f3d Saski"], "answer_start": [11, 11, 11]}, "prediction_text": "Summer Theatre"}
{"answers": {"text": ["Saxon Garden", "the Saxon Garden", "Saxon Garden"], "answer_start": [28, 24, 28]}, "prediction_text": "Nearby, in Ogr\u00f3d Saski (the Saxon Garden)"}
{"answers": {"text": ["1870 to 1939", "1870 to 1939", "1870 to 1939"], "answer_start": [84, 84, 84]}, "prediction_text": "1870 to 1939"}
{"answers": {"text": ["Momus", "Momus", "Momus"], "answer_start": [161, 161, 161]}, "prediction_text": "Momus (or the Summer Theatre)"}
{"answers": {"text": ["Wojciech Bogus\u0142awski Theatre", "Wojciech Bogus\u0142awski Theatre", "Wojciech Bogus\u0142awski Theatre"], "answer_start": [251, 251, 251]}, "prediction_text": "Wojciech Bogus\u0142awski Theatre"}
{"answers": {"text": ["Wianki", "Wianki", "Wianki"], "answer_start": [157, 157, 157]}, "prediction_text": "Wreaths (Polish for Wreaths)"}
{"answers": {"text": ["thousands", "thousands", "thousands"], "answer_start": [66, 66, 66]}, "prediction_text": "Thousands of people gather."}
{"answers": {"text": ["Midsummer\u2019s Night", "Midsummer\u2019s Night", "Midsummer\u2019s Night"], "answer_start": [117, 117, 117]}, "prediction_text": "Midsummer's Night"}
{"answers": {"text": ["when they would be married", "when they would be married, and to whom", "when they would be married,"], "answer_start": [405, 405, 405]}, "prediction_text": "When they are married"}
{"answers": {"text": ["the fern", "fern", "fern"], "answer_start": [685, 689, 689]}, "prediction_text": "Fern flower"}
{"answers": {"text": ["art posters", "art posters", "art posters"], "answer_start": [140, 140, 140]}, "prediction_text": "One of the largest collections of art posters in the world."}
{"answers": {"text": ["60", "60", "60"], "answer_start": [239, 239, 239]}, "prediction_text": "60 museums"}
{"answers": {"text": ["prestigious", "prestigious", "prestigious"], "answer_start": [260, 260, 260]}, "prediction_text": "prestigious museums"}
{"answers": {"text": ["some paintings", "paintings", "paintings"], "answer_start": [467, 472, 472]}, "prediction_text": "Works from Adolf Hitler's private collection."}
{"answers": {"text": ["arms", "history of arms", "arms"], "answer_start": [586, 575, 586]}, "prediction_text": "Arms"}
{"answers": {"text": ["Warsaw Uprising Museum", "Warsaw Uprising Museum", "Warsaw Uprising Museum"], "answer_start": [79, 79, 79]}, "prediction_text": "Warsaw Uprising Museum"}
{"answers": {"text": ["Katy\u0144", "Katy\u0144 Museum", "Katy\u0144 Museum"], "answer_start": [113, 113, 113]}, "prediction_text": "Warsaw Uprising Museum"}
{"answers": {"text": ["stereoscopic", "stereoscopic theatre", "stereoscopic"], "answer_start": [248, 248, 248]}, "prediction_text": "Rare preserved and operating historic stereoscopic theatre."}
{"answers": {"text": ["Museum of Independence", "Museum of Independence", "Museum of Independence"], "answer_start": [300, 300, 300]}, "prediction_text": "Warsaw Uprising Museum"}
{"answers": {"text": ["60", "60", "60"], "answer_start": [471, 471, 471]}, "prediction_text": "60 rooms"}
{"answers": {"text": ["Royal Ujazd\u00f3w Castle", "Royal Ujazd\u00f3w Castle", "Royal Ujazd\u00f3w"], "answer_start": [17, 17, 17]}, "prediction_text": "17th century Royal Ujazd\u00f3w Castle"}
{"answers": {"text": ["about 500", "500", "about 500"], "answer_start": [201, 207, 201]}, "prediction_text": "About 500 projects"}
{"answers": {"text": ["Zach\u0119ta National Gallery of Art", "Zach\u0119ta National Gallery of Art", "Zach\u0119ta National Gallery of Art"], "answer_start": [228, 228, 228]}, "prediction_text": "Zach\u0119ta National Gallery of Art"}
{"answers": {"text": ["Polish and international artists", "modern art by Polish and international artists", "Polish and international artists a"], "answer_start": [395, 381, 395]}, "prediction_text": "Poland"}
{"answers": {"text": ["last weekend of September", "last weekend of September", "last weekend of September"], "answer_start": [510, 510, 510]}, "prediction_text": "Last weekend of September"}
{"answers": {"text": ["Polonia Warsaw", "Polonia Warsaw", "Polonia Warsaw"], "answer_start": [20, 20, 20]}, "prediction_text": "Polonia Warsaw"}
{"answers": {"text": ["1946", "1946", "1946"], "answer_start": [175, 175, 175]}, "prediction_text": "1946"}
{"answers": {"text": ["twice", "twice", "twice"], "answer_start": [197, 197, 197]}, "prediction_text": "Twice"}
{"answers": {"text": ["at Konwiktorska Street", "Konwiktorska Street", "Konwiktorska Street"], "answer_start": [244, 247, 247]}, "prediction_text": "Konwiktorska Street, a ten-minute walk north from the Old Town."}
{"answers": {"text": ["disastrous financial situation", "their disastrous financial situation", "disastrous financial situation."], "answer_start": [388, 382, 388]}, "prediction_text": "Their financial situation"}
{"answers": {"text": ["syrenka", "syrenka", "syrenka"], "answer_start": [13, 13, 13]}, "prediction_text": "Symbol of Warsaw"}
{"answers": {"text": ["The mermaid", "mermaid", "The mermaid"], "answer_start": [0, 4, 0]}, "prediction_text": "The mermaid (syrenka)"}
{"answers": {"text": ["since at least the mid-14th century", "mid-14th century", "at least the mid-14th century"], "answer_start": [150, 169, 156]}, "prediction_text": "At least since at least the mid-14th century."}
{"answers": {"text": ["1390", "1390", "1390"], "answer_start": [245, 245, 245]}, "prediction_text": "1390"}
{"answers": {"text": ["a sword", "sword", "sword"], "answer_start": [496, 498, 498]}, "prediction_text": "A sword"}
{"answers": {"text": ["legend", "The best-known legend", "legend"], "answer_start": [70, 55, 70]}, "prediction_text": "A legendary figure"}
{"answers": {"text": ["depths of the oceans and seas", "depths of the oceans and seas", "depths of the oceans and seas"], "answer_start": [171, 171, 171]}, "prediction_text": "The depths of the oceans and seas"}
{"answers": {"text": ["coast of Denmark", "coast of Denmark", "coast of Denmark"], "answer_start": [237, 237, 237]}, "prediction_text": "Denmark"}
{"answers": {"text": ["Warszowa", "village of Warszowa", "Warszowa"], "answer_start": [463, 452, 463]}, "prediction_text": "Warszowa"}
{"answers": {"text": ["captured", "captured the mermaid", "captured"], "answer_start": [620, 620, 620]}, "prediction_text": "He followed the fishermen"}
{"answers": {"text": ["Warsaw", "Warsaw", "Warsaw"], "answer_start": [47, 47, 84]}, "prediction_text": "Warsaw (Poland)"}
{"answers": {"text": ["1916", "1916", "1916"], "answer_start": [117, 117, 117]}, "prediction_text": "1916"}
{"answers": {"text": ["the Art Deco style", "Art Deco style in painting and art", "Art Deco style"], "answer_start": [204, 208, 208]}, "prediction_text": "Art Deco style"}
{"answers": {"text": ["poet", "poet", "poet"], "answer_start": [273, 273, 273]}, "prediction_text": "Composer"}
{"answers": {"text": ["Isaac Bashevis Singer", "Isaac Bashevis Singer", "Isaac Bashevis Singer"], "answer_start": [444, 444, 444]}, "prediction_text": "Isaac Bashevis Singer"}
{"answers": {"text": ["Economist Intelligence Unit", "Economist Intelligence Unit", "Economist Intelligence Unit"], "answer_start": [12, 12, 12]}, "prediction_text": "The Economist Intelligence Unit"}
{"answers": {"text": ["2012", "2012", "2012"], "answer_start": [3, 3, 3]}, "prediction_text": "2012"}
{"answers": {"text": ["wide variety of industries", "FMCG manufacturing, metal processing, steel and electronic manufacturing and food processing", "FMCG manufacturing"], "answer_start": [345, 393, 393]}, "prediction_text": "FMCG manufacturing, metal processing, steel and electronic manufacturing."}
{"answers": {"text": ["Stock", "Warsaw Stock Exchange", "Warsaw Stock Exchange"], "answer_start": [611, 604, 604]}, "prediction_text": "Frontex"}
{"answers": {"text": ["Frontex", "Frontex", "Frontex"], "answer_start": [698, 698, 698]}, "prediction_text": "Frontex"}
{"answers": {"text": ["1313", "1313", "1313"], "answer_start": [64, 64, 64]}, "prediction_text": "1313 (at a time when Krak\u00f3w served as the Polish capital city)"}
{"answers": {"text": ["Krak\u00f3w", "Krak\u00f3w", "Krak\u00f3w"], "answer_start": [85, 85, 85]}, "prediction_text": "Warsaw"}
{"answers": {"text": ["1596", "1596", "1596"], "answer_start": [390, 390, 390]}, "prediction_text": "1596"}
{"answers": {"text": ["King Sigismund III Vasa", "King Sigismund III Vasa", "King Sigismund III Vasa"], "answer_start": [325, 325, 325]}, "prediction_text": "Sigismund III Vasa"}
{"answers": {"text": ["survived many wars, conflicts and invasions", "it has survived many wars, conflicts and invasions", "because it has survived many wars, conflicts and invasions throughout its long history"], "answer_start": [1250, 1243, 1235]}, "prediction_text": "It survived many wars, conflicts and invasions."}
{"answers": {"text": ["Roman Catholic", "Roman Catholic", "Roman Catholic"], "answer_start": [26, 26, 26]}, "prediction_text": "Roman Catholic archdiocese"}
{"answers": {"text": ["Polish Academy of Sciences", "Polish Academy of Sciences", "Polish Academy of Sciences"], "answer_start": [159, 159, 159]}, "prediction_text": "Polish Academy of Sciences"}
{"answers": {"text": ["a UNESCO World Heritage Site", "UNESCO World Heritage Site", "UNESCO World Heritage Site"], "answer_start": [365, 367, 367]}, "prediction_text": "UNESCO World Heritage Site"}
{"answers": {"text": ["architectural", "architectural", "architectural"], "answer_start": [406, 406, 406]}, "prediction_text": "Royal Castle"}
{"answers": {"text": ["luxurious parks and royal gardens", "luxurious parks and royal gardens", "luxurious parks and royal gardens"], "answer_start": [905, 905, 905]}, "prediction_text": "Luxury parks and royal gardens."}
{"answers": {"text": ["Warszawa", "Warszawa", "Warszawa"], "answer_start": [40, 40, 40]}, "prediction_text": "Warszawa"}
{"answers": {"text": ["belonging to Warsz", "belonging to Warsz", "belonging to Warsz"], "answer_start": [133, 133, 133]}, "prediction_text": "\"Belonging to Warsz\""}
{"answers": {"text": ["12th/13th-century nobleman", "shortened form of the masculine name of Slavic origin Warcis\u0142aw", "nobleman"], "answer_start": [469, 168, 487]}, "prediction_text": "A fisherman, Wars, and his wife, Sawa."}
{"answers": {"text": ["a village", "village"], "answer_start": [506, 508]}, "prediction_text": "A village located at the modern-day site of Mariensztat neighbourhood."}
{"answers": {"text": ["miasto sto\u0142eczne Warszawa", "miasto sto\u0142eczne Warszawa", "miasto sto\u0142eczne Warszawa"], "answer_start": [668, 668, 668]}, "prediction_text": "miasto sto\u0142eczne Warszawa"}
{"answers": {"text": ["Jazd\u00f3w", "Jazd\u00f3w", "Jazd\u00f3w"], "answer_start": [142, 142, 142]}, "prediction_text": "Jazd\u00f3w"}
{"answers": {"text": ["The Prince of P\u0142ock", "Prince of P\u0142ock", "Prince of P\u0142ock"], "answer_start": [284, 288, 288]}, "prediction_text": "Boles\u0142aw II of Masovia was the prince of P\u0142ock, Boles\u0142aw II of Masovia was the prince of P\u0142ock, Boles\u0142aw II of Masovia was the prince of Jazd\u00f3w."}
{"answers": {"text": ["1300", "1300", "1300"], "answer_start": [390, 390, 390]}, "prediction_text": "About 1300"}
{"answers": {"text": ["1413", "1413", "1413"], "answer_start": [536, 536, 536]}, "prediction_text": "1413"}
{"answers": {"text": ["1526", "1526", "1526"], "answer_start": [706, 706, 706]}, "prediction_text": "1526"}
{"answers": {"text": ["General Sejm", "General Sejm", "General Sejm"], "answer_start": [58, 58, 58]}, "prediction_text": "General Sejm"}
{"answers": {"text": ["1569", "1569", "1569"], "answer_start": [87, 87, 87]}, "prediction_text": "1569"}
{"answers": {"text": ["religious freedom", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "religious freedom"], "answer_start": [175, 175, 175]}, "prediction_text": "Religious freedom"}
{"answers": {"text": ["Due to its central location", "its central location", "central location"], "answer_start": [232, 239, 243]}, "prediction_text": "Central location between Commonwealth's capitals"}
{"answers": {"text": ["1596", "1596", "1596"], "answer_start": [474, 474, 474]}, "prediction_text": "1596"}
{"answers": {"text": ["until 1796", "until 1796"], "answer_start": [66, 66]}, "prediction_text": "Until 1796"}
{"answers": {"text": ["Prussia", "Kingdom of Prussia", "Prussia"], "answer_start": [116, 105, 116]}, "prediction_text": "Kingdom of Prussia"}
{"answers": {"text": ["Napoleon's", "Napoleon's", "Napoleon's"], "answer_start": [193, 193, 193]}, "prediction_text": "Napoleon's army"}
{"answers": {"text": ["1815", "1815", "1815"], "answer_start": [320, 320, 320]}, "prediction_text": "1816"}
{"answers": {"text": ["1816", "1816", "1816"], "answer_start": [496, 496, 496]}, "prediction_text": "1816"}
{"answers": {"text": ["from 4 August 1915 until November 1918", "4 August 1915 until November 1918", "from 4 August 1915 until November 1918"], "answer_start": [31, 36, 31]}, "prediction_text": "From 4 August 1915 until November 1918."}
{"answers": {"text": ["areas controlled by Russia in 1914", "areas controlled by Russia in 1914", "areas controlled by Russia"], "answer_start": [148, 148, 148]}, "prediction_text": "Warsaw"}
{"answers": {"text": ["underground leader Pi\u0142sudski", "Pi\u0142sudski", "Pi\u0142sudski"], "answer_start": [227, 246, 246]}, "prediction_text": "Pi\u0142sudski"}
{"answers": {"text": ["1920", "1920", "1920"], "answer_start": [411, 411, 411]}, "prediction_text": "1920"}
{"answers": {"text": ["the Red Army", "Red Army", "Red Army"], "answer_start": [542, 546, 546]}, "prediction_text": "Red Army"}
{"answers": {"text": ["September 1939", "1 September 1939", "1 September 1939"], "answer_start": [41, 39, 39]}, "prediction_text": "September 27, 1939"}
{"answers": {"text": ["a German Nazi colonial administration", "German Nazi", "German Nazi colonial administration"], "answer_start": [204, 206, 206]}, "prediction_text": "Warsaw Ghetto administration"}
{"answers": {"text": ["some 30% of the city", "30%", "30%"], "answer_start": [367, 372, 372]}, "prediction_text": "Several hundred thousand"}
{"answers": {"text": ["April 1943", "19 April 1943", "19 April 1943"], "answer_start": [595, 592, 592]}, "prediction_text": "April 1943"}
{"answers": {"text": ["almost a month", "almost a month", "almost a month"], "answer_start": [733, 733, 733]}, "prediction_text": "Almost a month"}
{"answers": {"text": ["the Red Army", "Red Army", "e Red Army"], "answer_start": [14, 18, 16]}, "prediction_text": "Red Army"}
{"answers": {"text": ["Stalin was hostile to the idea of an independent Poland", "Stalin was hostile to the idea of an independent Poland", "Stalin was hostile to the idea of an independent Poland"], "answer_start": [111, 111, 111]}, "prediction_text": "Soviet hostile attitude"}
{"answers": {"text": ["August 1944", "the Red Army was nearing the city", "1 August 1944"], "answer_start": [346, 362, 344]}, "prediction_text": "August 1, 1944"}
{"answers": {"text": ["63 days", "63", "63 days"], "answer_start": [519, 519, 519]}, "prediction_text": "63 days"}
{"answers": {"text": ["between 150,000 and 200,000", "between 150,000 and 200,000", "between 150,000 and 200,000"], "answer_start": [756, 756, 756]}, "prediction_text": "150,000 to 200,000."}
{"answers": {"text": ["\"Bricks for Warsaw\"", "Bricks for Warsaw", "Bricks for Warsaw"], "answer_start": [83, 84, 84]}, "prediction_text": "\"Bricks for Warsaw\" campaign"}
{"answers": {"text": ["prefabricated", "prefabricated", "prefabricated"], "answer_start": [137, 137, 137]}, "prediction_text": "Large prefabricated housing projects"}
{"answers": {"text": ["an Eastern Bloc city", "an Eastern Bloc city"], "answer_start": [262, 262]}, "prediction_text": "Eastern Bloc cities"}
{"answers": {"text": ["Palace of Culture and Science", "Palace of Culture and Science", "Palace of Culture and Science"], "answer_start": [296, 296, 296]}, "prediction_text": "Palace of Culture and Science"}
{"answers": {"text": ["UNESCO's World Heritage list", "UNESCO's World Heritage", "UNESCO's World Heritage"], "answer_start": [612, 612, 612]}, "prediction_text": "World Heritage list"}
{"answers": {"text": ["John Paul II", "John Paul II", "John Paul II"], "answer_start": [0, 0, 0]}, "prediction_text": "John Paul II"}
{"answers": {"text": ["growing anti-communist fervor", "anti-communist fervor", "growing anti-communist fervor"], "answer_start": [131, 139, 131]}, "prediction_text": "Solidarity movement and anti-communist fervor."}
{"answers": {"text": ["less than a year", "less than a year", "less than a year"], "answer_start": [177, 177, 177]}, "prediction_text": "Less than a year"}
{"answers": {"text": ["Victory Square", "Victory Square", "1979"], "answer_start": [244, 244, 171]}, "prediction_text": "Victory Square"}
{"answers": {"text": ["incentive for the democratic changes", "incentive for the democratic changes", "democratic changes"], "answer_start": [507, 507, 525]}, "prediction_text": "The incentive for democratic changes."}
{"answers": {"text": ["about 300", "300", "300"], "answer_start": [35, 41, 41]}, "prediction_text": "About 300 km (190 mi)"}
{"answers": {"text": ["325", "325", "325"], "answer_start": [142, 142, 142]}, "prediction_text": "523 km (325 mi)"}
{"answers": {"text": ["Vistula River", "Vistula", "Vistula"], "answer_start": [198, 198, 198]}, "prediction_text": "Vistula River"}
{"answers": {"text": ["452.8 ft", "115.7 metres", "115.7 metres"], "answer_start": [866, 400, 400]}, "prediction_text": "122.1 metres (400.6 ft)"}
{"answers": {"text": ["at the right bank of the Vistula", "at the right bank of the Vistula, by the eastern border of Warsaw", "by the eastern border"], "answer_start": [633, 633, 667]}, "prediction_text": "At a height of 115.7 metres (379.6 ft) (at the right bank of the Vistula)"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [21, 21, 21]}, "prediction_text": "Two main geomorphologic formations: plain moraine plateau and Vistula Valley."}
{"answers": {"text": ["Vistula Valley", "geomorphologic", "Vistula Valley"], "answer_start": [91, 30, 91]}, "prediction_text": "Vistula Valley"}
{"answers": {"text": ["moraine", "moraine", "moraine"], "answer_start": [301, 301, 301]}, "prediction_text": "The Vistula River"}
{"answers": {"text": ["Vistula River", "Vistula River", "Vistula River"], "answer_start": [163, 163, 163]}, "prediction_text": "Vistula River"}
{"answers": {"text": ["Warsaw Escarpment", "Warsaw Escarpment", "Warsaw Escarpment"], "answer_start": [541, 541, 541]}, "prediction_text": "Warsaw Escarpment"}
{"answers": {"text": ["moraine", "moraine", "moraine"], "answer_start": [10, 10, 10]}, "prediction_text": "The plain moraine plateau"}
{"answers": {"text": ["former flooded terraces", "former flooded terraces", "peat swamps or small ponds"], "answer_start": [222, 222, 806]}, "prediction_text": "Former flooded terraces"}
{"answers": {"text": ["valleys", "valleys and ground depressions", "valleys"], "answer_start": [341, 341, 341]}, "prediction_text": "Vistula old \u2013 riverbed"}
{"answers": {"text": ["plain Vistula terraces", "highest terrace", "highest terrace"], "answer_start": [637, 843, 843]}, "prediction_text": "Forested areas"}
{"answers": {"text": ["pine", "pine", "pine"], "answer_start": [893, 893, 893]}, "prediction_text": "Pine forest"}
{"answers": {"text": ["turbulent history of the city", "turbulent history of the city and country", "turbulent history of the city"], "answer_start": [54, 54, 54]}, "prediction_text": "turbulent history"}
{"answers": {"text": ["During the Second World War", "Second World War", "During the Second World War"], "answer_start": [97, 108, 97]}, "prediction_text": "1945"}
{"answers": {"text": ["After liberation", "After liberation", "After liberation"], "answer_start": [199, 199, 199]}, "prediction_text": "1950s and 1960s"}
{"answers": {"text": ["Leopold Kronenberg Palace", "Leopold Kronenberg Palace", "Leopold Kronenberg Palace"], "answer_start": [514, 514, 514]}, "prediction_text": "Leopold Kronenberg Palace"}
{"answers": {"text": ["typical of Eastern bloc countries", "basic design typical of Eastern bloc countries", "design typical of Eastern bloc countries"], "answer_start": [598, 585, 591]}, "prediction_text": "Eastern bloc countries"}
{"answers": {"text": ["Gothic", "Gothic", "Gothic"], "answer_start": [0, 0, 0]}, "prediction_text": "Gothic architecture"}
{"answers": {"text": ["14th century", "14th century", "14th century"], "answer_start": [168, 168, 168]}, "prediction_text": "14th century"}
{"answers": {"text": ["Masovian gothic", "Gothic architecture", "Masovian gothic"], "answer_start": [232, 0, 232]}, "prediction_text": "Gothic architecture"}
{"answers": {"text": ["Renaissance", "Renaissance", "Renaissance"], "answer_start": [432, 432, 432]}, "prediction_text": "Renaissance architecture"}
{"answers": {"text": ["mannerist architecture", "mannerist architecture", "mannerist"], "answer_start": [631, 631, 631]}, "prediction_text": "Renaissance architecture"}
{"answers": {"text": ["17th century", "17th century", "17th century."], "answer_start": [98, 98, 98]}, "prediction_text": "Late 17th century"}
{"answers": {"text": ["1688\u20131692", "1677\u20131683", "1688\u20131692"], "answer_start": [245, 180, 245]}, "prediction_text": "1688\u20131692."}
{"answers": {"text": ["rococo", "rococo", "rococo"], "answer_start": [289, 289, 289]}, "prediction_text": "neoclassical architecture"}
{"answers": {"text": ["neoclassical architecture", "neoclassical architecture", "neoclassical architecture"], "answer_start": [423, 423, 423]}, "prediction_text": "Neoclassical architecture"}
{"answers": {"text": ["1775\u20131795", "1696", "1775\u20131795"], "answer_start": [663, 213, 663]}, "prediction_text": "1775\u20131795"}
{"answers": {"text": ["bourgeois", "bourgeois", "bourgeois"], "answer_start": [28, 28, 28]}, "prediction_text": "bourgeois architecture"}
{"answers": {"text": ["not restored by the communist authorities", "were not restored", "not restored by the communist authorities after the war"], "answer_start": [77, 72, 77]}, "prediction_text": "They were not restored or rebuilt."}
{"answers": {"text": ["socialist realism", "socialist realism", "socialist realism"], "answer_start": [229, 229, 229]}, "prediction_text": "Socialist realism"}
{"answers": {"text": ["Warsaw University of Technology building", "Warsaw University of Technology building", "Warsaw University of Technology"], "answer_start": [352, 352, 352]}, "prediction_text": "Warsaw University of Technology building"}
{"answers": {"text": ["the most distinctive buildings", "the most distinctive buildings", "most distinctive buildings"], "answer_start": [712, 712, 716]}, "prediction_text": "Most distinctive buildings in prewar Warsaw."}
{"answers": {"text": ["many places", "many places"], "answer_start": [15, 15]}, "prediction_text": "Mausoleum of Martyrdom"}
{"answers": {"text": ["Pawiak", "Pawiak", "Pawiak"], "answer_start": [71, 71, 71]}, "prediction_text": "Pawiak"}
{"answers": {"text": ["The Warsaw Citadel", "Warsaw Citadel", "The Warsaw Citadel"], "answer_start": [242, 246, 242]}, "prediction_text": "Warsaw Citadel"}
{"answers": {"text": ["children", "children who served as messengers and frontline troops in the Warsaw Uprising", "children"], "answer_start": [506, 506, 506]}, "prediction_text": "Children who served as messengers and frontline troops in the Warsaw Uprising."}
{"answers": {"text": ["Warsaw Uprising Monument", "Warsaw Uprising Monument", "Warsaw Uprising Monument"], "answer_start": [606, 606, 606]}, "prediction_text": "Warsaw Uprising Monument"}
{"answers": {"text": ["green", "green", "green"], "answer_start": [6, 6, 6]}, "prediction_text": "Botanic Garden"}
{"answers": {"text": ["New Orangery", "New Orangery", "New Orangery"], "answer_start": [197, 197, 197]}, "prediction_text": "New Orangery"}
{"answers": {"text": ["Pole Mokotowskie", "Mokot\u00f3w", "Pole Mokotowskie"], "answer_start": [315, 360, 315]}, "prediction_text": "In the northern Mokot\u00f3w"}
{"answers": {"text": ["Park Ujazdowski", "Park Ujazdowski", "Park Ujazdowski"], "answer_start": [428, 428, 428]}, "prediction_text": "Park Skaryszewski"}
{"answers": {"text": ["1927", "1927", "1927"], "answer_start": [715, 715, 715]}, "prediction_text": "1865\u20131871"}
{"answers": {"text": ["location of Warsaw", "location of Warsaw", "location"], "answer_start": [104, 104, 104]}, "prediction_text": "Near-wilderness areas, natural forests, wetlands, meadows, forests."}
{"answers": {"text": ["within the borders of Warsaw", "Warsaw", "within the borders of Warsaw"], "answer_start": [357, 379, 357]}, "prediction_text": "Within the borders of Warsaw"}
{"answers": {"text": ["Masovian Primeval Forest", "Masovian Primeval Forest", "Masovian Primeval Forest"], "answer_start": [416, 416, 416]}, "prediction_text": "Masovian Primeval Forest"}
{"answers": {"text": ["Kabaty", "Kabaty Forest", "Kabaty"], "answer_start": [630, 630, 630]}, "prediction_text": "Bielany Forest"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [689, 689, 689]}, "prediction_text": "Two botanic gardens"}
{"answers": {"text": ["1,300,000", "1,300,000", "1,300,000"], "answer_start": [12, 12, 12]}, "prediction_text": "1,300,000 people"}
{"answers": {"text": ["420,000", "420,000", "420,000"], "answer_start": [65, 65, 65]}, "prediction_text": "420,000"}
{"answers": {"text": ["1951", "1951", "1951"], "answer_start": [295, 295, 295]}, "prediction_text": "1951"}
{"answers": {"text": ["as better", "thought of themselves as better", "better"], "answer_start": [715, 693, 718]}, "prediction_text": "Better only because they lived in the capital."}
{"answers": {"text": ["residency registration", "residency registration", "residency registration"], "answer_start": [909, 909, 909]}, "prediction_text": "residency registration"}
{"answers": {"text": ["multi-cultural", "multi-cultural city", "multi-cultural"], "answer_start": [44, 44, 44]}, "prediction_text": "Multi-cultural city"}
{"answers": {"text": ["711,988", "711,988", "711,988"], "answer_start": [102, 102, 102]}, "prediction_text": "711,988"}
{"answers": {"text": ["56.2%", "35.7", "56.2%"], "answer_start": [122, 144, 122]}, "prediction_text": "56.2%"}
{"answers": {"text": ["2.8%", "2.8", "2.8%"], "answer_start": [189, 189, 189]}, "prediction_text": "35.7%"}
{"answers": {"text": ["1944", "1944", "1944"], "answer_start": [488, 488, 488]}, "prediction_text": "After the war"}
{"answers": {"text": ["a commune", "commune", "commune"], "answer_start": [52, 54, 54]}, "prediction_text": "A commune (gmina)"}
{"answers": {"text": ["counties or powiats", "counties or powiats", "counties or powiats"], "answer_start": [421, 421, 421]}, "prediction_text": "County or powiat grodzki"}
{"answers": {"text": ["Krak\u00f3w", "Krak\u00f3w"], "answer_start": [1085, 1085]}, "prediction_text": "Krak\u00f3w"}
{"answers": {"text": ["Warsaw City Council", "Warsaw City Council", "Warsaw City Council"], "answer_start": [54, 54, 54]}, "prediction_text": "City Council"}
{"answers": {"text": ["60", "60", "60"], "answer_start": [105, 105, 105]}, "prediction_text": "60 members"}
{"answers": {"text": ["every four years", "four years", "every four years."], "answer_start": [154, 160, 154]}, "prediction_text": "Every four years"}
{"answers": {"text": ["committees", "committees", "committees"], "answer_start": [239, 239, 239]}, "prediction_text": "Committees"}
{"answers": {"text": ["30 days", "30", "30"], "answer_start": [475, 475, 475]}, "prediction_text": "30 days"}
{"answers": {"text": ["President", "President", "President"], "answer_start": [30, 30, 30]}, "prediction_text": "President"}
{"answers": {"text": ["Jan Andrzej Menich", "Jan Andrzej Menich", "Jan Andrzej Menich"], "answer_start": [246, 246, 246]}, "prediction_text": "Jan Andrzej Menich"}
{"answers": {"text": ["1695\u20131696", "1695\u20131696", "1695\u20131696"], "answer_start": [266, 266, 266]}, "prediction_text": "1695-1696"}
{"answers": {"text": ["the City council", "City council", "City council"], "answer_start": [416, 420, 420]}, "prediction_text": "City council"}
{"answers": {"text": ["Centrum", "Centrum", "Centrum"], "answer_start": [486, 486, 486]}, "prediction_text": "Centrum"}
{"answers": {"text": ["\u015ar\u00f3dmie\u015bcie", "\u015ar\u00f3dmie\u015bcie", "\u015ar\u00f3dmie\u015bcie"], "answer_start": [36, 36, 36]}, "prediction_text": "\u015ar\u00f3dmie\u015bcie"}
{"answers": {"text": ["304,016", "304,016"], "answer_start": [186, 186]}, "prediction_text": "304,016 companies"}
{"answers": {"text": ["emerging market", "emerging market", "emerging market"], "answer_start": [470, 470, 470]}, "prediction_text": "Emerging market"}
{"answers": {"text": ["12%", "12%", "12%"], "answer_start": [620, 620, 620]}, "prediction_text": "12%"}
{"answers": {"text": ["191.766 billion PLN", "191.766 billion PLN", "191.766 billion PLN"], "answer_start": [892, 892, 892]}, "prediction_text": "191.766 billion PLN"}
{"answers": {"text": ["1817", "1817", "1817"], "answer_start": [49, 49, 49]}, "prediction_text": "1817"}
{"answers": {"text": ["World War II", "World War II", "World War II."], "answer_start": [82, 82, 82]}, "prediction_text": "Communist control and reintroduction of a free-market economy."}
{"answers": {"text": ["April 1991", "April 1991", "April 1991"], "answer_start": [121, 121, 121]}, "prediction_text": "April 1991"}
{"answers": {"text": ["374", "374", "374"], "answer_start": [361, 361, 361]}, "prediction_text": "374 companies"}
{"answers": {"text": ["Polish United Workers' Party", "Polish United Workers' Party", "Polish United Workers' Party"], "answer_start": [573, 573, 573]}, "prediction_text": "Polish United Workers' Party (PZPR)"}
{"answers": {"text": ["1951", "1951", "1951"], "answer_start": [39, 39, 39]}, "prediction_text": "1951"}
{"answers": {"text": ["Polonez", "125p", "Polonez"], "answer_start": [235, 196, 235]}, "prediction_text": "Tico"}
{"answers": {"text": ["Daewoo", "Daewoo", "Daewoo"], "answer_start": [440, 440, 440]}, "prediction_text": "Daewoo"}
{"answers": {"text": ["AvtoZAZ", "AvtoZAZ", "AvtoZAZ"], "answer_start": [585, 585, 585]}, "prediction_text": "South Korean car manufacturer Daewoo"}
{"answers": {"text": ["Chevrolet Aveo", "Aveo", "Aveo"], "answer_start": [649, 703, 703]}, "prediction_text": "The license expired in February 2011."}
{"answers": {"text": ["Warszawa", "Warszawa", "Warszawa"], "answer_start": [16, 16, 16]}, "prediction_text": "Warszawa"}
{"answers": {"text": ["Warsaw", "Warsaw", "Warsaw"], "answer_start": [0, 0, 0]}, "prediction_text": "Warsaw (Warsaw)"}
{"answers": {"text": ["Vistula River", "Vistula River", "Vistula"], "answer_start": [129, 129, 129]}, "prediction_text": "Vistula River"}
{"answers": {"text": ["2.666 million residents", "2.666 million", "2.666 million"], "answer_start": [371, 371, 371]}, "prediction_text": "6,100.43"}
{"answers": {"text": ["9th", "9th", "9th"], "answer_start": [419, 419, 419]}, "prediction_text": "9th most-populous capital city"}
{"answers": {"text": ["Warsaw", "Warsaw", "Warsaw"], "answer_start": [0, 0, 0]}, "prediction_text": "Warsaw (Warsaw)"}
{"answers": {"text": ["Vistula", "Vistula River", "Vistula"], "answer_start": [129, 129, 129]}, "prediction_text": "Vistula River"}
{"answers": {"text": ["roughly 260 kilometres", "260 kilometres", "260 kilometres"], "answer_start": [167, 175, 175]}, "prediction_text": "300 kilometres (190 mi)"}
{"answers": {"text": ["2.666 million", "2.666 million", "2.666 million"], "answer_start": [371, 371, 371]}, "prediction_text": "6,100.43"}
{"answers": {"text": ["9th", "9th", "9th"], "answer_start": [419, 419, 419]}, "prediction_text": "9th most populous city"}
{"answers": {"text": ["France", "France", "France", "France"], "answer_start": [159, 159, 159, 159]}, "prediction_text": "France"}
{"answers": {"text": ["10th and 11th centuries", "in the 10th and 11th centuries", "10th and 11th centuries", "10th and 11th centuries"], "answer_start": [94, 87, 94, 94]}, "prediction_text": "10th and 11th centuries"}
{"answers": {"text": ["Denmark, Iceland and Norway", "Denmark, Iceland and Norway", "Denmark, Iceland and Norway", "Denmark, Iceland and Norway"], "answer_start": [256, 256, 256, 256]}, "prediction_text": "Denmark, Iceland, Norway"}
{"answers": {"text": ["Rollo", "Rollo", "Rollo", "Rollo"], "answer_start": [308, 308, 308, 308]}, "prediction_text": "Rollo"}
{"answers": {"text": ["10th century", "the first half of the 10th century", "10th", "10th"], "answer_start": [671, 649, 671, 671]}, "prediction_text": "10th century"}
{"answers": {"text": ["William the Conqueror", "William the Conqueror", "William the Conqueror"], "answer_start": [1022, 1022, 1022]}, "prediction_text": "William the Conqueror"}
{"answers": {"text": ["Richard I", "Richard I", "Richard I"], "answer_start": [573, 573, 573]}, "prediction_text": "Richard I of Normandy"}
{"answers": {"text": ["Catholic", "Catholic orthodoxy", "Catholic"], "answer_start": [230, 230, 230]}, "prediction_text": "Catholic"}
{"answers": {"text": ["Viking", "Norseman, Viking", "Norseman, Viking"], "answer_start": [341, 331, 331]}, "prediction_text": "Viking"}
{"answers": {"text": ["9th century", "9th century", "9th century"], "answer_start": [309, 309, 309]}, "prediction_text": "9th century"}
{"answers": {"text": ["911", "911", "911"], "answer_start": [244, 244, 244]}, "prediction_text": "911"}
{"answers": {"text": ["King Charles III", "King Charles III", "King Charles III"], "answer_start": [324, 324, 324]}, "prediction_text": "King Charles III of West Francia"}
{"answers": {"text": ["Seine", "Epte", "Seine"], "answer_start": [711, 524, 711]}, "prediction_text": "Epte"}
{"answers": {"text": ["Rollo", "Rollo", "Rollo"], "answer_start": [7, 7, 7]}, "prediction_text": "Danes, Norwegians, Norse\u2013Gaels, Orkney Vikings, possibly Swedes."}
{"answers": {"text": ["Catholicism", "Catholicism", "Catholicism"], "answer_start": [121, 121, 121]}, "prediction_text": "Norse religion"}
{"answers": {"text": ["north", "the north", "north"], "answer_start": [327, 323, 327]}, "prediction_text": "North of France"}
{"answers": {"text": ["fighting horsemen", "fighting horsemen", "fighting horsemen"], "answer_start": [428, 428, 428]}, "prediction_text": "Fighting horsemen"}
{"answers": {"text": ["999", "In 999", "999"], "answer_start": [233, 230, 233]}, "prediction_text": "999"}
{"answers": {"text": ["Archangel Michael", "the Archangel Michael", "Archangel Michael"], "answer_start": [621, 617, 621]}, "prediction_text": "Monte Gargano shrine"}
{"answers": {"text": ["Monte Gargano", "at Monte Gargano", "Monte Gargano"], "answer_start": [642, 639, 642]}, "prediction_text": "Monte Gargano"}
{"answers": {"text": ["Drogo", "Drogo", "Drogo"], "answer_start": [627, 627, 627]}, "prediction_text": "Drogo"}
{"answers": {"text": ["William Iron Arm", "William Iron Arm", "William Iron Arm"], "answer_start": [432, 432, 432]}, "prediction_text": "William Iron Arm"}
{"answers": {"text": ["Saracens", "the Saracens", "Saracens"], "answer_start": [76, 72, 76]}, "prediction_text": "Saracens"}
{"answers": {"text": ["1130", "1130", "1130"], "answer_start": [252, 252, 252]}, "prediction_text": "1130"}
{"answers": {"text": ["Squillace", "Squillace", "Squillace"], "answer_start": [536, 536, 536]}, "prediction_text": "Squillace"}
{"answers": {"text": ["Kitab Rudjdjar", "Kitab Rudjdjar", "Kitab Rudjdjar"], "answer_start": [837, 837, 837]}, "prediction_text": "\"Kitab Rudjdjar\""}
{"answers": {"text": ["The Book of Roger", "The Book of Roger", "The Book of Roger"], "answer_start": [855, 855, 855]}, "prediction_text": "The Book of Roger"}
{"answers": {"text": ["meritocratic", "meritocratic", "meritocratic"], "answer_start": [282, 282, 282]}, "prediction_text": "Jews, Muslims, Christians."}
{"answers": {"text": ["Seljuk Turks", "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "the Seljuk Turks"], "answer_start": [161, 114, 157]}, "prediction_text": "Pechenegs"}
{"answers": {"text": ["1050s", "in the 1050s", "in the 1050s"], "answer_start": [85, 78, 78]}, "prediction_text": "1050s"}
{"answers": {"text": ["1060s", "In the 1060s", "In the 1060s"], "answer_start": [292, 285, 285]}, "prediction_text": "1060s"}
{"answers": {"text": ["Alexius Komnenos", "Alexius Komnenos", "Alexius Komnenos"], "answer_start": [522, 522, 522]}, "prediction_text": "Alexius Komnenos"}
{"answers": {"text": ["Afranji", "Afranji", "Afranji"], "answer_start": [539, 539, 539]}, "prediction_text": "Afranji"}
{"answers": {"text": ["Oursel", "Oursel", "Oursel"], "answer_start": [256, 256, 256]}, "prediction_text": "Oursel"}
{"answers": {"text": ["Turkish forces", "Turkish forces", "Turkish forces"], "answer_start": [20, 20, 20]}, "prediction_text": "Turkish forces"}
{"answers": {"text": ["Norman mercenary", "an Italo-Norman named Raoul", "descended from an Italo-Norman named Raoul"], "answer_start": [45, 217, 202]}, "prediction_text": "Norman mercenary origin"}
{"answers": {"text": ["Robert Guiscard", "Robert Guiscard", "Robert Guiscard"], "answer_start": [0, 0, 0]}, "prediction_text": "Robert Guiscard"}
{"answers": {"text": ["1082", "February 1082", "February 1082"], "answer_start": [1315, 1306, 1306]}, "prediction_text": "1085"}
{"answers": {"text": ["30,000", "30,000", "30,000"], "answer_start": [492, 492, 492]}, "prediction_text": "30,000 men"}
{"answers": {"text": ["Deabolis", "Deabolis", "Deabolis"], "answer_start": [302, 718, 718]}, "prediction_text": "Deabolis"}
{"answers": {"text": ["Bohemond", "Bohemond", "Bohemond"], "answer_start": [79, 79, 79]}, "prediction_text": "Robert's son was Robert the Great's son."}
{"answers": {"text": ["Deabolis", "the river Deabolis", "Deabolis"], "answer_start": [302, 292, 302]}, "prediction_text": "Deabolis"}
{"answers": {"text": ["1185", "in 1185", "1185"], "answer_start": [86, 83, 86]}, "prediction_text": "1185"}
{"answers": {"text": ["Dyrrachium", "Dyrrachium", "Dyrrachium"], "answer_start": [125, 205, 205]}, "prediction_text": "Dyrrachium"}
{"answers": {"text": ["the Adriatic", "the Adriatic", "Adriatic"], "answer_start": [257, 257, 261]}, "prediction_text": "Adriatic"}
{"answers": {"text": ["King Ethelred II", "Ethelred II", "King Ethelred II"], "answer_start": [360, 365, 360]}, "prediction_text": "King Ethelred II of England"}
{"answers": {"text": ["Duke Richard II", "Duke Richard II", "Duke Richard II"], "answer_start": [327, 327, 327]}, "prediction_text": "Ethelred II"}
{"answers": {"text": ["Normandy", "Normandy", "Normandy"], "answer_start": [423, 423, 423]}, "prediction_text": "Normandy (until 1016)"}
{"answers": {"text": ["Sweyn Forkbeard", "Sweyn Forkbeard", "Sweyn Forkbeard"], "answer_start": [480, 480, 480]}, "prediction_text": "Sweyn Forkbeard"}
{"answers": {"text": ["Harthacnut", "Harthacnut", "Harthacnut"], "answer_start": [115, 115, 115]}, "prediction_text": "Harthacnut"}
{"answers": {"text": ["1041", "in 1041", "1041"], "answer_start": [71, 68, 71]}, "prediction_text": "1041"}
{"answers": {"text": ["Robert of Jumi\u00e8ges", "Robert of Jumi\u00e8ges", "Robert of Jumi\u00e8ges"], "answer_start": [382, 382, 382]}, "prediction_text": "Robert of Jumi\u00e8ges"}
{"answers": {"text": ["Battle of Hastings", "the Battle of Hastings", "at the Battle of Hastings"], "answer_start": [85, 81, 78]}, "prediction_text": "Battle of Hastings"}
{"answers": {"text": ["William II", "Duke William II", "Duke William II"], "answer_start": [14, 9, 9]}, "prediction_text": "King Harold II"}
{"answers": {"text": ["1066", "In 1066", "1066"], "answer_start": [3, 0, 3]}, "prediction_text": "1066"}
{"answers": {"text": ["Anglo-Saxons", "the Anglo-Saxons", "Anglo-Saxons"], "answer_start": [161, 157, 161]}, "prediction_text": "Anglo-Saxons"}
{"answers": {"text": ["Modern English", "Modern English", "Modern English"], "answer_start": [629, 629, 629]}, "prediction_text": "Anglo-Saxon language"}
{"answers": {"text": ["1169", "1169", "1169"], "answer_start": [101, 101, 101]}, "prediction_text": "1169"}
{"answers": {"text": ["Ireland", "Ireland", "Ireland"], "answer_start": [379, 379, 379]}, "prediction_text": "Ireland"}
{"answers": {"text": ["Irish", "Irish", "Irish"], "answer_start": [37, 220, 220]}, "prediction_text": "Irish culture"}
{"answers": {"text": ["Edgar", "Edgar", "Edgar Atheling"], "answer_start": [75, 157, 75]}, "prediction_text": "Edgar Atheling"}
{"answers": {"text": ["King Malcolm III of Scotland", "King Malcolm III", "King Malcolm III"], "answer_start": [120, 120, 120]}, "prediction_text": "Edgar Atheling"}
{"answers": {"text": ["1072", "1072", "1072"], "answer_start": [300, 300, 300]}, "prediction_text": "1072"}
{"answers": {"text": ["Duncan", "Duncan", "Duncan"], "answer_start": [440, 440, 440]}, "prediction_text": "Duncan (as a hostage)"}
{"answers": {"text": ["Sybilla of Normandy", "Sybilla of Normandy", "Sybilla"], "answer_start": [271, 271, 271]}, "prediction_text": "Sybilla of Normandy"}
{"answers": {"text": ["Norman", "Norman", "Norman"], "answer_start": [336, 336, 336]}, "prediction_text": "Normans"}
{"answers": {"text": ["Hereford", "Hereford", "Hereford"], "answer_start": [158, 158, 158]}, "prediction_text": "Hereford"}
{"answers": {"text": ["the Welsh", "the Welsh", "the Welsh"], "answer_start": [227, 227, 227]}, "prediction_text": "Welsh"}
{"answers": {"text": ["Edward the Confessor", "Edward the Confessor", "Edward the Confessor"], "answer_start": [90, 90, 90]}, "prediction_text": "Edward the Confessor"}
{"answers": {"text": ["Wales", "Wales", "Wales"], "answer_start": [299, 299, 299]}, "prediction_text": "Wales"}
{"answers": {"text": ["1018", "1064", "1018"], "answer_start": [221, 345, 221]}, "prediction_text": "1064"}
{"answers": {"text": ["William of Montreuil", "William of Montreuil", "William of Montreuil"], "answer_start": [380, 380, 380]}, "prediction_text": "William of Montreuil"}
{"answers": {"text": ["1097", "1097", "1097"], "answer_start": [267, 267, 267]}, "prediction_text": "1097"}
{"answers": {"text": ["Tancred", "Tancred", "Tancred"], "answer_start": [100, 100, 100]}, "prediction_text": "Tancred"}
{"answers": {"text": ["Jerusalem", "Jerusalem", "Jerusalem"], "answer_start": [390, 390, 390]}, "prediction_text": "Jerusalem conquest"}
{"answers": {"text": ["380 years", "380 years", "380 years"], "answer_start": [189, 189, 189]}, "prediction_text": "380 years"}
{"answers": {"text": ["a storm", "a storm", "a storm"], "answer_start": [99, 99, 99]}, "prediction_text": "The treasure ship"}
{"answers": {"text": ["Berengaria", "Berengaria", "Berengaria"], "answer_start": [218, 218, 218]}, "prediction_text": "Berengaria"}
{"answers": {"text": ["1191", "1191", "1191"], "answer_start": [9, 9, 9]}, "prediction_text": "1191"}
{"answers": {"text": ["Isaac Komnenos", "Isaac", "Isaac Komnenos"], "answer_start": [421, 522, 421]}, "prediction_text": "Isaac Komnenos"}
{"answers": {"text": ["Conrad of Montferrat", "Conrad of Montferrat", "Conrad of Montferrat"], "answer_start": [188, 188, 188]}, "prediction_text": "Conrad of Montferrat"}
{"answers": {"text": ["silver", "silver", "silver"], "answer_start": [565, 565, 565]}, "prediction_text": "Silver chains"}
{"answers": {"text": ["Guy de Lusignan", "Guy de Lusignan", "Guy de Lusignan"], "answer_start": [85, 508, 508]}, "prediction_text": "Richard de Camville and Robert de Thornham"}
{"answers": {"text": ["Richard the Lion-Heart", "Richard the Lion-Heart", "Richard the Lion-Heart"], "answer_start": [19, 19, 19]}, "prediction_text": "Richard Lion-Heart"}
{"answers": {"text": ["12 May 1191", "12 May 1191", "12 May 1191"], "answer_start": [147, 147, 147]}, "prediction_text": "12 May 1191"}
{"answers": {"text": ["double coronation", "double", "double"], "answer_start": [359, 359, 359]}, "prediction_text": "Richard caused himself to be crowned King of Cyprus."}
{"answers": {"text": ["1489", "1489", "1489"], "answer_start": [419, 419, 419]}, "prediction_text": "1489"}
{"answers": {"text": ["Knights Templar", "the Knights Templar", "the Knights Templar"], "answer_start": [290, 286, 286]}, "prediction_text": "Knights Templar"}
{"answers": {"text": ["Africa", "Africa", "Africa"], "answer_start": [219, 219, 219]}, "prediction_text": "Africa"}
{"answers": {"text": ["Bethencourt", "Bethencourt", "Bethencourt"], "answer_start": [0, 0, 0]}, "prediction_text": "Henry III of Castile"}
{"answers": {"text": ["Enrique P\u00e9rez de Guzm\u00e1n", "Enrique P\u00e9rez de Guzm\u00e1n", "Enrique P\u00e9rez de Guzm\u00e1n"], "answer_start": [172, 172, 172]}, "prediction_text": "Enrique P\u00e9rez de Guzm\u00e1n"}
{"answers": {"text": ["Maciot de Bethencourt", "Maciot de Bethencourt", "Maciot de Bethencourt"], "answer_start": [116, 116, 116]}, "prediction_text": "Enrique P\u00e9rez de Guzm\u00e1n"}
{"answers": {"text": ["Channel Islands", "the Channel Islands", "the Channel Islands"], "answer_start": [155, 151, 151]}, "prediction_text": "Channel Islands"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [212, 212, 212]}, "prediction_text": "Two customaries"}
{"answers": {"text": ["Romanesque", "Romanesque", "Romanesque"], "answer_start": [135, 135, 135]}, "prediction_text": "Romanesque idiom"}
{"answers": {"text": ["rounded", "rounded", "rounded"], "answer_start": [332, 332, 332]}, "prediction_text": "Round arches"}
{"answers": {"text": ["Early Gothic", "Early Gothic", "Early Gothic"], "answer_start": [108, 108, 108]}, "prediction_text": "Early Gothic"}
{"answers": {"text": ["Anglo-Saxon", "Anglo-Saxon", "Anglo-Saxon"], "answer_start": [79, 79, 79]}, "prediction_text": "Early Gothic"}
{"answers": {"text": ["Sicily", "Sicily", "Kingdom of Sicily"], "answer_start": [328, 328, 317]}, "prediction_text": "Sicily"}
{"answers": {"text": ["early 11th century", "11th century", "in the early 11th century"], "answer_start": [129, 135, 122]}, "prediction_text": "Early 11th century"}
{"answers": {"text": ["dukes", "the dukes", "dukes"], "answer_start": [152, 422, 426]}, "prediction_text": "The dukes used the church to unify themselves."}
{"answers": {"text": ["16th century", "the 16th century", "in the 16th century"], "answer_start": [35, 31, 28]}, "prediction_text": "16th century"}
{"answers": {"text": ["embroidery", "embroidery", "embroidery"], "answer_start": [104, 104, 104]}, "prediction_text": "Embroidery"}
{"answers": {"text": ["Bayeux Tapestry", "the Bayeux Tapestry", "the Bayeux Tapestry"], "answer_start": [49, 45, 45]}, "prediction_text": "Bayeux Tapestry"}
{"answers": {"text": ["Odo", "Odo", "Odo"], "answer_start": [139, 139, 139]}, "prediction_text": "Odo the Bishop of Bayeux"}
{"answers": {"text": ["mosaics", "mosaics", "mosaics"], "answer_start": [466, 466, 466]}, "prediction_text": "Fonts, capitals, and mosaics."}
{"answers": {"text": ["11th", "the 11th", "11th"], "answer_start": [97, 93, 97]}, "prediction_text": "11th century"}
{"answers": {"text": ["William of Volpiano and John of Ravenna", "William of Volpiano and John of Ravenna", "William of Volpiano and John of Ravenna"], "answer_start": [234, 234, 234]}, "prediction_text": "William of Volpiano and John of Ravenna"}
{"answers": {"text": ["southern Italy", "southern Italy", "southern Italy"], "answer_start": [179, 179, 179]}, "prediction_text": "Southern Italy"}
{"answers": {"text": ["Latin monastery at Sant'Eufemia.", "a Latin monastery at Sant'Eufemia", "Sant'Eufemia"], "answer_start": [259, 257, 278]}, "prediction_text": "Sant'Eufemia"}
{"answers": {"text": ["Robert Guiscard", "Robert Guiscard", "Robert Guiscard"], "answer_start": [225, 225, 225]}, "prediction_text": "Robert Guiscard"}
{"answers": {"text": ["singing", "singing", "singing"], "answer_start": [32, 32, 330]}, "prediction_text": "Singing"}
{"answers": {"text": ["1856", "1856", "1856"], "answer_start": [54, 54, 54]}, "prediction_text": "10 July 1856"}
{"answers": {"text": ["Serbian", "Serbian", "Serbian"], "answer_start": [14, 14, 14]}, "prediction_text": "Serbian"}
{"answers": {"text": ["1943", "1943", "1943"], "answer_start": [71, 71, 71]}, "prediction_text": "1943"}
{"answers": {"text": ["1856", "10 July 1856", "1856"], "answer_start": [54, 46, 54]}, "prediction_text": "10 July 1856"}
{"answers": {"text": ["1943", "1943", "1943"], "answer_start": [71, 71, 71]}, "prediction_text": "1943"}
{"answers": {"text": ["Serbian", "Serbian", "Serbian"], "answer_start": [14, 83, 14]}, "prediction_text": "Serbia"}
{"answers": {"text": ["alternating current", "alternating current", "alternating current"], "answer_start": [237, 237, 237]}, "prediction_text": "Alternating Current"}
{"answers": {"text": ["1884", "1884", "1884"], "answer_start": [106, 106, 106]}, "prediction_text": "1884"}
{"answers": {"text": ["Thomas Edison", "Thomas Edison", "Thomas Edison"], "answer_start": [123, 123, 123]}, "prediction_text": "George Westinghouse"}
{"answers": {"text": ["George Westinghouse", "George Westinghouse", "George Westinghouse"], "answer_start": [354, 354, 354]}, "prediction_text": "George Westinghouse"}
{"answers": {"text": ["New York City", "New York City", "New York City"], "answer_start": [140, 140, 140]}, "prediction_text": "New York City"}
{"answers": {"text": ["War of Currents", "War of Currents", "War of Currents"], "answer_start": [556, 556, 556]}, "prediction_text": "War of Currents"}
{"answers": {"text": ["1884", "1884", "1884"], "answer_start": [106, 106, 106]}, "prediction_text": "1884"}
{"answers": {"text": ["Thomas Edison", "Thomas Edison", "Thomas Edison"], "answer_start": [123, 123, 123]}, "prediction_text": "Thomas Edison"}
{"answers": {"text": ["New York City", "New York City", "New York City"], "answer_start": [140, 140, 140]}, "prediction_text": "New York City"}
{"answers": {"text": ["George Westinghouse", "George Westinghouse", "George Westinghouse"], "answer_start": [354, 354, 354]}, "prediction_text": "George Westinghouse"}
{"answers": {"text": ["transformer", "transformer", "transformer"], "answer_start": [325, 325, 325]}, "prediction_text": "AC induction motor and transformer"}
{"answers": {"text": ["1893", "1893", "1893"], "answer_start": [188, 188, 188]}, "prediction_text": "1893"}
{"answers": {"text": ["high-voltage", "high-voltage", "high-voltage"], "answer_start": [91, 91, 91]}, "prediction_text": "High-voltage"}
{"answers": {"text": ["mechanical oscillators/generators, electrical discharge tubes, and early X-ray imaging", "power experiments", "high-voltage, high-frequency power"], "answer_start": [484, 120, 91]}, "prediction_text": "Wireless lighting and electricity distribution"}
{"answers": {"text": ["Colorado Springs", "Colorado Springs", "Colorado Springs"], "answer_start": [154, 154, 154]}, "prediction_text": "Colorado Springs"}
{"answers": {"text": ["1893", "1893", "1893"], "answer_start": [188, 188, 188]}, "prediction_text": "1893"}
{"answers": {"text": ["boat", "boat", "boat"], "answer_start": [608, 608, 608]}, "prediction_text": "A boat"}
{"answers": {"text": ["Wardenclyffe Tower project", "Wardenclyffe Tower", "Wardenclyffe Tower"], "answer_start": [399, 399, 399]}, "prediction_text": "Wardenclyffe Tower"}
{"answers": {"text": ["1943", "1943", "1943"], "answer_start": [399, 399, 399]}, "prediction_text": "1943"}
{"answers": {"text": ["SI unit of magnetic flux density", "the SI unit of magnetic flux density", "SI unit of magnetic flux density"], "answer_start": [529, 525, 529]}, "prediction_text": "General Conference on Weights and Measures"}
{"answers": {"text": ["New York hotels", "New York hotels", "New York hotels"], "answer_start": [334, 334, 334]}, "prediction_text": "New York hotels"}
{"answers": {"text": ["mad scientist", "mad scientist", "mad scientist"], "answer_start": [130, 130, 130]}, "prediction_text": "Mad scientist"}
{"answers": {"text": ["patents", "His patents", "His patents"], "answer_start": [150, 146, 146]}, "prediction_text": "With patents and money"}
{"answers": {"text": ["1943", "1943", "1943"], "answer_start": [399, 399, 399]}, "prediction_text": "1943"}
{"answers": {"text": ["SI unit of magnetic flux density", "the SI unit of magnetic flux density", "SI unit of magnetic flux density"], "answer_start": [529, 525, 529]}, "prediction_text": "Tesla in honor of the General Conference on Weights and Measures."}
{"answers": {"text": ["1990s", "the 1990s", "1990s"], "answer_start": [653, 649, 653]}, "prediction_text": "1990s"}
{"answers": {"text": ["showmanship", "showmanship", "showmanship"], "answer_start": [44, 44, 44]}, "prediction_text": "Showmanship and patents"}
{"answers": {"text": ["Croatia", "Croatia", "Croatia"], "answer_start": [120, 120, 120]}, "prediction_text": "Austria (modern-day Croatia)"}
{"answers": {"text": ["priest", "priest", "Serbian Orthodox priest"], "answer_start": [180, 180, 163]}, "prediction_text": "Serbian Orthodox priest"}
{"answers": {"text": ["eidetic", "eidetic", "eidetic"], "answer_start": [451, 451, 451]}, "prediction_text": "He had a talent for making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems."}
{"answers": {"text": ["his mother's genetics", "his mother", "his mother"], "answer_start": [492, 492, 492]}, "prediction_text": "His mother's genetics"}
{"answers": {"text": ["priest", "priest", "Serbian Orthodox priest"], "answer_start": [180, 180, 163]}, "prediction_text": "Serbian Orthodox priest"}
{"answers": {"text": ["Milutin Tesla", "Milutin Tesla", "Milutin Tesla"], "answer_start": [142, 142, 142]}, "prediction_text": "Milutin Tesla"}
{"answers": {"text": ["\u0110uka Tesla", "\u0110uka Tesla", "\u0110uka Tesla (n\u00e9e Mandi\u0107)"], "answer_start": [204, 204, 204]}, "prediction_text": "\u0110uka Tesla"}
{"answers": {"text": ["making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems", "making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems", "making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems"], "answer_start": [291, 291, 291]}, "prediction_text": "Made home craft tools, mechanical appliances, and memorized Serbian epic poems."}
{"answers": {"text": ["his mother's genetics and influence", "his mother", "his mother's genetics and influence"], "answer_start": [492, 492, 492]}, "prediction_text": "From Serbian Orthodox priest family"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [14, 14, 14]}, "prediction_text": "Five siblings"}
{"answers": {"text": ["German", "German", "German"], "answer_start": [270, 270, 270]}, "prediction_text": "German"}
{"answers": {"text": ["1862", "1862", "1862"], "answer_start": [307, 307, 307]}, "prediction_text": "1862"}
{"answers": {"text": ["Dane", "Dane", "Dane"], "answer_start": [69, 69, 69]}, "prediction_text": "Dane"}
{"answers": {"text": ["Milka, Angelina and Marica", "Milka, Angelina and Marica", "Milka, Angelina and Marica"], "answer_start": [93, 93, 93]}, "prediction_text": "Angelina, Milka, Marica"}
{"answers": {"text": ["killed in a horse-riding accident", "killed in a horse-riding accident", "killed in a horse-riding accident"], "answer_start": [130, 130, 130]}, "prediction_text": "He was killed in a horse-riding accident."}
{"answers": {"text": ["Gospi\u0107, Austrian Empire", "Gospi\u0107", "Gospi\u0107"], "answer_start": [339, 339, 339]}, "prediction_text": "Gospi\u0107, Austrian Empire"}
{"answers": {"text": ["pastor", "a pastor", "pastor"], "answer_start": [397, 395, 397]}, "prediction_text": "Pastor"}
{"answers": {"text": ["Martin Sekuli\u0107", "Martin Sekuli\u0107", "math teacher Martin Sekuli\u0107"], "answer_start": [134, 134, 121]}, "prediction_text": "Martin Sekuli\u0107"}
{"answers": {"text": ["German", "German", "German"], "answer_start": [178, 178, 178]}, "prediction_text": "German"}
{"answers": {"text": ["integral calculus", "integral calculus", "integral calculus"], "answer_start": [278, 278, 278]}, "prediction_text": "Integral calculus"}
{"answers": {"text": ["cheating", "cheating", "cheating"], "answer_start": [360, 360, 360]}, "prediction_text": "Cheating"}
{"answers": {"text": ["1873", "1873", "1873"], "answer_start": [429, 429, 429]}, "prediction_text": "1873"}
{"answers": {"text": ["1870", "In 1870", "1870"], "answer_start": [3, 0, 3]}, "prediction_text": "1870"}
{"answers": {"text": ["to attend school", "to attend school", "attend school at the Higher Real Gymnasium"], "answer_start": [34, 34, 37]}, "prediction_text": "To attend school"}
{"answers": {"text": ["Martin Sekuli\u0107", "Martin Sekuli\u0107", "math teacher Martin Sekuli\u0107"], "answer_start": [134, 134, 121]}, "prediction_text": "Martin Sekuli\u0107"}
{"answers": {"text": ["German", "German", "German"], "answer_start": [178, 178, 178]}, "prediction_text": "German"}
{"answers": {"text": ["1873", "1873", "1873"], "answer_start": [429, 429, 429]}, "prediction_text": "1873"}
{"answers": {"text": ["cholera", "cholera", "cholera"], "answer_start": [94, 94, 94]}, "prediction_text": "Cholera"}
{"answers": {"text": ["nine months", "nine months", "nine months"], "answer_start": [124, 124, 124]}, "prediction_text": "Nine months"}
{"answers": {"text": ["the best engineering school", "to send him to the best engineering school", "send him to the best engineering school if he recovered"], "answer_start": [235, 220, 223]}, "prediction_text": "Sent him to the best engineering school"}
{"answers": {"text": ["enter the priesthood", "enter the priesthood", "enter the priesthood"], "answer_start": [337, 337, 337]}, "prediction_text": "Enter the priesthood"}
{"answers": {"text": ["Smiljan", "Smiljan", "his birthtown, Smiljan"], "answer_start": [42, 42, 27]}, "prediction_text": "Smiljan"}
{"answers": {"text": ["1873", "1873", "1873"], "answer_start": [3, 3, 3]}, "prediction_text": "1873"}
{"answers": {"text": ["cholera", "cholera", "cholera"], "answer_start": [94, 94, 94]}, "prediction_text": "Cholera"}
{"answers": {"text": ["nine months", "nine months", "nine months"], "answer_start": [124, 124, 124]}, "prediction_text": "Nine months"}
{"answers": {"text": ["enter the priesthood", "the priesthood", "enter the priesthood"], "answer_start": [337, 343, 337]}, "prediction_text": "To send him to the best engineering school"}
{"answers": {"text": ["to send him to the best engineering school", "to send him to the best engineering school", "promised to send him to the best engineering school"], "answer_start": [220, 220, 211]}, "prediction_text": "Sent him to the best engineering school"}
{"answers": {"text": ["Tomingaj", "Tomingaj", "Tomingaj"], "answer_start": [97, 97, 97]}, "prediction_text": "Near Gra\u010dac"}
{"answers": {"text": ["Mark Twain", "Mark Twain's", "Mark Twain's"], "answer_start": [319, 319, 319]}, "prediction_text": "Mark Twain's works"}
{"answers": {"text": ["the mountains", "the mountains", "mountains"], "answer_start": [139, 139, 143]}, "prediction_text": "Mountains"}
{"answers": {"text": ["1874", "1874", "1874"], "answer_start": [3, 3, 3]}, "prediction_text": "1874"}
{"answers": {"text": ["hunter's garb", "hunter's garb", "hunter's garb"], "answer_start": [156, 156, 156]}, "prediction_text": "Hunter's garb"}
{"answers": {"text": ["being drafted into the Austro-Hungarian Army", "being drafted", "being drafted into the Austro-Hungarian Army"], "answer_start": [22, 22, 22]}, "prediction_text": "To Tomingaj"}
{"answers": {"text": ["1874", "In 1874", "1874"], "answer_start": [3, 0, 3]}, "prediction_text": "1874"}
{"answers": {"text": ["he explored the mountains in hunter's garb", "he explored", "explored the mountains in hunter's garb"], "answer_start": [127, 127, 130]}, "prediction_text": "Explored the mountains"}
{"answers": {"text": ["Mark Twain", "Mark Twain", "Mark Twain"], "answer_start": [319, 319, 319]}, "prediction_text": "Mark Twain"}
{"answers": {"text": ["1875", "1875", "1875"], "answer_start": [3, 3, 3]}, "prediction_text": "1875"}
{"answers": {"text": ["Austrian Polytechnic", "Austrian Polytechnic", "Austrian Polytechnic"], "answer_start": [27, 27, 27]}, "prediction_text": "Austrian Polytechnic"}
{"answers": {"text": ["1879", "1879", "1879"], "answer_start": [611, 611, 611]}, "prediction_text": "1879"}
{"answers": {"text": ["gambling", "gambling", "gambling"], "answer_start": [1012, 1012, 1012]}, "prediction_text": "Overwork and gambling."}
{"answers": {"text": ["no", "not", "He never graduated"], "answer_start": [474, 1436, 1389]}, "prediction_text": "No, Tesla did not graduate from the university."}
{"answers": {"text": ["Graz, Austria", "in Graz, Austria", "Graz, Austria"], "answer_start": [51, 48, 51]}, "prediction_text": "Graz, Austria"}
{"answers": {"text": ["1875", "In 1875", "1875"], "answer_start": [3, 0, 3]}, "prediction_text": "1875"}
{"answers": {"text": ["1879", "in 1879", "1879"], "answer_start": [611, 608, 611]}, "prediction_text": "1879"}
{"answers": {"text": ["gambled", "gambling", "gambling"], "answer_start": [1051, 1012, 1012]}, "prediction_text": "He gambled away his allowance and his tuition money."}
{"answers": {"text": ["Tesla would be killed through overwork", "killed through overwork", "would be killed through overwork"], "answer_start": [738, 753, 744]}, "prediction_text": "Overwork"}
{"answers": {"text": ["left Graz", "left Graz", "left Graz and severed all relations with his family"], "answer_start": [24, 24, 24]}, "prediction_text": "Left Graz and hid the fact that he dropped out of school."}
{"answers": {"text": ["to hide the fact that he dropped out of school", "hide the fact that he dropped out of school", "to hide the fact that he dropped out of school"], "answer_start": [76, 79, 76]}, "prediction_text": "To hide the fact that he dropped out of school."}
{"answers": {"text": ["a draftsman", "a draftsman", "as a draftsman"], "answer_start": [242, 242, 239]}, "prediction_text": "A draftsman"}
{"answers": {"text": ["return home", "return home", "return home"], "answer_start": [410, 410, 410]}, "prediction_text": "Return home"}
{"answers": {"text": ["nervous breakdown", "nervous breakdown", "nervous breakdown"], "answer_start": [461, 461, 461]}, "prediction_text": "A nervous breakdown"}
{"answers": {"text": ["1878", "December 1878", "to hide the fact that he dropped out of school"], "answer_start": [12, 3, 76]}, "prediction_text": "December 1878"}
{"answers": {"text": ["that he dropped out of school", "the fact that he dropped out of school", "he dropped out of school"], "answer_start": [93, 84, 98]}, "prediction_text": "He dropped out of school."}
{"answers": {"text": ["His friends thought that he had drowned in the Mur River.", "drowned in the Mur River", "drowned in the Mur River"], "answer_start": [124, 156, 156]}, "prediction_text": "He drowned in the Mur River."}
{"answers": {"text": ["draftsman", "he worked as a draftsman", "draftsman"], "answer_start": [244, 229, 244]}, "prediction_text": "Worked as a draftsman."}
{"answers": {"text": ["nervous breakdown", "a nervous breakdown", "nervous breakdown"], "answer_start": [461, 459, 461]}, "prediction_text": "A nervous breakdown"}
{"answers": {"text": ["not having a residence permit", "not having a residence permit", "not having a residence permit"], "answer_start": [70, 70, 70]}, "prediction_text": "For not having a residence permit."}
{"answers": {"text": ["March 1879", "On 24 March 1879", "24 March 1879"], "answer_start": [6, 0, 3]}, "prediction_text": "March 24, 1879"}
{"answers": {"text": ["60", "60", "60"], "answer_start": [152, 152, 152]}, "prediction_text": "60 years old"}
{"answers": {"text": ["a stroke"], "answer_start": [239]}, "prediction_text": "A stroke"}
{"answers": {"text": ["taught", "Higher Real Gymnasium", "taught a large class of students"], "answer_start": [274, 326, 274]}, "prediction_text": "Teach a large class of students."}
{"answers": {"text": ["for not having a residence permit.", "for not having a residence permit", "not having a residence permit"], "answer_start": [66, 66, 70]}, "prediction_text": "For not having a residence permit."}
{"answers": {"text": ["1879", "On 24 March 1879,", "24 March 1879"], "answer_start": [12, 0, 3]}, "prediction_text": "March 1879"}
{"answers": {"text": ["Higher Real Gymnasium", "Higher Real Gymnasium", "Higher Real Gymnasium"], "answer_start": [326, 326, 326]}, "prediction_text": "Higher Real Gymnasium"}
{"answers": {"text": ["stroke", "a stroke", "a stroke"], "answer_start": [241, 239, 239]}, "prediction_text": "A stroke"}
{"answers": {"text": ["Prague", "Prague", "Prague"], "answer_start": [94, 94, 94]}, "prediction_text": "Prague"}
{"answers": {"text": ["arrived too late", "arrived too late to enroll", "he arrived too late to enroll at Charles-Ferdinand University; he never studied Greek, a required subject; and he was illiterate in Czech"], "answer_start": [142, 142, 139]}, "prediction_text": "He was illiterate."}
{"answers": {"text": ["as an auditor", "as an auditor", "as an auditor"], "answer_start": [369, 369, 369]}, "prediction_text": "He attended lectures."}
{"answers": {"text": ["Charles-Ferdinand University", "Charles-Ferdinand University", "Charles-Ferdinand University"], "answer_start": [172, 172, 172]}, "prediction_text": "Charles-Ferdinand University"}
{"answers": {"text": ["Prague", "Prague", "Prague"], "answer_start": [94, 94, 94]}, "prediction_text": "Prague"}
{"answers": {"text": ["1880", "In January 1880", "In January 1880"], "answer_start": [11, 0, 0]}, "prediction_text": "January 1880"}
{"answers": {"text": ["Charles-Ferdinand University", "at Charles-Ferdinand University", "Charles-Ferdinand University"], "answer_start": [172, 169, 172]}, "prediction_text": "Charles-Ferdinand University"}
{"answers": {"text": ["two of Tesla's uncles", "Tesla's uncles", "two of Tesla's uncles"], "answer_start": [17, 24, 17]}, "prediction_text": "Uncles"}
{"answers": {"text": ["Budapest", "to Budapest", "Budapest"], "answer_start": [24, 21, 24]}, "prediction_text": "Budapest"}
{"answers": {"text": ["Budapest Telephone Exchange", "the Budapest Telephone Exchange", "Budapest Telephone Exchange"], "answer_start": [304, 85, 89]}, "prediction_text": "Budapest Telephone Exchange"}
{"answers": {"text": ["chief electrician", "chief electrician", "chief electrician"], "answer_start": [378, 378, 378]}, "prediction_text": "Chief electrician"}
{"answers": {"text": ["a telephone repeater or amplifier", "a telephone repeater or amplifier", "a telephone repeater or amplifier"], "answer_start": [521, 521, 521]}, "prediction_text": "Telephone repeater or amplifier"}
{"answers": {"text": ["draftsman", "chief electrician", "draftsman"], "answer_start": [228, 378, 228]}, "prediction_text": "Chief electrician"}
{"answers": {"text": ["1881", "1881", "1881"], "answer_start": [3, 3, 3]}, "prediction_text": "1881"}
{"answers": {"text": ["a telegraph company", "the Budapest Telephone Exchange", "Budapest Telephone Exchange"], "answer_start": [64, 85, 89]}, "prediction_text": "Budapest Telephone Exchange"}
{"answers": {"text": ["Budapest Telephone Exchange", "the Budapest Telephone Exchange", "Budapest Telephone Exchange"], "answer_start": [89, 85, 89]}, "prediction_text": "Budapest Telephone Exchange"}
{"answers": {"text": ["chief electrician", "chief electrician", "chief electrician"], "answer_start": [378, 378, 378]}, "prediction_text": "Chief electrician"}
{"answers": {"text": ["1882", "1882", "1882"], "answer_start": [3, 3, 3]}, "prediction_text": "1882"}
{"answers": {"text": ["France", "in France", "France"], "answer_start": [67, 64, 67]}, "prediction_text": "France"}
{"answers": {"text": ["New York City", "to New York City", "New York City"], "answer_start": [164, 161, 164]}, "prediction_text": "New York City"}
{"answers": {"text": ["Thomas Edison", "Thomas Edison", "Thomas Edison"], "answer_start": [206, 206, 206]}, "prediction_text": "Thomas Edison"}
{"answers": {"text": ["Edison Machine Works", "Edison Machine Works", "Edison Machine Works"], "answer_start": [235, 235, 235]}, "prediction_text": "France"}
{"answers": {"text": ["Continental Edison Company", "Continental Edison Company", "Continental Edison Company"], "answer_start": [37, 37, 37]}, "prediction_text": "New York City"}
{"answers": {"text": ["France", "in France", "France"], "answer_start": [67, 64, 67]}, "prediction_text": "France"}
{"answers": {"text": ["1884", "1884", "1884"], "answer_start": [142, 142, 142]}, "prediction_text": "June 1884"}
{"answers": {"text": ["Thomas Edison", "Thomas Edison", "Thomas Edison"], "answer_start": [206, 206, 206]}, "prediction_text": "Thomas Edison"}
{"answers": {"text": ["Manhattan's lower east side", "Manhattan's lower east side", "New York City"], "answer_start": [259, 259, 164]}, "prediction_text": "Lower east side of Manhattan"}
{"answers": {"text": ["fifty thousand dollars", "fifty thousand dollars", "fifty thousand dollars"], "answer_start": [281, 281, 281]}, "prediction_text": "$18 per week"}
{"answers": {"text": ["$10 a week raise", "a US$10 a week raise", "a US$10 a week raise over Tesla's US$18 per week salary"], "answer_start": [690, 686, 686]}, "prediction_text": "A US$10 a week raise over Tesla's salary."}
{"answers": {"text": ["months", "months", "months"], "answer_start": [490, 490, 490]}, "prediction_text": "Months of work"}
{"answers": {"text": ["fifty thousand dollars", "fifty thousand dollars", "fifty thousand dollars"], "answer_start": [281, 281, 281]}, "prediction_text": "$10 a week"}
{"answers": {"text": ["American humor.", "Tesla, you don't understand our American humor", "you don't understand our American humor"], "answer_start": [641, 609, 616]}, "prediction_text": "Edison was joking."}
{"answers": {"text": ["US$10 a week raise", "a US$10 a week raise", "a US$10 a week raise"], "answer_start": [688, 686, 686]}, "prediction_text": "US$10 a week raise"}
{"answers": {"text": ["Robert Lane and Benjamin Vail", "Robert Lane and Benjamin Vail", "Robert Lane and Benjamin Vail"], "answer_start": [77, 77, 77]}, "prediction_text": "Robert Lane and Benjamin Vail"}
{"answers": {"text": ["Tesla Electric Light & Manufacturing", "Tesla Electric Light & Manufacturing", "an electric lighting company in Tesla's name"], "answer_start": [176, 176, 130]}, "prediction_text": "An electric lighting company"}
{"answers": {"text": ["installed electrical arc light based illumination systems designed by Tesla", "installed electrical arc light based illumination systems", "installed electrical arc light based illumination systems designed by Tesla and also had designs for dynamo electric machine commutators"], "answer_start": [226, 226, 226]}, "prediction_text": "Introduced electrical arc light systems and dynamo electric machine commutators."}
{"answers": {"text": ["patents", "patents", "patents"], "answer_start": [374, 374, 374]}, "prediction_text": "First patents"}
{"answers": {"text": ["dynamo electric machine commutators", "electrical arc light based illumination systems", "electrical arc light based illumination systems"], "answer_start": [327, 236, 236]}, "prediction_text": "Electric lighting systems"}
{"answers": {"text": ["Robert Lane and Benjamin Vail", "Robert Lane and Benjamin Vail", "Robert Lane and Benjamin Vail"], "answer_start": [77, 77, 77]}, "prediction_text": "Robert Lane and Benjamin Vail"}
{"answers": {"text": ["1886", "in 1886", "1886"], "answer_start": [71, 68, 71]}, "prediction_text": "1886"}
{"answers": {"text": ["Tesla Electric Light & Manufacturing", "Tesla Electric Light & Manufacturing", "Tesla Electric Light & Manufacturing"], "answer_start": [176, 176, 176]}, "prediction_text": "Tesla Electric Light & Manufacturing"}
{"answers": {"text": ["installed electrical arc light based illumination systems", "installed electrical arc light based illumination systems", "installed electrical arc light based illumination systems designed by Tesla and also had designs for dynamo electric machine commutators"], "answer_start": [226, 226, 226]}, "prediction_text": "Introduced electrical arc light systems and dynamo electric machine commutators."}
{"answers": {"text": ["Tesla", "Tesla", "Tesla"], "answer_start": [31, 296, 176]}, "prediction_text": "Tesla Electric Light & Manufacturing"}
{"answers": {"text": ["forced Tesla out", "forced Tesla out", "forced Tesla out leaving him penniless"], "answer_start": [229, 229, 229]}, "prediction_text": "Showed little interest in Tesla's ideas."}
{"answers": {"text": ["penniless", "penniless", "penniless"], "answer_start": [258, 258, 258]}, "prediction_text": "He lost his education."}
{"answers": {"text": ["ditch digger", "ditch digger", "ditch digger"], "answer_start": [445, 445, 445]}, "prediction_text": "Worked at various electrical repair jobs."}
{"answers": {"text": ["1886/1887", "1886/1887", "1886/1887"], "answer_start": [505, 505, 505]}, "prediction_text": "1886/1887"}
{"answers": {"text": ["assigned them to the company in lieu of stock.", "assigned them to the company", "assigned them to the company in lieu of stock"], "answer_start": [335, 335, 335]}, "prediction_text": "He worked at various electrical repair jobs."}
{"answers": {"text": ["ditch digger", "ditch digger", "ditch digger"], "answer_start": [445, 445, 445]}, "prediction_text": "Worked at electrical repair jobs."}
{"answers": {"text": ["various electrical repair jobs", "various electrical repair jobs", "He had to work at various electrical repair jobs"], "answer_start": [400, 400, 382]}, "prediction_text": "Worked at various electrical repair jobs."}
{"answers": {"text": ["a Western Union superintendent", "a Western Union superintendent", "a Western Union superintendent"], "answer_start": [40, 40, 40]}, "prediction_text": "Western Union superintendent"}
{"answers": {"text": ["April 1887", "in April 1887", "April 1887"], "answer_start": [334, 331, 334]}, "prediction_text": "April 1887"}
{"answers": {"text": ["\u2153 to Tesla, \u2153 to Peck and Brown, and \u2153 to fund development", "\u2153 to Tesla, \u2153 to Peck and Brown, and \u2153 to fund development", "\u2153 to Tesla, \u2153 to Peck and Brown, and \u2153 to fund development"], "answer_start": [447, 447, 447]}, "prediction_text": "To Tesla, Peck, Brown, and the fund fund."}
{"answers": {"text": ["Manhattan", "at 89 Liberty Street", "89 Liberty Street in Manhattan"], "answer_start": [566, 542, 545]}, "prediction_text": "89 Liberty Street"}
{"answers": {"text": ["1886", "late 1886", "In late 1886"], "answer_start": [8, 3, 0]}, "prediction_text": "Late 1886"}
{"answers": {"text": ["Western Union superintendent", "Western Union superintendent", "Western Union superintendent"], "answer_start": [42, 42, 42]}, "prediction_text": "Superintendent of Western Union"}
{"answers": {"text": ["Charles F. Peck", "Charles F. Peck", "New York attorney Charles F. Peck"], "answer_start": [94, 94, 76]}, "prediction_text": "Alfred S. Brown"}
{"answers": {"text": ["89 Liberty Street in Manhattan", "Manhattan", "89 Liberty Street in Manhattan"], "answer_start": [545, 566, 545]}, "prediction_text": "89 Liberty Street"}
{"answers": {"text": ["Tesla Electric Company", "the Tesla Electric Company", "Tesla Electric Company"], "answer_start": [361, 357, 361]}, "prediction_text": "Tesla Electric Company"}
{"answers": {"text": ["an induction motor", "an induction motor", "induction motor that ran on alternating current"], "answer_start": [65, 65, 68]}, "prediction_text": "An induction motor"}
{"answers": {"text": ["May 1888", "in May 1888", "May 1888"], "answer_start": [464, 461, 464]}, "prediction_text": "May 1888"}
{"answers": {"text": ["a commutator", "commutator", "a commutator"], "answer_start": [526, 528, 526]}, "prediction_text": "A commutator"}
{"answers": {"text": ["sparking", "sparking and the high maintenance", "sparking and the high maintenance of constantly servicing and replacing mechanical brushes"], "answer_start": [554, 554, 554]}, "prediction_text": "Sparks and high maintenance"}
{"answers": {"text": ["self-starting", "self-starting", "induction"], "answer_start": [487, 487, 68]}, "prediction_text": "Simple self-starting design"}
{"answers": {"text": ["1887", "1887", "1887"], "answer_start": [56, 56, 56]}, "prediction_text": "1887"}
{"answers": {"text": ["because of its advantages in long-distance, high-voltage transmission", "advantages in long-distance, high-voltage transmission", "because of its advantages in long-distance, high-voltage transmission"], "answer_start": [201, 216, 201]}, "prediction_text": "Long-distance, high-voltage transmission."}
{"answers": {"text": ["mechanical brushes", "a commutator", "mechanical brushes"], "answer_start": [626, 526, 626]}, "prediction_text": "Commutator"}
{"answers": {"text": ["1888", "in May 1888", "1888"], "answer_start": [468, 461, 468]}, "prediction_text": "May 1888"}
{"answers": {"text": ["editor of Electrical World magazine", "the editor of Electrical World magazine", "editor of Electrical World magazine"], "answer_start": [13, 9, 13]}, "prediction_text": "A friend and publicist."}
{"answers": {"text": ["American Institute of Electrical Engineers", "the American Institute of Electrical Engineers", "American Institute of Electrical Engineers"], "answer_start": [205, 201, 205]}, "prediction_text": "American Institute of Electrical Engineers"}
{"answers": {"text": ["1888", "1888", "1888"], "answer_start": [3, 3, 3]}, "prediction_text": "1888"}
{"answers": {"text": ["decided Tesla's patent would probably control the market", "decided Tesla's patent would probably control the market", "Tesla's patent would probably control the market"], "answer_start": [692, 692, 700]}, "prediction_text": "Lack of patents"}
{"answers": {"text": ["Thomas Commerford Martin", "Thomas Commerford Martin", "Thomas Commerford Martin"], "answer_start": [50, 50, 50]}, "prediction_text": "Thomas Commerford Martin"}
{"answers": {"text": ["Thomas Commerford Martin", "Thomas Commerford Martin", "Thomas Commerford Martin"], "answer_start": [50, 50, 50]}, "prediction_text": "Thomas Commerford Martin"}
{"answers": {"text": ["George Westinghouse", "George Westinghouse", "George Westinghouse"], "answer_start": [344, 344, 344]}, "prediction_text": "Tesla (or Ferraris)"}
{"answers": {"text": ["Galileo Ferraris", "Galileo Ferraris", "the Italian physicist Galileo Ferraris"], "answer_start": [670, 670, 648]}, "prediction_text": "Galileo Ferraris"}
{"answers": {"text": ["physicist", "physicist", "Italian physicist"], "answer_start": [660, 660, 652]}, "prediction_text": "Italian physicist"}
{"answers": {"text": ["Westinghouse Electric & Manufacturing Company", "Westinghouse Electric & Manufacturing Company", "Westinghouse Electric & Manufacturing Company"], "answer_start": [286, 286, 286]}, "prediction_text": "Westinghouse Electric & Manufacturing Company"}
{"answers": {"text": ["1888", "1888", "1888"], "answer_start": [8, 8, 8]}, "prediction_text": "1888"}
{"answers": {"text": ["$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor", "$60,000 in cash and stock and a royalty", "$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor"], "answer_start": [148, 148, 148]}, "prediction_text": "$60,000"}
{"answers": {"text": ["George Westinghouse", "Westinghouse", "George Westinghouse"], "answer_start": [62, 239, 62]}, "prediction_text": "George Westinghouse"}
{"answers": {"text": ["consultant", "consultant", "consultant"], "answer_start": [357, 357, 357]}, "prediction_text": "Consultant at Westinghouse Electric & Manufacturing Company"}
{"answers": {"text": ["$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor", "$60,000 in cash and stock and a royalty", "$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor"], "answer_start": [148, 148, 148]}, "prediction_text": "$52,700"}
{"answers": {"text": ["1888", "In July 1888,", "July 1888"], "answer_start": [8, 0, 3]}, "prediction_text": "July 1888"}
{"answers": {"text": ["$2,000", "$2,000", "$2,000"], "answer_start": [303, 303, 303]}, "prediction_text": "$52,700"}
{"answers": {"text": ["Pittsburgh", "Pittsburgh", "Pittsburgh"], "answer_start": [423, 423, 423]}, "prediction_text": "Pittsburgh"}
{"answers": {"text": ["Pittsburgh", "Pittsburgh", "Pittsburgh"], "answer_start": [34, 34, 34]}, "prediction_text": "Pittsburgh"}
{"answers": {"text": ["system to power the city's streetcars", "alternating current system", "an alternating current system to power the city's streetcars"], "answer_start": [87, 67, 64]}, "prediction_text": "Creating an alternating current system for Pittsburgh."}
{"answers": {"text": ["60-cycle", "60", "60"], "answer_start": [301, 301, 301]}, "prediction_text": "60 cycle system"}
{"answers": {"text": ["DC traction motor", "a DC traction motor", "DC traction motor"], "answer_start": [548, 546, 548]}, "prediction_text": "DC traction motor"}
{"answers": {"text": ["to power the city's streetcars.", "the city's streetcars", "street cars"], "answer_start": [94, 103, 513]}, "prediction_text": "Streetcars"}
{"answers": {"text": ["a DC traction motor", "a DC traction motor", "DC traction motor"], "answer_start": [546, 546, 548]}, "prediction_text": "DC traction motor"}
{"answers": {"text": ["Thomas Edison and George Westinghouse", "Thomas Edison and George Westinghouse", "Thomas Edison and George Westinghouse"], "answer_start": [238, 238, 238]}, "prediction_text": "Thomas Edison and George Westinghouse"}
{"answers": {"text": ["lighting systems", "electrical distribution", "a competition between rival lighting systems"], "answer_start": [447, 187, 419]}, "prediction_text": "Thomas Edison and George Westinghouse"}
{"answers": {"text": ["AC development", "AC development", "AC development"], "answer_start": [1033, 1033, 1033]}, "prediction_text": "AC development"}
{"answers": {"text": ["General Electric", "General Electric", "General Electric"], "answer_start": [1172, 1172, 1172]}, "prediction_text": "General Electric"}
{"answers": {"text": ["AC", "AC", "AC"], "answer_start": [139, 1210, 139]}, "prediction_text": "AC current"}
{"answers": {"text": ["Thomas Edison", "Thomas Edison", "Thomas Edison"], "answer_start": [238, 1068, 238]}, "prediction_text": "Edison"}
{"answers": {"text": ["1888", "1888", "1888"], "answer_start": [108, 393, 393]}, "prediction_text": "1888"}
{"answers": {"text": ["financial strain", "financial strain", "the financial strain of buying up patents and hiring the engineers needed to build"], "answer_start": [823, 823, 819]}, "prediction_text": "Financial strain of buying up patents and hiring engineers."}
{"answers": {"text": ["General Electric", "General Electric", "General Electric"], "answer_start": [1172, 1172, 1172]}, "prediction_text": "General Electric"}
{"answers": {"text": ["George Westinghouse", "George Westinghouse", "George Westinghouse"], "answer_start": [9, 9, 9]}, "prediction_text": "George Westinghouse"}
{"answers": {"text": ["Chicago", "Chicago", "Chicago"], "answer_start": [91, 91, 91]}, "prediction_text": "Chicago"}
{"answers": {"text": ["General Electric", "General Electric", "General Electric"], "answer_start": [139, 139, 139]}, "prediction_text": "General Electric"}
{"answers": {"text": ["Tesla Polyphase System", "Tesla Polyphase System"], "answer_start": [494, 494]}, "prediction_text": "Tesla Polyphase System"}
{"answers": {"text": ["Tesla Polyphase System", "electrical effects"], "answer_start": [494, 550]}, "prediction_text": "Tesla Polyphase System"}
{"answers": {"text": ["George Westinghouse", "George Westinghouse", "George Westinghouse"], "answer_start": [9, 9, 9]}, "prediction_text": "George Westinghouse"}
{"answers": {"text": ["Chicago", "Chicago", "Chicago"], "answer_start": [91, 91, 91]}, "prediction_text": "Chicago"}
{"answers": {"text": ["1893", "1893", "1893"], "answer_start": [3, 54, 3]}, "prediction_text": "1893"}
{"answers": {"text": ["AC power", "alternating current", "AC power"], "answer_start": [282, 104, 282]}, "prediction_text": "Electrical displays"}
{"answers": {"text": ["Richard Dean Adams", "Richard Dean Adams", "Richard Dean Adams"], "answer_start": [8, 8, 8]}, "prediction_text": "Richard Dean Adams"}
{"answers": {"text": ["Niagara Falls", "Niagara Falls", "Niagara Falls"], "answer_start": [46, 46, 46]}, "prediction_text": "Niagara Falls"}
{"answers": {"text": ["Westinghouse Electric", "Westinghouse Electric", "Westinghouse Electric"], "answer_start": [955, 955, 955]}, "prediction_text": "Westinghouse Electric"}
{"answers": {"text": ["General Electric", "General Electric", "Westinghouse Electric"], "answer_start": [1048, 1048, 955]}, "prediction_text": "General Electric"}
{"answers": {"text": ["a two-phased system", "a two-phased system", "two-phased system"], "answer_start": [580, 580, 582]}, "prediction_text": "Two-phased system"}
{"answers": {"text": ["Richard Dean Adams", "Richard Dean Adams"], "answer_start": [8, 8]}, "prediction_text": "Richard Dean Adams"}
{"answers": {"text": ["1893", "In 1893", "1893"], "answer_start": [3, 0, 3]}, "prediction_text": "1893"}
{"answers": {"text": ["two-phased system", "a two-phased system", "two-phased system"], "answer_start": [582, 580, 582]}, "prediction_text": "Two-phased system"}
{"answers": {"text": ["most reliable", "most reliable", "would be the most reliable and that there was a Westinghouse system to light incandescent bulbs using two-phase alternating current"], "answer_start": [613, 613, 600]}, "prediction_text": "Reliable and light bulbs using two-phase alternating current."}
{"answers": {"text": ["1896", "1896", "1896"], "answer_start": [240, 240, 240]}, "prediction_text": "1896"}
{"answers": {"text": ["$216,000", "$216,000", "a lump sum payment of $216,000"], "answer_start": [1032, 1032, 1010]}, "prediction_text": "$216,000"}
{"answers": {"text": ["$2.50 per AC horsepower royalty", "$2.50 per AC horsepower", "$2.50 per AC horsepower"], "answer_start": [1183, 1183, 1183]}, "prediction_text": "$2.50 per AC horsepower"}
{"answers": {"text": ["$200,000", "estimated $200,000", "an estimated $200,000"], "answer_start": [502, 492, 489]}, "prediction_text": "$200,000"}
{"answers": {"text": ["J. P. Morgan", "J. P. Morgan", "financier J. P. Morgan"], "answer_start": [73, 73, 63]}, "prediction_text": "J.P. Morgan"}
{"answers": {"text": ["an estimated $200,000", "estimated $200,000", "an estimated $200,000 in licenses and royalties"], "answer_start": [489, 492, 489]}, "prediction_text": "$200,000"}
{"answers": {"text": ["$216,000", "$216,000", "a lump sum payment of $216,000"], "answer_start": [1032, 1032, 1010]}, "prediction_text": "$216,000"}
{"answers": {"text": ["35", "35", "35"], "answer_start": [31, 31, 31]}, "prediction_text": "35 years old"}
{"answers": {"text": ["New York", "South Fifth Avenue", "South Fifth Avenue"], "answer_start": [189, 112, 112]}, "prediction_text": "South Fifth Avenue, New York"}
{"answers": {"text": ["electric lamps", "electric lamps wirelessly", "electric lamps"], "answer_start": [206, 206, 206]}, "prediction_text": "Electric lamps"}
{"answers": {"text": ["Tesla coil", "the Tesla coil", "Tesla coil"], "answer_start": [345, 341, 345]}, "prediction_text": "Tesla coil"}
{"answers": {"text": ["1891", "On 30 July 1891", "30 July 1891"], "answer_start": [11, 0, 3]}, "prediction_text": "At the age of 35."}
{"answers": {"text": ["the Tesla coil.", "the Tesla coil", "Tesla coil"], "answer_start": [341, 341, 345]}, "prediction_text": "Tesla coil"}
{"answers": {"text": ["35", "35", "35"], "answer_start": [31, 31, 31]}, "prediction_text": "35 years old"}
{"answers": {"text": ["wireless", "wireless", "wireless"], "answer_start": [221, 282, 282]}, "prediction_text": "Wireless power transmission"}
{"answers": {"text": ["American Institute of Electrical Engineers", "the American Institute of Electrical Engineers", "American Institute of Electrical Engineers"], "answer_start": [40, 36, 40]}, "prediction_text": "American Institute of Electrical Engineers"}
{"answers": {"text": ["American Institute of Electrical Engineers", "the American Institute of Electrical Engineers", "American Institute of Electrical Engineers"], "answer_start": [40, 36, 40]}, "prediction_text": "American Institute of Electrical Engineers"}
{"answers": {"text": ["1894", "1894", "1894"], "answer_start": [182, 182, 182]}, "prediction_text": "1894"}
{"answers": {"text": ["vice president", "vice president", "vice president"], "answer_start": [18, 18, 18]}, "prediction_text": "Vice president"}
{"answers": {"text": ["1892 to 1894", "from 1892 to 1894", "from 1892 to 1894"], "answer_start": [174, 169, 169]}, "prediction_text": "1892 to 1894"}
{"answers": {"text": ["the Institute of Radio Engineers", "the Institute of Radio Engineers", "Institute of Radio Engineers"], "answer_start": [111, 111, 115]}, "prediction_text": "Radio Engineers"}
{"answers": {"text": ["he had noticed damaged film in his laboratory in previous experiments", "he had noticed damaged film in his laboratory", "after he had noticed damaged film in his laboratory in previous experiments"], "answer_start": [109, 109, 103]}, "prediction_text": "After noticing damaged film in Crookes tubes."}
{"answers": {"text": ["5th Avenue laboratory fire of March 1895", "fire", "fire"], "answer_start": [477, 499, 499]}, "prediction_text": "5th Avenue laboratory fire"}
{"answers": {"text": ["December 1895", "December 1895", "December 1895"], "answer_start": [716, 716, 716]}, "prediction_text": "December 1895"}
{"answers": {"text": ["the metal locking screw on the camera lens", "the metal locking screw", "the metal locking screw on the camera lens"], "answer_start": [921, 921, 921]}, "prediction_text": "Metal locking screw"}
{"answers": {"text": ["1894", "1894", "1894"], "answer_start": [12, 12, 12]}, "prediction_text": "He began investigating invisible radiant energy in 1895."}
{"answers": {"text": ["X-Rays", "x-rays", "\"Roentgen rays\" or \"X-Rays\""], "answer_start": [220, 763, 200]}, "prediction_text": "X-rays"}
{"answers": {"text": ["lost in the 5th Avenue laboratory fire of March 1895", "was lost", "was lost in the 5th Avenue laboratory fire of March 1895"], "answer_start": [465, 461, 461]}, "prediction_text": "Lost in 5th Avenue laboratory fire."}
{"answers": {"text": ["X-ray image", "X-ray", "X-ray image"], "answer_start": [659, 659, 659]}, "prediction_text": "X-ray image"}
{"answers": {"text": ["Mark Twain", "Mark Twain", "Mark Twain"], "answer_start": [798, 798, 798]}, "prediction_text": "Mark Twain"}
{"answers": {"text": ["X-ray imaging", "X-ray imaging", "X-ray imaging"], "answer_start": [73, 147, 147]}, "prediction_text": "X-ray imaging and high energy single terminal vacuum tube"}
{"answers": {"text": ["March 1896", "In March 1896", "March 1896"], "answer_start": [3, 0, 3]}, "prediction_text": "March 1896"}
{"answers": {"text": ["radiography", "braking radiation", "radiography"], "answer_start": [88, 393, 88]}, "prediction_text": "Bremsstrahlung"}
{"answers": {"text": ["X-rays", "X-rays", "X-rays"], "answer_start": [483, 483, 483]}, "prediction_text": "X-rays"}
{"answers": {"text": ["Tesla Coil", "the Tesla Coil", "Tesla Coil"], "answer_start": [301, 297, 301]}, "prediction_text": "Tesla Coil (the modern term for braking radiation)"}
{"answers": {"text": ["1896", "In March 1896", "March 1896"], "answer_start": [9, 0, 3]}, "prediction_text": "March 1896"}
{"answers": {"text": ["Tesla Coil", "Tesla Coil", "Tesla Coil"], "answer_start": [301, 301, 301]}, "prediction_text": "Tesla Coil"}
{"answers": {"text": ["Roentgen rays", "Roentgen rays", "Roentgen rays"], "answer_start": [575, 575, 575]}, "prediction_text": "Radiographic images"}
{"answers": {"text": ["X-rays were longitudinal waves", "were longitudinal waves", "that X-rays were longitudinal waves, such as those produced in waves in plasmas."], "answer_start": [415, 422, 410]}, "prediction_text": "X-rays are longitudinal waves."}
{"answers": {"text": ["damage to the skin was not caused by the Roentgen rays, but by the ozone generated in contact with the skin", "ozone generated in contact with the skin", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid"], "answer_start": [233, 300, 296]}, "prediction_text": "Roentgen rays"}
{"answers": {"text": ["skin damage", "damage to the skin", "damage to the skin"], "answer_start": [176, 233, 233]}, "prediction_text": "Skin damage"}
{"answers": {"text": ["his circuit and single-node X-ray-producing devices", "X-ray-producing devices", "circuit and single-node X-ray-producing devices"], "answer_start": [40, 68, 44]}, "prediction_text": "Circuit and single-node X-ray-producing devices."}
{"answers": {"text": ["force-free magnetic fields", "force-free magnetic fields", "in force-free magnetic fields"], "answer_start": [523, 523, 520]}, "prediction_text": "Force-free magnetic fields"}
{"answers": {"text": ["ozone generated in contact with the skin", "ozone generated in contact with the skin", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid."], "answer_start": [300, 300, 296]}, "prediction_text": "Roentgen rays"}
{"answers": {"text": ["longitudinal waves", "longitudinal waves", "longitudinal waves, such as those produced in waves in plasmas"], "answer_start": [427, 427, 427]}, "prediction_text": "longitudinal waves"}
{"answers": {"text": ["force-free magnetic fields", "waves in plasmas", "in force-free magnetic fields"], "answer_start": [523, 473, 520]}, "prediction_text": "In force-free magnetic fields"}
{"answers": {"text": ["In his many notes", "In his many notes"], "answer_start": [93, 93]}, "prediction_text": "Early investigations of X-ray-producing devices."}
{"answers": {"text": ["Benjamin Lamme", "Benjamin Lamme", "Benjamin Lamme"], "answer_start": [47, 47, 47]}, "prediction_text": "Benjamin Lamme"}
{"answers": {"text": ["1893", "1893", "1893"], "answer_start": [20, 20, 20]}, "prediction_text": "1893"}
{"answers": {"text": ["Westinghouse Electric", "Westinghouse Electric", "Westinghouse Electric"], "answer_start": [149, 149, 149]}, "prediction_text": "Westinghouse Electric"}
{"answers": {"text": ["Egg of Columbus", "the Egg of Columbus", "Egg of Columbus"], "answer_start": [187, 183, 187]}, "prediction_text": "Egg of Columbus"}
{"answers": {"text": ["Tesla", "Tesla", "Tesla"], "answer_start": [0, 0, 0]}, "prediction_text": "Tesla"}
{"answers": {"text": ["1934", "On 11 July 1934", "11 July 1934"], "answer_start": [11, 0, 3]}, "prediction_text": "July 11, 1934"}
{"answers": {"text": ["physically strike him", "physically strike him", "physically strike him"], "answer_start": [274, 274, 274]}, "prediction_text": "Stung him."}
{"answers": {"text": ["he could feel a sharp stinging pain where it entered his body", "he could feel a sharp stinging pain", "he could feel a sharp stinging pain"], "answer_start": [309, 309, 309]}, "prediction_text": "Tesla recalled an event that happened while experimenting with his single-electrode vacuum tubes."}
{"answers": {"text": ["bits of metal", "bits of metal", "bits of metal projected by his \"electric gun,\""], "answer_start": [455, 455, 455]}, "prediction_text": "Metal particles"}
{"answers": {"text": ["National Electric Light Association", "possibility of the transmission", "National Electric Light Association"], "answer_start": [211, 24, 211]}, "prediction_text": "National Electric Light Association"}
{"answers": {"text": ["Tesla Coil", "the Tesla Coil", "Tesla Coil"], "answer_start": [368, 364, 368]}, "prediction_text": "Tesla Coil"}
{"answers": {"text": ["the Franklin Institute", "the Franklin Institute", "Franklin Institute"], "answer_start": [149, 149, 153]}, "prediction_text": "Franklin Institute"}
{"answers": {"text": ["1898", "In 1898,", "1898"], "answer_start": [3, 0, 3]}, "prediction_text": "May 13, 1899"}
{"answers": {"text": ["teleautomaton", "teleautomaton", "teleautomaton"], "answer_start": [69, 69, 69]}, "prediction_text": "\"Teleautomaton\""}
{"answers": {"text": ["Madison Square Garden", "Madison Square Garden", "Madison Square Garden"], "answer_start": [133, 133, 133]}, "prediction_text": "Madison Square Garden"}
{"answers": {"text": ["an electrical exhibition", "an electrical exhibition", "an electrical exhibition"], "answer_start": [105, 105, 105]}, "prediction_text": "Electric exhibition"}
{"answers": {"text": ["monkey", "monkey", "a trained monkey"], "answer_start": [311, 311, 301]}, "prediction_text": "A trained monkey"}
{"answers": {"text": ["1900", "1900", "1900"], "answer_start": [3, 3, 3]}, "prediction_text": "1901"}
{"answers": {"text": ["Marconi", "Guglielmo Marconi", "Guglielmo Marconi"], "answer_start": [132, 122, 122]}, "prediction_text": "Guglielmo Marconi"}
{"answers": {"text": ["1901", "1901", "1901"], "answer_start": [203, 203, 203]}, "prediction_text": "1901"}
{"answers": {"text": ["1943", "1943", "1943"], "answer_start": [476, 476, 476]}, "prediction_text": "1943"}
{"answers": {"text": ["Supreme Court of the United States", "Supreme Court of the United States", "Supreme Court of the United States"], "answer_start": [484, 484, 484]}, "prediction_text": "Supreme Court of the United States"}
{"answers": {"text": ["1899", "1899", "1899"], "answer_start": [10, 10, 10]}, "prediction_text": "1899"}
{"answers": {"text": ["Paris", "Paris", "Pikes Peak to Paris"], "answer_start": [523, 523, 509]}, "prediction_text": "Denver, Colorado"}
{"answers": {"text": ["15 June 1899", "15 June 1899", "15 June 1899"], "answer_start": [644, 644, 644]}, "prediction_text": "15 June 1899"}
{"answers": {"text": ["five inches", "five inches", "five inches"], "answer_start": [765, 765, 765]}, "prediction_text": "Five inches"}
{"answers": {"text": ["atmospheric", "atmospheric", "atmospheric electricity"], "answer_start": [19, 19, 19]}, "prediction_text": "Atmospheric electricity"}
{"answers": {"text": ["stationary", "stationary", "stationary waves"], "answer_start": [118, 118, 118]}, "prediction_text": "stationary waves"}
{"answers": {"text": ["that the earth had a resonant frequency.", "the earth had a resonant frequency", "earth had a resonant frequency"], "answer_start": [259, 264, 268]}, "prediction_text": "Resonant frequency"}
{"answers": {"text": ["lightning", "lightning", "lightning"], "answer_start": [23, 23, 23]}, "prediction_text": "Lightning"}
{"answers": {"text": ["135 feet", "135 feet long", "consisting of millions of volts and up to 135 feet long"], "answer_start": [92, 92, 50]}, "prediction_text": "Millions of volts"}
{"answers": {"text": ["15 miles", "15 miles", "15 miles away"], "answer_start": [150, 150, 150]}, "prediction_text": "15 miles away"}
{"answers": {"text": ["glowed even when turned off", "glowed", "glowed even when turned off"], "answer_start": [371, 371, 371]}, "prediction_text": "They were electrified."}
{"answers": {"text": ["Butterflies were electrified", "electrified", "electrified, swirling in circles with blue halos of St. Elmo's fire around their wings"], "answer_start": [501, 518, 518]}, "prediction_text": "Electrified with blue halos."}
{"answers": {"text": ["power outage", "a power outage", "power outage"], "answer_start": [86, 84, 86]}, "prediction_text": "A power station generator was faulted."}
{"answers": {"text": ["repeatedly burned out", "repeatedly burned out", "repeatedly burned out"], "answer_start": [353, 353, 353]}, "prediction_text": "They were repeatedly burned out."}
{"answers": {"text": ["powerful high frequency currents", "powerful high frequency currents", "powerful high frequency currents"], "answer_start": [387, 387, 387]}, "prediction_text": "High frequency currents"}
{"answers": {"text": ["destroy", "destroy", "jump through the windings and destroy the insulation"], "answer_start": [499, 499, 469]}, "prediction_text": "Destroyed the insulation."}
{"answers": {"text": ["communications from another planet", "communications from another planet", "communications from another planet"], "answer_start": [103, 103, 103]}, "prediction_text": "From Mars, Venus, or other planets."}
{"answers": {"text": ["Mars", "Mars", "Mars"], "answer_start": [536, 536, 536]}, "prediction_text": "Mars"}
{"answers": {"text": ["Collier's Weekly", "Collier's Weekly", "Collier's Weekly"], "answer_start": [599, 599, 599]}, "prediction_text": "Collier's Weekly"}
{"answers": {"text": ["intercepted Marconi's European experiments", "he may have intercepted Marconi's European experiments", "he may have intercepted Marconi's European experiments in July 1899"], "answer_start": [870, 858, 858]}, "prediction_text": "Mars, Venus, or other planets."}
{"answers": {"text": ["July 1899", "July 1899", "July 1899"], "answer_start": [916, 916, 916]}, "prediction_text": "July 1899"}
{"answers": {"text": ["$100,000", "$100,000", "$100,000"], "answer_start": [38, 38, 38]}, "prediction_text": "$100,000"}
{"answers": {"text": ["for Tesla to further develop and produce a new lighting system", "a new lighting system", "develop and produce a new lighting system"], "answer_start": [47, 88, 68]}, "prediction_text": "Development and production of a new lighting system."}
{"answers": {"text": ["to fund his Colorado Springs experiments.", "his Colorado Springs experiments", "fund his Colorado Springs experiments"], "answer_start": [141, 149, 144]}, "prediction_text": "Funding his Colorado Springs experiments"}
{"answers": {"text": ["1899", "In 1899", "1899"], "answer_start": [3, 0, 3]}, "prediction_text": "1899"}
{"answers": {"text": ["1900", "On 7 January 1900", "7 January 1900"], "answer_start": [13, 0, 3]}, "prediction_text": "1905"}
{"answers": {"text": ["His lab was torn down", "torn down", "torn down in 1904"], "answer_start": [65, 77, 77]}, "prediction_text": "Torn down in 1904."}
{"answers": {"text": ["1904", "1904", "1904"], "answer_start": [90, 90, 90]}, "prediction_text": "1904"}
{"answers": {"text": ["sold", "sold", "sold two years later"], "answer_start": [118, 118, 118]}, "prediction_text": "Sold to satisfy debt."}
{"answers": {"text": ["Wardenclyffe", "Wardenclyffe", "Wardenclyffe"], "answer_start": [134, 134, 134]}, "prediction_text": "Trans-Atlantic wireless telecommunications facility"}
{"answers": {"text": ["trans-Atlantic wireless telecommunications facility", "trans-Atlantic wireless telecommunications", "trans-Atlantic wireless telecommunications"], "answer_start": [73, 73, 73]}, "prediction_text": "Wireless telecommunications facility"}
{"answers": {"text": ["near Shoreham, Long Island", "Long Island", "near Shoreham, Long Island"], "answer_start": [147, 162, 147]}, "prediction_text": "Near Shoreham, Long Island"}
{"answers": {"text": ["Morgan", "Morgan", "Morgan"], "answer_start": [23, 23, 23]}, "prediction_text": "Morgan"}
{"answers": {"text": ["Panic of 1901", "the Panic of 1901", "the Panic of 1901"], "answer_start": [185, 181, 181]}, "prediction_text": "Panic of 1901"}
{"answers": {"text": ["shocked", "shocked", "shocked by the reminder of his part in the stock market crash and by Tesla's breach of contract"], "answer_start": [241, 241, 241]}, "prediction_text": "He was shocked and asked for more funds."}
{"answers": {"text": ["over 50 letters", "over 50 letters", "50 letters"], "answer_start": [199, 199, 204]}, "prediction_text": "Over 50 letters"}
{"answers": {"text": ["to complete the construction of Wardenclyffe.", "to complete the construction of Wardenclyffe", "to complete the construction of Wardenclyffe"], "answer_start": [272, 272, 272]}, "prediction_text": "To complete Wardenclyffe construction"}
{"answers": {"text": ["Marconi successfully transmitted the letter S from England to Newfoundland", "Marconi successfully transmitted the letter S from England to Newfoundland", "Marconi successfully transmitted the letter S from England to Newfoundland"], "answer_start": [18, 18, 18]}, "prediction_text": "Tesla successfully transmitted letter S from England to Newfoundland."}
{"answers": {"text": ["187 feet", "187 feet", "187 feet (57 m)"], "answer_start": [405, 405, 405]}, "prediction_text": "187 feet (57 m)"}
{"answers": {"text": ["200", "200", "200"], "answer_start": [53, 53, 53]}, "prediction_text": "200 horsepower"}
{"answers": {"text": ["16,000 rpm", "16,000 rpm", "16,000 rpm"], "answer_start": [84, 84, 84]}, "prediction_text": "100\u20135,000 hp"}
{"answers": {"text": ["1906", "1910\u20131911", "his 50th birthday in 1906"], "answer_start": [24, 121, 3]}, "prediction_text": "1906"}
{"answers": {"text": ["100\u20135,000 hp", "100\u20135,000", "100\u20135,000"], "answer_start": [231, 231, 231]}, "prediction_text": "150 kilowatts"}
{"answers": {"text": ["steam", "steam", "steam-powered"], "answer_start": [17, 17, 17]}, "prediction_text": "By a steam-powered oscillator"}
{"answers": {"text": ["Houston Street lab", "his Houston Street lab", "his Houston Street lab"], "answer_start": [128, 124, 124]}, "prediction_text": "Houston Street lab"}
{"answers": {"text": ["the machine oscillated at the resonance frequency of his own building", "the danger", "the machine oscillated at the resonance frequency of his own building"], "answer_start": [243, 338, 243]}, "prediction_text": "The earth's crust cracked."}
{"answers": {"text": ["World Today", "World Today", "World Today"], "answer_start": [541, 541, 541]}, "prediction_text": "World Today"}
{"answers": {"text": ["eventually split the earth in two", "destroy civilization", "he could set the earth's crust into such a state of vibration that it would rise and fall hundreds of feet and practically destroy civilization"], "answer_start": [882, 813, 690]}, "prediction_text": "Set the earth's crust into such a state of vibration."}
{"answers": {"text": ["application of electricity", "application of electricity to the brain", "the application of electricity"], "answer_start": [25, 25, 21]}, "prediction_text": "Electricity to the brain"}
{"answers": {"text": ["saturating them unconsciously with electricity", "saturating them unconsciously with electricity", "saturating them unconsciously with electricity"], "answer_start": [148, 148, 148]}, "prediction_text": "Stimulating electromagnetic field or 'bath\""}
{"answers": {"text": ["William H. Maxwell", "William H. Maxwell", "William H. Maxwell"], "answer_start": [550, 550, 550]}, "prediction_text": "William H. Maxwell"}
{"answers": {"text": ["superintendent of New York City schools", "superintendent of New York City schools", "superintendent of New York City schools"], "answer_start": [509, 509, 509]}, "prediction_text": "Superintendent of New York City schools"}
{"answers": {"text": ["overseas", "overseas", "overseas"], "answer_start": [33, 33, 33]}, "prediction_text": "Europe"}
{"answers": {"text": ["lost", "lost", "lost the funding"], "answer_start": [82, 82, 82]}, "prediction_text": "Tesla lost the funding."}
{"answers": {"text": ["sold", "sold", "sold"], "answer_start": [171, 171, 171]}, "prediction_text": "Sold it for $20,000 ($472,500 in today's dollars)"}
{"answers": {"text": ["$20,000", "$20,000", "$20,000"], "answer_start": [193, 193, 193]}, "prediction_text": "$472,500"}
{"answers": {"text": ["the Edison Medal.", "the Edison Medal", "the Edison Medal."], "answer_start": [396, 396, 396]}, "prediction_text": "Edison Medal"}
{"answers": {"text": ["Electrical Experimenter", "Electrical Experimenter", "Electrical Experimenter"], "answer_start": [43, 43, 43]}, "prediction_text": "Electrical Experimenter"}
{"answers": {"text": ["fluorescent screen", "fluorescent screen", "with the signal being viewed on a fluorescent screen"], "answer_start": [243, 243, 209]}, "prediction_text": "Viewed on fluorescent screen"}
{"answers": {"text": ["radar", "radar", "modern radar"], "answer_start": [491, 336, 329]}, "prediction_text": "Modern radar"}
{"answers": {"text": ["\u00c9mile Girardeau", "\u00c9mile Girardeau", "\u00c9mile Girardeau,"], "answer_start": [440, 440, 440]}, "prediction_text": "\u00c9mile Girardeau"}
{"answers": {"text": ["Thomas Edison and Nikola Tesla", "Thomas Edison and Nikola Tesla", "Thomas Edison and Nikola Tesla"], "answer_start": [108, 108, 108]}, "prediction_text": "Thomas Edison and Nikola Tesla"}
{"answers": {"text": ["Sir William Henry Bragg and William Lawrence Bragg", "Sir William Henry Bragg and William Lawrence Bragg", "Sir William Henry Bragg and William Lawrence Bragg"], "answer_start": [244, 244, 244]}, "prediction_text": "Thomas Edison"}
{"answers": {"text": ["Tesla and/or Edison had refused the prize", "Tesla and/or Edison had refused the prize", "Tesla and/or Edison had refused the prize"], "answer_start": [428, 428, 428]}, "prediction_text": "They refused the prize."}
{"answers": {"text": ["announced a winner", "he is announced a winner", "after he is announced a winner"], "answer_start": [694, 688, 682]}, "prediction_text": "He is announced a winner."}
{"answers": {"text": ["animosity toward each other", "their animosity toward each other", "because of their animosity toward each other"], "answer_start": [160, 154, 143]}, "prediction_text": "They sought to minimize each other's achievements."}
{"answers": {"text": ["38", "38", "38"], "answer_start": [108, 108, 108]}, "prediction_text": "38 bids"}
{"answers": {"text": ["Edison", "Edison", "Edison"], "answer_start": [51, 82, 82]}, "prediction_text": "Edison"}
{"answers": {"text": ["1937", "1937", "1937"], "answer_start": [182, 182, 182]}, "prediction_text": "1915"}
{"answers": {"text": ["U.S. Patent 1,655,114", "1,655,114", "1,655,114"], "answer_start": [41, 53, 53]}, "prediction_text": "1,655,114"}
{"answers": {"text": ["VTOL aircraft", "VTOL aircraft", "a biplane capable of taking off vertically"], "answer_start": [112, 112, 68]}, "prediction_text": "Biplane"}
{"answers": {"text": ["less than $1,000", "less than $1,000", "less than $1,000"], "answer_start": [299, 299, 299]}, "prediction_text": "Less than $1,000."}
{"answers": {"text": ["turbine engines", "turbine engines", "turbine"], "answer_start": [501, 501, 501]}, "prediction_text": "Turbine engines"}
{"answers": {"text": ["$125 per month", "$125 per month", "$125 per month"], "answer_start": [87, 87, 87]}, "prediction_text": "$125 per month"}
{"answers": {"text": ["rent at the Hotel New Yorker", "paying his rent", "paying his rent at the Hotel New Yorker"], "answer_start": [124, 113, 113]}, "prediction_text": "$125 per month"}
{"answers": {"text": ["for the rest of Tesla's life", "the rest of Tesla's life.", "the rest of Tesla's life"], "answer_start": [185, 189, 189]}, "prediction_text": "From 1934 to present."}
{"answers": {"text": ["bad publicity", "bad publicity", "potential bad publicity surrounding the impoverished conditions their former star inventor was living under"], "answer_start": [314, 314, 304]}, "prediction_text": "Bad publicity"}
{"answers": {"text": ["mechanical energy", "mechanical energy", "mechanical energy"], "answer_start": [95, 95, 95]}, "prediction_text": "Mechanical energy with minimal loss over terrestrial distances."}
{"answers": {"text": ["over any terrestrial distance", "any terrestrial distance", "any terrestrial distance"], "answer_start": [131, 136, 136]}, "prediction_text": "Over terrestrial distances"}
{"answers": {"text": ["minimal", "minimal", "minimal"], "answer_start": [118, 118, 118]}, "prediction_text": "minimal loss"}
{"answers": {"text": ["mineral deposits", "mineral deposits", "mineral deposits"], "answer_start": [267, 267, 267]}, "prediction_text": "Mineral deposits"}
{"answers": {"text": ["1935", "In 1935", "1935"], "answer_start": [3, 0, 3]}, "prediction_text": "1935"}
{"answers": {"text": ["feed the pigeons", "feed the pigeons", "feed the pigeons"], "answer_start": [143, 143, 143]}, "prediction_text": "Went to his hotel."}
{"answers": {"text": ["a doctor", "a doctor", "a doctor"], "answer_start": [465, 465, 465]}, "prediction_text": "A doctor"}
{"answers": {"text": ["broken", "broken", "broken"], "answer_start": [363, 363, 363]}, "prediction_text": "Tesla was severely wrenched and three of his ribs were broken."}
{"answers": {"text": ["early 1938", "In early 1938", "early 1938"], "answer_start": [754, 751, 754]}, "prediction_text": "Early 1938"}
{"answers": {"text": ["the fall of 1937", "In the fall of 1937", "fall of 1937"], "answer_start": [3, 0, 7]}, "prediction_text": "Fall of 1937"}
{"answers": {"text": ["\"teleforce\" weapon", "teleforce", "teleforce"], "answer_start": [46, 47, 47]}, "prediction_text": "A \"teleforce\" weapon"}
{"answers": {"text": ["Van de Graaff generator", "the Van de Graaff generator", "the Van de Graaff generator"], "answer_start": [84, 80, 80]}, "prediction_text": "Van de Graaff generator"}
{"answers": {"text": ["infantry", "infantry", "infantry"], "answer_start": [247, 247, 247]}, "prediction_text": "Ground-based infantry"}
{"answers": {"text": ["anti-aircraft purposes", "anti-aircraft purposes", "anti-aircraft purposes"], "answer_start": [263, 263, 263]}, "prediction_text": "Against infantry or anti-aircraft purposes."}
{"answers": {"text": ["death ray", "death ray", "death ray"], "answer_start": [163, 163, 163]}, "prediction_text": "Death ray"}
{"answers": {"text": ["1937", "In 1937", "1937"], "answer_start": [3, 0, 3]}, "prediction_text": "1937"}
{"answers": {"text": ["at a luncheon in his honor", "a luncheon in his honor", "a luncheon in his honor"], "answer_start": [9, 12, 12]}, "prediction_text": "Luncheon in his honor"}
{"answers": {"text": ["tungsten", "tungsten", "tungsten"], "answer_start": [288, 288, 288]}, "prediction_text": "Tungsten"}
{"answers": {"text": ["high voltage", "high voltage", "high voltage"], "answer_start": [330, 330, 330]}, "prediction_text": "High voltage (by means akin to Tesla's magnifying transformer)"}
{"answers": {"text": ["Only a little", "a little", "Only a little time"], "answer_start": [149, 154, 149]}, "prediction_text": "A little time"}
{"answers": {"text": ["charged particle beam weapons", "charged particle beam weapons", "charged particle beam"], "answer_start": [141, 141, 141]}, "prediction_text": "Charged particle beam weapons"}
{"answers": {"text": ["Nikola Tesla Museum archive", "the Nikola Tesla Museum archive", "Nikola Tesla Museum"], "answer_start": [342, 338, 342]}, "prediction_text": "Nikola Tesla Museum archive"}
{"answers": {"text": ["Belgrade", "Belgrade", "Belgrade"], "answer_start": [373, 373, 373]}, "prediction_text": "Belgrade"}
{"answers": {"text": ["millions", "millions", "millions"], "answer_start": [507, 507, 507]}, "prediction_text": "Millions of volts"}
{"answers": {"text": ["all war", "all war", "all war"], "answer_start": [298, 298, 298]}, "prediction_text": "All war"}
{"answers": {"text": ["steal the invention", "steal", "steal"], "answer_start": [107, 107, 107]}, "prediction_text": "Steal it"}
{"answers": {"text": ["in his mind.", "in his mind", "all in his mind"], "answer_start": [410, 410, 406]}, "prediction_text": "In his mind"}
{"answers": {"text": ["his papers", "his papers", "his papers"], "answer_start": [158, 158, 158]}, "prediction_text": "His blueprint for the teleforce weapon"}
{"answers": {"text": ["86", "86", "86"], "answer_start": [33, 33, 33]}, "prediction_text": "86 years old"}
{"answers": {"text": ["7 January 1943", "7 January 1943", "7 January 1943"], "answer_start": [3, 3, 3]}, "prediction_text": "7 January 1943"}
{"answers": {"text": ["maid Alice Monaghan", "maid Alice Monaghan", "maid Alice Monaghan"], "answer_start": [120, 120, 120]}, "prediction_text": "Alice Monaghan"}
{"answers": {"text": ["\"do not disturb\" sign", "do not disturb\" sign", "\"do not disturb\" sign"], "answer_start": [189, 190, 189]}, "prediction_text": "\"Do not disturb\" sign"}
{"answers": {"text": ["coronary thrombosis", "coronary thrombosis", "coronary thrombosis"], "answer_start": [363, 363, 363]}, "prediction_text": "coronary thrombosis"}
{"answers": {"text": ["FBI ordered the Alien Property Custodian to seize Tesla's belongings", "the FBI ordered the Alien Property Custodian to seize Tesla's belongings", "Alien Property Custodian"], "answer_start": [20, 16, 36]}, "prediction_text": "They were seized."}
{"answers": {"text": ["John G. Trump", "John G. Trump", "John G. Trump"], "answer_start": [322, 322, 322]}, "prediction_text": "Office of Alien Property (OAP)"}
{"answers": {"text": ["nothing", "nothing", "nothing"], "answer_start": [598, 598, 598]}, "prediction_text": "Nothing which would constitute a hazard."}
{"answers": {"text": ["Manhattan Storage and Warehouse Company", "Manhattan Storage and Warehouse Company", "Manhattan Storage and Warehouse Company"], "answer_start": [235, 235, 235]}, "prediction_text": "Manhattan Storage and Warehouse Company"}
{"answers": {"text": ["New York City mayor Fiorello La Guardia", "Fiorello La Guardia", "New York City mayor Fiorello La Guardia"], "answer_start": [20, 40, 20]}, "prediction_text": "Fiorello La Guardia"}
{"answers": {"text": ["Louis Adamic", "Louis Adamic", "Slovene-American author Louis Adamic"], "answer_start": [109, 109, 85]}, "prediction_text": "Fiorello La Guardia"}
{"answers": {"text": ["12 January", "12 January", "12 January"], "answer_start": [231, 231, 231]}, "prediction_text": "12 January 1943"}
{"answers": {"text": ["two thousand", "two thousand", "two thousand people"], "answer_start": [243, 243, 243]}, "prediction_text": "Two thousand people"}
{"answers": {"text": ["the Cathedral of Saint John the Divine", "the Cathedral of Saint John the Divine", "the Cathedral of Saint John the Divine"], "answer_start": [301, 301, 301]}, "prediction_text": "Cathedral of Saint John the Divine"}
{"answers": {"text": ["Belgrade", "Belgrade", "Belgrade"], "answer_start": [102, 102, 102]}, "prediction_text": "United States"}
{"answers": {"text": ["Sava Kosanovi\u0107", "Sava Kosanovi\u0107", "Sava Kosanovi\u0107"], "answer_start": [49, 49, 49]}, "prediction_text": "Sava Kosanovi\u0107"}
{"answers": {"text": ["Charlotte Muzar", "Charlotte Muzar", "Charlotte Muzar"], "answer_start": [167, 167, 167]}, "prediction_text": "Charlotte Muzar"}
{"answers": {"text": ["Belgrade", "Belgrade", "Belgrade"], "answer_start": [102, 235, 235]}, "prediction_text": "United States"}
{"answers": {"text": ["Nikola Tesla Museum", "the Nikola Tesla Museum", "the Nikola Tesla Museum"], "answer_start": [321, 317, 317]}, "prediction_text": "In Belgrade"}
{"answers": {"text": ["around 300", "around 300", "around 300"], "answer_start": [15, 15, 15]}, "prediction_text": "Around 300 patents"}
{"answers": {"text": ["26", "26", "26"], "answer_start": [248, 248, 248]}, "prediction_text": "26 countries"}
{"answers": {"text": ["Canada", "Canada", "Canada"], "answer_start": [355, 355, 355]}, "prediction_text": "Canada"}
{"answers": {"text": ["patent archives", "patent archives", "patent archives"], "answer_start": [177, 177, 177]}, "prediction_text": "Patent archives"}
{"answers": {"text": ["8:10 p.m", "8:10 p.m", "exactly 8:10 p.m.,"], "answer_start": [89, 89, 81]}, "prediction_text": "At 8:10 p.m."}
{"answers": {"text": ["9:00 a.m. until 6:00 p.m. or later", "9:00 a.m. until 6:00 p.m", "9:00 a.m. until 6:00 p.m. or later"], "answer_start": [28, 28, 28]}, "prediction_text": "9:00 a.m. until 6:00 p.m."}
{"answers": {"text": ["3:00 a.m", "3:00 a.m", "3:00 a.m"], "answer_start": [484, 484, 484]}, "prediction_text": "At least 3:00 a.m."}
{"answers": {"text": ["headwaiter", "the headwaiter", "the headwaiter"], "answer_start": [209, 205, 205]}, "prediction_text": "The headwaiter"}
{"answers": {"text": ["between 8 to 10 miles per day", "8 to 10 miles", "8 to 10 miles"], "answer_start": [27, 35, 35]}, "prediction_text": "8 to 10 miles"}
{"answers": {"text": ["exercise", "For exercise", "exercise"], "answer_start": [4, 0, 4]}, "prediction_text": "For exercise"}
{"answers": {"text": ["squished his toes", "squished his toes", "squished his toes one hundred times for each foot"], "answer_start": [61, 61, 61]}, "prediction_text": "Squished his toes one hundred times."}
{"answers": {"text": ["brain cells", "brain cells", "brain cells"], "answer_start": [154, 154, 154]}, "prediction_text": "Brain cells"}
{"answers": {"text": ["telepathy", "telepathy", "telepathy"], "answer_start": [93, 93, 93]}, "prediction_text": "Telepathy"}
{"answers": {"text": ["newspaper editor", "newspaper editor", "newspaper editor"], "answer_start": [21, 21, 21]}, "prediction_text": "Newspaper editor"}
{"answers": {"text": ["one", "one", "one"], "answer_start": [369, 369, 369]}, "prediction_text": "One law"}
{"answers": {"text": ["pigeons", "pigeons", "pigeons"], "answer_start": [73, 73, 73]}, "prediction_text": "Birds, injured pigeons, and white pigeons."}
{"answers": {"text": ["over $2,000", "over $2,000,", "over $2,000"], "answer_start": [243, 243, 243]}, "prediction_text": "Over $2,000"}
{"answers": {"text": ["broken wing and leg", "broken wing and leg", "broken wing and leg"], "answer_start": [351, 351, 351]}, "prediction_text": "Broken wing and leg."}
{"answers": {"text": ["the park", "the park", "the park"], "answer_start": [42, 42, 42]}, "prediction_text": "In his hotel room"}
{"answers": {"text": ["hotel room", "his hotel room", "his hotel room"], "answer_start": [120, 116, 116]}, "prediction_text": "Tesla's hotel room"}
{"answers": {"text": ["142 pounds", "142 pounds", "142 pounds (64 kg)"], "answer_start": [52, 52, 52]}, "prediction_text": "142 pounds (64 kg)"}
{"answers": {"text": ["6 feet 2 inches", "6 feet 2 inches", "6 feet 2 inches (1.88 m)"], "answer_start": [10, 10, 10]}, "prediction_text": "6 feet 2 inches (1.88 m) tall"}
{"answers": {"text": ["1888 to about 1926", "from 1888 to about 1926", "1888 to about 1926"], "answer_start": [108, 103, 108]}, "prediction_text": "About 1926"}
{"answers": {"text": ["New York City", "New York City", "New York City"], "answer_start": [169, 169, 169]}, "prediction_text": "New York City"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [129, 129, 129]}, "prediction_text": "Eight languages"}
{"answers": {"text": ["visions", "blinding flashes of light", "visions"], "answer_start": [504, 427, 504]}, "prediction_text": "Blind spots and visions."}
{"answers": {"text": ["picture thinking", "picture thinking"], "answer_start": [945, 945]}, "prediction_text": "Picture thinking"}
{"answers": {"text": ["blinding flashes of light", "flashbacks", "blinding flashes of light"], "answer_start": [427, 1077, 427]}, "prediction_text": "Blindsight flashes"}
{"answers": {"text": ["photographic memory", "photographic", "photographic"], "answer_start": [77, 77, 77]}, "prediction_text": "Pictures of events in his life."}
{"answers": {"text": ["more than 48 hours", "48 hours", "48 hours"], "answer_start": [157, 167, 167]}, "prediction_text": "84 hours"}
{"answers": {"text": ["84 hours", "84 hours", "84 hours"], "answer_start": [280, 280, 280]}, "prediction_text": "84 hours"}
{"answers": {"text": ["Graz", "Graz", "Graz"], "answer_start": [35, 35, 35]}, "prediction_text": "Graz, Austria"}
{"answers": {"text": ["Kenneth Swezey", "Kenneth Swezey", "Kenneth Swezey,"], "answer_start": [316, 316, 316]}, "prediction_text": "Kenneth Swezey"}
{"answers": {"text": ["journalist", "journalist", "journalist"], "answer_start": [334, 334, 334]}, "prediction_text": "A journalist"}
{"answers": {"text": ["chastity", "his chastity", "chastity"], "answer_start": [33, 29, 33]}, "prediction_text": "Chastity"}
{"answers": {"text": ["women", "women"], "answer_start": [270, 270]}, "prediction_text": "Women"}
{"answers": {"text": ["toward the end of his life", "toward the end of his life", "toward the end of his life"], "answer_start": [100, 100, 100]}, "prediction_text": "End of his life"}
{"answers": {"text": ["Dorothy Skerrit", "Dorothy Skerrit", "Dorothy Skerrit"], "answer_start": [324, 324, 324]}, "prediction_text": "Dorothy Skerrit"}
{"answers": {"text": ["Robert Underwood Johnson", "Robert Underwood Johnson", "Robert Underwood Johnson"], "answer_start": [167, 167, 167]}, "prediction_text": "Robert Underwood Johnson"}
{"answers": {"text": ["seclude himself", "seclude himself", "seclude himself with his work"], "answer_start": [31, 31, 31]}, "prediction_text": "Engage in social life"}
{"answers": {"text": ["asocial", "asocial"], "answer_start": [10, 10]}, "prediction_text": "Attractive"}
{"answers": {"text": ["friend", "friend", "friend"], "answer_start": [482, 482, 482]}, "prediction_text": "Julian Hawthorne was Tesla's friend."}
{"answers": {"text": ["Mark Twain", "Mark Twain", "Mark Twain"], "answer_start": [194, 194, 194]}, "prediction_text": "Mark Twain"}
{"answers": {"text": ["lab", "in his lab", "in his lab and elsewhere"], "answer_start": [247, 240, 240]}, "prediction_text": "In his lab"}
{"answers": {"text": ["late 1920s", "the late 1920s", "the late 1920s"], "answer_start": [382, 378, 378]}, "prediction_text": "Late 1920s"}
{"answers": {"text": ["overweight people", "overweight people", "overweight people"], "answer_start": [63, 63, 63]}, "prediction_text": "overweight people"}
{"answers": {"text": ["secretary", "a secretary", "a secretary"], "answer_start": [106, 104, 104]}, "prediction_text": "Secretary"}
{"answers": {"text": ["her weight", "her weight", "her weight."], "answer_start": [127, 127, 127]}, "prediction_text": "Weight"}
{"answers": {"text": ["go home and change", "go home and change", "to go home and change her dress"], "answer_start": [233, 233, 230]}, "prediction_text": "Change her dress."}
{"answers": {"text": ["electron", "an electron"], "answer_start": [194, 191]}, "prediction_text": "An electron"}
{"answers": {"text": ["ether", "ether"], "answer_start": [592, 592]}, "prediction_text": "Electrons and subatomic particles."}
{"answers": {"text": ["transmitted electrical energy", "transmitted electrical energy", "transmitted electrical energy"], "answer_start": [604, 604, 604]}, "prediction_text": "transmitted electrical energy"}
{"answers": {"text": ["19th", "the 19th", "19th"], "answer_start": [550, 546, 550]}, "prediction_text": "19th century"}
{"answers": {"text": ["Einstein's", "Einstein's", "Einstein's"], "answer_start": [122, 122, 122]}, "prediction_text": "Einstein's theory of relativity"}
{"answers": {"text": ["antagonistic", "antagonistic", "antagonistic"], "answer_start": [20, 20, 20]}, "prediction_text": "Anticipated rejection."}
{"answers": {"text": ["relativity", "relativity", "theory of relativity"], "answer_start": [143, 143, 133]}, "prediction_text": "Einstein's theory of relativity"}
{"answers": {"text": ["gravity", "gravity", "of gravity"], "answer_start": [206, 206, 203]}, "prediction_text": "Dynamic theory of gravity"}
{"answers": {"text": ["1892", "1892, and in 1937", "1892"], "answer_start": [117, 117, 117]}, "prediction_text": "1892"}
{"answers": {"text": ["curved", "curved", "curved"], "answer_start": [295, 295, 295]}, "prediction_text": "curved space"}
{"answers": {"text": ["81", "81", "81"], "answer_start": [143, 143, 143]}, "prediction_text": "81"}
{"answers": {"text": ["eugenics", "eugenics", "imposed selective breeding version of eugenics"], "answer_start": [92, 92, 54]}, "prediction_text": "Eugenics"}
{"answers": {"text": ["ruthless", "ruthless", "ruthless workings"], "answer_start": [191, 191, 191]}, "prediction_text": "A \"master race\" or inherent superiority."}
{"answers": {"text": ["pity", "pity", "pity"], "answer_start": [152, 152, 152]}, "prediction_text": "Pity"}
{"answers": {"text": ["1937", "1937", "1937"], "answer_start": [379, 379, 379]}, "prediction_text": "1937"}
{"answers": {"text": ["women", "women", "women"], "answer_start": [67, 207, 207]}, "prediction_text": "Queen Bees"}
{"answers": {"text": ["1926", "1926", "1926"], "answer_start": [3, 3, 3]}, "prediction_text": "1926"}
{"answers": {"text": ["Queen Bees", "Queen Bees", "Queen Bees"], "answer_start": [177, 177, 177]}, "prediction_text": "Queen Bees"}
{"answers": {"text": ["post-World War I", "post-World War I", "post-World War I"], "answer_start": [54, 54, 54]}, "prediction_text": "World War I"}
{"answers": {"text": ["Science and Discovery", "Science and Discovery", "Science and Discovery"], "answer_start": [106, 106, 106]}, "prediction_text": "Science and Discovery"}
{"answers": {"text": ["20 December 1914", "20 December 1914", "20 December 1914"], "answer_start": [198, 198, 198]}, "prediction_text": "December 1914"}
{"answers": {"text": ["League of Nations", "the League of Nations", "League of Nations"], "answer_start": [241, 237, 241]}, "prediction_text": "The League of Nations"}
{"answers": {"text": ["Orthodox Christian", "Orthodox Christian", "Orthodox Christian"], "answer_start": [20, 20, 20]}, "prediction_text": "Orthodox Christian"}
{"answers": {"text": ["fanaticism", "fanaticism", "fanaticism"], "answer_start": [151, 151, 151]}, "prediction_text": "Religious fanaticism"}
{"answers": {"text": ["Buddhism and Christianity", "Buddhism and Christianity", "Buddhism and Christianity"], "answer_start": [212, 212, 212]}, "prediction_text": "Buddhism and Christianity"}
{"answers": {"text": ["\"A Machine to End War\"", "\"A Machine to End War\"", "A Machine to End War"], "answer_start": [113, 113, 114]}, "prediction_text": "\"A Machine to End War\""}
{"answers": {"text": ["uncertain", "uncertain", "uncertain"], "answer_start": [36, 36, 36]}, "prediction_text": "Uncertain"}
{"answers": {"text": ["War", "War", "War"], "answer_start": [131, 131, 131]}, "prediction_text": "War"}
{"answers": {"text": ["books and articles", "a number of books and articles", "a number of books and articles"], "answer_start": [24, 12, 12]}, "prediction_text": "Autobiography of Nikola Tesla"}
{"answers": {"text": ["magazines and journals", "magazines and journals", "magazines and journals"], "answer_start": [47, 47, 47]}, "prediction_text": "Ben Johnston"}
{"answers": {"text": ["Ben Johnston", "Ben Johnston", "Ben Johnston"], "answer_start": [164, 164, 164]}, "prediction_text": "Ben Johnston"}
{"answers": {"text": ["the web", "on the web", "freely available on the web"], "answer_start": [49, 46, 29]}, "prediction_text": "The web"}
{"answers": {"text": ["1900", "1900", "1900"], "answer_start": [159, 159, 159]}, "prediction_text": "1900"}
{"answers": {"text": ["Inventions, Researches and Writings of Nikola Tesla.", "Researches and Writings of Nikola Tesla", "Researches and Writings of Nikola Tesla"], "answer_start": [279, 291, 291]}, "prediction_text": "Inventions, Researches and Writings"}
{"answers": {"text": ["science fiction", "science", "science fiction"], "answer_start": [204, 204, 204]}, "prediction_text": "Science fiction"}
{"answers": {"text": ["books, films, radio, TV, music, live theater, comics and video games", "books, films, radio, TV, music, live theater, comics and video games", "books, films, radio, TV, music, live theater, comics and video games"], "answer_start": [30, 30, 30]}, "prediction_text": "Books, films, radio, TV, comics, live theater, games, and video games."}
{"answers": {"text": ["several", "several", "several"], "answer_start": [187, 187, 187]}, "prediction_text": "Several types"}
{"answers": {"text": ["Time magazine", "Time", "Time"], "answer_start": [34, 34, 34]}, "prediction_text": "Time magazine"}
{"answers": {"text": ["75th birthday", "75th birthday", "75th birthday"], "answer_start": [11, 11, 11]}, "prediction_text": "Tesla's 75th birthday"}
{"answers": {"text": ["electrical power generation", "electrical power generation", "electrical power generation"], "answer_start": [148, 148, 148]}, "prediction_text": "Electrical power generation"}
{"answers": {"text": ["Einstein", "Albert Einstein", "Albert Einstein"], "answer_start": [284, 277, 277]}, "prediction_text": "Albert Einstein"}
{"answers": {"text": ["more than 70", "more than 70", "more than 70"], "answer_start": [217, 217, 217]}, "prediction_text": "More than 70 people"}
{"answers": {"text": ["Computational complexity theory", "Computational complexity theory", "Computational complexity theory"], "answer_start": [0, 0, 0]}, "prediction_text": "Computational complexity theory"}
{"answers": {"text": ["inherent difficulty", "their inherent difficulty", "inherent difficulty"], "answer_start": [175, 169, 175]}, "prediction_text": "They are amenable to being solved by a computer."}
{"answers": {"text": ["computational problems", "A computational problem", "computational problem"], "answer_start": [133, 238, 240]}, "prediction_text": "Computational complexity theory"}
{"answers": {"text": ["if its solution requires significant resources", "its solution requires significant resources", "if its solution requires significant resources"], "answer_start": [46, 49, 46]}, "prediction_text": "Mathematical models of computation"}
{"answers": {"text": ["mathematical models of computation", "mathematical models of computation", "mathematical models of computation"], "answer_start": [176, 176, 176]}, "prediction_text": "Mathematical models of computation"}
{"answers": {"text": ["time and storage", "time and storage", "time and storage"], "answer_start": [305, 305, 305]}, "prediction_text": "Time and storage."}
{"answers": {"text": ["number of gates in a circuit", "number of gates in a circuit", "number of gates"], "answer_start": [440, 440, 440]}, "prediction_text": "Number of processors"}
{"answers": {"text": ["determine the practical limits on what computers can and cannot do", "what computers can and cannot do", "determine the practical limits on what computers can and cannot do"], "answer_start": [615, 649, 615]}, "prediction_text": "Determine practical limits"}
{"answers": {"text": ["analysis of algorithms and computability theory", "analysis of algorithms and computability theory", "analysis of algorithms and computability theory"], "answer_start": [59, 59, 59]}, "prediction_text": "Analysis of algorithms and computational complexity theory"}
{"answers": {"text": ["analysis of algorithms", "analysis of algorithms", "analysis of algorithms"], "answer_start": [59, 134, 134]}, "prediction_text": "Analysis of algorithms"}
{"answers": {"text": ["computational complexity theory", "computational complexity theory", "computational complexity theory"], "answer_start": [161, 161, 161]}, "prediction_text": "Analysis of algorithms and computational complexity theory"}
{"answers": {"text": ["computability theory", "computability theory", "computability theory"], "answer_start": [86, 663, 663]}, "prediction_text": "Analysis of algorithms"}
{"answers": {"text": ["problem instance", "a problem instance", "problem instance"], "answer_start": [187, 185, 187]}, "prediction_text": "Problem instance"}
{"answers": {"text": ["the problem", "a problem", "problem"], "answer_start": [237, 293, 295]}, "prediction_text": "Problem instance"}
{"answers": {"text": ["concrete", "concrete", "abstract"], "answer_start": [402, 402, 317]}, "prediction_text": "Abstract or concrete."}
{"answers": {"text": ["instances", "the instance", "instance"], "answer_start": [67, 675, 679]}, "prediction_text": "An instance of a problem"}
{"answers": {"text": ["solution", "the solution", "solution"], "answer_start": [93, 730, 734]}, "prediction_text": "Output to the given input."}
{"answers": {"text": ["2000", "2000", "2000"], "answer_start": [190, 190, 190]}, "prediction_text": "At most 2000 kilometers"}
{"answers": {"text": ["round trip through all sites in Milan", "asking for a round trip through all sites in Milan whose total length is at most 10 km", "a round trip through all sites in Milan whose total length is at most 10 km"], "answer_start": [400, 387, 398]}, "prediction_text": "The traveling salesman problem"}
{"answers": {"text": ["computational problems", "computational problems", "computational problems"], "answer_start": [520, 520, 520]}, "prediction_text": "Problems with computational complexity."}
{"answers": {"text": ["problem instance", "a problem instance", "problem instance"], "answer_start": [43, 41, 43]}, "prediction_text": "Bitstrings"}
{"answers": {"text": ["binary alphabet", "binary", "binary"], "answer_start": [131, 131, 131]}, "prediction_text": "Binary alphabet"}
{"answers": {"text": ["bitstrings", "bitstrings", "bitstrings"], "answer_start": [195, 195, 195]}, "prediction_text": "Bitstrings"}
{"answers": {"text": ["binary notation", "binary notation", "binary notation"], "answer_start": [349, 349, 349]}, "prediction_text": "In binary notation."}
{"answers": {"text": ["adjacency matrices", "directly via their adjacency matrices"], "answer_start": [411, 392]}, "prediction_text": "By encoding their adjacency lists."}
{"answers": {"text": ["Decision problems", "Decision problems", "Decision"], "answer_start": [0, 0, 0]}, "prediction_text": "Decision problems"}
{"answers": {"text": ["yes or no", "yes or no", "yes or no"], "answer_start": [179, 179, 179]}, "prediction_text": "Yes or no"}
{"answers": {"text": ["1 or 0", "1 or 0", "1 or 0"], "answer_start": [212, 212, 212]}, "prediction_text": "Yes or no"}
{"answers": {"text": ["yes", "yes", "yes"], "answer_start": [179, 339, 339]}, "prediction_text": "Yes or no"}
{"answers": {"text": ["yes", "yes", "yes"], "answer_start": [179, 605, 605]}, "prediction_text": "Yes or no"}
{"answers": {"text": ["arbitrary graph", "arbitrary", "arbitrary"], "answer_start": [67, 67, 67]}, "prediction_text": "Graphs with arbitrary connections."}
{"answers": {"text": ["formal language", "The formal language", "The formal language associated with this decision problem"], "answer_start": [167, 163, 163]}, "prediction_text": "Set of all connected graphs"}
{"answers": {"text": ["how graphs are encoded as binary strings", "how graphs are encoded as binary strings", "how graphs are encoded as binary strings"], "answer_start": [339, 339, 339]}, "prediction_text": "Graph encoding"}
{"answers": {"text": ["a computational problem", "a computational problem", "a computational problem"], "answer_start": [22, 22, 22]}, "prediction_text": "computational problem"}
{"answers": {"text": ["a single output", "single", "single"], "answer_start": [52, 54, 54]}, "prediction_text": "Each output is expected for every input."}
{"answers": {"text": ["A function problem", "function", "function problem"], "answer_start": [0, 2, 2]}, "prediction_text": "computational problem"}
{"answers": {"text": ["the integer factorization problem", "integer factorization", "integer factorization problem"], "answer_start": [277, 281, 281]}, "prediction_text": "integer factorization"}
{"answers": {"text": ["complex", "complex", "complex"], "answer_start": [142, 142, 142]}, "prediction_text": "Simple answer."}
{"answers": {"text": ["decision problems", "as decision problems", "as decision problems"], "answer_start": [95, 190, 190]}, "prediction_text": "As decision problems."}
{"answers": {"text": ["set of triples", "triple", "the set of triples (a, b, c) such that the relation a \u00d7 b = c holds"], "answer_start": [284, 374, 280]}, "prediction_text": "Triples"}
{"answers": {"text": ["how much time the best algorithm requires to solve the problem", "time", "time"], "answer_start": [82, 91, 91]}, "prediction_text": "Time required to solve a problem (or space required)"}
{"answers": {"text": ["the instance", "the instance", "the size of the instance"], "answer_start": [199, 199, 405]}, "prediction_text": "Size of the instance"}
{"answers": {"text": ["as a function of the size of the instance", "as a function of the size of the instance", "a function of the size of the instance"], "answer_start": [388, 388, 391]}, "prediction_text": "As a function of the size of the instance."}
{"answers": {"text": ["bits", "bits", "bits"], "answer_start": [484, 484, 484]}, "prediction_text": "In bits"}
{"answers": {"text": ["an increase in the input size", "input size", "input size"], "answer_start": [551, 570, 570]}, "prediction_text": "Input size"}
{"answers": {"text": ["Cobham's thesis", "Cobham's", "Cobham"], "answer_start": [347, 347, 347]}, "prediction_text": "Cobham's thesis"}
{"answers": {"text": ["the time taken", "the time taken", "the time taken"], "answer_start": [24, 24, 24]}, "prediction_text": "Time taken over all inputs of size n."}
{"answers": {"text": ["worst-case time complexity", "worst-case time complexity", "the worst-case time complexity"], "answer_start": [156, 156, 152]}, "prediction_text": "T(n)"}
{"answers": {"text": ["T(n)", "T(n)", "T(n)"], "answer_start": [183, 183, 183]}, "prediction_text": "T(n)"}
{"answers": {"text": ["polynomial time algorithm", "polynomial time", "polynomial time algorithm"], "answer_start": [320, 320, 320]}, "prediction_text": "Polynomial time algorithm"}
{"answers": {"text": ["A Turing machine", "A Turing machine", "Turing machine"], "answer_start": [0, 0, 2]}, "prediction_text": "Turing machine"}
{"answers": {"text": ["an algorithm", "an algorithm", "an algorithm"], "answer_start": [427, 427, 427]}, "prediction_text": "An algorithm"}
{"answers": {"text": ["the Turing machine", "the Turing machine", "Turing machine"], "answer_start": [924, 924, 928]}, "prediction_text": "Turing machine"}
{"answers": {"text": ["symbols", "symbols", "symbols"], "answer_start": [117, 117, 117]}, "prediction_text": "Symbols contained on a strip of tape."}
{"answers": {"text": ["A deterministic Turing machine", "deterministic", "deterministic Turing machine"], "answer_start": [0, 2, 2]}, "prediction_text": "A deterministic Turing machine"}
{"answers": {"text": ["rules", "rules", "a fixed set of rules to determine its future actions"], "answer_start": [91, 91, 76]}, "prediction_text": "A fixed set of rules"}
{"answers": {"text": ["A probabilistic Turing machine", "probabilistic", "probabilistic Turing machine"], "answer_start": [130, 132, 132]}, "prediction_text": "Random bits"}
{"answers": {"text": ["A non-deterministic Turing machine", "non-deterministic", "non-deterministic Turing machine"], "answer_start": [398, 400, 400]}, "prediction_text": "Random Turing machine"}
{"answers": {"text": ["randomized algorithms", "randomized algorithms", "randomized algorithms"], "answer_start": [375, 375, 375]}, "prediction_text": "Random bits are used in algorithms that use random bits."}
{"answers": {"text": ["complexity classes", "complexity classes", "complexity classes"], "answer_start": [49, 49, 49]}, "prediction_text": "Complexity classes"}
{"answers": {"text": ["time or space", "time or space", "time or space"], "answer_start": [330, 330, 330]}, "prediction_text": "Resources (time or space)"}
{"answers": {"text": ["probabilistic Turing machines, non-deterministic Turing machines", "probabilistic Turing machines, non-deterministic Turing machines"], "answer_start": [108, 108]}, "prediction_text": "deterministic Turing machines, probabilistic Turing machines."}
{"answers": {"text": ["random access machines", "random access machines", "random access machines"], "answer_start": [125, 125, 125]}, "prediction_text": "Random access machine"}
{"answers": {"text": ["computational power", "computational power", "computational power"], "answer_start": [248, 248, 248]}, "prediction_text": "Time and memory consumption"}
{"answers": {"text": ["time and memory", "time and memory consumption", "time and memory consumption"], "answer_start": [273, 273, 273]}, "prediction_text": "Time and memory"}
{"answers": {"text": ["the machines operate deterministically", "deterministically", "the machines operate deterministically"], "answer_start": [382, 403, 382]}, "prediction_text": "They operate deterministically."}
{"answers": {"text": ["non-deterministic", "non-deterministic", "non-deterministic Turing machine"], "answer_start": [110, 110, 110]}, "prediction_text": "Non-deterministic Turing machine"}
{"answers": {"text": ["unusual resources", "more unusual resources", "more unusual resources"], "answer_start": [76, 71, 71]}, "prediction_text": "More unusual resources"}
{"answers": {"text": ["mathematical models", "mathematical models", "branching"], "answer_start": [402, 402, 363]}, "prediction_text": "Mathematical models"}
{"answers": {"text": ["time", "non-deterministic time", "non-deterministic time"], "answer_start": [468, 450, 450]}, "prediction_text": "Mathematical models"}
{"answers": {"text": ["state transitions", "the total number of state transitions, or steps", "total number of state transitions, or steps, the machine makes before it halts and outputs the answer"], "answer_start": [261, 241, 245]}, "prediction_text": "The total number of state transitions or steps the machine makes before stopping."}
{"answers": {"text": ["difficulty", "difficulty", "difficulty"], "answer_start": [695, 695, 695]}, "prediction_text": "Difficulty"}
{"answers": {"text": ["DTIME(f(n))", "DTIME(f(n)).", "DTIME(f(n))"], "answer_start": [873, 873, 873]}, "prediction_text": "DTIME(f(n)"}
{"answers": {"text": ["time", "time", "time"], "answer_start": [85, 583, 583]}, "prediction_text": "Time and space"}
{"answers": {"text": ["complexity resources", "complexity resources", "complexity"], "answer_start": [106, 106, 106]}, "prediction_text": "Complexity resources"}
{"answers": {"text": ["computational resource", "computational", "computational"], "answer_start": [170, 170, 170]}, "prediction_text": "computational resource"}
{"answers": {"text": ["Blum complexity axioms", "the Blum complexity axioms", "the Blum complexity axioms"], "answer_start": [248, 244, 244]}, "prediction_text": "Blum complexity axioms"}
{"answers": {"text": ["Complexity measures", "complexity measures", "complexity"], "answer_start": [194, 278, 278]}, "prediction_text": "Decision tree complexity"}
{"answers": {"text": ["Complexity measures", "complexity measures", "complexity"], "answer_start": [194, 278, 396]}, "prediction_text": "Decision tree"}
{"answers": {"text": ["best, worst and average", "best, worst and average case", "best, worst and average case complexity"], "answer_start": [4, 4, 4]}, "prediction_text": "Best, worst, average case complexity"}
{"answers": {"text": ["complexity measure", "complexity", "complexity"], "answer_start": [121, 121, 121]}, "prediction_text": "Time complexity"}
{"answers": {"text": ["time", "time complexity", "time complexity"], "answer_start": [91, 91, 91]}, "prediction_text": "Time complexity (or any other complexity measure)"}
{"answers": {"text": ["inputs", "inputs", "inputs"], "answer_start": [154, 154, 154]}, "prediction_text": "Time complexity"}
{"answers": {"text": ["deterministic sorting algorithm quicksort", "quicksort", "the deterministic sorting algorithm quicksort"], "answer_start": [26, 58, 22]}, "prediction_text": "Quicksort"}
{"answers": {"text": ["worst-case", "worst", "worst-case"], "answer_start": [155, 155, 155]}, "prediction_text": "Worst-case"}
{"answers": {"text": ["O(n2)", "O(n2)", "O(n2)"], "answer_start": [251, 251, 251]}, "prediction_text": "O(n log n)"}
{"answers": {"text": ["the most efficient algorithm", "the most efficient algorithm", "the most efficient algorithm solving a given problem"], "answer_start": [178, 178, 178]}, "prediction_text": "An algorithm solving a given problem."}
{"answers": {"text": ["analysis of algorithms", "analysis of algorithms", "analysis of algorithms"], "answer_start": [399, 399, 399]}, "prediction_text": "Analysis of algorithms"}
{"answers": {"text": ["lower bounds", "lower", "lower bounds"], "answer_start": [123, 597, 597]}, "prediction_text": "Lower bounds for algorithms with running time."}
{"answers": {"text": ["upper bound", "upper and lower bounds", "upper bound"], "answer_start": [434, 113, 434]}, "prediction_text": "Lower bounds on time complexity"}
{"answers": {"text": ["all possible algorithms", "all possible algorithms", "all possible algorithms"], "answer_start": [676, 740, 740]}, "prediction_text": "\"All possible algorithms\""}
{"answers": {"text": ["big O notation", "big O notation", "big O notation"], "answer_start": [52, 52, 52]}, "prediction_text": "Big O notation"}
{"answers": {"text": ["constant factors and smaller terms", "constant factors and smaller terms", "constant factors and smaller terms"], "answer_start": [80, 80, 80]}, "prediction_text": "Constant factors and smaller terms."}
{"answers": {"text": ["T(n) = O(n2)", "T(n) = O(n2)", "T(n) = O(n2)"], "answer_start": [281, 281, 281]}, "prediction_text": "In big O notation one would write T(n) = O(n2)"}
{"answers": {"text": ["the computational model", "specific details of the computational model used", "the specific details of the computational model used"], "answer_start": [177, 157, 153]}, "prediction_text": "computational model"}
{"answers": {"text": ["complexity classes", "complexity classes", "some complexity classes"], "answer_start": [16, 16, 11]}, "prediction_text": "Complexity classes"}
{"answers": {"text": ["framework", "framework", "framework"], "answer_start": [90, 90, 90]}, "prediction_text": "Complexity classes are classified into what?"}
{"answers": {"text": ["complicated definitions", "complicated definitions", "definitions"], "answer_start": [40, 40, 52]}, "prediction_text": "Variable in the definition"}
{"answers": {"text": ["chosen machine model", "the chosen machine model", "the chosen machine model"], "answer_start": [122, 118, 118]}, "prediction_text": "Machine model"}
{"answers": {"text": ["linear time", "linear", "linear"], "answer_start": [218, 218, 218]}, "prediction_text": "Quadratic time"}
{"answers": {"text": ["single-tape Turing machines", "single-tape", "single-tape"], "answer_start": [318, 318, 318]}, "prediction_text": "Single-tape Turing machines"}
{"answers": {"text": ["Cobham-Edmonds thesis", "Cobham-Edmonds", "Cobham-Edmonds thesis"], "answer_start": [398, 398, 398]}, "prediction_text": "Cobham-Edmonds thesis"}
{"answers": {"text": ["complexity class P", "P", "complexity class P"], "answer_start": [597, 614, 597]}, "prediction_text": "Pairs of decision problems"}
{"answers": {"text": ["time or space", "time or space", "time or space"], "answer_start": [65, 65, 65]}, "prediction_text": "Time and space measurements"}
{"answers": {"text": ["bounding", "bounding", "bounding"], "answer_start": [52, 52, 52]}, "prediction_text": "Time or space function"}
{"answers": {"text": ["complexity classes", "complexity classes", "complexity classes"], "answer_start": [15, 15, 15]}, "prediction_text": "Complexity classes"}
{"answers": {"text": ["BPP, ZPP and RP", "BPP, ZPP and RP", "BPP, ZPP and RP"], "answer_start": [43, 43, 43]}, "prediction_text": "BPP, ZPP, RP"}
{"answers": {"text": ["Boolean", "Boolean", "Boolean circuits;"], "answer_start": [150, 150, 150]}, "prediction_text": "Boolean circuits"}
{"answers": {"text": ["quantum", "quantum", "quantum"], "answer_start": [209, 209, 209]}, "prediction_text": "Quantum Turing machines"}
{"answers": {"text": ["#P", "#P", "#P"], "answer_start": [234, 234, 234]}, "prediction_text": "#P"}
{"answers": {"text": ["Interactive", "Interactive", "Interactive"], "answer_start": [357, 357, 357]}, "prediction_text": "Interactive proof systems"}
{"answers": {"text": ["computation time", "computation time", "computation time"], "answer_start": [113, 113, 113]}, "prediction_text": "DTIME(n)"}
{"answers": {"text": ["DTIME(n2)", "DTIME(n2)", "DTIME(n2)"], "answer_start": [220, 220, 220]}, "prediction_text": "DTIME(n2)"}
{"answers": {"text": ["time and space hierarchy theorems", "time and space hierarchy theorems", "time and space hierarchy theorems"], "answer_start": [369, 369, 369]}, "prediction_text": "DTIME(n) and DTIME(n2)"}
{"answers": {"text": ["a proper hierarchy on the classes defined", "a proper hierarchy on the classes", "a proper hierarchy"], "answer_start": [472, 472, 472]}, "prediction_text": "Proper hierarchy"}
{"answers": {"text": ["quantitative statements", "quantitative", "quantitative"], "answer_start": [714, 714, 714]}, "prediction_text": "Quantitative statements about additional time or space needed."}
{"answers": {"text": ["time and space hierarchy theorems", "The time and space hierarchy theorems", "time and space hierarchy theorems"], "answer_start": [4, 0, 4]}, "prediction_text": "Time and space hierarchy theorem"}
{"answers": {"text": ["EXPTIME", "EXPTIME", "EXPTIME"], "answer_start": [186, 186, 186]}, "prediction_text": "Existence in EXPTIME"}
{"answers": {"text": ["PSPACE", "PSPACE", "PSPACE"], "answer_start": [268, 268, 268]}, "prediction_text": "PSPACE"}
{"answers": {"text": ["reduction", "a reduction", "reduction"], "answer_start": [59, 57, 59]}, "prediction_text": "Reduction concept"}
{"answers": {"text": ["another problem", "another problem", "another problem"], "answer_start": [122, 122, 122]}, "prediction_text": "Another problem"}
{"answers": {"text": ["reduces", "reduces", "X reduces to Y"], "answer_start": [350, 350, 348]}, "prediction_text": "Reduce to Y"}
{"answers": {"text": ["Karp reductions and Levin reductions", "Cook reductions, Karp reductions"], "answer_start": [469, 452]}, "prediction_text": "Cook reductions, Karp reductions, and log-space reductions."}
{"answers": {"text": ["the bound on the complexity of reductions", "types of reductions", "the bound on the complexity of reductions"], "answer_start": [511, 389, 511]}, "prediction_text": "Polynomial-time reductions"}
{"answers": {"text": ["polynomial-time reduction", "polynomial-time", "polynomial-time reduction"], "answer_start": [38, 38, 38]}, "prediction_text": "Polynomial-time reduction"}
{"answers": {"text": ["multiplying two integers", "multiplying two integers", "multiplying two integers"], "answer_start": [207, 207, 207]}, "prediction_text": "Two integers"}
{"answers": {"text": ["polynomial time", "polynomial", "polynomial time"], "answer_start": [109, 109, 109]}, "prediction_text": "Polynomial time"}
{"answers": {"text": ["input", "input", "input"], "answer_start": [364, 364, 364]}, "prediction_text": "Inputs of the multiplication algorithm."}
{"answers": {"text": ["multiplication", "multiplication", "multiplication"], "answer_start": [392, 520, 520]}, "prediction_text": "multiplication"}
{"answers": {"text": ["the type of reduction being used", "the type of reduction being used"], "answer_start": [315, 315]}, "prediction_text": "Reduction methods"}
{"answers": {"text": ["if every problem in C can be reduced to X", "problem in C is harder than X"], "answer_start": [121, 172]}, "prediction_text": "A conflict between a problem X and problem C within the context of reduction."}
{"answers": {"text": ["solve any problem in C", "solve any problem in C", "solve any problem in C"], "answer_start": [241, 241, 241]}, "prediction_text": "Solve any problem in C."}
{"answers": {"text": ["NP-hard", "NP-hard", "NP-hard problems"], "answer_start": [503, 503, 503]}, "prediction_text": "The set of problems that are NP-hard."}
{"answers": {"text": ["NP-complete", "NP-complete", "NP-complete"], "answer_start": [244, 244, 244]}, "prediction_text": "NP-complete problems"}
{"answers": {"text": ["NP", "P", "P"], "answer_start": [244, 370, 370]}, "prediction_text": "P (Possible solution)"}
{"answers": {"text": ["there is no known polynomial-time solution", "no known polynomial-time solution", "there is no known polynomial-time solution"], "answer_start": [513, 522, 513]}, "prediction_text": "No known polynomial-time solution."}
{"answers": {"text": ["NP", "NP", "NP"], "answer_start": [244, 810, 810]}, "prediction_text": "P = NP"}
{"answers": {"text": ["P", "P", "P"], "answer_start": [21, 21, 21]}, "prediction_text": "P"}
{"answers": {"text": ["Cobham\u2013Edmonds thesis", "Cobham\u2013Edmonds thesis", "Cobham\u2013Edmonds thesis"], "answer_start": [167, 167, 167]}, "prediction_text": "Cobham\u2013Edmonds thesis"}
{"answers": {"text": ["NP", "NP", "NP"], "answer_start": [211, 211, 211]}, "prediction_text": "P"}
{"answers": {"text": ["Boolean satisfiability problem", "Boolean satisfiability problem"], "answer_start": [361, 361]}, "prediction_text": "Boolean satisfiability problem"}
{"answers": {"text": ["Turing machines", "deterministic Turing machines", "deterministic Turing machines"], "answer_start": [472, 458, 458]}, "prediction_text": "Turing machines"}
{"answers": {"text": ["more efficient solutions", "shown to have more efficient solutions", "many important problems can be shown to have more efficient solutions"], "answer_start": [227, 213, 182]}, "prediction_text": "More efficient solutions."}
{"answers": {"text": ["protein structure prediction", "protein structure prediction", "protein structure prediction"], "answer_start": [365, 365, 365]}, "prediction_text": "Protein structure prediction"}
{"answers": {"text": ["$1,000,000", "US$1,000,000", "US$1,000,000"], "answer_start": [595, 593, 593]}, "prediction_text": "US$1,000,000"}
{"answers": {"text": ["Ladner", "Ladner", "Ladner"], "answer_start": [16, 16, 16]}, "prediction_text": "Ladner"}
{"answers": {"text": ["NP-intermediate problems", "NP-intermediate problems", "NP-intermediate"], "answer_start": [134, 134, 134]}, "prediction_text": "NP-intermediate problem"}
{"answers": {"text": ["graph isomorphism problem", "the discrete logarithm problem", "graph isomorphism problem, the discrete logarithm problem and the integer factorization problem"], "answer_start": [164, 191, 164]}, "prediction_text": "integer factorization problem"}
{"answers": {"text": ["The graph isomorphism problem", "graph isomorphism", "The graph isomorphism problem"], "answer_start": [0, 4, 0]}, "prediction_text": "Graph isomorphism problem"}
{"answers": {"text": ["NP-complete", "NP-complete", "NP-complete"], "answer_start": [217, 327, 327]}, "prediction_text": "NP-complete"}
{"answers": {"text": ["polynomial time hierarchy", "polynomial time", "polynomial time hierarchy"], "answer_start": [381, 381, 381]}, "prediction_text": "Polynomial time hierarchy"}
{"answers": {"text": ["second level", "second", "second"], "answer_start": [424, 424, 424]}, "prediction_text": "Second level"}
{"answers": {"text": ["Laszlo Babai and Eugene Luks", "Babai and Eugene Luks", "Laszlo Babai and Eugene Luks"], "answer_start": [637, 644, 637]}, "prediction_text": "Laszlo Babai and Eugene Luks"}
{"answers": {"text": ["The integer factorization problem", "integer factorization", "integer factorization problem"], "answer_start": [0, 4, 4]}, "prediction_text": "integer factorization"}
{"answers": {"text": ["k", "k", "k"], "answer_start": [224, 224, 224]}, "prediction_text": "k (in a given integer)"}
{"answers": {"text": ["modern cryptographic systems", "modern cryptographic systems", "RSA algorithm"], "answer_start": [323, 323, 365]}, "prediction_text": "RSA algorithm"}
{"answers": {"text": ["the general number field sieve", "RSA", "general number field sieve"], "answer_start": [641, 365, 645]}, "prediction_text": "Shor's algorithm"}
{"answers": {"text": ["suspected to be unequal", "unequal", "Many known complexity classes are suspected to be unequal"], "answer_start": [34, 50, 0]}, "prediction_text": "P = PSPACE"}
{"answers": {"text": ["P \u2286 NP \u2286 PP \u2286 PSPACE", "P \u2286 NP \u2286 PP \u2286 PSPACE", "P \u2286 NP \u2286 PP \u2286 PSPACE"], "answer_start": [102, 102, 102]}, "prediction_text": "P = PSPACE"}
{"answers": {"text": ["between P and PSPACE", "between P and PSPACE", "between P and PSPACE"], "answer_start": [269, 269, 269]}, "prediction_text": "In the class P."}
{"answers": {"text": ["Proving that any of these classes are unequal", "Proving that any of these classes are unequal", "Proving that any of these classes are unequal"], "answer_start": [403, 403, 403]}, "prediction_text": "Evidence between complexity classes and one class."}
{"answers": {"text": ["co-NP", "co-NP", "co-NP"], "answer_start": [22, 22, 22]}, "prediction_text": "NP problems"}
{"answers": {"text": ["reversed", "reversed", "reversed"], "answer_start": [115, 115, 115]}, "prediction_text": "Reverse"}
{"answers": {"text": ["not equal", "not equal", "not equal"], "answer_start": [167, 303, 167]}, "prediction_text": "P is not equal to co-NP."}
{"answers": {"text": ["P is not equal to NP", "not equal", "P is not equal to NP"], "answer_start": [298, 303, 298]}, "prediction_text": "P is not equal to NP."}
{"answers": {"text": ["L", "L", "L"], "answer_start": [30, 30, 30]}, "prediction_text": "L (the set of all problems)"}
{"answers": {"text": ["strictly contained in P or equal to P", "contained in P or equal to P.", "strictly contained in P or equal to P"], "answer_start": [101, 110, 101]}, "prediction_text": "L is not strictly contained in P."}
{"answers": {"text": ["complexity classes", "many complexity classes", "many complexity classes"], "answer_start": [162, 157, 157]}, "prediction_text": "Complexity classes"}
{"answers": {"text": ["NL and NC", "NL and NC", "NL and NC"], "answer_start": [206, 206, 206]}, "prediction_text": "NL and NC"}
{"answers": {"text": ["if they are distinct or equal classes", "if they are distinct or equal classes", "if they are distinct or equal classes"], "answer_start": [237, 237, 237]}, "prediction_text": "They are not distinct classes."}
{"answers": {"text": ["intractable problems", "intractable problems", "intractable", "intractable"], "answer_start": [158, 158, 158, 158]}, "prediction_text": "Intractable problems"}
{"answers": {"text": ["exponential-time algorithms", "exponential-time", "exponential-time algorithms", "exponential-time algorithms"], "answer_start": [673, 673, 673, 673]}, "prediction_text": "exponential-time algorithms"}
{"answers": {"text": ["NP-complete problems", "NP-complete", "NP-complete", "NP-complete"], "answer_start": [605, 605, 605, 605]}, "prediction_text": "Existence-hard problems"}
{"answers": {"text": ["Presburger arithmetic", "Presburger", "Presburger arithmetic"], "answer_start": [219, 219, 219]}, "prediction_text": "Presburger arithmetic"}
{"answers": {"text": ["algorithms have been written", "algorithms have been written", "algorithms have been written that solve the problem in reasonable times in most cases"], "answer_start": [276, 276, 276]}, "prediction_text": "Algorithms have been written that solve the problem in reasonable times."}
{"answers": {"text": ["NP-complete knapsack problem", "NP-complete knapsack", "the NP-complete knapsack problem"], "answer_start": [399, 399, 395]}, "prediction_text": "NP-complete Boolean satisfiability problem"}
{"answers": {"text": ["in less than quadratic time", "less than quadratic time", "less than quadratic time"], "answer_start": [455, 458, 458]}, "prediction_text": "Less than quadratic time"}
{"answers": {"text": ["NP-complete Boolean satisfiability problem", "NP-complete Boolean satisfiability", "the NP-complete Boolean satisfiability problem"], "answer_start": [539, 539, 535]}, "prediction_text": "NP-complete Boolean satisfiability problem"}
{"answers": {"text": ["foundations were laid out", "numerous foundations were laid out", "numerous foundations were laid out by various researchers"], "answer_start": [110, 101, 101]}, "prediction_text": "Discernible simplifications"}
{"answers": {"text": ["Alan Turing", "Alan Turing", "Alan Turing"], "answer_start": [230, 230, 230]}, "prediction_text": "Alan Turing"}
{"answers": {"text": ["Turing machines", "Turing machines", "Turing machines"], "answer_start": [211, 211, 211]}, "prediction_text": "Turing machines"}
{"answers": {"text": ["1936", "1936", "1936"], "answer_start": [245, 245, 245]}, "prediction_text": "1936"}
{"answers": {"text": ["a computer", "a computer", "a computer"], "answer_start": [319, 319, 319]}, "prediction_text": "A computer's behavior"}
{"answers": {"text": ["On the Computational Complexity of Algorithms", "On the Computational Complexity of Algorithms", "\"On the Computational Complexity of Algorithms\""], "answer_start": [137, 137, 136]}, "prediction_text": "\"On the Computational Complexity of Algorithms\" by Juris Hartmanis and Richard Stearns"}
{"answers": {"text": ["Juris Hartmanis and Richard Stearns", "Juris Hartmanis and Richard Stearns", "Juris Hartmanis and Richard Stearns"], "answer_start": [187, 187, 187]}, "prediction_text": "Juris Hartmanis, Richard Stearns"}
{"answers": {"text": ["1965", "1965", "1965"], "answer_start": [224, 224, 224]}, "prediction_text": "1965"}
{"answers": {"text": ["time and space", "definitions of time and space complexity", "time and space complexity"], "answer_start": [265, 250, 265]}, "prediction_text": "Time and space complexity"}
{"answers": {"text": ["1965", "1965", "1965"], "answer_start": [224, 335, 335]}, "prediction_text": "1965"}
{"answers": {"text": ["John Myhill", "John Myhill", "John Myhill"], "answer_start": [102, 102, 102]}, "prediction_text": "John Myhill"}
{"answers": {"text": ["1961", "1961", "1961"], "answer_start": [215, 215, 215]}, "prediction_text": "1961"}
{"answers": {"text": ["Hisao Yamada", "Hisao Yamada", "Hisao Yamada"], "answer_start": [233, 233, 233]}, "prediction_text": "Hisao Yamada"}
{"answers": {"text": ["input encoding", "input encoding", "input encoding"], "answer_start": [98, 98, 98]}, "prediction_text": "Input encoding"}
{"answers": {"text": ["encoding", "encoding", "encoding"], "answer_start": [104, 198, 198]}, "prediction_text": "Encoding choice"}
{"answers": {"text": ["Manuel Blum", "Manuel Blum", "Manuel Blum"], "answer_start": [9, 9, 9]}, "prediction_text": "Manuel Blum"}
{"answers": {"text": ["speed-up theorem", "speed-up theorem", "speed-up theorem"], "answer_start": [129, 129, 129]}, "prediction_text": "Speed-up theorem"}
{"answers": {"text": ["\"Reducibility Among Combinatorial Problems\"", "Reducibility Among Combinatorial Problems", "\"Reducibility Among Combinatorial Problems\""], "answer_start": [433, 434, 433]}, "prediction_text": "\"Reducibility Among Combinatorial Problems\""}
{"answers": {"text": ["21", "21", "21"], "answer_start": [502, 502, 502]}, "prediction_text": "21"}
{"answers": {"text": ["the curriculum.", "curriculum", "curriculum"], "answer_start": [619, 623, 623]}, "prediction_text": "The curriculum"}
{"answers": {"text": ["pedagogy", "pedagogy", "formal education"], "answer_start": [328, 328, 91]}, "prediction_text": "Pedagogy"}
{"answers": {"text": ["university or college.", "university", "university or college"], "answer_start": [246, 246, 246]}, "prediction_text": "University or college"}
{"answers": {"text": ["lesson plan", "lesson plan", "lesson plan"], "answer_start": [531, 531, 531]}, "prediction_text": "Lessons plan"}
{"answers": {"text": ["school", "school", "school"], "answer_start": [66, 66, 66]}, "prediction_text": "At a school or other place of formal education."}
{"answers": {"text": ["cultures", "cultures", "cultures"], "answer_start": [32, 32, 32]}, "prediction_text": "Culture"}
{"answers": {"text": ["numeracy", "numeracy", "numeracy"], "answer_start": [91, 91, 91]}, "prediction_text": "Literacy and numeracy"}
{"answers": {"text": ["craftsmanship", "craftsmanship", "craftsmanship"], "answer_start": [101, 101, 101]}, "prediction_text": "Art, religion, civics, community roles, or life skills."}
{"answers": {"text": ["life skills", "life skills", "life skills"], "answer_start": [187, 187, 187]}, "prediction_text": "Literacy and numeracy teaching"}
{"answers": {"text": ["family member", "family member", "family member"], "answer_start": [171, 171, 171]}, "prediction_text": "A teacher"}
{"answers": {"text": ["home schooling", "home schooling", "home schooling"], "answer_start": [59, 59, 59]}, "prediction_text": "Home schooling"}
{"answers": {"text": ["formal", "Informal", "formal education"], "answer_start": [19, 75, 19]}, "prediction_text": "Informal learning"}
{"answers": {"text": ["transient", "transient", "Informal learning"], "answer_start": [134, 134, 75]}, "prediction_text": "Temporary or ongoing role"}
{"answers": {"text": ["knowledge or skills", "anyone with knowledge or skills", "knowledge or skills"], "answer_start": [204, 192, 204]}, "prediction_text": "Knowledge or skills in the wider community setting."}
{"answers": {"text": ["spiritual", "spiritual teachers", "gurus, mullahs, rabbis, pastors/youth pastors and lamas"], "answer_start": [14, 14, 42]}, "prediction_text": "Mullahs"}
{"answers": {"text": ["religious", "religious", "religious"], "answer_start": [109, 109, 109]}, "prediction_text": "Quran (or other religious text)"}
{"answers": {"text": ["the Quran, Torah or Bible", "Quran", "Torah"], "answer_start": [133, 137, 144]}, "prediction_text": "Quran"}
{"answers": {"text": ["Religious and spiritual teachers", "pastors", "Religious and spiritual teachers"], "answer_start": [0, 80, 0]}, "prediction_text": "Gurus, mullahs, rabbis, pastors/youth pastors."}
{"answers": {"text": ["homeschooling", "homeschooling", "homeschooling"], "answer_start": [75, 75, 75]}, "prediction_text": "Homeschooling"}
{"answers": {"text": ["paid professionals.", "professionals", "paid professionals"], "answer_start": [155, 160, 155]}, "prediction_text": "Paid professionals"}
{"answers": {"text": ["Chartered", "Chartered", "Chartered"], "answer_start": [290, 290, 290]}, "prediction_text": "Chartered or CPA"}
{"answers": {"text": ["the wider community", "wider community", "in the wider community"], "answer_start": [96, 100, 93]}, "prediction_text": "In the wider community"}
{"answers": {"text": ["paid professionals.", "professionals", "Formal teaching"], "answer_start": [155, 180, 117]}, "prediction_text": "Physicians, lawyers, engineers, and accountants."}
{"answers": {"text": ["school functions", "school functions", "school functions"], "answer_start": [193, 193, 193]}, "prediction_text": "School functions"}
{"answers": {"text": ["extracurricular", "extracurricular", "extracurricular"], "answer_start": [240, 240, 240]}, "prediction_text": "Extracurricular activities"}
{"answers": {"text": ["study halls", "study halls"], "answer_start": [150, 150]}, "prediction_text": "Extracurricular activities"}
{"answers": {"text": ["teachers", "teachers", "teachers"], "answer_start": [92, 295, 295]}, "prediction_text": "Teachers"}
{"answers": {"text": ["teacher's colleges", "colleges", "teacher's colleges"], "answer_start": [166, 176, 166]}, "prediction_text": "Certifying, governing, enforcing standards"}
{"answers": {"text": ["to serve and protect the public interest", "serve and protect the public", "to serve and protect the public interest"], "answer_start": [218, 221, 218]}, "prediction_text": "To protect public interest through certifying, governing and enforcing standards."}
{"answers": {"text": ["the public", "public", "public interest"], "answer_start": [239, 243, 243]}, "prediction_text": "Public interest"}
{"answers": {"text": ["teachers", "teachers", "the teaching profession"], "answer_start": [114, 114, 333]}, "prediction_text": "Teachers"}
{"answers": {"text": ["standards of practice", "standards of practice", "standards of practice for the teaching profession"], "answer_start": [307, 307, 307]}, "prediction_text": "Standards of practice for teaching"}
{"answers": {"text": ["members", "members", "members"], "answer_start": [177, 177, 177]}, "prediction_text": "Members of the teacher's college"}
{"answers": {"text": ["allegations of professional misconduct", "professional misconduct", "professional misconduct"], "answer_start": [211, 226, 226]}, "prediction_text": "Professional misconduct"}
{"answers": {"text": ["teacher's colleges", "college", "the college"], "answer_start": [21, 434, 430]}, "prediction_text": "The State Board of Education"}
{"answers": {"text": ["teacher's colleges", "teacher's colleges", "teacher's colleges"], "answer_start": [21, 21, 21]}, "prediction_text": "Teacher may be subject to disciplinary action."}
{"answers": {"text": ["teacher's colleges", "State Board of Education", "teacher's colleges"], "answer_start": [21, 563, 21]}, "prediction_text": "State Board of Education"}
{"answers": {"text": ["outdoors", "outdoors", "outdoors"], "answer_start": [123, 123, 123]}, "prediction_text": "Outside"}
{"answers": {"text": ["tutor", "tutor", "tutor"], "answer_start": [200, 200, 200]}, "prediction_text": "A tutor"}
{"answers": {"text": ["academy", "academy", "academy"], "answer_start": [73, 73, 73]}, "prediction_text": "Outside"}
{"answers": {"text": ["facilitate student learning", "facilitate student learning", "facilitate student learning"], "answer_start": [23, 23, 23]}, "prediction_text": "Help students learn"}
{"answers": {"text": ["informal", "informal", "informal"], "answer_start": [58, 58, 58]}, "prediction_text": "A course of study"}
{"answers": {"text": ["pedagogy", "pedagogy", "pedagogy"], "answer_start": [247, 247, 247]}, "prediction_text": "Pedagogy"}
{"answers": {"text": ["field trips", "field trips", "field trips"], "answer_start": [555, 555, 555]}, "prediction_text": "Pedagogy"}
{"answers": {"text": ["increasing use of technology", "use of technology,", "increasing use of technology"], "answer_start": [572, 583, 572]}, "prediction_text": "Rise of the internet"}
{"answers": {"text": ["the internet", "the internet", "technology"], "answer_start": [627, 627, 590]}, "prediction_text": "The rise of the internet"}
{"answers": {"text": ["skill", "skill", "skill"], "answer_start": [74, 74, 74]}, "prediction_text": "A course of study, lesson plan, or practical skill."}
{"answers": {"text": ["the relevant authority", "teacher", "teacher"], "answer_start": [142, 83, 83]}, "prediction_text": "The relevant authority"}
{"answers": {"text": ["learning", "learning", "learning"], "answer_start": [300, 300, 300]}, "prediction_text": "Learning disabilities"}
{"answers": {"text": ["infants", "infants", "infants"], "answer_start": [229, 229, 229]}, "prediction_text": "A student with learning disabilities."}
{"answers": {"text": ["standardized", "standardized", "standardized"], "answer_start": [102, 102, 102]}, "prediction_text": "Standardized curricula"}
{"answers": {"text": ["particular skills", "educational", "particular skills"], "answer_start": [89, 51, 89]}, "prediction_text": "Pedagogy of teaching styles"}
{"answers": {"text": ["self-study and problem solving", "classroom", "in self-study and problem solving"], "answer_start": [758, 156, 755]}, "prediction_text": "Self-study and problem solving with a lot of feedback around that loop."}
{"answers": {"text": ["encourage", "encourage", "encourage"], "answer_start": [921, 921, 921]}, "prediction_text": "Encourage and correct individual flaws."}
{"answers": {"text": ["deflate", "deflate", "deflate"], "answer_start": [902, 902, 902]}, "prediction_text": "Pressure him/her."}
{"answers": {"text": ["a coach", "coach", "coach"], "answer_start": [1046, 1048, 1048]}, "prediction_text": "Coach using psychology to get each new class of rookies off the bench and into the game."}
{"answers": {"text": ["the relationship between teachers and children", "the relationship between teachers and children.", "the relationship between teachers and children.", "the relationship between teachers and children"], "answer_start": [96, 96, 96, 96]}, "prediction_text": "Teachers stay with children for most of the week."}
{"answers": {"text": ["the whole curriculum", "whole curriculum", "whole curriculum", "the whole curriculum"], "answer_start": [249, 253, 253, 249]}, "prediction_text": "Students learn the whole curriculum."}
{"answers": {"text": ["different subject specialists", "subject specialists", "subject specialists", "teachers"], "answer_start": [315, 325, 325, 121]}, "prediction_text": "Different subject specialists"}
{"answers": {"text": ["primary school", "primary", "primary", "primary school"], "answer_start": [48, 498, 498, 498]}, "prediction_text": "Primary school"}
{"answers": {"text": ["surrogate", "surrogate", "surrogate", "surrogate"], "answer_start": [566, 566, 566, 566]}, "prediction_text": "Form tutor, specialist teacher, surrogate parent."}
{"answers": {"text": ["alternative", "alternative", "platoon\" system"], "answer_start": [68, 68, 165]}, "prediction_text": "Platoon systems"}
{"answers": {"text": ["platoon", "platoon", "platoon\" system"], "answer_start": [165, 165, 165]}, "prediction_text": "Platoon system"}
{"answers": {"text": ["staying with the same group of peers for all classes", "staying with the same group of peers for all classes", "by staying with the same group of peers for all classes"], "answer_start": [537, 537, 534]}, "prediction_text": "Teachers specialize in one subject and tend to be more knowledgeable in that area."}
{"answers": {"text": ["knowledgeable", "knowledgeable", "knowledgeable"], "answer_start": [412, 412, 412]}, "prediction_text": "Knowledgeable in one area"}
{"answers": {"text": ["United States", "United States", "United States"], "answer_start": [36, 36, 36]}, "prediction_text": "United States"}
{"answers": {"text": ["Co-teaching", "Co-teaching", "Co-teaching"], "answer_start": [0, 0, 0]}, "prediction_text": "Co-teaching"}
{"answers": {"text": ["two or more", "two or more", "two or more"], "answer_start": [100, 100, 100]}, "prediction_text": "Two or more teachers"}
{"answers": {"text": ["learning", "learning", "learning"], "answer_start": [233, 233, 233]}, "prediction_text": "Learning by sharing social networking support."}
{"answers": {"text": ["harmoniously", "in sync", "harmoniously"], "answer_start": [129, 358, 129]}, "prediction_text": "In sync with one another"}
{"answers": {"text": ["social networking support", "social networking", "social networking"], "answer_start": [257, 257, 257]}, "prediction_text": "Social networking support"}
{"answers": {"text": ["corporal punishment", "corporal punishment", "corporal"], "answer_start": [82, 82, 82]}, "prediction_text": "corporal punishment"}
{"answers": {"text": ["substitute parent", "substitute parent", "substitute parent"], "answer_start": [167, 167, 167]}, "prediction_text": "A substitute parent"}
{"answers": {"text": ["all the normal forms of parental discipline", "parental", "normal forms of parental discipline"], "answer_start": [191, 215, 199]}, "prediction_text": "Parental discipline"}
{"answers": {"text": ["the most common", "most common", "most common"], "answer_start": [36, 40, 40]}, "prediction_text": "Most common form"}
{"answers": {"text": ["While a child was in school", "While a child was in school", "While a child was in school"], "answer_start": [103, 103, 103]}, "prediction_text": "In school"}
{"answers": {"text": ["one of the most common", "one of the most common", "most common", "most common"], "answer_start": [141, 141, 152, 152]}, "prediction_text": "Most common in Western countries"}
{"answers": {"text": ["Most Western countries", "Most Western countries", "Most Western countries", "Most Western countries"], "answer_start": [221, 221, 221, 221]}, "prediction_text": "United States"}
{"answers": {"text": ["United States", "United States", "United States", "United States"], "answer_start": [311, 311, 311, 311]}, "prediction_text": "United States"}
{"answers": {"text": ["Supreme Court", "US Supreme Court", "US Supreme Court", "US Supreme Court"], "answer_start": [340, 337, 337, 337]}, "prediction_text": "US Supreme Court"}
{"answers": {"text": ["physical pain", "physical pain", "physical pain", "physical pain"], "answer_start": [122, 122, 122, 122]}, "prediction_text": "Physical pain"}
{"answers": {"text": ["30", "30", "30"], "answer_start": [0, 0, 0]}, "prediction_text": "30 states"}
{"answers": {"text": ["the South", "the South", "the South"], "answer_start": [68, 68, 68]}, "prediction_text": "In public schools"}
{"answers": {"text": ["declining", "declining", "declining"], "answer_start": [131, 131, 131]}, "prediction_text": "Increasing in the South."}
{"answers": {"text": ["a specially made wooden paddle", "wooden paddle", "wooden paddle"], "answer_start": [430, 447, 447]}, "prediction_text": "Wooden paddle"}
{"answers": {"text": ["privately in the principal's office", "principal's office.", "principal's office"], "answer_start": [566, 583, 583]}, "prediction_text": "Principal's office"}
{"answers": {"text": ["caning", "caning", "caning"], "answer_start": [39, 39, 39]}, "prediction_text": "Caning"}
{"answers": {"text": ["some Asian, African and Caribbean countries", "Asian, African and Caribbean", "Asian, African and Caribbean"], "answer_start": [81, 86, 86]}, "prediction_text": "Asian, African, Caribbean"}
{"answers": {"text": ["see School corporal punishment.", "School corporal punishment", "School corporal punishment"], "answer_start": [162, 166, 166]}, "prediction_text": "School corporal punishment"}
{"answers": {"text": ["detention", "detention", "detention"], "answer_start": [10, 10, 10]}, "prediction_text": "Saturday detention"}
{"answers": {"text": ["detention", "detention", "detention"], "answer_start": [10, 10, 10]}, "prediction_text": "Lunch, recess, after school."}
{"answers": {"text": ["in schools", "school", "school"], "answer_start": [58, 174, 174]}, "prediction_text": "In school"}
{"answers": {"text": ["quietly", "quietly", "quietly"], "answer_start": [468, 468, 468]}, "prediction_text": "In a classroom"}
{"answers": {"text": ["lines or a punishment essay", "punishment essay", "lines or a punishment essay"], "answer_start": [432, 443, 432]}, "prediction_text": "A punishment essay"}
{"answers": {"text": ["assertive", "assertive", "assertive"], "answer_start": [101, 101, 101]}, "prediction_text": "A assertive teacher"}
{"answers": {"text": ["immediate and fair punishment for misbehavior", "immediate and fair punishment for misbehavior and firm, clear boundaries", "immediate and fair punishment for misbehavior"], "answer_start": [210, 210, 210]}, "prediction_text": "immediate and fair punishment"}
{"answers": {"text": ["firm, clear boundaries", "firm, clear", "clear"], "answer_start": [260, 260, 266]}, "prediction_text": "Severe boundaries define what is appropriate and inappropriate behavior."}
{"answers": {"text": ["sarcasm and attempts to humiliate pupils", "sarcasm and attempts to humiliate pupils", "sarcasm and attempts to humiliate pupils"], "answer_start": [387, 387, 387]}, "prediction_text": "Dictating behavior"}
{"answers": {"text": ["respect", "respect", "respect"], "answer_start": [363, 363, 363]}, "prediction_text": "Respect"}
{"answers": {"text": ["some teachers and parents", "some teachers and parents", "some teachers and parents advocate"], "answer_start": [74, 74, 74]}, "prediction_text": "Teachers and parents"}
{"answers": {"text": ["East Asia", "East Asia", "countries\u2014in East Asia"], "answer_start": [470, 470, 457]}, "prediction_text": "East Asia"}
{"answers": {"text": ["weakness in school discipline", "weakness in school discipline", "the weakness in school discipline"], "answer_start": [262, 262, 258]}, "prediction_text": "Weak school discipline and high standards of education."}
{"answers": {"text": ["a more assertive and confrontational style", "strict discipline", "more assertive and confrontational"], "answer_start": [109, 506, 111]}, "prediction_text": "More assertive and confrontational discipline."}
{"answers": {"text": ["Japan", "Japan", "Japan"], "answer_start": [202, 202, 202]}, "prediction_text": "Japan"}
{"answers": {"text": ["Japan", "Japan", "Japan"], "answer_start": [202, 202, 202]}, "prediction_text": "Japan"}
{"answers": {"text": ["Japan", "Japan", "Japan"], "answer_start": [202, 202, 202]}, "prediction_text": "Japan"}
{"answers": {"text": ["Japan", "Japan", "Japan"], "answer_start": [202, 202, 202]}, "prediction_text": "Japan"}
{"answers": {"text": ["40 to 50 students", "40 to 50 students,", "40 to 50 students"], "answer_start": [39, 39, 39]}, "prediction_text": "40 to 50 students"}
{"answers": {"text": ["instruction", "instruction", "instruction"], "answer_start": [121, 121, 121]}, "prediction_text": "Concentration and focus on motivated students."}
{"answers": {"text": ["motivated students", "motivated students", "motivated students"], "answer_start": [271, 271, 271]}, "prediction_text": "motivated students"}
{"answers": {"text": ["attention-seeking and disruptive students", "attention-seeking and disruptive students", "attention-seeking and disruptive students"], "answer_start": [300, 300, 300]}, "prediction_text": "Challenged students"}
{"answers": {"text": ["motivated students", "motivated students", "motivated students"], "answer_start": [271, 370, 370]}, "prediction_text": "Students with demanding entrance exams"}
{"answers": {"text": ["popularly based authority", "popularly based", "popularly based"], "answer_start": [44, 44, 44]}, "prediction_text": "Popularly based authority"}
{"answers": {"text": ["governments", "governments", "governments"], "answer_start": [137, 137, 137]}, "prediction_text": "Governments and schools alike"}
{"answers": {"text": ["persuasion and negotiation", "persuasion and negotiation", "persuasion and negotiation"], "answer_start": [405, 405, 405]}, "prediction_text": "One of persuasion and negotiation."}
{"answers": {"text": ["easier and more efficient", "easier and more efficient", "easier and more efficient"], "answer_start": [242, 242, 242]}, "prediction_text": "Easy and efficient"}
{"answers": {"text": ["good, clear laws", "laws", "laws"], "answer_start": [568, 580, 580]}, "prediction_text": "Laws passed by the entire school community."}
{"answers": {"text": ["enthusiasm", "enthusiasm", "enthusiasm"], "answer_start": [113, 113, 113]}, "prediction_text": "A positive disposition towards the course materials."}
{"answers": {"text": ["passion", "passion", "passion"], "answer_start": [378, 378, 378]}, "prediction_text": "Passion for the course materials"}
{"answers": {"text": ["teach by rote", "teach by rote", "teach by rote"], "answer_start": [431, 431, 431]}, "prediction_text": "Teach by rote."}
{"answers": {"text": ["higher", "higher", "higher than teachers who didn't show much enthusiasm"], "answer_start": [771, 771, 771]}, "prediction_text": "Higher than teachers who don't show much enthusiasm."}
{"answers": {"text": ["teacher enthusiasm", "enthusiasm", "teacher enthusiasm"], "answer_start": [207, 22, 207]}, "prediction_text": "Intrinsic motivation"}
{"answers": {"text": ["read lecture material", "read lecture material", "read lecture material"], "answer_start": [699, 699, 699]}, "prediction_text": "Read lecture material"}
{"answers": {"text": ["nonverbal expressions of enthusiasm", "nonverbal expressions of enthusiasm", "nonverbal expressions of enthusiasm"], "answer_start": [400, 400, 400]}, "prediction_text": "Emotional facial expressions"}
{"answers": {"text": ["Controlled, experimental studies", "Controlled, experimental", "Controlled, experimental"], "answer_start": [301, 301, 301]}, "prediction_text": "Controlled, experimental studies"}
{"answers": {"text": ["higher", "higher levels", "higher levels"], "answer_start": [578, 578, 578]}, "prediction_text": "Higher levels of motivation"}
{"answers": {"text": ["self-determined", "self-determined", "self-determined"], "answer_start": [338, 338, 338]}, "prediction_text": "Enthusiastic teachers may cause students to become more intrinsically motivated."}
{"answers": {"text": ["enthusiasm", "enthusiasm", "enthusiasm"], "answer_start": [46, 560, 560]}, "prediction_text": "Increased interest by enthusiastic teacher."}
{"answers": {"text": ["emotional contagion", "emotional contagion", "emotional contagion"], "answer_start": [768, 768, 768]}, "prediction_text": "Emotional contagion"}
{"answers": {"text": ["Teacher enthusiasm", "excitement", "Teacher enthusiasm"], "answer_start": [111, 233, 111]}, "prediction_text": "Teacher enthusiasm"}
{"answers": {"text": ["student-teacher relationships", "student-teacher relationships", "student-teacher relationships"], "answer_start": [90, 90, 90]}, "prediction_text": "Enthusiastic teachers create beneficial relationships."}
{"answers": {"text": ["beneficial", "beneficial", "beneficial"], "answer_start": [177, 177, 177]}, "prediction_text": "Enthusiastic teachers create beneficial relationships."}
{"answers": {"text": ["the goals he receives from his superior.", "goals he receives from his superior.", "personal goals"], "answer_start": [589, 593, 679]}, "prediction_text": "Personal goals"}
{"answers": {"text": ["aligning his personal goals with his academic goals.", "aligning his personal goals with his academic goals.", "aligning his personal goals with his academic goals"], "answer_start": [666, 666, 666]}, "prediction_text": "aligning personal goals with academic goals."}
{"answers": {"text": ["student motivation and attitudes towards school", "student motivation and attitudes towards school", "student motivation and attitudes towards school"], "answer_start": [20, 20, 20]}, "prediction_text": "Enthusiastic teachers' ability to create beneficial relationships."}
{"answers": {"text": ["friendly and supportive", "friendly and supportive", "friendly and supportive"], "answer_start": [70, 70, 70]}, "prediction_text": "Friendly and supportive teachers"}
{"answers": {"text": ["friendly and supportive", "friendly and supportive", "friendly and supportive"], "answer_start": [70, 70, 70]}, "prediction_text": "Friendly and supportive teachers"}
{"answers": {"text": ["interacting and working directly with students", "more time interacting and working directly with students", "interacting and working directly with students"], "answer_start": [189, 179, 189]}, "prediction_text": "Interacting with students"}
{"answers": {"text": ["effective", "Effective", "Effective"], "answer_start": [268, 288, 288]}, "prediction_text": "Effective teachers"}
{"answers": {"text": ["enthusiasm about the students", "students", "enthusiasm about the students"], "answer_start": [200, 221, 200]}, "prediction_text": "Enthusiasm about teaching"}
{"answers": {"text": ["enthusiastic", "enthusiastic", "enthusiastic"], "answer_start": [568, 568, 824]}, "prediction_text": "Excitement about teaching, enthusiasm about the students, and enthusiasm about the subject matter."}
{"answers": {"text": ["in the student", "t in the student", "student"], "answer_start": [797, 795, 804]}, "prediction_text": "In the young students life"}
{"answers": {"text": ["very influential", "influential", "influential"], "answer_start": [867, 872, 872]}, "prediction_text": "Influence in the young students life."}
{"answers": {"text": ["teaching", "teaching", "being around their students"], "answer_start": [47, 293, 401]}, "prediction_text": "Teaching enthusiasm"}
{"answers": {"text": ["sexual misconduct", "sexual", "sexual misconduct"], "answer_start": [35, 35, 35]}, "prediction_text": "Sexual misconduct"}
{"answers": {"text": ["9.6%", "9.6%", "9.6%"], "answer_start": [191, 191, 191]}, "prediction_text": "9.6%"}
{"answers": {"text": ["United States", "United States", "United States"], "answer_start": [215, 215, 215]}, "prediction_text": "United States"}
{"answers": {"text": ["sometime during their educational career.", "educational career"], "answer_start": [391, 413]}, "prediction_text": "9.6%"}
{"answers": {"text": ["American Association of University Women", "American Association of University Women", "American Association of University Women"], "answer_start": [136, 136, 136]}, "prediction_text": "American Association of University Women"}
{"answers": {"text": ["England", "England", "England"], "answer_start": [11, 11, 11]}, "prediction_text": "England"}
{"answers": {"text": ["priests, religious leaders, and case workers as well as teachers", "priests, religious leaders, and case workers as well as teachers", "priests, religious leaders, and case workers as well as teachers"], "answer_start": [103, 103, 103]}, "prediction_text": "Priests, religious leaders, case workers."}
{"answers": {"text": ["2,869", "2,869", "2,869"], "answer_start": [324, 324, 324]}, "prediction_text": "2,869"}
{"answers": {"text": ["The AAUW study", "AAUW", "AAUW study"], "answer_start": [684, 688, 688]}, "prediction_text": "AAUW study"}
{"answers": {"text": ["United States", "United States", "United States"], "answer_start": [7, 7, 7]}, "prediction_text": "United States"}
{"answers": {"text": ["increased scrutiny on teacher misconduct", "increased scrutiny", "increased scrutiny on teacher misconduct"], "answer_start": [133, 133, 133]}, "prediction_text": "Increased scrutiny on teacher misconduct."}
{"answers": {"text": ["Fears of being labelled a pedophile or hebephile", "Fears of being labelled a pedophile or hebephile", "Fears of being labelled a pedophile"], "answer_start": [395, 395, 395]}, "prediction_text": "Lack of male teachers."}
{"answers": {"text": ["Chris Keates", "Chris Keates", "Chris Keates"], "answer_start": [0, 0, 0]}, "prediction_text": "Chris Keates"}
{"answers": {"text": ["child protection and parental rights groups", "child protection and parental rights groups", "child protection and parental rights groups"], "answer_start": [350, 350, 350]}, "prediction_text": "Parents and child protection groups"}
{"answers": {"text": ["a shortage of male teachers", "a shortage of male teachers", "shortage of male teachers"], "answer_start": [560, 560, 562]}, "prediction_text": "A shortage of male teachers."}
{"answers": {"text": ["the sex offenders register", "sex offenders", "sex offenders register"], "answer_start": [194, 198, 198]}, "prediction_text": "Sex offenders register"}
{"answers": {"text": ["occupational stress", "occupational stress", "occupational stress"], "answer_start": [76, 76, 76]}, "prediction_text": "Stress"}
{"answers": {"text": ["long hours", "organizational change, relationships with students, fellow teachers, and administrative personnel, working environment, expectations to substitute", "organizational change, relationships with students, fellow teachers, and administrative personnel, working environment, expectations to substitute, long hours"], "answer_start": [376, 228, 228]}, "prediction_text": "Organization change, relationships, and inspections."}
{"answers": {"text": ["occupational burnout", "occupational burnout", "occupational burnout"], "answer_start": [462, 462, 462]}, "prediction_text": "Occupational burnout"}
{"answers": {"text": ["stress", "Stress", "occupational stress"], "answer_start": [89, 204, 76]}, "prediction_text": "Stress, burnout, or burnout."}
{"answers": {"text": ["occupational stress", "occupational stress", "Stress"], "answer_start": [76, 76, 204]}, "prediction_text": "Stress and burnout"}
{"answers": {"text": ["42%", "42%", "42%"], "answer_start": [24, 24, 24]}, "prediction_text": "42%"}
{"answers": {"text": ["UK", "UK", "UK"], "answer_start": [31, 31, 31]}, "prediction_text": "UK"}
{"answers": {"text": ["twice the figure for the average profession", "twice", "twice"], "answer_start": [76, 76, 76]}, "prediction_text": "Twice the rate"}
{"answers": {"text": ["2012", "2012", "2012 study"], "answer_start": [123, 123, 123]}, "prediction_text": "2012 study"}
{"answers": {"text": ["average workers", "average workers", "average workers"], "answer_start": [222, 222, 222]}, "prediction_text": "Average workers"}
{"answers": {"text": ["several", "several", "several"], "answer_start": [10, 10, 10]}, "prediction_text": "Several ways"}
{"answers": {"text": ["Organizational interventions", "effective", "Organizational interventions"], "answer_start": [73, 255, 73]}, "prediction_text": "Important for reducing occupational stress among teachers."}
{"answers": {"text": ["Individual-level interventions", "Individual-level interventions", "Individual-level interventions"], "answer_start": [322, 322, 322]}, "prediction_text": "A tool for reducing occupational stress."}
{"answers": {"text": ["occupational stress among teachers", "occupational stress", "occupational stress"], "answer_start": [286, 286, 432]}, "prediction_text": "Stress"}
{"answers": {"text": ["Organizational interventions", "Organizational", "Organizational interventions"], "answer_start": [73, 73, 73]}, "prediction_text": "Support networks"}
{"answers": {"text": ["a university or college", "university or college", "university or college"], "answer_start": [126, 128, 128]}, "prediction_text": "In a university or college"}
{"answers": {"text": ["certification by a recognized body", "certification", "certification by a recognized body"], "answer_start": [175, 175, 175]}, "prediction_text": "A recognized body or a background check."}
{"answers": {"text": ["elementary school education certificate", "elementary school education certificate", "elementary school education certificate"], "answer_start": [264, 264, 264]}, "prediction_text": "High school diploma"}
{"answers": {"text": ["a background check and psychiatric evaluation", "background check and psychiatric evaluation", "background check and psychiatric evaluation"], "answer_start": [649, 651, 651]}, "prediction_text": "A background check and psychiatric evaluation."}
{"answers": {"text": ["US", "US", "US"], "answer_start": [606, 606, 606]}, "prediction_text": "United States"}
{"answers": {"text": ["the individual states and territories", "individual states", "individual states and territories"], "answer_start": [58, 62, 62]}, "prediction_text": "Individual states and territories"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [143, 143, 143]}, "prediction_text": "Three tiers"}
{"answers": {"text": ["tertiary education", "tertiary education", "tertiary education"], "answer_start": [281, 281, 281]}, "prediction_text": "tertiary education"}
{"answers": {"text": ["universities and/or TAFE colleges", "universities and/or TAFE colleges", "universities and/or TAFE colleges"], "answer_start": [301, 301, 301]}, "prediction_text": "Universities and TAFE colleges"}
{"answers": {"text": ["primary", "primary education", "primary education"], "answer_start": [175, 175, 175]}, "prediction_text": "Three-tier model"}
{"answers": {"text": ["a post-secondary degree Bachelor's Degree", "a post-secondary degree Bachelor's Degree", "post-secondary degree Bachelor's Degree"], "answer_start": [28, 28, 30]}, "prediction_text": "Bachelor's Degree"}
{"answers": {"text": ["a second Bachelor's Degree such as a Bachelor of Education", "a second Bachelor's Degree", "a second Bachelor's Degree"], "answer_start": [89, 89, 89]}, "prediction_text": "A second Bachelor's Degree"}
{"answers": {"text": ["the private sector, businesses and sponsors", "private sector", "private sector, businesses and sponsors"], "answer_start": [388, 392, 392]}, "prediction_text": "Public school"}
{"answers": {"text": ["civil servants", "civil servants", "civil servants"], "answer_start": [32, 32, 32]}, "prediction_text": "Civil servants"}
{"answers": {"text": ["Lehramtstudien (Teaching Education Studies)", "Lehramtstudien", "special university classes"], "answer_start": [95, 95, 60]}, "prediction_text": "Special university classes"}
{"answers": {"text": ["Grundschule", "Grundschule", "Grundschule"], "answer_start": [212, 212, 212]}, "prediction_text": "Grundschule"}
{"answers": {"text": ["civil servants' salary index scale (Bundesbesoldungsordnung)", "Bundesbesoldungsordnung", "civil servants' salary index scale"], "answer_start": [393, 429, 393]}, "prediction_text": "Bundesbesoldungsordnung"}
{"answers": {"text": ["Gymnasium", "Gymnasium", "Gymnasium"], "answer_start": [345, 345, 345]}, "prediction_text": "Realschule"}
{"answers": {"text": ["Extra pay", "Extra pay", "Extra pay"], "answer_start": [182, 182, 182]}, "prediction_text": "Extra pay"}
{"answers": {"text": ["27,814", "\u20ac27,814", "\u20ac27,814"], "answer_start": [325, 324, 324]}, "prediction_text": "\u20ac27,814 p.a."}
{"answers": {"text": ["53,423", "\u20ac53,423", "\u20ac53,423"], "answer_start": [363, 362, 362]}, "prediction_text": "Over \u20ac90,000"}
{"answers": {"text": ["90,000", "\u20ac90,000", "\u20ac90,000"], "answer_start": [529, 528, 528]}, "prediction_text": "Over \u20ac90,000"}
{"answers": {"text": ["the Teaching Council", "Teaching Council", "Teaching Council"], "answer_start": [44, 48, 48]}, "prediction_text": "Teaching Council"}
{"answers": {"text": ["Section 30", "Section 30", "Section 30"], "answer_start": [72, 72, 72]}, "prediction_text": "Section 30"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [111, 111, 111]}, "prediction_text": "2001"}
{"answers": {"text": ["Oireachtas funds", "Oireachtas", "Oireachtas funds"], "answer_start": [254, 254, 254]}, "prediction_text": "Oireachtas funds"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [5, 5, 5]}, "prediction_text": "2006"}
{"answers": {"text": ["new entrants to the teaching profession", "new entrants", "new entrants"], "answer_start": [48, 48, 48]}, "prediction_text": "Non-teaching posts"}
{"answers": {"text": ["on a phased basis", "phased basis", "on a phased basis"], "answer_start": [308, 313, 308]}, "prediction_text": "On a phased basis."}
{"answers": {"text": ["those who refuse vetting", "those who refuse vetting", "those who refuse vetting"], "answer_start": [159, 159, 159]}, "prediction_text": "Non-teaching staff"}
{"answers": {"text": ["41,004", "\u00a341,004", "41,004"], "answer_start": [84, 83, 84]}, "prediction_text": "\u00a341,004"}
{"answers": {"text": ["experience and extra responsibilities", "experience and extra responsibilities", "experience and extra responsibilities"], "answer_start": [165, 165, 165]}, "prediction_text": "Extra responsibilities"}
{"answers": {"text": ["20,980", "\u00a320,980", "20,980"], "answer_start": [233, 232, 233]}, "prediction_text": "\u00a320,980 annually."}
{"answers": {"text": ["a bachelor's degree", "bachelor's degree", "bachelor's"], "answer_start": [312, 314, 314]}, "prediction_text": "Bachelor's degree"}
{"answers": {"text": ["September 2007", "September 2007", "September 2007"], "answer_start": [94, 94, 94]}, "prediction_text": "September 2007"}
{"answers": {"text": ["alternative licensing programs", "alternative licensing programs", "alternative licensing programs"], "answer_start": [20, 20, 20]}, "prediction_text": "Alternative licensing programs"}
{"answers": {"text": ["hard-to-fill positions", "hard-to-fill", "hard-to-fill"], "answer_start": [99, 99, 99]}, "prediction_text": "Hard-to-fill positions"}
{"answers": {"text": ["vary", "vary", "vary"], "answer_start": [279, 279, 279]}, "prediction_text": "Different in each subject."}
{"answers": {"text": ["Excellent job opportunities", "Excellent", "Excellent"], "answer_start": [123, 123, 123]}, "prediction_text": "Excellent job opportunities"}
{"answers": {"text": ["secondary school teachers", "secondary school teachers", "secondary school teachers"], "answer_start": [197, 197, 197]}, "prediction_text": "Secondary school teachers"}
{"answers": {"text": ["the General Teaching Council for Scotland (GTCS)", "General Teaching Council for Scotland", "General Teaching Council for Scotland"], "answer_start": [61, 65, 65]}, "prediction_text": "General Teaching Council for Scotland (GTCS)"}
{"answers": {"text": ["Teaching", "Teaching", "Teaching"], "answer_start": [73, 111, 111]}, "prediction_text": "Teaching"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [290, 290, 290]}, "prediction_text": "Seven universities"}
{"answers": {"text": ["Provisional Registration", "Provisional Registration", "Provisional Registration"], "answer_start": [373, 373, 373]}, "prediction_text": "\"Provisional Registration\" status."}
{"answers": {"text": ["after a year", "a year", "a year"], "answer_start": [466, 472, 472]}, "prediction_text": "After a year"}
{"answers": {"text": ["April 2008", "April 2008", "April 2008"], "answer_start": [30, 30, 30]}, "prediction_text": "April 2008"}
{"answers": {"text": ["20,427", "\u00a320,427", "20,427"], "answer_start": [87, 86, 87]}, "prediction_text": "\u00a320,427"}
{"answers": {"text": ["32,583", "\u00a332,583", "32,583"], "answer_start": [120, 119, 120]}, "prediction_text": "Up to \u00a339,942"}
{"answers": {"text": ["earn Chartered Teacher Status", "complete the modules to earn Chartered Teacher Status", "complete the modules to earn Chartered Teacher Status"], "answer_start": [226, 202, 202]}, "prediction_text": "Complete modules"}
{"answers": {"text": ["trade unions", "trade unions", "Educational Institute of Scotland"], "answer_start": [518, 518, 560]}, "prediction_text": "Trade unions"}
{"answers": {"text": ["Wales", "Wales", "Wales"], "answer_start": [13, 13, 13]}, "prediction_text": "Wales"}
{"answers": {"text": ["Welsh", "Welsh", "Welsh"], "answer_start": [216, 216, 216]}, "prediction_text": "Welsh"}
{"answers": {"text": ["until the age of 16", "age of 16", "until the age of 16"], "answer_start": [535, 545, 535]}, "prediction_text": "Until the age of 16."}
{"answers": {"text": ["22", "22 per cent", "22"], "answer_start": [235, 235, 235]}, "prediction_text": "22%"}
{"answers": {"text": ["all age groups", "all age groups", "all age groups"], "answer_start": [381, 381, 381]}, "prediction_text": "All age groups"}
{"answers": {"text": ["trade unions", "ATL, NUT or NASUWT", "trade unions"], "answer_start": [47, 68, 47]}, "prediction_text": "Trade unions"}
{"answers": {"text": ["falling", "falling", "falling"], "answer_start": [168, 168, 168]}, "prediction_text": "Falling"}
{"answers": {"text": ["between 2005 and 2010", "2005 and 2010", "between 2005 and 2010"], "answer_start": [332, 340, 332]}, "prediction_text": "2005-2010"}
{"answers": {"text": ["trade unions", "trade unions", "trade unions"], "answer_start": [47, 47, 47]}, "prediction_text": "National Union of Teachers"}
{"answers": {"text": ["concern", "A growing cause of concern", "concern"], "answer_start": [247, 228, 247]}, "prediction_text": "All-time high"}
{"answers": {"text": ["each state", "each state", "each state"], "answer_start": [22, 22, 22]}, "prediction_text": "Each state determines the requirements."}
{"answers": {"text": ["ten years", "ten years", "ten years"], "answer_start": [222, 222, 222]}, "prediction_text": "Ten years"}
{"answers": {"text": ["a bachelor's degree", "bachelor's degree", "bachelor's degree"], "answer_start": [277, 279, 279]}, "prediction_text": "A bachelor's degree"}
{"answers": {"text": ["charter schools", "charter schools", "charter schools"], "answer_start": [371, 371, 371]}, "prediction_text": "Public school teachers"}
{"answers": {"text": ["No Child Left Behind", "No Child Left Behind", "No Child Left Behind"], "answer_start": [502, 502, 502]}, "prediction_text": "No Child Left Behind"}
{"answers": {"text": ["relatively low salaries", "relatively low salaries", "relatively low salaries"], "answer_start": [37, 37, 37]}, "prediction_text": "Low salaries"}
{"answers": {"text": ["average teacher salaries", "average teacher salaries", "teacher salaries"], "answer_start": [71, 71, 79]}, "prediction_text": "Teacher salaries have improved rapidly."}
{"answers": {"text": ["more experience and higher education", "more experience and higher education", "more experience and higher education"], "answer_start": [238, 238, 238]}, "prediction_text": "More experience, higher education, and higher education."}
{"answers": {"text": ["elementary school teachers", "elementary school teachers", "preschool teachers"], "answer_start": [1348, 1348, 761]}, "prediction_text": "Elementary school teachers"}
{"answers": {"text": ["TeachersPayTeachers.com", "TeachersPayTeachers.com", "TeachersPayTeachers.com"], "answer_start": [2142, 2142, 2142]}, "prediction_text": "TeachersPayTeachers.com"}
{"answers": {"text": ["many", "three", "many"], "answer_start": [10, 84, 10]}, "prediction_text": "Many types of religious or spiritual teachers."}
{"answers": {"text": ["Protestant", "Protestant", "Protestant"], "answer_start": [160, 1932, 1932]}, "prediction_text": "Protestantism"}
{"answers": {"text": ["not always", "not always"], "answer_start": [1139, 1139]}, "prediction_text": "Yes, the Pope's confessor is a Bishop."}
{"answers": {"text": ["(Roman) Catholic, (Eastern) Orthodox Catholic, and Protestant/Non-Denominational", "(Roman) Catholic, (Eastern) Orthodox Catholic, and Protestant/Non-Denominational", "(Roman) Catholic, (Eastern) Orthodox Catholic, and Protestant/Non-Denominational"], "answer_start": [109, 109, 109]}, "prediction_text": "Roman Catholic, Eastern Orthodox Catholic, Protestant/Non-Denominational."}
{"answers": {"text": ["LDS Church", "LDS Church", "LDS Church"], "answer_start": [52, 52, 52]}, "prediction_text": "LDS Church"}
{"answers": {"text": ["many individuals", "many individuals", "many individuals"], "answer_start": [285, 285, 285]}, "prediction_text": "Many individuals in the LDS Church."}
{"answers": {"text": ["spiritual", "spiritual", "spiritual"], "answer_start": [206, 429, 429]}, "prediction_text": "Spiritual mentorship"}
{"answers": {"text": ["the husband and father", "husband and father", "husband"], "answer_start": [576, 580, 580]}, "prediction_text": "The husband of the family"}
{"answers": {"text": ["the father of the house", "father of the house", "father of the house"], "answer_start": [929, 933, 933]}, "prediction_text": "Father of the house"}
{"answers": {"text": ["guru", "guru", "guru"], "answer_start": [48, 48, 48]}, "prediction_text": "Guru (or guru-in-training)"}
{"answers": {"text": ["extremely high", "high", "extremely high"], "answer_start": [170, 180, 170]}, "prediction_text": "High"}
{"answers": {"text": ["their disciples", "lives of their disciples", "disciples"], "answer_start": [256, 247, 262]}, "prediction_text": "Their disciples"}
{"answers": {"text": ["the West", "the West", "the West"], "answer_start": [119, 119, 119]}, "prediction_text": "Hinduism"}
{"answers": {"text": ["a Lama", "Lama", "Lama"], "answer_start": [77, 79, 79]}, "prediction_text": "A Lama"}
{"answers": {"text": ["be reborn", "consciously determined to be reborn", "to be reborn"], "answer_start": [151, 125, 148]}, "prediction_text": "Be reborn"}
{"answers": {"text": ["Tulku", "Tulku", "Tulku"], "answer_start": [235, 235, 235]}, "prediction_text": "Tulku"}
{"answers": {"text": ["often many times", "many times", "many times"], "answer_start": [162, 168, 168]}, "prediction_text": "Many times"}
{"answers": {"text": ["through phowa and siddhi", "phowa and siddhi", "phowa and siddhi"], "answer_start": [100, 108, 108]}, "prediction_text": "Phowa and siddhi"}
{"answers": {"text": ["ulemas", "ulemas", "ulemas"], "answer_start": [98, 98, 98]}, "prediction_text": "The teachers at madrassas"}
{"answers": {"text": ["ulemas", "ulemas", "ulemas"], "answer_start": [98, 98, 98]}, "prediction_text": "One of the Four Schools of Jurisprudence"}
{"answers": {"text": ["Sufism", "Sufism", "Sufism"], "answer_start": [401, 401, 401]}, "prediction_text": "Sufism"}
{"answers": {"text": ["actions-oriented", "actions-oriented", "actions-oriented"], "answer_start": [487, 487, 487]}, "prediction_text": "Five Pillars of Islam"}
{"answers": {"text": ["Qutb", "Qutb", "Qutb"], "answer_start": [684, 684, 684]}, "prediction_text": "Qutb"}
{"answers": {"text": ["German", "German", "German"], "answer_start": [39, 119, 119]}, "prediction_text": "German"}
{"answers": {"text": ["18 February 1546", "1546", "1546"], "answer_start": [95, 107, 107]}, "prediction_text": "18 February 1546"}
{"answers": {"text": ["Catholic Church.", "Late Medieval Catholic Church", "Late Medieval Catholic Church"], "answer_start": [306, 292, 292]}, "prediction_text": "Late Medieval Catholic Church"}
{"answers": {"text": ["God's punishment", "God's punishment for sin", "God's punishment"], "answer_start": [372, 372, 372]}, "prediction_text": "Freedom from God's punishment for sin"}
{"answers": {"text": ["excommunication", "excommunication", "excommunication"], "answer_start": [702, 702, 702]}, "prediction_text": "Excommunicated him."}
{"answers": {"text": ["gift of God's grace", "free gift", "through faith"], "answer_start": [118, 113, 138]}, "prediction_text": "Through faith in Jesus Christ as redeemer."}
{"answers": {"text": ["faith in Jesus Christ", "faith", "faith"], "answer_start": [146, 146, 146]}, "prediction_text": "Salvation and eternal life"}
{"answers": {"text": ["the Pope", "Pope", "Pope"], "answer_start": [242, 246, 246]}, "prediction_text": "Pope's authority"}
{"answers": {"text": ["Bible", "Bible", "Bible"], "answer_start": [272, 272, 272]}, "prediction_text": "The Bible"}
{"answers": {"text": ["holy priesthood", "holy priesthood", "holy priesthood"], "answer_start": [410, 410, 410]}, "prediction_text": "A holy priesthood"}
{"answers": {"text": ["Bible", "Bible"], "answer_start": [23, 23]}, "prediction_text": "The Tyndale Bible"}
{"answers": {"text": ["standard version", "standard version", "writing of an English translation"], "answer_start": [190, 190, 302]}, "prediction_text": "Development of a standard version of the German language."}
{"answers": {"text": ["Tyndale Bible", "Tyndale Bible.", "Tyndale"], "answer_start": [341, 341, 341]}, "prediction_text": "Tyndale Bible"}
{"answers": {"text": ["singing in churches", "singing", "singing"], "answer_start": [396, 396, 396]}, "prediction_text": "Singing development"}
{"answers": {"text": ["Protestant clergy to marry.", "Protestant clergy to marry", "clerical marriage"], "answer_start": [512, 512, 484]}, "prediction_text": "Protestant clergy marry."}
{"answers": {"text": ["10 November 1483", "10 November 1483", "10 November 1483"], "answer_start": [106, 106, 106]}, "prediction_text": "10 November 1483"}
{"answers": {"text": ["Eisleben, Saxony", "Eisleben, Saxony", "Eisleben, Saxony"], "answer_start": [126, 126, 126]}, "prediction_text": "Eisleben, Saxony"}
{"answers": {"text": ["Holy Roman Empire", "Holy Roman Empire", "Holy Roman Empire."], "answer_start": [161, 161, 161]}, "prediction_text": "Holy Roman Empire"}
{"answers": {"text": ["Catholic", "Catholic", "Catholic"], "answer_start": [201, 201, 201]}, "prediction_text": "Catholic"}
{"answers": {"text": ["lawyer", "lawyer", "lawyer"], "answer_start": [870, 870, 870]}, "prediction_text": "Lawyer"}
{"answers": {"text": ["University of Erfurt", "University of Erfurt", "University of Erfurt"], "answer_start": [42, 42, 42]}, "prediction_text": "University of Erfurt"}
{"answers": {"text": ["beerhouse and whorehouse", "beerhouse and whorehouse", "beerhouse and whorehouse"], "answer_start": [94, 94, 94]}, "prediction_text": "A beerhouse and whorehouse."}
{"answers": {"text": ["at four", "four", "four"], "answer_start": [140, 143, 143]}, "prediction_text": "At four every morning"}
{"answers": {"text": ["rote learning", "rote", "\"a day of rote learning and often wearying spiritual exercises.\""], "answer_start": [203, 203, 193]}, "prediction_text": "\"A day of rote learning and wearying spiritual exercises.\""}
{"answers": {"text": ["1505", "1505", "1505"], "answer_start": [293, 293, 293]}, "prediction_text": "1505"}
{"answers": {"text": ["law", "law", "law"], "answer_start": [59, 59, 59]}, "prediction_text": "Law school"}
{"answers": {"text": ["uncertainty", "uncertainty", "uncertainty"], "answer_start": [170, 170, 170]}, "prediction_text": "Uncertainty and uncertainty."}
{"answers": {"text": ["theology and philosophy", "theology and philosophy", "theology and philosophy"], "answer_start": [236, 236, 236]}, "prediction_text": "Law, philosophy, and theology."}
{"answers": {"text": ["by experience", "by experience", "experience"], "answer_start": [534, 534, 537]}, "prediction_text": "Bartholomaeus Arnoldi von Usingen and Jodocus Trutfetter"}
{"answers": {"text": ["God", "God", "God"], "answer_start": [917, 917, 917]}, "prediction_text": "Men and institutions."}
{"answers": {"text": ["death and divine judgment,", "death and divine judgment", "death"], "answer_start": [227, 227, 227]}, "prediction_text": "Divine judgment"}
{"answers": {"text": ["2 July 1505", "2 July 1505", "1505"], "answer_start": [49, 49, 56]}, "prediction_text": "July 2, 1505"}
{"answers": {"text": ["Augustinian cloister in Erfurt", "closed Augustinian cloister", "Augustinian cloister in Erfurt"], "answer_start": [431, 424, 431]}, "prediction_text": "Black Cloister"}
{"answers": {"text": ["deaths of two friends", "deaths of two friends", "deaths of two friends"], "answer_start": [539, 539, 539]}, "prediction_text": "Luther's sadness"}
{"answers": {"text": ["Luther's education", "Luther's education", "education"], "answer_start": [801, 801, 810]}, "prediction_text": "Luther's education"}
{"answers": {"text": ["Augustinian order", "fasting, long hours in prayer, pilgrimage, and frequent confession", "Augustinian order"], "answer_start": [32, 71, 32]}, "prediction_text": "Augustinian order"}
{"answers": {"text": ["deep spiritual despair", "deep spiritual despair", "deep spiritual despair"], "answer_start": [190, 190, 190]}, "prediction_text": "One of deep spiritual despair."}
{"answers": {"text": ["jailer and hangman", "jailer", "jailer and hangman of my poor soul."], "answer_start": [295, 295, 295]}, "prediction_text": "Jailer and hangman."}
{"answers": {"text": ["Johann von Staupitz", "Johann von Staupitz", "Johann von Staupitz,"], "answer_start": [332, 332, 332]}, "prediction_text": "Johann von Staupitz"}
{"answers": {"text": ["a change of heart", "change of heart", "true repentance does not involve self-inflicted penances and punishments but rather a change of heart."], "answer_start": [562, 564, 478]}, "prediction_text": "True repentance does not involve self-inflicted penances and punishments."}
{"answers": {"text": ["1507", "1507", "1507"], "answer_start": [3, 3, 3]}, "prediction_text": "1507"}
{"answers": {"text": ["von Staupitz", "von Staupitz", "von Staupitz"], "answer_start": [57, 57, 57]}, "prediction_text": "von Staupitz"}
{"answers": {"text": ["1508", "1508", "1508"], "answer_start": [51, 51, 51]}, "prediction_text": "1508"}
{"answers": {"text": ["9 March 1508", "9 March 1508", "9 March 1508,"], "answer_start": [220, 220, 220]}, "prediction_text": "1508"}
{"answers": {"text": ["Sentences by Peter Lombard", "Sentences", "Sentences by Peter Lombard"], "answer_start": [271, 271, 271]}, "prediction_text": "Sentences by Peter Lombard"}
{"answers": {"text": ["19 October 1512", "19 October 1512", "1512"], "answer_start": [3, 3, 14]}, "prediction_text": "On 21 October 1512."}
{"answers": {"text": ["21 October 1512", "21 October 1512", "October 1512,"], "answer_start": [66, 66, 69]}, "prediction_text": "On 21 October 1512."}
{"answers": {"text": ["Doctor in Bible", "Doctor in Bible", "Doctor in Bible."], "answer_start": [210, 210, 210]}, "prediction_text": "Doctor of Theology"}
{"answers": {"text": ["University of Wittenberg", "University of Wittenberg", "University of Wittenberg."], "answer_start": [283, 283, 283]}, "prediction_text": "University of Wittenberg"}
{"answers": {"text": ["Doctor of Theology", "Doctor of Theology", "Doctor of Theology"], "answer_start": [39, 39, 39]}, "prediction_text": "Doctor of Theology"}
{"answers": {"text": ["1516", "1516", "1516"], "answer_start": [3, 3, 3]}, "prediction_text": "1516"}
{"answers": {"text": ["rebuild St. Peter's Basilica", "rebuild St. Peter's Basilica", "rebuild St. Peter's Basilica"], "answer_start": [169, 169, 169]}, "prediction_text": "To sell indulgences"}
{"answers": {"text": ["Roman Catholic", "Roman Catholic", "Roman Catholic"], "answer_start": [207, 207, 207]}, "prediction_text": "Fides caritate formata"}
{"answers": {"text": ["charity and good works", "charity and good works", "in charity and good works"], "answer_start": [371, 371, 368]}, "prediction_text": "Faith alone"}
{"answers": {"text": ["charity and good works", "benefits of good works could be obtained by donating money to the church", "justification rather depends only on such faith as is active in charity and good works"], "answer_start": [371, 424, 307]}, "prediction_text": "Faith alone, whether fiduciary or dogmatic, cannot justify man."}
{"answers": {"text": ["31 October 1517", "31 October 1517", "1517"], "answer_start": [3, 3, 14]}, "prediction_text": "October 31, 1517"}
{"answers": {"text": ["Albert of Mainz", "Albert of Mainz", ", Albert of Mainz"], "answer_start": [48, 48, 46]}, "prediction_text": "Albert of Mainz"}
{"answers": {"text": ["The Ninety-Five Theses", "The Ninety-Five Theses", "The Ninety-Five Theses."], "answer_start": [240, 240, 240]}, "prediction_text": "The Ninety-Five Theses"}
{"answers": {"text": ["Hans Hillerbrand", "Hans Hillerbrand", "Hillerbrand"], "answer_start": [264, 264, 269]}, "prediction_text": "Hans Hillerbrand"}
{"answers": {"text": ["Thesis 86", "Thesis 86,", "86"], "answer_start": [612, 612, 619]}, "prediction_text": "Thesis 86"}
{"answers": {"text": ["Johann Tetzel", "Johann Tetzel", "Tetzel"], "answer_start": [42, 42, 49]}, "prediction_text": "Johann Tetzel's saying"}
{"answers": {"text": ["coin in the coffer", "coin", "coin in the coffer rings, the soul from purgatory"], "answer_start": [77, 77, 77]}, "prediction_text": "Through the coin in the coffer"}
{"answers": {"text": ["Luther", "Luther", "Luther"], "answer_start": [0, 0, 0]}, "prediction_text": "Luther"}
{"answers": {"text": ["Johann Tetzel", "Johann Tetzel", "Tetzel"], "answer_start": [42, 42, 49]}, "prediction_text": "Luther"}
{"answers": {"text": ["God", "God", "God"], "answer_start": [40, 40, 40]}, "prediction_text": "Christ"}
{"answers": {"text": ["salvation", "salvation", "salvation"], "answer_start": [151, 151, 151]}, "prediction_text": "Salvation"}
{"answers": {"text": ["punishments", "punishments", "all punishments"], "answer_start": [122, 122, 118]}, "prediction_text": "All punishments"}
{"answers": {"text": ["false assurances", "false assurances", "false assurances."], "answer_start": [253, 253, 253]}, "prediction_text": "Absolution from all punishments"}
{"answers": {"text": ["Christ", "Christ", "Christ"], "answer_start": [227, 227, 227]}, "prediction_text": "Luther (in the context)"}
{"answers": {"text": ["Tetzel", "Tetzel", "Tetzel"], "answer_start": [35, 35, 35]}, "prediction_text": "Tetzel's saying"}
{"answers": {"text": ["capacity to exaggerate", "capacity to exaggerate", "capacity to exaggerate"], "answer_start": [154, 154, 154]}, "prediction_text": "He overstated the matter in regard to indulgences for the dead."}
{"answers": {"text": ["indulgences for the dead,", "in regard to indulgences for the dead", "teaching"], "answer_start": [227, 214, 257]}, "prediction_text": "In regard to indulgences for the dead"}
{"answers": {"text": ["indulgences for the living", "on indulgences for the living", "in line"], "answer_start": [269, 266, 300]}, "prediction_text": "Catholic dogma"}
{"answers": {"text": ["the posting on the door", "the posting on the door", "posting on the door"], "answer_start": [101, 101, 105]}, "prediction_text": "The story of the posting on the door"}
{"answers": {"text": ["posting on the door", "story of the posting on the door", "posting on the door"], "answer_start": [105, 92, 105]}, "prediction_text": "The story of the posting on the door"}
{"answers": {"text": ["Philipp Melanchthon", "Philipp Melanchthon", "Philipp Melanchthon"], "answer_start": [258, 258, 258]}, "prediction_text": "Philipp Melanchthon"}
{"answers": {"text": ["not in Wittenberg", "not in Wittenberg", "not in Wittenberg"], "answer_start": [312, 312, 312]}, "prediction_text": "Wittenberg"}
{"answers": {"text": ["little foundation in truth", "has little foundation in truth", "settled as one of the pillars of history"], "answer_start": [191, 187, 145]}, "prediction_text": "It has settled as one of the pillars of history."}
{"answers": {"text": ["January 1518", "January 1518", "1518"], "answer_start": [17, 17, 25]}, "prediction_text": "January 1518"}
{"answers": {"text": ["printing press", "printing press", "printing press."], "answer_start": [207, 207, 207]}, "prediction_text": "Printing press"}
{"answers": {"text": ["friends of Luther", "friends of Luther", "friends of Luther"], "answer_start": [35, 35, 35]}, "prediction_text": "Friends of Luther"}
{"answers": {"text": ["two weeks", "two weeks", "two weeks"], "answer_start": [230, 230, 230]}, "prediction_text": "Within two weeks"}
{"answers": {"text": ["two months", "two months", "two months"], "answer_start": [300, 300, 300]}, "prediction_text": "Within two months"}
{"answers": {"text": ["1519", "1519", "1519"], "answer_start": [85, 85, 85]}, "prediction_text": "1519"}
{"answers": {"text": ["Students", "Students", "Students"], "answer_start": [91, 91, 91]}, "prediction_text": "Students thronged to Wittenberg to hear Luther speak."}
{"answers": {"text": ["early part", "early", "early"], "answer_start": [223, 223, 223]}, "prediction_text": "Early part of his career"}
{"answers": {"text": ["1520", "1520", "To the Christian Nobility of the German Nation, On the Babylonian Captivity of the Church, and On the Freedom of a Christian."], "answer_start": [346, 346, 352]}, "prediction_text": "1520"}
{"answers": {"text": ["On the Freedom of a Christian", "On the Freedom of a Christian", "On the Freedom of a Christian."], "answer_start": [447, 447, 447]}, "prediction_text": "On the Freedom of a Christian"}
{"answers": {"text": ["lectured", "lectured on the Psalms", "lectured"], "answer_start": [26, 26, 26]}, "prediction_text": "He lectured on the Psalms, the books of Hebrews, Romans, and Galatians."}
{"answers": {"text": ["penance and righteousness", "penance and righteousness", "penance and righteousness"], "answer_start": [179, 179, 179]}, "prediction_text": "The doctrine of justification"}
{"answers": {"text": ["corrupt in its ways", "corrupt", "corrupt"], "answer_start": [281, 281, 281]}, "prediction_text": "Lost sight of central truths of Christianity."}
{"answers": {"text": ["central truths of Christianity", "central truths of Christianity", "several of the central truths of Christianity"], "answer_start": [353, 353, 338]}, "prediction_text": "God's grace and salvation"}
{"answers": {"text": ["doctrine of justification", "doctrine of justification", "salvation or redemption is a gift of God's grace, attainable only through faith in Jesus as the Messiah"], "answer_start": [423, 702, 554]}, "prediction_text": "The doctrine of justification"}
{"answers": {"text": ["God", "God", "God"], "answer_start": [64, 64, 64]}, "prediction_text": "Christians"}
{"answers": {"text": ["1525", "1525", "1525"], "answer_start": [122, 122, 122]}, "prediction_text": "1525"}
{"answers": {"text": ["gift from God", "that which brings the Holy Spirit through the merits of Christ", "Faith is that which brings the Holy Spirit through the merits of Christ"], "answer_start": [869, 779, 770]}, "prediction_text": "A gift from God."}
{"answers": {"text": ["Smalcald Articles", "the Smalcald Articles", "Smalcald Articles"], "answer_start": [1198, 1194, 1198]}, "prediction_text": "In the Smalcald Articles"}
{"answers": {"text": ["lives by faith", "faith", "faith"], "answer_start": [1131, 1140, 1140]}, "prediction_text": "By faith"}
{"answers": {"text": ["Christ and His salvation", "rediscovery of \"Christ and His salvation\"", "rediscovery of \"Christ and His salvation\"", "Christ"], "answer_start": [25, 9, 9, 25]}, "prediction_text": "Luther's rediscovery of \"Christ and His salvation\""}
{"answers": {"text": ["Christ and His salvation", "Christ and His salvation", "Christ and His salvation", "Christ and His salvation"], "answer_start": [25, 25, 25, 25]}, "prediction_text": "Luther's railing against the sale of indulgences"}
{"answers": {"text": ["sale of indulgences", "sale of indulgences", "sale of indulgences", "sale of indulgences"], "answer_start": [151, 151, 151, 151]}, "prediction_text": "His railing against the sale of indulgences"}
{"answers": {"text": ["two points", "two", "two", "two"], "answer_start": [68, 68, 68, 68]}, "prediction_text": "Two points"}
{"answers": {"text": ["Archbishop Albrecht", "Archbishop Albrecht", "Archbishop Albrecht of Mainz and Magdeburg"], "answer_start": [0, 0, 0]}, "prediction_text": "Archbishop Albrecht of Mainz and Magdeburg"}
{"answers": {"text": ["Rome", "Rome", "Rome"], "answer_start": [178, 178, 178]}, "prediction_text": "Rome"}
{"answers": {"text": ["papal dispensation", "papal dispensation", "pay off a papal dispensation for his tenure"], "answer_start": [240, 240, 230]}, "prediction_text": "His tenure of more than one bishopric."}
{"answers": {"text": ["one half", "one half", "half"], "answer_start": [376, 376, 380]}, "prediction_text": "One half"}
{"answers": {"text": ["December 1517", "December 1517", "1517"], "answer_start": [146, 146, 155]}, "prediction_text": "December 1517"}
{"answers": {"text": ["Pope Leo X", "Pope Leo X", "Leo X"], "answer_start": [0, 0, 5]}, "prediction_text": "Pope Leo X"}
{"answers": {"text": ["papal theologians and envoys", "papal theologians and envoys", "papal theologians and envoys"], "answer_start": [154, 154, 154]}, "prediction_text": "A series of theologians and envoys against Luther."}
{"answers": {"text": ["October 1518", "October 1518", "1518"], "answer_start": [507, 507, 515]}, "prediction_text": "October 1518"}
{"answers": {"text": ["papacy was the Antichrist", "papacy was the Antichrist", "papacy was the Antichrist"], "answer_start": [724, 724, 724]}, "prediction_text": "He did not consider the papacy part of the biblical Church."}
{"answers": {"text": ["arrest Luther", "to arrest Luther", "arrest"], "answer_start": [1033, 1030, 1033]}, "prediction_text": "Arrest Luther if he failed to recant."}
{"answers": {"text": ["January 1519", "January 1519", "1519"], "answer_start": [3, 3, 11]}, "prediction_text": "January 1519"}
{"answers": {"text": ["remain silent", "remain silent", "remain silent if his opponents did"], "answer_start": [210, 210, 210]}, "prediction_text": "Stay silent if opponents did."}
{"answers": {"text": ["Johann Eck", "Johann Eck", "Eck"], "answer_start": [261, 261, 268]}, "prediction_text": "Johann Eck"}
{"answers": {"text": ["Matthew 16:18", "Matthew 16:18", "Matthew 16:18"], "answer_start": [523, 523, 523]}, "prediction_text": "Matthew 16:18"}
{"answers": {"text": ["new Jan Hus", "Jan Hus", "new Jan Hus"], "answer_start": [707, 711, 707]}, "prediction_text": "Jan Hus"}
{"answers": {"text": ["15 June 1520", "15 June 1520", "1520"], "answer_start": [3, 3, 11]}, "prediction_text": "June 1520"}
{"answers": {"text": ["recanted 41 sentences", "recanted 41 sentences", "recanted 41 sentences"], "answer_start": [124, 124, 124]}, "prediction_text": "Recanted 41 sentences"}
{"answers": {"text": ["60 days", "60 days", "60 days"], "answer_start": [203, 203, 203]}, "prediction_text": "60 days"}
{"answers": {"text": ["Karl von Miltitz", "Karl von Miltitz", ". Karl von Miltitz"], "answer_start": [284, 284, 282]}, "prediction_text": "Karl von Miltitz"}
{"answers": {"text": ["3 January 1521", "3 January 1521", "3 January 1521"], "answer_start": [682, 682, 682]}, "prediction_text": "3 January 1521"}
{"answers": {"text": ["secular authorities", "secular", "secular authorities."], "answer_start": [56, 56, 56]}, "prediction_text": "The Diet of Worms"}
{"answers": {"text": ["18 April 1521", "18 April 1521", "1521"], "answer_start": [80, 80, 89]}, "prediction_text": "April 18, 1521"}
{"answers": {"text": ["estates of the Holy Roman Empire", "estates of the Holy Roman Empire", "general assembly of the estates of the Holy Roman Empire"], "answer_start": [183, 183, 159]}, "prediction_text": "The Diet of Worms was an assembly of the estates of the Holy Roman Empire."}
{"answers": {"text": ["Emperor Charles V", "Emperor Charles V", "Emperor Charles V"], "answer_start": [317, 317, 317]}, "prediction_text": "Emperor Charles V"}
{"answers": {"text": ["Prince Frederick III", "Prince Frederick III", "Elector of Saxony"], "answer_start": [346, 346, 368]}, "prediction_text": "Prince Frederick III"}
{"answers": {"text": ["Johann Eck", "Johann Eck", "Eck"], "answer_start": [0, 0, 7]}, "prediction_text": "The Archbishop of Trier"}
{"answers": {"text": ["Archbishop of Trier", "Archbishop of Trier", "Archbishop of Trier"], "answer_start": [65, 65, 65]}, "prediction_text": "Archbishop of Trier"}
{"answers": {"text": ["stood by their contents", "whether he stood by their contents", "whether he stood by their contents."], "answer_start": [203, 192, 192]}, "prediction_text": "He asked if he stood by their contents."}
{"answers": {"text": ["next day", "next day", "the next day:"], "answer_start": [391, 391, 387]}, "prediction_text": "Next day"}
{"answers": {"text": ["confirmed", "confirmed", "confirmed"], "answer_start": [235, 235, 235]}, "prediction_text": "He denied the books were his."}
{"answers": {"text": ["raised his arm", "raised his arm", "raised his arm"], "answer_start": [34, 34, 34]}, "prediction_text": "Raise his arm in the traditional salute of a knight winning a bout."}
{"answers": {"text": ["knight winning a bout", "a knight winning a bout", "traditional salute of a knight winning a bout"], "answer_start": [81, 79, 57]}, "prediction_text": "Traditional salute"}
{"answers": {"text": ["Michael Mullett", "Michael Mullett", "Michael Mullett"], "answer_start": [105, 105, 105]}, "prediction_text": "Michael Mullett"}
{"answers": {"text": ["epoch-making oratory", "world classic of epoch-making oratory", "world classic of epoch-making oratory"], "answer_start": [166, 149, 149]}, "prediction_text": "\"World classic of oratory\""}
{"answers": {"text": ["recant his writings", "recant his writings", "recant"], "answer_start": [18, 18, 18]}, "prediction_text": "Recant his writings."}
{"answers": {"text": ["Luther", "Luther", "Luther"], "answer_start": [0, 0, 0]}, "prediction_text": "Mullett"}
{"answers": {"text": ["not recorded", "not recorded in witness accounts", "not recorded in witness accounts"], "answer_start": [276, 276, 276]}, "prediction_text": "Lack of recorded witnesses."}
{"answers": {"text": ["more dramatic form", "more dramatic form", "more dramatic form"], "answer_start": [439, 439, 439]}, "prediction_text": "More dramatic form"}
{"answers": {"text": ["private conferences", "private conferences", "conferences"], "answer_start": [25, 25, 33]}, "prediction_text": "By private conferences"}
{"answers": {"text": ["25 May 1521", "25 May 1521", "25 May 1521"], "answer_start": [146, 146, 146]}, "prediction_text": "May 25, 1521"}
{"answers": {"text": ["Emperor", "Emperor", "Emperor"], "answer_start": [87, 87, 87]}, "prediction_text": "Emperor (Empire)"}
{"answers": {"text": ["his arrest", "requiring his arrest", "arrest"], "answer_start": [225, 215, 229]}, "prediction_text": "Luther's fate was decided."}
{"answers": {"text": ["kill Luther", "kill", "kill"], "answer_start": [407, 407, 407]}, "prediction_text": "Kill him without legal consequence."}
{"answers": {"text": ["Luther's disappearance", "disappearance", "disappearance"], "answer_start": [0, 9, 9]}, "prediction_text": "Luther's disappearance was planned."}
{"answers": {"text": ["Wartburg Castle", "Wartburg Castle", "Wartburg Castle"], "answer_start": [266, 266, 266]}, "prediction_text": "In the forest near Wittenberg"}
{"answers": {"text": ["my Patmos", "my Patmos", "my Patmos"], "answer_start": [349, 349, 349]}, "prediction_text": "\"My Patmos\""}
{"answers": {"text": ["New Testament", "New Testament", "New Testament"], "answer_start": [383, 383, 383]}, "prediction_text": "New Testament"}
{"answers": {"text": ["shamed", "shamed", "shamed"], "answer_start": [542, 542, 542]}, "prediction_text": "Luther persuaded Archbishop Albrecht to stop the sale of indulgences."}
{"answers": {"text": ["a sin", "sin", "sin", "sin"], "answer_start": [126, 128, 128, 128]}, "prediction_text": "Sinners"}
{"answers": {"text": ["cannot be earned", "cannot be earned", "cannot be earned", "All humans are sinners by nature, he explained, and God's grace (which cannot be earned) alone can make them just."], "answer_start": [204, 204, 204, 133]}, "prediction_text": "God's grace can make you just."}
{"answers": {"text": ["1 August 1521", "1 August 1521", "1 August 1521", "1521"], "answer_start": [251, 251, 251, 260]}, "prediction_text": "August 1521"}
{"answers": {"text": ["trust in Christ", "trust in Christ", "trust in Christ", "trust in Christ be stronger,"], "answer_start": [369, 369, 369, 369]}, "prediction_text": "Christ's victory over sin, death, and the world."}
{"answers": {"text": ["justice", "justice", "justice", "justice"], "answer_start": [544, 544, 544, 544]}, "prediction_text": "Justice"}
{"answers": {"text": ["summer of 1521", "summer of 1521", "1521"], "answer_start": [7, 7, 17]}, "prediction_text": "1521"}
{"answers": {"text": ["condemned as idolatry", "idolatry", "gift"], "answer_start": [198, 211, 290]}, "prediction_text": "A gift to be received with thanksgiving."}
{"answers": {"text": ["a gift", "gift", "gift"], "answer_start": [288, 290, 290]}, "prediction_text": "A gift"}
{"answers": {"text": ["private confession and absolution", "private confession and absolution", "private confession"], "answer_start": [472, 472, 472]}, "prediction_text": "Encouragement of private confession and absolution."}
{"answers": {"text": ["break their vows", "illegitimate", "break their vows without sin,"], "answer_start": [664, 715, 664]}, "prediction_text": "They could break their vows without sin."}
{"answers": {"text": ["prophetic faith", "placing them on prophetic faith", "placing them on prophetic faith."], "answer_start": [117, 101, 101]}, "prediction_text": "He broadened the foundations."}
{"answers": {"text": ["1521", "1521", "1521"], "answer_start": [3, 3, 3]}, "prediction_text": "1521"}
{"answers": {"text": ["Daniel 8:9\u201312, 23\u201325", "prophecy", "prophecy of the Little Horn"], "answer_start": [203, 34, 172]}, "prediction_text": "Rome"}
{"answers": {"text": ["the Little Horn", "Little Horn", "Little Horn"], "answer_start": [184, 188, 188]}, "prediction_text": "Little Horn of Daniel"}
{"answers": {"text": ["antichrist", "antichrist of 2 Thessalonians 2", "The antichrist of 2 Thessalonians 2"], "answer_start": [229, 229, 225]}, "prediction_text": "Power of the Papacy"}
{"answers": {"text": ["Gabriel Zwilling", "Gabriel Zwilling"], "answer_start": [185, 185]}, "prediction_text": "Gabriel Zwilling"}
{"answers": {"text": ["June 1521", "June 1521", "1521"], "answer_start": [254, 254, 259]}, "prediction_text": "June 1521"}
{"answers": {"text": ["disturbances", "disturbances", "disturbances"], "answer_start": [326, 326, 326]}, "prediction_text": "Revolutions and disturbances."}
{"answers": {"text": ["Zwickau prophets", "Zwickau prophets", "Augustinian friars"], "answer_start": [765, 765, 366]}, "prediction_text": "Zwickau prophets"}
{"answers": {"text": ["town council", "the town council", "town council"], "answer_start": [909, 905, 909]}, "prediction_text": "The council"}
{"answers": {"text": ["6 March 1522", "6 March 1522", "6 March 1522"], "answer_start": [42, 42, 42]}, "prediction_text": "March 1522"}
{"answers": {"text": ["personal presence", "personal presence and living word", "trust God's word"], "answer_start": [204, 204, 529]}, "prediction_text": "Trust God's word"}
{"answers": {"text": ["preached eight sermons", "preached eight sermons", "preached"], "answer_start": [311, 311, 311]}, "prediction_text": "preached eight sermons"}
{"answers": {"text": ["Invocavit Sermons", "Invocavit Sermons", "Invocavit Sermons"], "answer_start": [362, 362, 362]}, "prediction_text": "Invocavit Sermons"}
{"answers": {"text": ["trust God's word", "trust God's word", "love, patience, charity, and freedom"], "answer_start": [529, 529, 462]}, "prediction_text": "Through faith in God's word"}
{"answers": {"text": ["immediate", "immediate", "immediate"], "answer_start": [40, 40, 40]}, "prediction_text": "After the sixth sermon, the effect was immediate."}
{"answers": {"text": ["Jerome Schurf", "Jerome Schurf", "Schurf"], "answer_start": [97, 97, 104]}, "prediction_text": "Jerome Schurf"}
{"answers": {"text": ["After the sixth sermon", "sixth", "After the sixth sermon"], "answer_start": [51, 61, 51]}, "prediction_text": "Sixth sermon"}
{"answers": {"text": ["joy", "joy", "joy"], "answer_start": [143, 143, 143]}, "prediction_text": "Every day misguided people into the way of the truth."}
{"answers": {"text": ["misguided", "misguided", "misguided"], "answer_start": [249, 249, 249]}, "prediction_text": "misguided people"}
{"answers": {"text": ["public order", "public order", "public order,"], "answer_start": [119, 119, 119]}, "prediction_text": "Public order"}
{"answers": {"text": ["conservative", "conservative", "reinvention as a conservative"], "answer_start": [167, 167, 150]}, "prediction_text": "Conservative force"}
{"answers": {"text": ["Zwickau prophets", "Zwickau prophets", "Zwickau prophets"], "answer_start": [230, 230, 230]}, "prediction_text": "Zwickau prophets"}
{"answers": {"text": ["unrest and violence.", "social unrest and violence", "social unrest"], "answer_start": [390, 383, 383]}, "prediction_text": "Social unrest and violence."}
{"answers": {"text": ["established Church", "the established Church", "established Church"], "answer_start": [291, 287, 291]}, "prediction_text": "The established Church"}
{"answers": {"text": ["Zwickau prophet", "Preachers", "Zwickau prophet"], "answer_start": [108, 90, 108]}, "prediction_text": "Nicholas Storch was a German Peasant's War prophet."}
{"answers": {"text": ["German Peasants' War", "German Peasants' War", "German Peasants' War"], "answer_start": [180, 180, 180]}, "prediction_text": "Peasants' War of 1524\u201325"}
{"answers": {"text": ["1524\u201325", "1524\u201325", "1524\u201325,"], "answer_start": [204, 204, 204]}, "prediction_text": "1524\u201325"}
{"answers": {"text": ["support an attack", "support an attack", "support an attack on the upper classes"], "answer_start": [505, 505, 505]}, "prediction_text": "Support an attack on the upper classes."}
{"answers": {"text": ["upper classes", "upper classes", "upper classes"], "answer_start": [530, 530, 530]}, "prediction_text": "Upper classes"}
{"answers": {"text": ["temporal authorities", "temporal authorities", "temporal authorities"], "answer_start": [165, 165, 165]}, "prediction_text": "temporal authorities"}
{"answers": {"text": ["tour of Thuringia", "Thuringia", "Thuringia"], "answer_start": [196, 204, 204]}, "prediction_text": "In Thuringia"}
{"answers": {"text": ["mad dogs", "Murderous, Thieving Hordes", "mad dogs"], "answer_start": [569, 333, 569]}, "prediction_text": "\"Mad dogs\""}
{"answers": {"text": ["the devil's work", "devil's work", "devil's work,"], "answer_start": [497, 501, 501]}, "prediction_text": "He condemned the violence as the devil's work."}
{"answers": {"text": ["the nobles", "nobles", "nobles"], "answer_start": [530, 534, 534]}, "prediction_text": "The nobles"}
{"answers": {"text": ["on three grounds", "three", "three"], "answer_start": [46, 49, 49]}, "prediction_text": "Three ways"}
{"answers": {"text": ["ignoring Christ's counsel", "ignoring", "ignoring"], "answer_start": [152, 152, 152]}, "prediction_text": "Ignoring Christ's counsel."}
{"answers": {"text": ["God", "God", "God"], "answer_start": [327, 327, 327]}, "prediction_text": "By God"}
{"answers": {"text": ["Divine Right of Kings", "Divine Right of Kings", "Divine Right of Kings"], "answer_start": [450, 450, 450]}, "prediction_text": "Divine Right of Kings"}
{"answers": {"text": ["in body and soul", "death in body and soul", "death in body and soul,"], "answer_start": [677, 671, 671]}, "prediction_text": "Death in body and soul."}
{"answers": {"text": ["backing for the uprising", "backing", "backing"], "answer_start": [17, 17, 17]}, "prediction_text": "Luther denied the rebels' weapons."}
{"answers": {"text": ["Swabian League", "Swabian League", "Swabian League"], "answer_start": [122, 122, 122]}, "prediction_text": "The Swabian League"}
{"answers": {"text": ["15 May 1525", "15 May 1525", "1525"], "answer_start": [171, 171, 178]}, "prediction_text": "1525"}
{"answers": {"text": ["M\u00fcntzer's execution", "M\u00fcntzer's execution", "M\u00fcntzer's execution,"], "answer_start": [196, 196, 196]}, "prediction_text": "M\u00fcntzer's execution"}
{"answers": {"text": ["the secular powers", "secular powers", "wing of the secular powers"], "answer_start": [432, 436, 424]}, "prediction_text": "The secular powers"}
{"answers": {"text": ["Katharina von Bora", "Katharina von Bora", "Katharina von Bora,"], "answer_start": [22, 22, 22]}, "prediction_text": "Katharina von Bora"}
{"answers": {"text": ["in herring barrels", "herring barrels", "herring barrels."], "answer_start": [176, 179, 179]}, "prediction_text": "In herring barrels"}
{"answers": {"text": ["26 years old", "26", "26"], "answer_start": [377, 377, 377]}, "prediction_text": "26 years old"}
{"answers": {"text": ["41 years old", "41", "41"], "answer_start": [405, 405, 405]}, "prediction_text": "26 years old"}
{"answers": {"text": ["April 1523", "April 1523", "1523"], "answer_start": [119, 119, 125]}, "prediction_text": "April 1523"}
{"answers": {"text": ["13 June 1525", "13 June 1525", "13 June 1525,"], "answer_start": [3, 3, 3]}, "prediction_text": "June 13, 1525"}
{"answers": {"text": ["evening", "evening", "evening"], "answer_start": [177, 177, 177]}, "prediction_text": "June 13, 1525"}
{"answers": {"text": ["wedding banquet", "wedding banquet", "banquet"], "answer_start": [282, 282, 290]}, "prediction_text": "Wedding banquet"}
{"answers": {"text": ["27 June", "27 June", "two weeks later"], "answer_start": [349, 349, 330]}, "prediction_text": "27 June"}
{"answers": {"text": ["Johannes Bugenhagen", "Johannes Bugenhagen", "Bugenhagen"], "answer_start": [45, 45, 228]}, "prediction_text": "Johannes Bugenhagen, Justus Jonas, Philipp Melanchthon, Lucas Cranach the Elder, and their wives."}
{"answers": {"text": ["seal of approval", "seal of approval on clerical marriage", "seal of approval on clerical marriage", "seal of approval on clerical marriage"], "answer_start": [130, 130, 130, 130]}, "prediction_text": "Reckless and reckless."}
{"answers": {"text": ["clerical marriage", "clerical", "clerical marriage.", "clerical marriage."], "answer_start": [150, 150, 150, 150]}, "prediction_text": "clerical marriage"}
{"answers": {"text": ["on Biblical grounds", "Biblical grounds", "Biblical grounds,", "Biblical grounds,"], "answer_start": [208, 211, 211, 211]}, "prediction_text": "For Biblical reasons."}
{"answers": {"text": ["death of a heretic", "the death of a heretic", "expect the death of a heretic", "expect the death of a heretic"], "answer_start": [566, 562, 555, 555]}, "prediction_text": "Death of a heretic."}
{"answers": {"text": ["reckless", "reckless", "reckless", "reckless"], "answer_start": [308, 308, 308, 308]}, "prediction_text": "\" reckless.\""}
{"answers": {"text": ["The Black Cloister", "The Black Cloister", ", \"The Black Cloister,\""], "answer_start": [52, 52, 49]}, "prediction_text": "1526-1532"}
{"answers": {"text": ["former monastery", "a former monastery", "former monastery,"], "answer_start": [33, 31, 33]}, "prediction_text": "A former monastery, where Luther and his wife lived."}
{"answers": {"text": ["six children", "six", "six"], "answer_start": [265, 265, 265]}, "prediction_text": "Six children"}
{"answers": {"text": ["riches of Croesus", "poverty", "my poverty for the riches of Croesus."], "answer_start": [710, 694, 691]}, "prediction_text": "Poverty"}
{"answers": {"text": ["farming the land", "farming the land", "farming"], "answer_start": [512, 512, 512]}, "prediction_text": "She helped Luther earn a living by farming the land."}
{"answers": {"text": ["choosing their own ministers", "choosing their own ministers", "confessional church based on personal faith and experience and a territorial church including all in a given locality"], "answer_start": [117, 117, 235]}, "prediction_text": "Personal faith and experience."}
{"answers": {"text": ["supervisory church body", "supervisory church body", "supervisory church"], "answer_start": [507, 507, 507]}, "prediction_text": "A supervisory church body"}
{"answers": {"text": ["new form", "a new form", "two catechisms."], "answer_start": [544, 542, 631]}, "prediction_text": "A new form of worship service."}
{"answers": {"text": ["two catechisms", "two catechisms", "two catechisms."], "answer_start": [631, 631, 631]}, "prediction_text": "Two catechisms"}
{"answers": {"text": ["revolutionary", "theology of the cross,", "revolutionary"], "answer_start": [667, 708, 667]}, "prediction_text": "A theology of the cross"}
{"answers": {"text": ["extreme change", "extreme change", "extreme change."], "answer_start": [59, 59, 59]}, "prediction_text": "confusing or upsetting people."}
{"answers": {"text": ["Electorate of Saxony", "Electorate of Saxony", "Electorate"], "answer_start": [181, 181, 181]}, "prediction_text": "Electorate of Saxony"}
{"answers": {"text": ["adviser", "adviser", "adviser"], "answer_start": [221, 221, 221]}, "prediction_text": "He worked closely with churches in new territories, many of which followed his Saxon model."}
{"answers": {"text": ["John the Steadfast", "John the Steadfast", "John the Steadfast,"], "answer_start": [341, 341, 341]}, "prediction_text": "John the Steadfast"}
{"answers": {"text": ["under the temporal sovereign", "church government under the temporal sovereign", "church government under the temporal sovereign"], "answer_start": [659, 641, 641]}, "prediction_text": "Difficulties with the Eisleben reformer."}
{"answers": {"text": ["early 1526", "1526", "1526"], "answer_start": [95, 101, 101]}, "prediction_text": "Early 1526"}
{"answers": {"text": ["1523 adaptation of the Latin Mass", "Latin Mass", "adaptation of the Latin Mass"], "answer_start": [153, 176, 158]}, "prediction_text": "The Latin Mass"}
{"answers": {"text": ["simple people", "simple people", "\"simple people"], "answer_start": [218, 218, 217]}, "prediction_text": "The simple people"}
{"answers": {"text": ["sacrifice", "everything that smacks of sacrifice", "everything that smacks of sacrifice"], "answer_start": [388, 362, 362]}, "prediction_text": "The host and chalice."}
{"answers": {"text": ["freedom of ceremony", "freedom", "wine as well as the bread"], "answer_start": [632, 632, 462]}, "prediction_text": "Freedom of ceremony."}
{"answers": {"text": ["1527", "1527", "1527"], "answer_start": [130, 130, 130]}, "prediction_text": "1527"}
{"answers": {"text": ["visitation of the Electorate", "Electorate of Saxony", "visitation of the Electorate of Saxony,"], "answer_start": [75, 93, 75]}, "prediction_text": "Electorate of Saxony"}
{"answers": {"text": ["Christian education", "Christian", "standard of pastoral care and Christian education"], "answer_start": [189, 189, 159]}, "prediction_text": "Christian education"}
{"answers": {"text": ["Christian doctrine", "Christian doctrine", "Christian doctrine"], "answer_start": [327, 327, 327]}, "prediction_text": "Christian doctrine"}
{"answers": {"text": ["incapable of teaching", "teaching", "teaching"], "answer_start": [409, 422, 422]}, "prediction_text": "Teach Christian doctrine"}
{"answers": {"text": ["catechism", "catechism", "catechism"], "answer_start": [19, 19, 19]}, "prediction_text": "The basics of Christianity"}
{"answers": {"text": ["1529", "1529", "1529"], "answer_start": [106, 106, 106]}, "prediction_text": "1529"}
{"answers": {"text": ["pastors and teachers", "pastors and teachers", "pastors"], "answer_start": [155, 155, 155]}, "prediction_text": "The congregations"}
{"answers": {"text": ["the people", "the people", "people"], "answer_start": [240, 240, 244]}, "prediction_text": "People who were not pastors or teachers."}
{"answers": {"text": ["questions and answers", "questions and answers", "questions and answers in the catechism so that the basics of Christian faith"], "answer_start": [461, 461, 461]}, "prediction_text": "Questions and answers"}
{"answers": {"text": ["The catechism", "catechism", "catechism"], "answer_start": [0, 4, 4]}, "prediction_text": "The catechism"}
{"answers": {"text": ["writings in volumes", "plan to collect my writings in volumes", "Saturnian hunger,"], "answer_start": [88, 69, 188]}, "prediction_text": "Collecting his writings in volumes"}
{"answers": {"text": ["the Catechism", "Catechism", "Catechism"], "answer_start": [347, 351, 351]}, "prediction_text": "The Catechism"}
{"answers": {"text": ["Small Catechism", "Small Catechism", "The Small Catechism"], "answer_start": [367, 367, 363]}, "prediction_text": "The Small Catechism"}
{"answers": {"text": ["the Bible", "Bible", "Bible"], "answer_start": [521, 525, 525]}, "prediction_text": "The Bible"}
{"answers": {"text": ["Small Catechism", "Small Catechism", "Small Catechism"], "answer_start": [9, 9, 9]}, "prediction_text": "The Larger Catechism"}
{"answers": {"text": ["Larger Catechism", "Larger Catechism", "Larger Catechism"], "answer_start": [107, 107, 107]}, "prediction_text": "Teaching their children."}
{"answers": {"text": ["German vernacular", "German", "German"], "answer_start": [161, 161, 161]}, "prediction_text": "German (vernacular)"}
{"answers": {"text": ["as persons", "persons to be known.", "Father, the Son, or the Holy Spirit."], "answer_start": [622, 625, 333]}, "prediction_text": "By showing the character of the Father, the Son, or the Holy Spirit."}
{"answers": {"text": ["with the Father", "with the Father", "Father"], "answer_start": [775, 775, 784]}, "prediction_text": "In the Father and Son."}
{"answers": {"text": ["1522", "1522", "1522"], "answer_start": [68, 68, 68]}, "prediction_text": "1522"}
{"answers": {"text": ["1534", "1534", "1534"], "answer_start": [153, 153, 153]}, "prediction_text": "1534"}
{"answers": {"text": ["the translation", "translation", "translation"], "answer_start": [228, 232, 232]}, "prediction_text": "Translation of the Bible"}
{"answers": {"text": ["alone", "alone", "alone"], "answer_start": [420, 420, 420]}, "prediction_text": "\"alone\""}
{"answers": {"text": ["Faith alone", "faith", "faith in Christ without any works of the Law"], "answer_start": [905, 671, 671]}, "prediction_text": "Faith alone"}
{"answers": {"text": ["Saxon chancellery", "Saxon chancellery", "variant of German spoken at the Saxon chancellery,"], "answer_start": [62, 62, 30]}, "prediction_text": "Saxon chancellery"}
{"answers": {"text": ["northern and southern", "northern and southern", "both northern and southern Germans"], "answer_start": [102, 102, 97]}, "prediction_text": "Northern and southern Germans"}
{"answers": {"text": ["everyday Germans", "everyday Germans", "everyday Germans"], "answer_start": [207, 207, 207]}, "prediction_text": "Germans"}
{"answers": {"text": ["read it without hindrance", "may read it without hindrance", "removing impediments and difficulties so that other people may read it without hindrance"], "answer_start": [300, 296, 237]}, "prediction_text": "For other people to read it."}
{"answers": {"text": ["impediments and difficulties", "impediments and difficulties", "impediments"], "answer_start": [246, 246, 246]}, "prediction_text": "impediments and difficulties"}
{"answers": {"text": ["German-language publications", "German-language publications", "German-language publications,"], "answer_start": [41, 41, 41]}, "prediction_text": "German-language publications"}
{"answers": {"text": ["Bible translation", "Bible", "Bible"], "answer_start": [129, 129, 129]}, "prediction_text": "Luther's version of the Bible"}
{"answers": {"text": ["evolution of the German language", "evolution of the German language and literature", "evolution of the German language and literature"], "answer_start": [199, 199, 199]}, "prediction_text": "Evolution of German language and literature."}
{"answers": {"text": ["Lucas Cranach", "Lucas Cranach", "Lucas Cranach"], "answer_start": [314, 314, 314]}, "prediction_text": "Lucas Cranach"}
{"answers": {"text": ["William Tyndale", "William Tyndale's", "Tyndale"], "answer_start": [508, 508, 516]}, "prediction_text": "William Tyndale's English Bible"}
{"answers": {"text": ["authoring hymns", "hymn-writer", "hymn-writer"], "answer_start": [35, 22, 22]}, "prediction_text": "Song-writing"}
{"answers": {"text": ["high art and folk music", "high art and folk music", "singing of German hymns in connection with worship"], "answer_start": [262, 262, 395]}, "prediction_text": "High art and folk music"}
{"answers": {"text": ["singing of German hymns", "singing of German hymns", "singing"], "answer_start": [395, 395, 395]}, "prediction_text": "German hymns"}
{"answers": {"text": ["lute", "a lute", "singing"], "answer_start": [526, 524, 395]}, "prediction_text": "A lute"}
{"answers": {"text": ["waldzither", "waldzither", "waldzither"], "answer_start": [555, 555, 555]}, "prediction_text": "Waldzither"}
{"answers": {"text": ["events in his life", "particular events in his life", "events in his life"], "answer_start": [52, 41, 52]}, "prediction_text": "Learning of Johann Esch's execution and Heinrich Voes' martyrdom."}
{"answers": {"text": ["for Lutheran views", "Lutheran views", "Lutheran views,"], "answer_start": [259, 263, 263]}, "prediction_text": "For Lutheran views"}
{"answers": {"text": ["Ein neues Lied wir heben an", "Ein neues Lied wir heben an", "Ein neues Lied wir heben an"], "answer_start": [315, 315, 315]}, "prediction_text": "\"Ein neues Lied wir heben an\""}
{"answers": {"text": ["John C. Messenger", "John C. Messenger", "Messenger"], "answer_start": [408, 408, 416]}, "prediction_text": "John C. Messenger"}
{"answers": {"text": ["Flung to the Heedless Winds", "Flung to the Heedless Winds", "A new song we raise"], "answer_start": [469, 469, 346]}, "prediction_text": "\"A new song we raise\""}
{"answers": {"text": ["1524", "1524", "1524"], "answer_start": [9, 9, 9]}, "prediction_text": "1524"}
{"answers": {"text": ["Apostles' Creed", "explanation of the Apostles' Creed", "three-part explanation of the Apostles' Creed"], "answer_start": [188, 169, 158]}, "prediction_text": "Luther's 1529 three-part explanation of the Apostles' Creed."}
{"answers": {"text": ["Small Catechism", "Small Catechism", "Small Catechism"], "answer_start": [211, 211, 211]}, "prediction_text": "Small Catechism (1529)"}
{"answers": {"text": ["German creedal hymn", "creedal", "earlier German creedal hymn,"], "answer_start": [280, 287, 272]}, "prediction_text": "\"Wir glauben all\""}
{"answers": {"text": ["difficulty of its tune", "perceived difficulty of its tune", "difficulty of its tune"], "answer_start": [639, 629, 639]}, "prediction_text": "Lack of difficulty in tune."}
{"answers": {"text": ["1538", "1538", "1538"], "answer_start": [9, 9, 9]}, "prediction_text": "1538"}
{"answers": {"text": ["Small Catechism", "Small Catechism", "Small Catechism,"], "answer_start": [146, 146, 146]}, "prediction_text": "Small Catechism"}
{"answers": {"text": ["specific catechism questions", "specific catechism questions", "specific catechism questions"], "answer_start": [365, 365, 365]}, "prediction_text": "Catechism questions"}
{"answers": {"text": ["multiple revisions", "multiple revisions", "multiple revisions"], "answer_start": [423, 423, 423]}, "prediction_text": "Multiple revisions"}
{"answers": {"text": ["Luther's tune", "Luther's tune", "adopted Luther's tune"], "answer_start": [635, 635, 627]}, "prediction_text": "Luther's tune"}
{"answers": {"text": ["1523", "1523", "1523"], "answer_start": [87, 87, 87]}, "prediction_text": "1523"}
{"answers": {"text": ["Psalm 130", "Psalm 130", "Psalm 130"], "answer_start": [115, 115, 115]}, "prediction_text": "Essential Reformation doctrine"}
{"answers": {"text": ["write psalm-hymns", "write psalm-hymns", "to write psalm-hymns"], "answer_start": [188, 188, 185]}, "prediction_text": "Write psalm-hymns for use in German worship."}
{"answers": {"text": ["Achtliederbuch", "Achtliederbuch", "Achtliederbuch"], "answer_start": [321, 321, 321]}, "prediction_text": "Achtliederbuch"}
{"answers": {"text": ["Reformation doctrine", "essential Reformation doctrine", "essential Reformation doctrine"], "answer_start": [552, 542, 542]}, "prediction_text": "Reformation doctrine"}
{"answers": {"text": ["Nun komm, der Heiden Heiland", "Nun komm, der Heiden Heiland", "Nun komm, der Heiden Heiland"], "answer_start": [84, 84, 84]}, "prediction_text": "\"Ach Gott, vom Himmel sieh darein\""}
{"answers": {"text": ["Veni redemptor gentium", "Veni redemptor gentium", "Veni redemptor gentium"], "answer_start": [159, 159, 159]}, "prediction_text": "Veni redemptor gentium"}
{"answers": {"text": ["main hymn", "hymn", "main hymn"], "answer_start": [194, 199, 194]}, "prediction_text": "Hauptlied is a hymn for Advent."}
{"answers": {"text": ["two hymns", "two", "two"], "answer_start": [443, 443, 443]}, "prediction_text": "Two hymns based on the Ten Commandments."}
{"answers": {"text": ["German Te Deum", "the German Te Deum", "German Te Deum"], "answer_start": [1072, 1068, 1072]}, "prediction_text": "German Te Deum"}
{"answers": {"text": ["baptism", "baptism", "baptism"], "answer_start": [170, 170, 170]}, "prediction_text": "Baptism in the Small Catechism"}
{"answers": {"text": ["Johann Walter", "Johann Walter", "Walter"], "answer_start": [231, 231, 238]}, "prediction_text": "Johann Walter tune"}
{"answers": {"text": ["prayer for grace", "grace", "prayer for grace"], "answer_start": [297, 308, 297]}, "prediction_text": "Prayer for grace"}
{"answers": {"text": ["J. S. Bach", "J. S. Bach", "Bach"], "answer_start": [479, 479, 485]}, "prediction_text": "J. S. Bach"}
{"answers": {"text": ["Halle", "Halle", "Halle"], "answer_start": [409, 409, 409]}, "prediction_text": "Halle (1541)"}
{"answers": {"text": ["early Lutheran hymnals", "hymnals", "early Lutheran hymnals"], "answer_start": [32, 47, 32]}, "prediction_text": "Early Lutheran hymnals"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [108, 108, 108]}, "prediction_text": "Eight hymns"}
{"answers": {"text": ["18", "18", "18"], "answer_start": [173, 173, 173]}, "prediction_text": "Eight hymns"}
{"answers": {"text": ["24", "24", "24"], "answer_start": [219, 219, 219]}, "prediction_text": "Four hymns"}
{"answers": {"text": ["Eyn geystlich Gesangk Buchleyn", "Eyn geystlich Gesangk Buchleyn", "Eyn geystlich Gesangk Buchleyn"], "answer_start": [297, 297, 297]}, "prediction_text": "Johann Walter's Gesangk Buchleyn"}
{"answers": {"text": ["Johann Sebastian Bach", "Johann Sebastian Bach", "Bach"], "answer_start": [50, 50, 67]}, "prediction_text": "Johann Sebastian Bach"}
{"answers": {"text": ["chorale cantatas", "chorale cantatas", "chorale cantatas"], "answer_start": [134, 134, 134]}, "prediction_text": "Christ lag in Todes Banden"}
{"answers": {"text": ["1707", "1707", "1707"], "answer_start": [232, 232, 232]}, "prediction_text": "1707"}
{"answers": {"text": ["1724 to 1725", "1724 to 1725", "1724 to 1725"], "answer_start": [266, 266, 266]}, "prediction_text": "1707 to 1725."}
{"answers": {"text": ["1735", "1735", "W\u00e4r Gott nicht mit uns diese Zeit"], "answer_start": [537, 537, 542]}, "prediction_text": "1707"}
{"answers": {"text": ["sleeps", "sleeps", "sleeps"], "answer_start": [169, 169, 169]}, "prediction_text": "Sleeps in peace"}
{"answers": {"text": ["idea of torments", "torments", "Bible"], "answer_start": [388, 396, 288]}, "prediction_text": "Purgatory, torments, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory, Purgatory,"}
{"answers": {"text": ["sleep in peace", "enter a prepared bedchamber in which they sleep in peace.", "sleeps"], "answer_start": [591, 549, 169]}, "prediction_text": "They enter a prepared bedchamber."}
{"answers": {"text": ["rejected the existence", "rejected the existence of", "rejected"], "answer_start": [616, 616, 616]}, "prediction_text": "A Christian soul is not threatened by the torments and punishments of hell."}
{"answers": {"text": ["Smalcald Articles", "in their graves and in heaven", "Smalcald Articles"], "answer_start": [805, 871, 805]}, "prediction_text": "In their graves and in heaven."}
{"answers": {"text": ["Franz Pieper", "Franz Pieper", "Pieper"], "answer_start": [24, 24, 30]}, "prediction_text": "Franz Pieper"}
{"answers": {"text": ["Johann Gerhard", "Johann Gerhard", "Gerhard"], "answer_start": [174, 174, 181]}, "prediction_text": "Lessing"}
{"answers": {"text": ["Gerhard. Lessing", "Lessing", "Lessing"], "answer_start": [181, 190, 190]}, "prediction_text": "Franz Pieper"}
{"answers": {"text": ["1755", "1755", "1755"], "answer_start": [199, 199, 199]}, "prediction_text": "1755"}
{"answers": {"text": ["Commentary on Genesis", "Commentary on Genesis", "Commentary on Genesis"], "answer_start": [9, 9, 9]}, "prediction_text": "In the Commentary on Genesis"}
{"answers": {"text": ["Francis Blackburne", "Francis Blackburne", "Blackburne"], "answer_start": [170, 170, 178]}, "prediction_text": "Francis Blackburne"}
{"answers": {"text": ["1765", "1765", "1765"], "answer_start": [192, 192, 192]}, "prediction_text": "1765"}
{"answers": {"text": ["Gottfried Fritschel", "Gottfried Fritschel", "Fritschel"], "answer_start": [272, 272, 282]}, "prediction_text": "Gottfried Fritschel"}
{"answers": {"text": ["dreams", "dreams", "dreams"], "answer_start": [557, 557, 557]}, "prediction_text": "Dreams"}
{"answers": {"text": ["October 1529", "October 1529", "1529"], "answer_start": [3, 3, 11]}, "prediction_text": "October 1529"}
{"answers": {"text": ["Landgrave of Hesse", "Landgrave of Hesse", "Landgrave of Hesse"], "answer_start": [27, 27, 27]}, "prediction_text": "Landgrave of Hesse"}
{"answers": {"text": ["doctrinal unity", "doctrinal unity", "doctrinal unity"], "answer_start": [138, 138, 138]}, "prediction_text": "Protestant unity in the emerging states."}
{"answers": {"text": ["fourteen points", "fourteen", "fourteen"], "answer_start": [215, 215, 215]}, "prediction_text": "Fourteen points"}
{"answers": {"text": ["nature of the Eucharist", "nature of the Eucharist", "sacrament of the Lord's Supper"], "answer_start": [271, 271, 301]}, "prediction_text": "Eucharist issue"}
{"answers": {"text": ["words spoken by Jesus", "significance of the words spoken by Jesus", "words spoken"], "answer_start": [127, 107, 127]}, "prediction_text": "The Last Supper was the first time Jesus was publicly acknowledged as God's Son."}
{"answers": {"text": ["body and blood of Christ", "Real Presence", "Real Presence of the body and blood of Christ in the consecrated bread and wine"], "answer_start": [321, 300, 300]}, "prediction_text": "God's omnipresence"}
{"answers": {"text": ["sacramental union", "sacramental union", "sacramental union"], "answer_start": [401, 401, 401]}, "prediction_text": "The sacramental union"}
{"answers": {"text": ["symbolically present", "spiritually or symbolically present", "symbolically present."], "answer_start": [479, 464, 479]}, "prediction_text": "Luther believed God to be only spiritually or symbolically present."}
{"answers": {"text": ["confrontational", "confrontational", "confrontational"], "answer_start": [696, 696, 696]}, "prediction_text": "confrontational"}
{"answers": {"text": ["1530", "1530", "1530"], "answer_start": [98, 98, 98]}, "prediction_text": "1530"}
{"answers": {"text": ["Marburg Colloquy", "Marburg Colloquy", "Marburg Colloquy"], "answer_start": [48, 48, 48]}, "prediction_text": "Marburg Colloquy"}
{"answers": {"text": ["Schmalkaldic League", "Schmalkaldic League", "Schmalkaldic League"], "answer_start": [160, 160, 160]}, "prediction_text": "Schmalkaldic League"}
{"answers": {"text": ["The Swiss cities", "Swiss cities", "The Swiss cities"], "answer_start": [314, 318, 314]}, "prediction_text": "Swiss cities"}
{"answers": {"text": ["George, Margrave of Brandenburg-Ansbach", "George, Margrave of Brandenburg-Ansbach", "George, Margrave of Brandenburg-Ansbach"], "answer_start": [273, 273, 273]}, "prediction_text": "George Margrave of Brandenburg-Ansbach"}
{"answers": {"text": ["antithetical", "antithetical", "antithetical"], "answer_start": [74, 74, 74]}, "prediction_text": "Luther believed that faith and reason were antithetical."}
{"answers": {"text": ["reason", "reason", "human reason"], "answer_start": [152, 152, 555]}, "prediction_text": "Reason"}
{"answers": {"text": ["no way contributes", "in no way", "in no way"], "answer_start": [342, 339, 339]}, "prediction_text": "Luther said that reason contributes to faith."}
{"answers": {"text": ["reason", "reason", "Reason"], "answer_start": [381, 381, 332]}, "prediction_text": "Reason"}
{"answers": {"text": ["different epistemological spheres.", "separate spheres of knowledge that each applies to", "separate spheres of knowledge"], "answer_start": [1796, 855, 855]}, "prediction_text": "Their different epistemological spheres."}
{"answers": {"text": ["Jesus Christ was born a Jew", "that Jesus Christ was born a Jew", "conversion"], "answer_start": [27, 22, 118]}, "prediction_text": "Luther wrote that Jesus Christ was born a Jew."}
{"answers": {"text": ["Jewish conversion to Christianity", "large-scale Jewish conversion to Christianity", "large-scale Jewish conversion"], "answer_start": [284, 272, 272]}, "prediction_text": "Jews' conversion to Christianity"}
{"answers": {"text": ["Jews", "Jews", "Jews"], "answer_start": [375, 375, 375]}, "prediction_text": "The Anabaptists, Zwinglianism, and the papacy."}
{"answers": {"text": ["Anabaptists", "Anabaptists, Zwinglianism, and the papacy", "Anabaptists"], "answer_start": [457, 457, 457]}, "prediction_text": "The Anabaptists, Zwinglianism, and papacy."}
{"answers": {"text": ["1543", "1543", "1543"], "answer_start": [504, 504, 504]}, "prediction_text": "1543"}
{"answers": {"text": ["as a scourge", "scourge", "argued against resisting"], "answer_start": [259, 264, 120]}, "prediction_text": "A scourge sent to punish Christians."}
{"answers": {"text": ["to punish Christians", "punish Christians by God", "scourge sent to punish Christians"], "answer_start": [277, 280, 264]}, "prediction_text": "Punishing Christians by God."}
{"answers": {"text": ["destroy the antichrist", "destroy the antichrist", "punish"], "answer_start": [354, 354, 280]}, "prediction_text": "To punish Christians."}
{"answers": {"text": ["the papacy", "papacy", "papacy"], "answer_start": [405, 409, 409]}, "prediction_text": "The Roman Church"}
{"answers": {"text": ["secular war", "non-religious", "non-religious war"], "answer_start": [994, 732, 732]}, "prediction_text": "Non-religious war"}
{"answers": {"text": ["Qur'an", "Qur'an", "Qur'an"], "answer_start": [48, 48, 48]}, "prediction_text": "The Qur'an"}
{"answers": {"text": ["critical pamphlets on Islam", "critical", "critical pamphlets on Islam"], "answer_start": [86, 86, 86]}, "prediction_text": "Critical pamphlets on Islam"}
{"answers": {"text": ["Islam", "Islam", "pamphlets"], "answer_start": [108, 108, 95]}, "prediction_text": "The Turk is a tool of the devil."}
{"answers": {"text": ["tool of the devil", "a tool of the devil", "tool of the devil,"], "answer_start": [202, 200, 202]}, "prediction_text": "He viewed it as a tool of the devil."}
{"answers": {"text": ["exposed to scrutiny.", "wanting it exposed to scrutiny.", "exposed to scrutiny"], "answer_start": [423, 412, 423]}, "prediction_text": "Opposed banning."}
{"answers": {"text": ["God's wrath to Christians", "God's wrath", "God's wrath to Christians."], "answer_start": [222, 222, 222]}, "prediction_text": "God's wrath revealed to Christians."}
{"answers": {"text": ["Johannes Agricola", "Agricola", "Agricola"], "answer_start": [15, 316, 316]}, "prediction_text": "Agricola"}
{"answers": {"text": ["city hall", "city hall", "city hall."], "answer_start": [495, 495, 495]}, "prediction_text": "City hall"}
{"answers": {"text": ["theses against Agricola", "six series of theses", "six series of theses against Agricola"], "answer_start": [558, 544, 544]}, "prediction_text": "Luther responded to Agricola's theses against Luther."}
{"answers": {"text": ["On the Councils and the Church", "On the Councils and the Church", "On the Councils"], "answer_start": [811, 811, 811]}, "prediction_text": "On the Councils and the Church"}
{"answers": {"text": ["second use of the law", "second use of the law", "second use of the law"], "answer_start": [129, 129, 129]}, "prediction_text": "The law as the Holy Spirit's tool to work sorrow over sin."}
{"answers": {"text": ["work sorrow over sin", "work sorrow over sin in man's heart", "work sorrow over sin in man's heart"], "answer_start": [199, 199, 199]}, "prediction_text": "Helps prepare man for Christ's fulfillment."}
{"answers": {"text": ["everything", "everything", "everything that is used to work sorrow over sin is called the law,"], "answer_start": [333, 333, 333]}, "prediction_text": "Everything that is used to work sorrow over sin."}
{"answers": {"text": ["eliminate the accusing law", "eliminate the accusing law.", "eliminate the accusing law"], "answer_start": [643, 643, 643]}, "prediction_text": "Exercises authority over Christians."}
{"answers": {"text": ["essentially holy people", "holy people", "only of essentially holy people"], "answer_start": [876, 888, 868]}, "prediction_text": "Holy people"}
{"answers": {"text": ["ought to live", "live", "how the Christian ought to live"], "answer_start": [231, 240, 213]}, "prediction_text": "Live according to God's will"}
{"answers": {"text": ["Ten Commandments", "the Ten Commandments", "Ten Commandments"], "answer_start": [51, 47, 51]}, "prediction_text": "The Ten Commandments"}
{"answers": {"text": ["third use of the law", "third use of the law", "third use of the law"], "answer_start": [286, 286, 286]}, "prediction_text": "Teaching Christians how to live"}
{"answers": {"text": ["illustration of the Ten Commandments", "an illustration of the Ten Commandments", "illustration of the Ten Commandments,"], "answer_start": [396, 393, 396]}, "prediction_text": "An illustration of the Ten Commandments"}
{"answers": {"text": ["Ten Commandments", "Ten Commandments", "his or her vocations on a daily basis"], "answer_start": [416, 416, 469]}, "prediction_text": "The Ten Commandments"}
{"answers": {"text": ["baptism", "baptism", "baptism"], "answer_start": [112, 112, 112]}, "prediction_text": "Baptism"}
{"answers": {"text": ["Ten Commandments", "Ten Commandments", "Ten Commandments,"], "answer_start": [4, 4, 4]}, "prediction_text": "Ten Commandments"}
{"answers": {"text": ["service to the neighbor", "service to the neighbor in the common", "service to the neighbor in the common, daily vocations of this perishing world"], "answer_start": [413, 413, 413]}, "prediction_text": "Serve to neighbor"}
{"answers": {"text": ["wanted to marry", "marry one of his wife's ladies-in-waiting", "marry one of his wife's ladies-in-waiting."], "answer_start": [96, 106, 106]}, "prediction_text": "marry one of his wife's ladies-in-waiting."}
{"answers": {"text": ["bigamy", "bigamy", "bigamy"], "answer_start": [52, 52, 52]}, "prediction_text": "Bigamy of Philip I"}
{"answers": {"text": ["one of his wife's ladies-in-waiting", "Margarethe von der Saale", "one of his wife's ladies-in-waiting"], "answer_start": [112, 516, 112]}, "prediction_text": "One of his wife's ladies-in-waiting."}
{"answers": {"text": ["holds Luther accountable", "Luther", "one of the worst mistakes Luther made,"], "answer_start": [1064, 1070, 936]}, "prediction_text": "Melanchthon and Bucer"}
{"answers": {"text": ["lasting damage", "lasting damage", "caused lasting damage"], "answer_start": [1245, 1245, 1238]}, "prediction_text": "Long lasting damage to Luther's reputation."}
{"answers": {"text": ["expelled Jews", "expelled", "expelled"], "answer_start": [336, 336, 336]}, "prediction_text": "Expelled Jews"}
{"answers": {"text": ["Jews", "Jews", "Jews"], "answer_start": [134, 231, 134]}, "prediction_text": "Jews"}
{"answers": {"text": ["murder of Christ", "murder of Christ", "murder of Christ,"], "answer_start": [271, 271, 271]}, "prediction_text": "Murder of Christ"}
{"answers": {"text": ["divinity of Jesus", "Jesus", "divinity of Jesus"], "answer_start": [448, 460, 448]}, "prediction_text": "Jesus' divinity"}
{"answers": {"text": ["convert them to Christianity.", "convert", "convert"], "answer_start": [946, 946, 946]}, "prediction_text": "Convert them to Christianity."}
{"answers": {"text": ["Von den Juden und Ihren L\u00fcgen", "treatise Von den Juden und Ihren L\u00fcgen", "Von den Juden und Ihren L\u00fcgen"], "answer_start": [69, 60, 69]}, "prediction_text": "Von den Juden und Ihren L\u00fcgen"}
{"answers": {"text": ["1543", "1543", "1543"], "answer_start": [244, 244, 244]}, "prediction_text": "1543"}
{"answers": {"text": ["three years before", "three years before", "three years before his death"], "answer_start": [250, 250, 250]}, "prediction_text": "Three years before his death."}
{"answers": {"text": ["the devil's people", "the devil's people", "the devil's people"], "answer_start": [346, 346, 346]}, "prediction_text": "The chosen people of God."}
{"answers": {"text": ["sanction for murder", "a sanction for murder.", "a sanction for murder."], "answer_start": [1059, 1057, 1057]}, "prediction_text": "A sanction for murder."}
{"answers": {"text": ["the Jews", "Jews", "Jews"], "answer_start": [25, 29, 29]}, "prediction_text": "Jews"}
{"answers": {"text": ["Martin Luther", "Martin Luther", "that priest whose name was Martin Luther"], "answer_start": [213, 213, 186]}, "prediction_text": "Martin Luther"}
{"answers": {"text": ["doomed to perdition", "doomed to perdition", "doomed to perdition."], "answer_start": [366, 366, 366]}, "prediction_text": "They were doomed to perdition."}
{"answers": {"text": ["Luther's anti-Jewish works", "Luther's anti-Jewish works", "Luther's anti-Jewish works"], "answer_start": [445, 445, 445]}, "prediction_text": "Luther's anti-Jewish works"}
{"answers": {"text": ["Throughout the 1580s", "the 1580s", "1580s"], "answer_start": [646, 657, 661]}, "prediction_text": "1580s"}
{"answers": {"text": ["Luther", "Luther", "Luther"], "answer_start": [0, 0, 0]}, "prediction_text": "Luther"}
{"answers": {"text": ["anti-Jewish rhetoric", "anti-Jewish rhetoric", "anti-Jewish rhetoric"], "answer_start": [169, 169, 169]}, "prediction_text": "He wrote against the Jews."}
{"answers": {"text": ["attacks on Jews", "ideal underpinning", "antisemitism"], "answer_start": [338, 303, 238]}, "prediction_text": "Attacks on Jews"}
{"answers": {"text": ["Luther", "Luther", "Luther"], "answer_start": [648, 0, 648]}, "prediction_text": "Heinrich Himmler's writings"}
{"answers": {"text": ["radically anti-Semitic", "most radically anti-Semitic tract ever published", "most radically anti-Semitic tract ever published"], "answer_start": [944, 939, 939]}, "prediction_text": "The most radically anti-Semitic tract ever published."}
{"answers": {"text": ["17 December 1941", "17 December 1941", "1941"], "answer_start": [3, 3, 15]}, "prediction_text": "December 1941"}
{"answers": {"text": ["Luther", "Luther", "Luther"], "answer_start": [190, 190, 190]}, "prediction_text": "Luther"}
{"answers": {"text": ["Diarmaid MacCulloch", "Diarmaid MacCulloch", "MacCulloch"], "answer_start": [467, 467, 476]}, "prediction_text": "Daniel Goldhagen"}
{"answers": {"text": ["Bishop Martin Sasse", "Martin Sasse", "Sasse"], "answer_start": [331, 338, 603]}, "prediction_text": "Sasse"}
{"answers": {"text": ["greatest antisemite", "greatest antisemite of his time", "the greatest antisemite of his time,"], "answer_start": [857, 857, 853]}, "prediction_text": "A blueprint for the Jews."}
{"answers": {"text": ["opportunistic", "opportunistic", "limited"], "answer_start": [245, 245, 202]}, "prediction_text": "As opportunistic."}
{"answers": {"text": ["misguided agitation", "misguided agitation", "misguided agitation"], "answer_start": [406, 406, 406]}, "prediction_text": "\"Ahistorical perspective\""}
{"answers": {"text": ["modern hatred of the Jews", "hatred of the Jews", "hatred of the Jews"], "answer_start": [555, 562, 562]}, "prediction_text": "Modern hatred of the Jews."}
{"answers": {"text": ["18th and 19th centuries", "18th and 19th centuries", "18th and 19th centuries"], "answer_start": [724, 724, 724]}, "prediction_text": "18th and 19th centuries"}
{"answers": {"text": ["religious and in no respect racial", "entirely religious", "entirely religious and in no respect racial"], "answer_start": [1327, 1318, 1318]}, "prediction_text": "Luther was a religious person."}
{"answers": {"text": ["violence", "violence", "violence"], "answer_start": [161, 161, 161]}, "prediction_text": "A new element to Christian suspicion of Judaism."}
{"answers": {"text": ["Ronald Berger", "Ronald Berger", "Berger"], "answer_start": [237, 237, 244]}, "prediction_text": "Ronald Berger"}
{"answers": {"text": ["hysterical and demonizing mentality", "a \"hysterical and demonizing mentality\" about Jews", "hysterical and demonizing mentality"], "answer_start": [459, 456, 459]}, "prediction_text": "He caused a \"hysterical and demonizing mentality\" about Jews."}
{"answers": {"text": ["Lutheran clergy and theologians", "German Lutheran clergy and theologians", "Luther"], "answer_start": [745, 738, 810]}, "prediction_text": "Luther and the Protestant Church"}
{"answers": {"text": ["Luther's hostile publications", "Luther's hostile publications", "Luther's hostile publications towards the Jews"], "answer_start": [810, 810, 810]}, "prediction_text": "Luther's hostile publications"}
{"answers": {"text": ["declining state of mind", "a declining state of mind", "health deteriorated"], "answer_start": [281, 279, 202]}, "prediction_text": "Health deterioration"}
{"answers": {"text": ["his health", "state of mind", "declining state of mind"], "answer_start": [198, 291, 281]}, "prediction_text": "His health deteriorated"}
{"answers": {"text": ["vulgarity and violence", "vulgarity and violence", "\"vulgarity and violence"], "answer_start": [365, 365, 364]}, "prediction_text": "Vulgarity and violence"}
{"answers": {"text": ["Muslims) and Catholics", "Turks\" (Muslims) and Catholics", "Turks"], "answer_start": [476, 468, 468]}, "prediction_text": "Jews and Catholics."}
{"answers": {"text": ["Luther's Last Battles: Politics and Polemics 1531\u201346", "Luther's Last Battles: Politics and Polemics 1531\u201346", "Luther's Last Battles: Politics and Polemics 1531\u201346"], "answer_start": [51, 51, 51]}, "prediction_text": "Luther's Last Battles: Politics and Polemics"}
{"answers": {"text": ["Since the 1980s", "1980s", "Since the 1980s"], "answer_start": [0, 10, 0]}, "prediction_text": "Since the 1980s"}
{"answers": {"text": ["least prejudiced", "least prejudiced", "least prejudiced toward Jews"], "answer_start": [342, 342, 342]}, "prediction_text": "Lutherans were the least prejudiced toward Jews."}
{"answers": {"text": ["Richard (Dick) Geary", "Richard (Dick) Geary", "Geary"], "answer_start": [396, 396, 411]}, "prediction_text": "Professor Richard Geary"}
{"answers": {"text": ["1928-1933", "1928-1933"], "answer_start": [645, 645]}, "prediction_text": "From 1928-1933"}
{"answers": {"text": ["his health deteriorated", "deteriorated", "deteriorated"], "answer_start": [157, 168, 168]}, "prediction_text": "He suffered from ill health for years."}
{"answers": {"text": ["bigamy of the Philip of Hesse", "the bigamy of the Philip of Hesse incident", "bigamy of the Philip of Hesse"], "answer_start": [314, 310, 314]}, "prediction_text": "Bigamy scandal"}
{"answers": {"text": ["kidney and bladder stones", "kidney and bladder stones", "kidney and bladder stones, and arthritis,"], "answer_start": [456, 456, 456]}, "prediction_text": "Kidney and bladder stones"}
{"answers": {"text": ["arthritis, and an ear infection", "arthritis, and an ear infection ruptured an ear drum", "arthritis, and an ear infection ruptured an ear drum. In December 1544, he began to feel the effects of angina."], "answer_start": [487, 487, 487]}, "prediction_text": "M\u00e9ni\u00e8re's disease, vertigo, fainting, tinnitus, and an ear infection."}
{"answers": {"text": ["angina", "angina", "angina"], "answer_start": [591, 591, 591]}, "prediction_text": "Angina"}
{"answers": {"text": ["poor physical health", "poor physical health", "poor physical health"], "answer_start": [4, 4, 4]}, "prediction_text": "His poor physical health"}
{"answers": {"text": ["writings and comments", "his writings and comments", "writings and comments."], "answer_start": [73, 69, 73]}, "prediction_text": "His poor physical health"}
{"answers": {"text": ["harsher", "harsher", "harsher"], "answer_start": [58, 58, 58]}, "prediction_text": "He became harsher in his writings."}
{"answers": {"text": ["His wife Katharina", "wife Katharina", "Katharina"], "answer_start": [96, 100, 105]}, "prediction_text": "Justus Jonas"}
{"answers": {"text": ["three times", "three", "three"], "answer_start": [257, 257, 257]}, "prediction_text": "Three times"}
{"answers": {"text": ["Eisleben", "Eisleben", "Eisleben"], "answer_start": [33, 33, 33]}, "prediction_text": "Eisleben, Germany"}
{"answers": {"text": ["15 February 1546", "15 February 1546", "15 February 1546"], "answer_start": [66, 66, 66]}, "prediction_text": "February 1546"}
{"answers": {"text": ["Jews", "Jews", "entirely devoted to the obdurate Jews, whom it was a matter of great urgency to expel from all German territory,"], "answer_start": [154, 154, 121]}, "prediction_text": "Obdurate Jews"}
{"answers": {"text": ["all German territory", "all German territory", "1546"], "answer_start": [212, 212, 78]}, "prediction_text": "From German territory"}
{"answers": {"text": ["that they convert", "became Christians", "convert"], "answer_start": [528, 438, 538]}, "prediction_text": "They could kill us all."}
{"answers": {"text": ["Mansfeld", "Mansfeld", "Mansfeld"], "answer_start": [27, 27, 27]}, "prediction_text": "Mansfeld, Germany"}
{"answers": {"text": ["negotiations", "negotiations for a settlement", "siblings' families continuing in their father Hans Luther's copper mining"], "answer_start": [443, 443, 78]}, "prediction_text": "Count Albrecht"}
{"answers": {"text": ["late 1545", "1545", "1545"], "answer_start": [411, 416, 416]}, "prediction_text": "Late 1545 to early 1546"}
{"answers": {"text": ["early 1546", "1546", "1546"], "answer_start": [506, 512, 512]}, "prediction_text": "Early 1546"}
{"answers": {"text": ["his siblings' families", "his siblings", "siblings' families"], "answer_start": [74, 74, 78]}, "prediction_text": "His siblings' families"}
{"answers": {"text": ["17 February 1546", "17 February 1546", "17 February 1546"], "answer_start": [48, 48, 48]}, "prediction_text": "February 17, 1546"}
{"answers": {"text": ["chest pains", "chest pains", "chest pains"], "answer_start": [95, 95, 95]}, "prediction_text": "Chest pains"}
{"answers": {"text": ["Ps. 31:5", "Ps. 31:5", "Ps. 31:5"], "answer_start": [225, 225, 225]}, "prediction_text": "Psalm 31:5"}
{"answers": {"text": ["prayer of the dying", "the common prayer of the dying", "common prayer of the dying."], "answer_start": [247, 236, 240]}, "prediction_text": "\"I commit my spirit\""}
{"answers": {"text": ["1 a.m", "1 a.m.", "1 a.m"], "answer_start": [271, 271, 271]}, "prediction_text": "At 1 a.m."}
{"answers": {"text": ["apoplectic stroke", "apoplectic stroke", "apoplectic stroke"], "answer_start": [3, 3, 3]}, "prediction_text": "An apoplectic stroke deprived him of his speech."}
{"answers": {"text": ["2:45 a.m", "2:45 a.m.", "2:45 a.m"], "answer_start": [83, 83, 83]}, "prediction_text": "18 February 1546"}
{"answers": {"text": ["18 February 1546", "18 February 1546", "18 February 1546"], "answer_start": [96, 96, 96]}, "prediction_text": "18 February 1546"}
{"answers": {"text": ["in the Castle Church", "Castle Church in Wittenberg", "Castle Church in Wittenberg,"], "answer_start": [173, 180, 180]}, "prediction_text": "Castle Church in Wittenberg"}
{"answers": {"text": ["Johannes Bugenhagen and Philipp Melanchthon", "Johannes Bugenhagen and Philipp Melanchthon", "Johannes Bugenhagen and Philipp Melanchthon"], "answer_start": [265, 265, 265]}, "prediction_text": "Johannes Bugenhagen and Philipp Melanchthon"}
{"answers": {"text": ["his last statement", "his last statement", "last statement"], "answer_start": [61, 61, 65]}, "prediction_text": "A piece of paper"}
{"answers": {"text": ["Latin", "Latin", "Latin"], "answer_start": [102, 102, 102]}, "prediction_text": "Latin"}
{"answers": {"text": ["\"We are beggars,\"", "We are beggars", "We are beggars,"], "answer_start": [120, 121, 121]}, "prediction_text": "\"We are beggars\""}
{"answers": {"text": ["monumental", "printed images of Luther that emphasized his monumental size", "printed"], "answer_start": [69, 24, 24]}, "prediction_text": "Printed images of Luther emphasized his monumental size."}
{"answers": {"text": ["frail Catholic saints", "frail", "frail"], "answer_start": [155, 155, 155]}, "prediction_text": "They were portrayed as frail and thin."}
{"answers": {"text": ["physically imposing", "physically imposing", "stout man"], "answer_start": [322, 322, 204]}, "prediction_text": "By emphasizing his monumental size."}
{"answers": {"text": ["religious orders", "medieval religious orders", "ascetic life of the medieval religious orders"], "answer_start": [611, 602, 582]}, "prediction_text": "Medieval religious orders"}
{"answers": {"text": ["1530s and 1540s", "1530s and 1540s", "1530s and 1540s"], "answer_start": [7, 7, 7]}, "prediction_text": "1530s and 1540s"}
{"answers": {"text": ["18 February", "18 February", "18 February"], "answer_start": [22, 22, 22]}, "prediction_text": "18 February"}
{"answers": {"text": ["Episcopal (United States) Calendar of Saints.", "Episcopal", "Episcopal"], "answer_start": [101, 101, 101]}, "prediction_text": "Episcopal (United States) Calendar"}
{"answers": {"text": ["31 October", "31 October", "31 October"], "answer_start": [215, 215, 215]}, "prediction_text": "31 October"}
{"answers": {"text": ["Church of England's Calendar of Saints", "Calendar of Saints", "Church of England's Calendar of Saints"], "answer_start": [154, 174, 154]}, "prediction_text": "Church of England's Calendar of Saints"}
{"answers": {"text": ["Luther is honoured", "honoured", "honoured"], "answer_start": [0, 10, 10]}, "prediction_text": "On the Lutheran, Episcopal, and Church of England calendars."}
{"answers": {"text": ["SoCal", "SoCal", "SoCal"], "answer_start": [39, 39, 39]}, "prediction_text": "SoCal"}
{"answers": {"text": ["10 counties", "10", "10"], "answer_start": [133, 133, 133]}, "prediction_text": "Eight counties"}
{"answers": {"text": ["economic center", "major economic center", "economic center"], "answer_start": [514, 508, 514]}, "prediction_text": "Economic center"}
{"answers": {"text": ["demographics and economic ties", "economic", "demographics and economic"], "answer_start": [214, 231, 214]}, "prediction_text": "demographics and economic ties."}
{"answers": {"text": ["historical political divisions", "historical political divisions", "historical political divisions"], "answer_start": [451, 451, 451]}, "prediction_text": "Political divisions"}
{"answers": {"text": ["Southern California Megaregion", "the greater Southern California Megaregion", "Southern California Megaregion"], "answer_start": [62, 50, 62]}, "prediction_text": "Southern California Megaregion"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [105, 105, 105]}, "prediction_text": "11 megaregions"}
{"answers": {"text": ["Nevada", "Nevada", "Nevada"], "answer_start": [214, 214, 214]}, "prediction_text": "Southern California"}
{"answers": {"text": ["Mexican", "Mexican", "Mexican"], "answer_start": [243, 243, 243]}, "prediction_text": "Mexican border"}
{"answers": {"text": ["Tijuana", "Tijuana", "Tijuana"], "answer_start": [263, 263, 263]}, "prediction_text": "Tijuana"}
{"answers": {"text": ["Pacific", "Pacific", "Pacific"], "answer_start": [82, 82, 82]}, "prediction_text": "Pacific coast"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [246, 246, 246]}, "prediction_text": "Seven metropolitan areas"}
{"answers": {"text": ["12 million", "over 12 million inhabitants", "12 million"], "answer_start": [691, 686, 691]}, "prediction_text": "Over 12 million"}
{"answers": {"text": ["San Diego", "the San Diego area", "San Diego"], "answer_start": [793, 789, 793]}, "prediction_text": "Los Angeles area"}
{"answers": {"text": ["17.5 million", "over 17.5 million", "17.5 million"], "answer_start": [1020, 1015, 1020]}, "prediction_text": "Over 22 million people"}
{"answers": {"text": ["Colorado River", "the Colorado River", "Colorado River"], "answer_start": [43, 39, 43]}, "prediction_text": "Colorado Desert"}
{"answers": {"text": ["Colorado Desert", "the Colorado Desert", "Colorado Desert"], "answer_start": [19, 15, 19]}, "prediction_text": "Colorado Desert"}
{"answers": {"text": ["Mojave Desert", "the Mojave Desert", "Mojave Desert"], "answer_start": [94, 90, 94]}, "prediction_text": "Mojave Desert"}
{"answers": {"text": ["Mexico\u2013United States border", "the Mexico\u2013United States border", "Mexico\u2013United States border"], "answer_start": [168, 164, 168]}, "prediction_text": "Mexico\u2013United States border"}
{"answers": {"text": ["California", "California", "California"], "answer_start": [16, 16, 16]}, "prediction_text": "California"}
{"answers": {"text": ["3,792,621", "3,792,621", "3,792,621"], "answer_start": [159, 159, 159]}, "prediction_text": "3,792,621"}
{"answers": {"text": ["Los Angeles", "Los Angeles", "Los Angeles"], "answer_start": [170, 170, 49]}, "prediction_text": "Los Angeles"}
{"answers": {"text": ["San Diego", "San Diego", "San Diego"], "answer_start": [324, 324, 324]}, "prediction_text": "San Diego"}
{"answers": {"text": ["south", "south"], "answer_start": [280, 280]}, "prediction_text": "South"}
{"answers": {"text": ["Los Angeles", "Los Angeles", "Riverside"], "answer_start": [16, 16, 68]}, "prediction_text": "Los Angeles"}
{"answers": {"text": ["United States", "the United States", "Los Angeles"], "answer_start": [174, 170, 16]}, "prediction_text": "United States"}
{"answers": {"text": ["counties", "counties", "five most populous in the state"], "answer_start": [4, 4, 86]}, "prediction_text": "Five most populous counties in the state."}
{"answers": {"text": ["15", "15", "Riverside"], "answer_start": [141, 141, 68]}, "prediction_text": "Los Angeles"}
{"answers": {"text": ["counties", "Riverside"], "answer_start": [4, 68]}, "prediction_text": "Los Angeles County"}
{"answers": {"text": ["Hollywood", "Hollywood", "Hollywood"], "answer_start": [106, 106, 106]}, "prediction_text": "Los Angeles"}
{"answers": {"text": ["Los Angeles", "Los Angeles", "Los Angeles"], "answer_start": [135, 70, 135]}, "prediction_text": "Southern California"}
{"answers": {"text": ["The Walt Disney Company", "The Walt Disney Company", "The Walt Disney Company"], "answer_start": [249, 249, 249]}, "prediction_text": "The Walt Disney Company"}
{"answers": {"text": ["music", "major record companies"], "answer_start": [36, 432]}, "prediction_text": "Music industry"}
{"answers": {"text": ["Sony", "Sony", "Sony"], "answer_start": [418, 418, 418]}, "prediction_text": "20th Century Fox"}
{"answers": {"text": ["skateboard", "skateboard", "skateboard"], "answer_start": [64, 64, 64]}, "prediction_text": "Skateboarding culture"}
{"answers": {"text": ["Tony Hawk", "Tony Hawk", "Tony Hawk"], "answer_start": [206, 206, 206]}, "prediction_text": "Tony Hawk"}
{"answers": {"text": ["Shaun White", "Shaun White", "Shaun White"], "answer_start": [354, 354, 354]}, "prediction_text": "Shaun White"}
{"answers": {"text": ["Oahu", "Oahu", "Oahu"], "answer_start": [580, 580, 580]}, "prediction_text": "Hawaii"}
{"answers": {"text": ["Transpac", "Transpac", "Transpac"], "answer_start": [873, 873, 873]}, "prediction_text": "Transpacific Yacht Race"}
{"answers": {"text": ["Palm Springs", "Palm Springs", "Palm Springs"], "answer_start": [112, 112, 112]}, "prediction_text": "Palm Springs"}
{"answers": {"text": ["beaches", "for its popular beaches", "beaches"], "answer_start": [80, 64, 80]}, "prediction_text": "Desert city feel"}
{"answers": {"text": ["southern", "the desert", "southern"], "answer_start": [38, 93, 38]}, "prediction_text": "Southern California"}
{"answers": {"text": ["open spaces", "nearby open spaces", "nearby open spaces"], "answer_start": [167, 160, 160]}, "prediction_text": "Open spaces"}
{"answers": {"text": ["37\u00b0 9' 58.23\"", "37\u00b0 9' 58.23\"", "37\u00b0 9' 58.23\""], "answer_start": [194, 194, 194]}, "prediction_text": "Around 11 miles (18 km) south of San Jose."}
{"answers": {"text": ["11", "11", "11"], "answer_start": [225, 225, 225]}, "prediction_text": "Around 11 miles (18 km)"}
{"answers": {"text": ["ten", "ten", "ten"], "answer_start": [453, 453, 453]}, "prediction_text": "Ten counties"}
{"answers": {"text": ["Tehachapi Mountains", "Tehachapi Mountains"], "answer_start": [740, 740]}, "prediction_text": "Tehachapi Mountains"}
{"answers": {"text": ["northern", "the Tehachapi Mountains", "northern"], "answer_start": [767, 736, 767]}, "prediction_text": "Tehachapi Mountains"}
{"answers": {"text": ["Mexico", "Mexico", "Mexico"], "answer_start": [136, 136, 136]}, "prediction_text": "Mexico"}
{"answers": {"text": ["Alta California", "Alta California", "Alta California"], "answer_start": [281, 281, 281]}, "prediction_text": "Alta California"}
{"answers": {"text": ["Monterey", "Monterey", "Monterey"], "answer_start": [217, 217, 217]}, "prediction_text": "Monterey"}
{"answers": {"text": ["the Missouri Compromise", "the Compromise of 1850", "Compromise of 1850"], "answer_start": [523, 572, 576]}, "prediction_text": "Compromise of 1850"}
{"answers": {"text": ["free", "a free state", "free"], "answer_start": [647, 645, 647]}, "prediction_text": "Free state"}
{"answers": {"text": ["inequitable taxes", "inequitable taxes", "inequitable taxes"], "answer_start": [45, 45, 45]}, "prediction_text": "Taxation and land laws."}
{"answers": {"text": ["Cow Counties", "Cow Counties", "Cow Counties"], "answer_start": [132, 132, 132]}, "prediction_text": "\"Cow Counties\""}
{"answers": {"text": ["three", "three", "three"], "answer_start": [179, 179, 179]}, "prediction_text": "Three times"}
{"answers": {"text": ["75", "75%", "75"], "answer_start": [470, 470, 470]}, "prediction_text": "Nearly 75%"}
{"answers": {"text": ["Milton Latham", "Milton Latham", "Milton Latham"], "answer_start": [790, 790, 790]}, "prediction_text": "Milton Latham"}
{"answers": {"text": ["Los Angeles Times", "the Los Angeles Times", "Los Angeles Times"], "answer_start": [13, 9, 13]}, "prediction_text": "Los Angeles Times"}
{"answers": {"text": ["1900", "1900", "1900"], "answer_start": [3, 3, 3]}, "prediction_text": "1900"}
{"answers": {"text": ["1999", "1999", "1999"], "answer_start": [185, 185, 185]}, "prediction_text": "1999"}
{"answers": {"text": ["Imperial", "Imperial", "1999"], "answer_start": [222, 222, 185]}, "prediction_text": "Imperial"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [77, 77, 77]}, "prediction_text": "Seven counties"}
{"answers": {"text": ["regional tourism groups", "regional tourism groups", "AAA Auto Clubs"], "answer_start": [55, 55, 156]}, "prediction_text": "California State Automobile Association and Automobile Club of Southern California"}
{"answers": {"text": ["California State Automobile Association", "the California State Automobile Association", "California State Automobile Association"], "answer_start": [189, 185, 189]}, "prediction_text": "California State Automobile Association"}
{"answers": {"text": ["three-region", "the three-region point of view", "three-region"], "answer_start": [452, 448, 452]}, "prediction_text": "Three-region view"}
{"answers": {"text": ["Tehachapis", "the Tehachapis", "Tehachapis"], "answer_start": [538, 534, 538]}, "prediction_text": "South of the Tehachapis"}
{"answers": {"text": ["southern", "southern California", "southern California"], "answer_start": [773, 773, 773]}, "prediction_text": "Southern California"}
{"answers": {"text": ["third", "third", "third"], "answer_start": [190, 190, 190]}, "prediction_text": "Third most populated megalopolis"}
{"answers": {"text": ["vast areas", "vast areas", "vast areas"], "answer_start": [136, 136, 136]}, "prediction_text": "Some areas have been left undeveloped."}
{"answers": {"text": ["suburban", "suburban", "suburban communities and use of automobiles and highways"], "answer_start": [378, 378, 378]}, "prediction_text": "Large, spread-out, suburban communities"}
{"answers": {"text": ["highways", "highways"], "answer_start": [426, 426]}, "prediction_text": "Highways and automobiles"}
{"answers": {"text": ["international metropolitan", "an international metropolitan region", "international metropolitan"], "answer_start": [680, 677, 680]}, "prediction_text": "San Diego\u2013Tijuana"}
{"answers": {"text": ["Camp Pendleton", "Camp Pendleton", "Camp Pendleton"], "answer_start": [75, 75, 75]}, "prediction_text": "Camp Pendleton"}
{"answers": {"text": ["Inland Empire", "Temecula and Murrieta"], "answer_start": [286, 183]}, "prediction_text": "Inland Empire"}
{"answers": {"text": ["United States Census Bureau", "the United States Census Bureau", "United States Census Bureau"], "answer_start": [318, 314, 318]}, "prediction_text": "The United States Census Bureau"}
{"answers": {"text": ["Orange", "Orange Counties", "Orange"], "answer_start": [521, 521, 521]}, "prediction_text": "Los Angeles County"}
{"answers": {"text": ["1990s", "1990s", "1990s"], "answer_start": [688, 688, 688]}, "prediction_text": "1990s"}
{"answers": {"text": ["Mediterranean", "a Mediterranean climate", "Mediterranean"], "answer_start": [31, 29, 31]}, "prediction_text": "Mediterranean climate"}
{"answers": {"text": ["infrequent rain", "infrequent rain", "infrequent rain"], "answer_start": [59, 59, 59]}, "prediction_text": "Hot and dry summers, winters are mild, and summer temperatures are 90-60's."}
{"answers": {"text": ["60's", "60's", "60's"], "answer_start": [243, 243, 243]}, "prediction_text": "90-60's"}
{"answers": {"text": ["very rare", "very rare", "very rare"], "answer_start": [353, 353, 353]}, "prediction_text": "On the Southeast"}
{"answers": {"text": ["70", "70", "70"], "answer_start": [269, 269, 269]}, "prediction_text": "70-50's"}
{"answers": {"text": ["Pacific Ocean", "Pacific Ocean", "Pacific Ocean"], "answer_start": [222, 222, 222]}, "prediction_text": "Pacific Ocean"}
{"answers": {"text": ["varied", "varied", "natural ecosystem"], "answer_start": [48, 48, 97]}, "prediction_text": "Geologic, topographic, and natural ecosystem landscapes"}
{"answers": {"text": ["topographic", "topographic", "topographic"], "answer_start": [80, 80, 80]}, "prediction_text": "Southern California landscape is diverse and can be found in many different landscapes."}
{"answers": {"text": ["Peninsular", "Peninsular Ranges", "Peninsular Ranges"], "answer_start": [313, 313, 313]}, "prediction_text": "Peninsular Ranges"}
{"answers": {"text": ["valleys", "valleys", "interior valleys"], "answer_start": [383, 383, 374]}, "prediction_text": "Peninsular Ranges"}
{"answers": {"text": ["10,000", "10,000", "10,000"], "answer_start": [50, 50, 50]}, "prediction_text": "About 10,000 earthquakes"}
{"answers": {"text": ["small", "small", "small"], "answer_start": [96, 96, 96]}, "prediction_text": "Smaller than magnitude 3.0"}
{"answers": {"text": ["6.7", "6.7", "6.7"], "answer_start": [246, 246, 246]}, "prediction_text": "6.7"}
{"answers": {"text": ["property damage", "property damage"], "answer_start": [402, 402]}, "prediction_text": "Property damage"}
{"answers": {"text": ["$20 billion", "over $20 billion", "over $20 billion"], "answer_start": [471, 466, 466]}, "prediction_text": "Over $20 billion"}
{"answers": {"text": ["San Andreas", "the San Andreas Fault", "San Andreas Fault"], "answer_start": [73, 69, 73]}, "prediction_text": "San Andreas Fault"}
{"answers": {"text": ["6.7", "6.7+", "6.7+"], "answer_start": [44, 44, 44]}, "prediction_text": "6.7+"}
{"answers": {"text": ["Puente Hills", "the Puente Hills Fault", "Puente Hills Fault"], "answer_start": [181, 177, 181]}, "prediction_text": "Puente Hills Fault"}
{"answers": {"text": ["USGS", "The USGS", "USGS"], "answer_start": [234, 230, 234]}, "prediction_text": "USGS"}
{"answers": {"text": ["occurrence", "occurrence", "occurrence"], "answer_start": [309, 309, 309]}, "prediction_text": "Earthquake occurrence in California"}
{"answers": {"text": ["economically", "economically", "economically"], "answer_start": [60, 60, 60]}, "prediction_text": "Economic and cultural identity"}
{"answers": {"text": ["global", "global", "global"], "answer_start": [207, 207, 207]}, "prediction_text": "Global recognition"}
{"answers": {"text": ["economic", "economic", "economic activity"], "answer_start": [254, 254, 254]}, "prediction_text": "Tourism"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [10, 10, 10]}, "prediction_text": "2010"}
{"answers": {"text": ["high growth rates", "high growth rates", "high growth rates"], "answer_start": [114, 114, 114]}, "prediction_text": "High growth rates"}
{"answers": {"text": ["10.0%", "10.0%", "10.0%"], "answer_start": [196, 196, 196]}, "prediction_text": "10.0%"}
{"answers": {"text": ["tech-oriented", "tech-oriented"], "answer_start": [311, 311]}, "prediction_text": "Tech-oriented economy"}
{"answers": {"text": ["Greater Sacramento", "Greater Sacramento", "Greater Sacramento"], "answer_start": [365, 365, 365]}, "prediction_text": "Greater Sacramento region"}
{"answers": {"text": ["Metropolitan Statistical Areas", "Metropolitan Statistical Areas", "Metropolitan Statistical Areas"], "answer_start": [69, 69, 69]}, "prediction_text": "Combined Statistical Area, Metropolitan Statistical Area, International Metropolitan Area, and Multiple Metropolitan Areas."}
{"answers": {"text": ["two", "two", "two"], "answer_start": [197, 197, 197]}, "prediction_text": "Two extended metropolitan areas"}
{"answers": {"text": ["five million", "five million", "five million"], "answer_start": [241, 241, 241]}, "prediction_text": "Five million"}
{"answers": {"text": ["Southern Border Region", "the Southern Border Region", "Southern Border Region"], "answer_start": [672, 668, 672]}, "prediction_text": "Southern Border Region"}
{"answers": {"text": ["17,786,419", "17,786,419", "17,786,419"], "answer_start": [311, 311, 311]}, "prediction_text": "17,786,419"}
{"answers": {"text": ["Los Angeles", "Los Angeles", "Los Angeles"], "answer_start": [0, 0, 0]}, "prediction_text": "Los Angeles (3.7 million people)"}
{"answers": {"text": ["1.3 million", "1.3 million", "San Diego"], "answer_start": [54, 54, 40]}, "prediction_text": "San Diego"}
{"answers": {"text": ["twelve", "twelve", "twelve"], "answer_start": [250, 250, 250]}, "prediction_text": "Twelve cities"}
{"answers": {"text": ["100,000", "100,000", "100,000"], "answer_start": [316, 316, 316]}, "prediction_text": "100,000"}
{"answers": {"text": ["Riverside", "Riverside", "Riverside"], "answer_start": [478, 478, 478]}, "prediction_text": "Riverside"}
{"answers": {"text": ["petroleum", "petroleum", "petroleum"], "answer_start": [142, 142, 142]}, "prediction_text": "Petroleum"}
{"answers": {"text": ["Hollywood", "Hollywood", "Hollywood"], "answer_start": [319, 319, 319]}, "prediction_text": "Hollywood"}
{"answers": {"text": ["the housing bubble", "the housing bubble"], "answer_start": [495, 495]}, "prediction_text": "Housing bubble"}
{"answers": {"text": ["diverse", "diverse", "diverse"], "answer_start": [33, 33, 33]}, "prediction_text": "Largely dependent upon petroleum"}
{"answers": {"text": ["heavily impacted", "heavily impacted"], "answer_start": [538, 538]}, "prediction_text": "Larger housing bubble."}
{"answers": {"text": ["1920s", "1920s", "1920s"], "answer_start": [10, 10, 10]}, "prediction_text": "1920s"}
{"answers": {"text": ["richest", "rich", "one of the richest"], "answer_start": [113, 113, 102]}, "prediction_text": "Cattle and citrus industries"}
{"answers": {"text": ["citrus", "citrus", "citrus"], "answer_start": [166, 166, 166]}, "prediction_text": "Citrus and cattle"}
{"answers": {"text": ["cattle", "cattle", "cattle"], "answer_start": [155, 155, 155]}, "prediction_text": "Cattle and citrus"}
{"answers": {"text": ["aerospace", "aerospace", "aerospace"], "answer_start": [293, 293, 293]}, "prediction_text": "Aerospace"}
{"answers": {"text": ["business", "major business", "major business"], "answer_start": [42, 36, 36]}, "prediction_text": "Central business districts"}
{"answers": {"text": ["Central business districts", "Central business districts", "Central business districts"], "answer_start": [62, 62, 62]}, "prediction_text": "Central business district"}
{"answers": {"text": ["South Coast Metro", "South Coast Metro", "South Coast Metro"], "answer_start": [192, 192, 192]}, "prediction_text": "Downtown San Diego"}
{"answers": {"text": ["business", "major business districts", "major business"], "answer_start": [42, 36, 36]}, "prediction_text": "Business district"}
{"answers": {"text": ["Los Angeles Area", "the Los Angeles Area", "major business"], "answer_start": [11, 7, 36]}, "prediction_text": "Los Angeles"}
{"answers": {"text": ["San Fernando Valley", "the San Fernando Valley", "San Fernando Valley"], "answer_start": [374, 370, 374]}, "prediction_text": "San Fernando Valley"}
{"answers": {"text": ["Los Angeles", "Los Angeles", "Los Angeles"], "answer_start": [148, 148, 218]}, "prediction_text": "San Fernando Valley"}
{"answers": {"text": ["business", "business districts", "business"], "answer_start": [48, 48, 48]}, "prediction_text": "Business districts"}
{"answers": {"text": ["Riverside", "Riverside", "Downtown Riverside"], "answer_start": [19, 19, 182]}, "prediction_text": "Riverside"}
{"answers": {"text": ["Hospitality Business/Financial Centre", "Downtown Riverside", "Hospitality Business/Financial Centre"], "answer_start": [95, 182, 95]}, "prediction_text": "Hospitality Business/Financial Centre"}
{"answers": {"text": ["Orange", "Orange County", "Orange County"], "answer_start": [0, 0, 0]}, "prediction_text": "Orange County"}
{"answers": {"text": ["University of California, Irvine", "the University of California, Irvine", "University of California"], "answer_start": [268, 264, 268]}, "prediction_text": "University of California, Irvine"}
{"answers": {"text": ["West Irvine", "West Irvine", "West Irvine"], "answer_start": [302, 302, 302]}, "prediction_text": "Irvine Tech Center"}
{"answers": {"text": ["South Coast Metro", "the South Coast Metro", "South Coast Metro"], "answer_start": [92, 88, 92]}, "prediction_text": "South Coast Metro"}
{"answers": {"text": ["rapidly", "rapidly", "rapidly"], "answer_start": [19, 19, 19]}, "prediction_text": "Rapidly"}
{"answers": {"text": ["Downtown San Diego", "Downtown San Diego", "Downtown"], "answer_start": [0, 0, 0]}, "prediction_text": "Downtown San Diego"}
{"answers": {"text": ["Northern San Diego", "Northern San Diego", "Northern San Diego"], "answer_start": [271, 271, 271]}, "prediction_text": "Northern San Diego"}
{"answers": {"text": ["North County", "North County", "North County regions"], "answer_start": [306, 306, 306]}, "prediction_text": "North County"}
{"answers": {"text": ["San Diego", "San Diego", "San Diego"], "answer_start": [55, 55, 9]}, "prediction_text": "Northern San Diego"}
{"answers": {"text": ["Los Angeles International Airport", "Los Angeles International Airport", "Los Angeles International Airport"], "answer_start": [31, 31, 31]}, "prediction_text": "Los Angeles International Airport"}
{"answers": {"text": ["passenger volume", "passenger volume", "passenger volume"], "answer_start": [117, 117, 117]}, "prediction_text": "Passenger volume"}
{"answers": {"text": ["third", "third", "third"], "answer_start": [194, 194, 194]}, "prediction_text": "Third"}
{"answers": {"text": ["San Diego International Airport", "San Diego International Airport", "San Diego International Airport"], "answer_start": [314, 314, 314]}, "prediction_text": "San Diego International Airport"}
{"answers": {"text": ["Van Nuys Airport", "Van Nuys Airport", "Van Nuys Airport"], "answer_start": [394, 394, 394]}, "prediction_text": "Van Nuys Airport"}
{"answers": {"text": ["Metrolink", "Metrolink", "Metrolink"], "answer_start": [52, 52, 52]}, "prediction_text": "Metrolink"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [11, 11, 11]}, "prediction_text": "Seven lines"}
{"answers": {"text": ["Six", "Six", "Six"], "answer_start": [0, 0, 0]}, "prediction_text": "Seven lines"}
{"answers": {"text": ["Orange", "Orange", "Orange"], "answer_start": [249, 249, 249]}, "prediction_text": "Orange County"}
{"answers": {"text": ["Port of Los Angeles", "the Port of Los Angeles", "Port of Los Angeles"], "answer_start": [40, 36, 40]}, "prediction_text": "Port of Los Angeles"}
{"answers": {"text": ["Port of San Diego", "Port of Long Beach", "Port of Long Beach"], "answer_start": [196, 118, 118]}, "prediction_text": "Port of San Diego"}
{"answers": {"text": ["Southern", "Southern California", "Southern"], "answer_start": [0, 0, 0]}, "prediction_text": "Southern California"}
{"answers": {"text": ["The Tech Coast", "The Tech Coast", "Tech Coast"], "answer_start": [0, 0, 4]}, "prediction_text": "Tech Coast"}
{"answers": {"text": ["research", "research", "research"], "answer_start": [183, 183, 183]}, "prediction_text": "Research universities"}
{"answers": {"text": ["private", "private", "private"], "answer_start": [579, 579, 579]}, "prediction_text": "California Institute of Technology (Caltech)"}
{"answers": {"text": ["5", "5", "5"], "answer_start": [270, 270, 270]}, "prediction_text": "12 campuses"}
{"answers": {"text": ["12", "12", "12"], "answer_start": [370, 370, 370]}, "prediction_text": "12 campuses"}
{"answers": {"text": ["NFL", "Professional", "NFL"], "answer_start": [72, 0, 72]}, "prediction_text": "Professional sports team"}
{"answers": {"text": ["NBA", "NBA", "NBA"], "answer_start": [116, 116, 116]}, "prediction_text": "NBA"}
{"answers": {"text": ["MLB", "MLB", "MLB"], "answer_start": [164, 164, 164]}, "prediction_text": "Baseball"}
{"answers": {"text": ["Los Angeles Kings", "Los Angeles Kings", "Los Angeles Kings"], "answer_start": [245, 245, 245]}, "prediction_text": "Los Angeles Kings"}
{"answers": {"text": ["LA Galaxy", "LA Galaxy", "LA Galaxy"], "answer_start": [289, 289, 289]}, "prediction_text": "Los Angeles Galaxy"}
{"answers": {"text": ["Chivas USA", "Chivas", "Chivas"], "answer_start": [95, 179, 179]}, "prediction_text": "Chivas USA"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [30, 30, 30]}, "prediction_text": "Two teams"}
{"answers": {"text": ["2014", "2014", "2014"], "answer_start": [13, 215, 215]}, "prediction_text": "2014"}
{"answers": {"text": ["StubHub Center", "the StubHub Center", "StubHub Center"], "answer_start": [132, 128, 132]}, "prediction_text": "StubHub Center"}
{"answers": {"text": ["2018", "in 2018", "2018"], "answer_start": [278, 275, 278]}, "prediction_text": "2018"}
{"answers": {"text": ["College", "College", "College"], "answer_start": [0, 0, 0]}, "prediction_text": "College sports"}
{"answers": {"text": ["UCLA", "UCLA", "UCLA"], "answer_start": [60, 60, 60]}, "prediction_text": "Pac-12 Conference"}
{"answers": {"text": ["Trojans", "Trojans", "Trojans"], "answer_start": [84, 84, 84]}, "prediction_text": "UCLA Bruins"}
{"answers": {"text": ["Pac-12", "the Pac-12", "Pac-12"], "answer_start": [135, 131, 135]}, "prediction_text": "Pac-12 Conference"}
{"answers": {"text": ["Division I", "Division I", "Division I"], "answer_start": [117, 117, 117]}, "prediction_text": "Pac-12 Conference"}
{"answers": {"text": ["Rugby", "Rugby", "Rugby"], "answer_start": [0, 0, 0]}, "prediction_text": "Rugby"}
{"answers": {"text": ["high school", "high school", "high school"], "answer_start": [74, 74, 74]}, "prediction_text": "High school"}
{"answers": {"text": ["an official school sport", "an official school", "official school sport"], "answer_start": [144, 144, 147]}, "prediction_text": "Official school sport"}
{"answers": {"text": ["BSkyB", "BSkyB", "BSkyB"], "answer_start": [98, 98, 98]}, "prediction_text": "British Sky Broadcasting Group"}
{"answers": {"text": ["BSkyB", "BSkyB", "BSkyB"], "answer_start": [98, 98, 98]}, "prediction_text": "BSkyB"}
{"answers": {"text": ["2014", "2014", "2014"], "answer_start": [187, 187, 187]}, "prediction_text": "2014"}
{"answers": {"text": ["Sky plc", "British Sky Broadcasting Group plc", "British Sky Broadcasting Group plc"], "answer_start": [361, 306, 306]}, "prediction_text": "British Sky Broadcasting Group"}
{"answers": {"text": ["Sky UK Limited", "Sky UK Limited", "Sky UK Limited"], "answer_start": [471, 471, 471]}, "prediction_text": "Sky UK Limited"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [231, 231, 231]}, "prediction_text": "2007\u201308"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [286, 286, 286]}, "prediction_text": "Six packages"}
{"answers": {"text": ["Sky", "Sky", "Sky"], "answer_start": [370, 370, 370]}, "prediction_text": "Sky"}
{"answers": {"text": ["\u00a31.3bn", "\u00a31.3bn", "\u00a34.2bn"], "answer_start": [407, 407, 441]}, "prediction_text": "\u00a34.2bn"}
{"answers": {"text": ["ONdigital", "ONdigital", "ONdigital"], "answer_start": [55, 55, 55]}, "prediction_text": "ONdigital consortium"}
{"answers": {"text": ["Freeview", "ITV Digital", "ITV Digital"], "answer_start": [184, 145, 145]}, "prediction_text": "ITV Digital"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [307, 307, 307]}, "prediction_text": "Three channels"}
{"answers": {"text": ["Sky Three", "Sky Three", "Sky Three"], "answer_start": [485, 485, 485]}, "prediction_text": "Sky Three"}
{"answers": {"text": ["Pick TV", "Pick TV", "Pick TV"], "answer_start": [553, 553, 553]}, "prediction_text": "'Pick TV'"}
{"answers": {"text": ["Sky+ PVR", "Sky+ PVR", "Sky+ PVR"], "answer_start": [65, 65, 65]}, "prediction_text": "Sky+ PVR with their service."}
{"answers": {"text": ["September 2007", "September 2007", "March 2008"], "answer_start": [801, 801, 894]}, "prediction_text": "September 2007"}
{"answers": {"text": ["monthly fee", "a monthly fee", "SkyHD box"], "answer_start": [403, 401, 760]}, "prediction_text": "Sky+ Box"}
{"answers": {"text": ["January 2010", "In January 2010", "February 2011"], "answer_start": [444, 441, 652]}, "prediction_text": "January 2010"}
{"answers": {"text": ["Sky+HD Box", "Sky+HD Box", "Sky+HD Box"], "answer_start": [570, 570, 570]}, "prediction_text": "Sky+HD Box"}
{"answers": {"text": ["VideoGuard", "VideoGuard pay-TV", "VideoGuard"], "answer_start": [19, 19, 19]}, "prediction_text": "VideoGuard"}
{"answers": {"text": ["NDS", "NDS", "NDS"], "answer_start": [64, 64, 64]}, "prediction_text": "NDS"}
{"answers": {"text": ["Cisco Systems", "Cisco Systems", "Cisco Systems company"], "answer_start": [71, 71, 71]}, "prediction_text": "Cisco Systems"}
{"answers": {"text": ["BSkyB", "BSkyB", "BSkyB"], "answer_start": [229, 229, 229]}, "prediction_text": "BSkyB"}
{"answers": {"text": ["Sky+", "Sky+", "PVR"], "answer_start": [539, 539, 516]}, "prediction_text": "Sky+"}
{"answers": {"text": ["basic channels", "the basic channels", "the basic channels"], "answer_start": [233, 229, 229]}, "prediction_text": "Basic channels"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [3, 3, 3]}, "prediction_text": "2007"}
{"answers": {"text": ["substantially increased the asking price", "that BSkyB had substantially increased the asking price for the channels", "increased the asking price"], "answer_start": [318, 303, 332]}, "prediction_text": "Increased asking price for basic channels"}
{"answers": {"text": ["Video On Demand", "Video On Demand content", "HD channels and Video On Demand"], "answer_start": [502, 502, 486]}, "prediction_text": "Video On Demand content"}
{"answers": {"text": ["HD channels", "HD channels", "HD channels"], "answer_start": [486, 486, 486]}, "prediction_text": "HD channels and Video On Demand content"}
{"answers": {"text": ["July 2013", "In July 2013", "July 2013"], "answer_start": [3, 0, 3]}, "prediction_text": "July 2013"}
{"answers": {"text": ["2013", "2013", "31 July 2013"], "answer_start": [158, 158, 150]}, "prediction_text": "2013"}
{"answers": {"text": ["OneDrive", "OneDrive", "OneDrive"], "answer_start": [555, 555, 555]}, "prediction_text": "\"OneDrive for Business\""}
{"answers": {"text": ["OneDrive for Business", "OneDrive for Business", "OneDrive for Business"], "answer_start": [593, 593, 593]}, "prediction_text": "OneDrive for Business"}
{"answers": {"text": ["cloud storage", "cloud storage", "cloud storage service"], "answer_start": [288, 288, 288]}, "prediction_text": "Cloud storage service for businesses."}
{"answers": {"text": ["Sam Chisholm", "Sam Chisholm", "Sam Chisholm and Rupert Murdoch"], "answer_start": [97, 97, 97]}, "prediction_text": "Sam Chisholm"}
{"answers": {"text": ["Astra", "Astra's", "Astra's satellites"], "answer_start": [295, 295, 295]}, "prediction_text": "Astra's satellites"}
{"answers": {"text": ["27 September 2001", "27 September 2001", "September 2001"], "answer_start": [423, 423, 426]}, "prediction_text": "27 September 2001"}
{"answers": {"text": ["Sky Digital", "Sky Digital", "Sky Digital platform"], "answer_start": [481, 481, 481]}, "prediction_text": "Sky Digital platform"}
{"answers": {"text": ["3.5 million", "3.5 million", "3.5 million"], "answer_start": [876, 876, 876]}, "prediction_text": "3.5 million households"}
{"answers": {"text": ["BSkyB", "British Sky Broadcasting", "British Sky Broadcasting"], "answer_start": [53, 25, 25]}, "prediction_text": "British Sky Broadcasting"}
{"answers": {"text": ["telecommunications", "telecommunications", "British telecommunications company"], "answer_start": [73, 73, 65]}, "prediction_text": "British telecommunications company"}
{"answers": {"text": ["11 million", "11 million", "11 million customers"], "answer_start": [321, 321, 321]}, "prediction_text": "11 million"}
{"answers": {"text": ["Freeview", "Freeview", "Freeview"], "answer_start": [428, 428, 428]}, "prediction_text": "Freeview"}
{"answers": {"text": ["Sky Q Hub", "Sky Q Hub", "Sky Q Hub"], "answer_start": [206, 206, 206]}, "prediction_text": "Sky Q Hub"}
{"answers": {"text": ["Sky Q Silver set top boxes", "the Sky Q Silver set top boxes", "Sky Q Silver"], "answer_start": [451, 447, 451]}, "prediction_text": "Sky Q Hub"}
{"answers": {"text": ["share recordings", "to share recordings and other media", "share recordings"], "answer_start": [611, 608, 611]}, "prediction_text": "Sharing recordings and media."}
{"answers": {"text": ["2016", "later in 2016", "2016"], "answer_start": [763, 754, 763]}, "prediction_text": "Later in 2016."}
{"answers": {"text": ["2016", "in 2016", "2016"], "answer_start": [94, 91, 94]}, "prediction_text": "2016"}
{"answers": {"text": ["DVB-compliant MPEG-2", "DVB-compliant MPEG-2", "MPEG-2"], "answer_start": [46, 46, 60]}, "prediction_text": "MPEG-2"}
{"answers": {"text": ["Dolby Digital", "Dolby Digital", "Dolby Digital"], "answer_start": [135, 135, 135]}, "prediction_text": "Dolby Digital soundtracks"}
{"answers": {"text": ["MPEG-4", "MPEG-4", "MPEG-4"], "answer_start": [267, 267, 267]}, "prediction_text": "MPEG-4"}
{"answers": {"text": ["OpenTV", "OpenTV", "OpenTV"], "answer_start": [383, 383, 383]}, "prediction_text": "OpenTV"}
{"answers": {"text": ["DVB-S2", "DVB-S2", "DVB-compliant MPEG-2"], "answer_start": [311, 311, 46]}, "prediction_text": "DVB-S2 standard"}
{"answers": {"text": ["1998", "1998", "1998"], "answer_start": [33, 33, 33]}, "prediction_text": "1998"}
{"answers": {"text": ["Astra 2A", "the Astra 2A", "Astra 2A"], "answer_start": [63, 59, 63]}, "prediction_text": "Astra 2A"}
{"answers": {"text": ["Eutelsat's Eurobird 1", "Eutelsat's Eurobird 1", "Eutelsat's Eurobird 1"], "answer_start": [260, 260, 260]}, "prediction_text": "Astra 2A satellite"}
{"answers": {"text": ["hundreds", "hundreds", "hundreds"], "answer_start": [403, 403, 403]}, "prediction_text": "Hundreds of television and radio channels."}
{"answers": {"text": ["28.5\u00b0E", "28.5\u00b0E", "28.5\u00b0E"], "answer_start": [551, 551, 551]}, "prediction_text": "28.5\u00b0E"}
{"answers": {"text": ["22 May 2006", "on 22 May 2006", "22 May 2006"], "answer_start": [45, 42, 45]}, "prediction_text": "22 May 2006"}
{"answers": {"text": ["40,000", "40,000", "40,000"], "answer_start": [98, 98, 98]}, "prediction_text": "40,000 people"}
{"answers": {"text": ["Thomson", "Thomson", "STB"], "answer_start": [293, 293, 270]}, "prediction_text": "Thomson"}
{"answers": {"text": ["17,000", "17,000", "17,000"], "answer_start": [495, 495, 495]}, "prediction_text": "17,000 customers"}
{"answers": {"text": ["4,222,000", "4,222,000", "4,222,000"], "answer_start": [643, 643, 643]}, "prediction_text": "4,222,000 homes"}
{"answers": {"text": ["8 February 2007", "On 8 February 2007", "8 February 2007"], "answer_start": [3, 0, 3]}, "prediction_text": "8 February 2007"}
{"answers": {"text": ["March", "in March", "March"], "answer_start": [412, 409, 412]}, "prediction_text": "March"}
{"answers": {"text": ["digital terrestrial", "digital terrestrial", "digital terrestrial"], "answer_start": [451, 451, 451]}, "prediction_text": "Digital terrestrial platform"}
{"answers": {"text": ["Virgin Media", "Virgin Media", "Virgin Media"], "answer_start": [535, 535, 535]}, "prediction_text": "Virgin Media"}
{"answers": {"text": ["English Premier League Football", "English Premier League Football", "sport (including English Premier League Football), films, entertainment and news"], "answer_start": [264, 264, 247]}, "prediction_text": "English Premier League Football"}
{"answers": {"text": ["free-to-view", "free-to-view", "free-to-air"], "answer_start": [327, 327, 227]}, "prediction_text": "Free-to-view"}
{"answers": {"text": ["monthly subscription", "a monthly subscription", "monthly subscription"], "answer_start": [375, 373, 375]}, "prediction_text": "A monthly subscription"}
{"answers": {"text": ["VideoGuard UK", "VideoGuard UK", "VideoGuard UK"], "answer_start": [465, 465, 465]}, "prediction_text": "CAMs are available to view encrypted content."}
{"answers": {"text": ["Ku band", "9.75/10.600 GHz", "universal Ku band"], "answer_start": [24, 37, 14]}, "prediction_text": "9.75/10.600 GHz"}
{"answers": {"text": ["Sky", "Sky", "Sky service"], "answer_start": [532, 532, 532]}, "prediction_text": "Sky service"}
{"answers": {"text": ["1991", "autumn of 1991", "1991"], "answer_start": [17, 7, 17]}, "prediction_text": "Autumn of 1991"}
{"answers": {"text": ["ITV", "ITV", "ITV"], "answer_start": [129, 129, 129]}, "prediction_text": "ITV"}
{"answers": {"text": ["\u00a334m", "\u00a334m", "\u00a334m per year"], "answer_start": [249, 249, 249]}, "prediction_text": "\u00a318m"}
{"answers": {"text": ["BBC", "The BBC", "BBC"], "answer_start": [354, 350, 354]}, "prediction_text": "BSkyB"}
{"answers": {"text": ["\u00a3304m", "\u00a3304m", "\u00a3304m"], "answer_start": [426, 426, 426]}, "prediction_text": "\u00a3304m"}
{"answers": {"text": ["Ofcom", "Ofcom", "Ofcom"], "answer_start": [134, 134, 134]}, "prediction_text": "Ofcom"}
{"answers": {"text": ["\u00a315\u2013100,000", "\u00a315\u2013100,000", "\u00a315\u2013100,000"], "answer_start": [283, 283, 283]}, "prediction_text": "\u00a315\u2013100,000"}
{"answers": {"text": ["no", "no", "Third-party channels"], "answer_start": [10, 10, 296]}, "prediction_text": "No, BSkyB does not have veto over the presence of channels on their EPG."}
{"answers": {"text": ["not", "not", "BSkyB does not carry any control"], "answer_start": [529, 529, 518]}, "prediction_text": "No control over channel content."}
{"answers": {"text": ["not", "not", "BSkyB does not carry any control"], "answer_start": [529, 529, 518]}, "prediction_text": "No control over picture quality."}
{"answers": {"text": ["1 October 1998", "1 October 1998", "1 October 1998"], "answer_start": [51, 51, 51]}, "prediction_text": "1 October 1998"}
{"answers": {"text": ["Sky Digital", "Sky Digital", "Sky Digital"], "answer_start": [81, 81, 81]}, "prediction_text": "Sky Digital"}
{"answers": {"text": ["Sky Active", "Open", "Sky Active"], "answer_start": [434, 414, 434]}, "prediction_text": "Sky Active"}
{"answers": {"text": ["ONdigital", "ONdigital", "ONdigital"], "answer_start": [470, 470, 470]}, "prediction_text": "ONdigital (later ITV Digital)"}
{"answers": {"text": ["100,000", "over 100,000", "100,000"], "answer_start": [562, 557, 562]}, "prediction_text": "Over 100,000"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [28, 28, 28]}, "prediction_text": "2007"}
{"answers": {"text": ["Virgin Media", "Virgin Media", "Virgin Media"], "answer_start": [0, 0, 0]}, "prediction_text": "Virgin Media"}
{"answers": {"text": ["Video On Demand", "Video On Demand service", "(HDTV)"], "answer_start": [552, 552, 98]}, "prediction_text": "Video On Demand service"}
{"answers": {"text": ["BBC HD", "BBC HD", "BBC HD"], "answer_start": [215, 215, 215]}, "prediction_text": "BBC HD"}
{"answers": {"text": ["Channel 4 HD", "Channel 4 HD", "Channel 4 HD"], "answer_start": [431, 431, 431]}, "prediction_text": "Channel 4 HD"}
{"answers": {"text": ["10 million", "10 million", "10 million"], "answer_start": [61, 61, 61]}, "prediction_text": "10 million homes"}
{"answers": {"text": ["25m", "25m people", "36% of households"], "answer_start": [287, 287, 222]}, "prediction_text": "Over 25m people"}
{"answers": {"text": ["August 2004", "August 2004", "August 2004"], "answer_start": [333, 333, 333]}, "prediction_text": "August 2004"}
{"answers": {"text": ["36%", "36% of households", "2.4m customers"], "answer_start": [222, 222, 371]}, "prediction_text": "36%"}
{"answers": {"text": ["flattened", "flattened", "flattened"], "answer_start": [559, 559, 559]}, "prediction_text": "Felt flattened."}
{"answers": {"text": ["Welfare Cash Card", "Welfare Cash Card", "Welfare Cash Card"], "answer_start": [558, 558, 558]}, "prediction_text": "Welfare Cash Card"}
{"answers": {"text": ["essentials", "only \"essentials\"", "essentials"], "answer_start": [673, 667, 673]}, "prediction_text": "\"Essentials\""}
{"answers": {"text": ["often damaging", "often damaging", "often damaging"], "answer_start": [406, 406, 406]}, "prediction_text": "\"often damaging\""}
{"answers": {"text": ["Sky TV bills", "claimants' \"Sky TV bills", "claimants"], "answer_start": [108, 96, 96]}, "prediction_text": "Sky TV bills"}
{"answers": {"text": ["a man's presence", "mother is wrongly claiming to be living alone", "betray a man's presence in the household"], "answer_start": [290, 180, 283]}, "prediction_text": "A man's presence in the household."}
{"answers": {"text": ["\u00a330m", "\u00a330m", "\u00a330m"], "answer_start": [53, 53, 53]}, "prediction_text": "\u00a330m"}
{"answers": {"text": ["no", "no indication", "no indication"], "answer_start": [224, 224, 224]}, "prediction_text": "Yes, the new deal includes Video on demand and High Definition."}
{"answers": {"text": ["Virgin Media", "Virgin Media", "Virgin Media"], "answer_start": [419, 419, 419]}, "prediction_text": "Virgin Media"}
{"answers": {"text": ["BSkyB", "BSkyB", "BSkyB"], "answer_start": [409, 409, 409]}, "prediction_text": "BSkyB"}
{"answers": {"text": ["basic channels", "the carriage of their respective basic channels", "carriage of their respective basic channels"], "answer_start": [543, 510, 514]}, "prediction_text": "BSkyB and Virgin Media"}
{"answers": {"text": ["diversified", "highly diversified", "highly diversified"], "answer_start": [34, 27, 27]}, "prediction_text": "Service sectors"}
{"answers": {"text": ["second", "second", "second"], "answer_start": [266, 266, 266]}, "prediction_text": "Second in Australia"}
{"answers": {"text": ["fourth", "fourth", "fourth"], "answer_start": [315, 315, 315]}, "prediction_text": "Fourth in Australia"}
{"answers": {"text": ["Melbourne", "Melbourne", "Melbourne"], "answer_start": [536, 401, 401]}, "prediction_text": "Melbourne"}
{"answers": {"text": ["Melbourne Cricket Ground", "The Melbourne Cricket Ground", "Melbourne Cricket Ground"], "answer_start": [536, 532, 536]}, "prediction_text": "University of Melbourne"}
{"answers": {"text": ["Bendigo", "Bendigo", "Bendigo"], "answer_start": [181, 181, 181]}, "prediction_text": "Bendigo and its environs"}
{"answers": {"text": ["New South Wales", "New South Wales", "New South Wales"], "answer_start": [348, 348, 348]}, "prediction_text": "New South Wales"}
{"answers": {"text": ["Buckland Valley", "Buckland Valley near Bright", "Buckland Valley"], "answer_start": [394, 394, 394]}, "prediction_text": "Near Bright"}
{"answers": {"text": ["over 1,000", "1,000", "1,000"], "answer_start": [547, 552, 552]}, "prediction_text": "Over 1,000 miners died."}
{"answers": {"text": ["cramped and unsanitary", "cramped and unsanitary", "cramped and unsanitary"], "answer_start": [466, 466, 466]}, "prediction_text": "Larger and more crowded gold fields."}
{"answers": {"text": ["multi-member proportional", "multi-member proportional", "multi-member proportional representation system"], "answer_start": [84, 84, 84]}, "prediction_text": "Multi-member proportional representation"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [172, 172, 172]}, "prediction_text": "Eight electorates"}
{"answers": {"text": ["five", "five", "five"], "answer_start": [226, 226, 226]}, "prediction_text": "Five representatives"}
{"answers": {"text": ["four years", "four years", "four years"], "answer_start": [418, 418, 418]}, "prediction_text": "Four years"}
{"answers": {"text": ["every four years", "every four years", "four years"], "answer_start": [505, 505, 511]}, "prediction_text": "Every four years"}
{"answers": {"text": ["Australian Labor Party", "Australian Labor Party", "Labor"], "answer_start": [16, 16, 233]}, "prediction_text": "Labor (in Melbourne's working class suburbs)"}
{"answers": {"text": ["Liberal Party", "Liberal Party of Australia", "Liberals"], "answer_start": [63, 63, 373]}, "prediction_text": "Labor"}
{"answers": {"text": ["National Party", "National Party of Australia", "Nationals"], "answer_start": [107, 107, 498]}, "prediction_text": "Liberal Party"}
{"answers": {"text": ["The Greens", "Australian Greens", "Greens"], "answer_start": [584, 161, 588]}, "prediction_text": "Liberal Party"}
{"answers": {"text": ["Labor", "Australian Labor Party", "Labor"], "answer_start": [233, 16, 233]}, "prediction_text": "Liberal Party"}
{"answers": {"text": ["61.1%", "61.1%", "61.1%"], "answer_start": [6, 6, 6]}, "prediction_text": "About 61.1%"}
{"answers": {"text": ["26.7%", "26.7%", "26.7%"], "answer_start": [134, 134, 134]}, "prediction_text": "About 61.1%"}
{"answers": {"text": ["Buddhism", "Buddhism", "Buddhism"], "answer_start": [226, 226, 226]}, "prediction_text": "Buddhism"}
{"answers": {"text": ["168,637", "168,637", "168,637"], "answer_start": [287, 287, 287]}, "prediction_text": "168,637"}
{"answers": {"text": ["20%", "20%", "20%"], "answer_start": [440, 440, 440]}, "prediction_text": "168,637"}
{"answers": {"text": ["south-east", "south-east", "the south-east of Australia"], "answer_start": [48, 48, 44]}, "prediction_text": "South-east of Australia"}
{"answers": {"text": ["most densely populated", "most", "most densely populated state"], "answer_start": [97, 97, 97]}, "prediction_text": "Second-most populous state overall."}
{"answers": {"text": ["second", "second-most", "second-most populous"], "answer_start": [134, 134, 134]}, "prediction_text": "Second-most populous"}
{"answers": {"text": ["Melbourne", "Melbourne", "Melbourne"], "answer_start": [321, 321, 321]}, "prediction_text": "Melbourne"}
{"answers": {"text": ["second-largest", "second-largest", "second-largest city"], "answer_start": [353, 353, 353]}, "prediction_text": "Second-largest city in Australia."}
{"answers": {"text": ["Koori", "Koori", "Koori"], "answer_start": [146, 146, 146]}, "prediction_text": "Koori"}
{"answers": {"text": ["1788", "1788", "1788"], "answer_start": [254, 254, 254]}, "prediction_text": "1788"}
{"answers": {"text": ["New South Wales", "New South Wales", "New South Wales"], "answer_start": [305, 305, 305]}, "prediction_text": "East of the 135th meridian"}
{"answers": {"text": ["Sullivan Bay", "Sullivan Bay", "Sullivan Bay"], "answer_start": [375, 375, 375]}, "prediction_text": "Sullivan Bay"}
{"answers": {"text": ["1803", "1803", "1803"], "answer_start": [367, 367, 367]}, "prediction_text": "1803"}
{"answers": {"text": ["26,000 square kilometres", "26,000 square kilometres", "26,000 square kilometres"], "answer_start": [10, 10, 10]}, "prediction_text": "More than 26,000 square kilometres (10,000 sq mi)"}
{"answers": {"text": ["50%", "50%", "50%"], "answer_start": [130, 130, 130]}, "prediction_text": "33%"}
{"answers": {"text": ["6,000 square kilometres", "6,000 square kilometres", "6,000 square kilometres"], "answer_start": [208, 208, 208]}, "prediction_text": "7%"}
{"answers": {"text": ["90%", "90%", "90%"], "answer_start": [401, 401, 401]}, "prediction_text": "Nearly 90%"}
{"answers": {"text": ["270,000", "270,000", "121,200"], "answer_start": [618, 618, 590]}, "prediction_text": "270,000 tonnes"}
{"answers": {"text": ["1975", "1975", "1975"], "answer_start": [47, 47, 47]}, "prediction_text": "1975"}
{"answers": {"text": ["1855 colonial constitution", "the 1855 colonial constitution", "1855 colonial constitution"], "answer_start": [70, 66, 70]}, "prediction_text": "1855 colonial constitution"}
{"answers": {"text": ["Parliament of Victoria", "the Parliament of Victoria", "Parliament of Victoria"], "answer_start": [337, 333, 337]}, "prediction_text": "The Victorian people"}
{"answers": {"text": ["\"entrenched\" provisions", "certain \"entrenched\" provisions", "\"entrenched\" provisions"], "answer_start": [380, 372, 380]}, "prediction_text": "\"entrenched\" provisions"}
{"answers": {"text": ["Victoria Constitution Act 1855", "the Victoria Constitution Act 1855", "Victoria Constitution Act 185"], "answer_start": [145, 141, 145]}, "prediction_text": "Victoria Constitution Act 1855"}
{"answers": {"text": ["warmest regions", "semi-deserts", "semi-deserts"], "answer_start": [44, 95, 95]}, "prediction_text": "Warmest regions"}
{"answers": {"text": ["32 \u00b0C", "32 \u00b0C", "32 \u00b0C (90 \u00b0F)"], "answer_start": [137, 137, 137]}, "prediction_text": "32 \u00b0C (90 \u00b0F)"}
{"answers": {"text": ["15 \u00b0C", "15 \u00b0C", "15 \u00b0C (59 \u00b0F)"], "answer_start": [169, 169, 169]}, "prediction_text": "15 \u00b0C (59 \u00b0F)"}
{"answers": {"text": ["48.8 \u00b0C", "48.8 \u00b0C", "48.8 \u00b0C (119.8 \u00b0F)"], "answer_start": [387, 387, 387]}, "prediction_text": "48.8 \u00b0C (119.8 \u00b0F)"}
{"answers": {"text": ["2009", "the 2009 southeastern Australia heat wave", "7 February 2009"], "answer_start": [462, 458, 434]}, "prediction_text": "2009"}
{"answers": {"text": ["state or government", "state or government schools", "state or government schools"], "answer_start": [89, 89, 89]}, "prediction_text": "Public schools are funded and run by the Victoria Department of Education."}
{"answers": {"text": ["Victoria Department of Education", "the Victoria Department of Education", "Victoria Department of Education"], "answer_start": [153, 149, 153]}, "prediction_text": "Victoria Department of Education"}
{"answers": {"text": ["some extra costs", "some extra costs are levied", "extra costs"], "answer_start": [226, 226, 231]}, "prediction_text": "Extra costs"}
{"answers": {"text": ["Roman Catholic Church", "the Roman Catholic Church", "Roman Catholic"], "answer_start": [316, 312, 316]}, "prediction_text": "Roman Catholic Church"}
{"answers": {"text": ["curriculum", "curriculum standards", "curriculum"], "answer_start": [644, 644, 644]}, "prediction_text": "Government-set curriculum standards"}
{"answers": {"text": ["major car brands", "major car brands", "car"], "answer_start": [77, 77, 258]}, "prediction_text": "Ford, Toyota, and Holden"}
{"answers": {"text": ["2017", "2017", "2017"], "answer_start": [341, 341, 341]}, "prediction_text": "In February 2014."}
{"answers": {"text": ["May 2013", "in May 2013", "2013"], "answer_start": [381, 378, 385]}, "prediction_text": "December of the same year."}
{"answers": {"text": ["October 2016", "in October 2016", "2013"], "answer_start": [515, 512, 385]}, "prediction_text": "In October 2016."}
{"answers": {"text": ["Ford", "Ford"], "answer_start": [449, 449]}, "prediction_text": "Ford"}
{"answers": {"text": ["2,000 m", "almost 2,000 m", "2,000 m"], "answer_start": [219, 212, 219]}, "prediction_text": "Almost 2,000 m (6,600 ft)"}
{"answers": {"text": ["Mount Bogong", "Mount Bogong", "Mount Bogong"], "answer_start": [244, 244, 244]}, "prediction_text": "Mount Bogong (1,986 m)"}
{"answers": {"text": ["1,986 m", "1,986 m", "1,986 m"], "answer_start": [277, 277, 277]}, "prediction_text": "1,986 m (6,516 ft)"}
{"answers": {"text": ["river systems", "river systems", "river systems"], "answer_start": [393, 393, 393]}, "prediction_text": "Semi-arid plains"}
{"answers": {"text": ["helmeted honeyeater", "the helmeted honeyeater", "helmeted honeyeater"], "answer_start": [845, 841, 845]}, "prediction_text": "Leadbeater's possum"}
{"answers": {"text": ["Victorian Alps", "The Victorian Alps", "Victorian Alps"], "answer_start": [4, 0, 4]}, "prediction_text": "The Victorian Alps"}
{"answers": {"text": ["Great Dividing Range", "the Great Dividing Range", "Great Dividing Range"], "answer_start": [95, 91, 95]}, "prediction_text": "Great Dividing Range"}
{"answers": {"text": ["east-west", "east-west", "east-west"], "answer_start": [142, 142, 142]}, "prediction_text": "East-west"}
{"answers": {"text": ["below 0 \u00b0C", "below 0 \u00b0C", "below 0 \u00b0C (32 \u00b0F)"], "answer_start": [246, 246, 246]}, "prediction_text": "Below 0 \u00b0C (32 \u00b0F)"}
{"answers": {"text": ["\u221211.7 \u00b0C", "\u221211.7 \u00b0C", "\u221211.7 \u00b0C (10.9 \u00b0F)"], "answer_start": [343, 343, 343]}, "prediction_text": "\u221211.7 \u00b0C (10.9 \u00b0F)"}
{"answers": {"text": ["government-owned", "government", "several private and public railway operators"], "answer_start": [104, 104, 42]}, "prediction_text": "Victorian Government"}
{"answers": {"text": ["Metro Trains Melbourne", "Metro Trains Melbourne", "Metro Trains Melbourne"], "answer_start": [153, 153, 153]}, "prediction_text": "Metro Trains Melbourne"}
{"answers": {"text": ["Victorian Government", "the Victorian Government", "Victorian Government"], "answer_start": [298, 294, 298]}, "prediction_text": "Victorian Government"}
{"answers": {"text": ["freight services", "freight", "freight"], "answer_start": [476, 476, 476]}, "prediction_text": "CFCL Australia"}
{"answers": {"text": ["passenger", "extensive, electrified, passenger system", "passenger"], "answer_start": [214, 190, 214]}, "prediction_text": "Electrified, passenger system"}
{"answers": {"text": ["37", "37", "37"], "answer_start": [26, 26, 26]}, "prediction_text": "37 seats"}
{"answers": {"text": ["12", "12", "12"], "answer_start": [82, 82, 82]}, "prediction_text": "12 seats"}
{"answers": {"text": ["Legislative Assembly", "the Legislative Assembly", "Legislative Assembly"], "answer_start": [176, 172, 176]}, "prediction_text": "Legislative Assembly"}
{"answers": {"text": ["Legislative Council", "the Legislative Council", "Legislative Council"], "answer_start": [223, 219, 223]}, "prediction_text": "Legislative Assembly"}
{"answers": {"text": ["Linda Dessau", "Linda Dessau", "Linda Dessau"], "answer_start": [460, 460, 460]}, "prediction_text": "Linda Dessau"}
{"answers": {"text": ["1 July 1851", "1 July 1851", "1 July 1851"], "answer_start": [3, 3, 3]}, "prediction_text": "July 1, 1851"}
{"answers": {"text": ["1851", "in 1851", "1851"], "answer_start": [233, 230, 233]}, "prediction_text": "1851"}
{"answers": {"text": ["gold rush", "gold rush", "gold rushes"], "answer_start": [394, 394, 394]}, "prediction_text": "Gold rush triggered by discovery of gold near Ballarat."}
{"answers": {"text": ["sevenfold", "sevenfold", "76,000 to 540,000"], "answer_start": [544, 544, 559]}, "prediction_text": "One third of the world's output."}
{"answers": {"text": ["20 million ounces", "20 million ounces", "20 million ounces"], "answer_start": [753, 753, 753]}, "prediction_text": "20 million ounces"}
{"answers": {"text": ["1,548", "1,548", "1,548"], "answer_start": [32, 32, 32]}, "prediction_text": "1,548"}
{"answers": {"text": ["489", "489", "489"], "answer_start": [54, 54, 54]}, "prediction_text": "214 independent schools"}
{"answers": {"text": ["540,800", "540,800", "540,800"], "answer_start": [115, 115, 115]}, "prediction_text": "1,548"}
{"answers": {"text": ["63,519", "63,519", "63,519"], "answer_start": [541, 541, 541]}, "prediction_text": "63,519"}
{"answers": {"text": ["61", "61", "61"], "answer_start": [212, 212, 212]}, "prediction_text": "Over 61%"}
{"answers": {"text": ["Victoria", "Victoria", "Victoria"], "answer_start": [0, 0, 0]}, "prediction_text": "Victoria"}
{"answers": {"text": ["3 million", "3 million", "3 million"], "answer_start": [87, 87, 87]}, "prediction_text": "60%"}
{"answers": {"text": ["60%", "60%", "60%"], "answer_start": [68, 68, 68]}, "prediction_text": "60%"}
{"answers": {"text": ["two-thirds", "nearly two-thirds", "two-thirds"], "answer_start": [130, 123, 130]}, "prediction_text": "Nearly 6.4 billion litres"}
{"answers": {"text": ["Asia", "Asia", "Asia"], "answer_start": [617, 617, 617]}, "prediction_text": "Asia"}
{"answers": {"text": ["1,600 mm", "1,600 mm (5 ft 3 in) broad gauge", "1,600 mm (5 ft 3 in) broad gauge"], "answer_start": [178, 178, 178]}, "prediction_text": "1,600 mm (5 ft 3 in)"}
{"answers": {"text": ["1,435 mm", "1,435 mm (4 ft 8 1\u20442 in) standard gauge", "1,435 mm (4 ft 8 1\u20442 in) standard gauge"], "answer_start": [334, 334, 334]}, "prediction_text": "1,435 mm (4 ft 8 1\u20442 in) standard gauge"}
{"answers": {"text": ["760 mm", "760 mm (2 ft 6 in) narrow gauge lines", "760 mm (2 ft 6 in) narrow gauge lines"], "answer_start": [409, 409, 409]}, "prediction_text": "1,435 mm (4 ft 8 1\u20442 in) standard gauge"}
{"answers": {"text": ["mountainous areas", "mountainous areas", "mountainous areas"], "answer_start": [531, 531, 531]}, "prediction_text": "mountainous areas"}
{"answers": {"text": ["five", "five", "five"], "answer_start": [474, 474, 474]}, "prediction_text": "Five previously government-owned lines"}
{"answers": {"text": ["1788", "1788", "1788"], "answer_start": [55, 55, 55]}, "prediction_text": "1788"}
{"answers": {"text": ["New South Wales", "New South Wales", "New South Wales"], "answer_start": [110, 110, 110]}, "prediction_text": "New South Wales"}
{"answers": {"text": ["New Holland", "New Holland", "New Holland"], "answer_start": [151, 151, 151]}, "prediction_text": "New Holland"}
{"answers": {"text": ["Sydney", "Sydney", "Sydney"], "answer_start": [219, 219, 219]}, "prediction_text": "Sydney"}
{"answers": {"text": ["1854", "1854", "1854"], "answer_start": [3, 3, 3]}, "prediction_text": "1854"}
{"answers": {"text": ["British troops", "British troops", "British troops"], "answer_start": [171, 171, 171]}, "prediction_text": "British troops"}
{"answers": {"text": ["Eureka Stockade", "Eureka Stockade", "Eureka Stockade"], "answer_start": [132, 132, 132]}, "prediction_text": "Eureka Stockade"}
{"answers": {"text": ["mining licence fees", "mining licence fees", "mining licence fees"], "answer_start": [299, 299, 299]}, "prediction_text": "Mining licence fees"}
{"answers": {"text": ["Colony of Victoria Act", "the Colony of Victoria Act", "Colony of Victoria Act 1855"], "answer_start": [455, 451, 455]}, "prediction_text": "Colony of Victoria Act 1855"}
{"answers": {"text": ["most seats", "the most seats in the Legislative Assembly", "most seats in the Legislative Assembly"], "answer_start": [83, 79, 83]}, "prediction_text": "Leader of the political party or coalition with the most seats."}
{"answers": {"text": ["Premier", "The Premier is the public face of government and, with cabinet", "Premier of Victoria"], "answer_start": [127, 123, 4]}, "prediction_text": "Premier of Victoria"}
{"answers": {"text": ["representatives", "representatives elected to either house of parliament", "representatives elected to either house of parliament"], "answer_start": [250, 250, 250]}, "prediction_text": "Daniel Andrews"}
{"answers": {"text": ["Daniel Andrews", "Daniel Andrews", "Daniel Andrews"], "answer_start": [515, 515, 515]}, "prediction_text": "Daniel Andrews"}
{"answers": {"text": ["elected", "elected", "elected"], "answer_start": [266, 266, 266]}, "prediction_text": "Through cabinet selection process."}
{"answers": {"text": ["$8.7 billion", "24%", "$8.7 billion"], "answer_start": [89, 120, 89]}, "prediction_text": "17% increase"}
{"answers": {"text": ["17%", "17%", "17%"], "answer_start": [82, 82, 82]}, "prediction_text": "24%"}
{"answers": {"text": ["32,463", "32,463", "32,463"], "answer_start": [204, 204, 204]}, "prediction_text": "32,463"}
{"answers": {"text": ["136,000 square kilometres", "136,000 square kilometres", "136,000 square kilometres"], "answer_start": [233, 233, 233]}, "prediction_text": "More than 60%"}
{"answers": {"text": ["60%", "60%", "60%"], "answer_start": [318, 318, 318]}, "prediction_text": "32%"}
{"answers": {"text": ["tourism", "tourism", "big"], "answer_start": [37, 37, 25]}, "prediction_text": "Tourism"}
{"answers": {"text": ["sports", "sports tourism", "sports"], "answer_start": [92, 92, 92]}, "prediction_text": "Sports tourism"}
{"answers": {"text": ["Melbourne", "Melbourne", "Melbourne"], "answer_start": [144, 144, 144]}, "prediction_text": "Melbourne"}
{"answers": {"text": ["regional cities", "in regional cities", "Phillip Island"], "answer_start": [175, 172, 257]}, "prediction_text": "Regional cities"}
{"answers": {"text": ["SurfClassic", "SurfClassic", "SurfClassic"], "answer_start": [485, 485, 485]}, "prediction_text": "Bells Beach SurfClassic"}
{"answers": {"text": ["the southern and central parts of France", "southern and central parts of France,", "about one-eighth"], "answer_start": [86, 90, 128]}, "prediction_text": "Southern and central parts of France"}
{"answers": {"text": ["about one-eighth the number", "about one-eighth", "about one-eighth"], "answer_start": [128, 128, 128]}, "prediction_text": "One-eighth"}
{"answers": {"text": ["from 1562 to 1598", "1562 to 1598", "562 to 1598"], "answer_start": [469, 474, 475]}, "prediction_text": "1562 to 1598"}
{"answers": {"text": ["the Edict of Nantes", "Edict of Nantes", "the Edict of Nantes"], "answer_start": [532, 536, 532]}, "prediction_text": "Edict of Nantes"}
{"answers": {"text": ["granted the Huguenots substantial religious, political and military autonomy", "granted the Huguenots substantial religious, political and military autonomy", "granted the Huguenots substantial religious, political and military autonomy"], "answer_start": [559, 559, 559]}, "prediction_text": "granted religious, political, and military autonomy."}
{"answers": {"text": ["derision", "derision", "derision"], "answer_start": [26, 26, 26]}, "prediction_text": "political legitimacy and political influence."}
{"answers": {"text": ["Geneva", "Geneva", "Geneva"], "answer_start": [547, 547, 547]}, "prediction_text": "Geneva"}
{"answers": {"text": ["Besan\u00e7on Hugues", "Besan\u00e7on Hugues", "Besan\u00e7on Hugues"], "answer_start": [177, 177, 177]}, "prediction_text": "Besan\u00e7on Hugues"}
{"answers": {"text": ["Amboise plot", "Amboise", "the Amboise plot"], "answer_start": [1007, 1007, 1003]}, "prediction_text": "Amboise plot"}
{"answers": {"text": ["1560", "1560", "1560"], "answer_start": [1023, 1023, 1023]}, "prediction_text": "1560"}
{"answers": {"text": ["availability of the Bible in vernacular languages", "the Bible in vernacular languages", "The availability of the Bible in vernacular languages"], "answer_start": [4, 20, 0]}, "prediction_text": "Bible availability invernacular languages"}
{"answers": {"text": ["Around 1294", "1294", "Around 1294"], "answer_start": [275, 282, 275]}, "prediction_text": "1294"}
{"answers": {"text": ["Guyard de Moulin", "Guyard de Moulin", "Guyard de Moulin"], "answer_start": [366, 366, 366]}, "prediction_text": "Guyard de Moulin"}
{"answers": {"text": ["1487", "1487", "1487"], "answer_start": [500, 500, 500]}, "prediction_text": "1487"}
{"answers": {"text": ["Paris", "Paris", "Paris"], "answer_start": [491, 491, 491]}, "prediction_text": "Paris"}
{"answers": {"text": ["villes de s\u00fbret\u00e9", "\"villes de s\u00fbret\u00e9\"", "villes de s\u00fbret\u00e9"], "answer_start": [52, 51, 52]}, "prediction_text": "\"Villes de s\u00fbret\u00e9\""}
{"answers": {"text": ["Montpellier", "Montpellier", "Montpellier"], "answer_start": [0, 0, 0]}, "prediction_text": "Montpellier"}
{"answers": {"text": ["Edict of Al\u00e8s", "Edict of Al\u00e8s", "Edict of Al\u00e8s"], "answer_start": [455, 455, 455]}, "prediction_text": "Edict of 1598"}
{"answers": {"text": ["1622", "1622", "1622"], "answer_start": [266, 266, 266]}, "prediction_text": "1622"}
{"answers": {"text": ["1629", "1629", "1629"], "answer_start": [470, 470, 470]}, "prediction_text": "1598"}
{"answers": {"text": ["at the Cape of Good Hope", "Cape of Good Hope", "the Cape of Good Hope"], "answer_start": [29, 36, 32]}, "prediction_text": "Cape of Good Hope"}
{"answers": {"text": ["Cape Town", "Cape Town", "Cape Town"], "answer_start": [365, 365, 365]}, "prediction_text": "Cape Town"}
{"answers": {"text": ["Maria de la Queillerie", "Maria de la Queillerie", "Maria de la Queillerie"], "answer_start": [190, 190, 190]}, "prediction_text": "Maria de la Queillerie"}
{"answers": {"text": ["Dutch East India Company", "Dutch East India Company", "Dutch East India Company"], "answer_start": [522, 522, 522]}, "prediction_text": "Dutch East India Company"}
{"answers": {"text": ["1700", "1700", "1700"], "answer_start": [753, 753, 753]}, "prediction_text": "1688"}
{"answers": {"text": ["1624", "1624", "1624"], "answer_start": [115, 115, 115]}, "prediction_text": "1624"}
{"answers": {"text": ["Jess\u00e9 de Forest", "Jess\u00e9 de Forest", "Jess\u00e9 de Forest"], "answer_start": [71, 71, 71]}, "prediction_text": "Jess\u00e9 de Forest"}
{"answers": {"text": ["L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam (the French church in New Amsterdam)"], "answer_start": [482, 482, 482]}, "prediction_text": "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam"}
{"answers": {"text": ["L'Eglise du Saint-Esprit", "L'Eglise du Saint-Esprit", "L'Eglise du Saint-Esprit"], "answer_start": [594, 594, 594]}, "prediction_text": "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam"}
{"answers": {"text": ["Brooklyn", "Brooklyn", "Brooklyn"], "answer_start": [954, 954, 954]}, "prediction_text": "Brooklyn"}
{"answers": {"text": ["the Charleston Orange district", "Charleston Orange district", "Charleston Orange district"], "answer_start": [661, 665, 665]}, "prediction_text": "North America"}
{"answers": {"text": ["the British Landgrave Edmund Bellinger", "Edmund Bellinger", "Edmund Bellinger"], "answer_start": [955, 977, 977]}, "prediction_text": "British Landgrave Edmund Bellinger"}
{"answers": {"text": ["Pons", "Pons in France", "Pons"], "answer_start": [148, 148, 148]}, "prediction_text": "Pons in France"}
{"answers": {"text": ["1697", "1697", "1697"], "answer_start": [796, 796, 796]}, "prediction_text": "1697"}
{"answers": {"text": ["Charleston, South Carolina", "Charleston", "Charleston, South Carolina"], "answer_start": [75, 75, 75]}, "prediction_text": "Charleston"}
{"answers": {"text": ["William III of Orange", "Stadtholder William III of Orange", "Stadtholder William III of Orange"], "answer_start": [12, 0, 0]}, "prediction_text": "William III of Orange"}
{"answers": {"text": ["King of England", "King of England", "King of England"], "answer_start": [52, 52, 52]}, "prediction_text": "King of England"}
{"answers": {"text": ["League of Augsburg", "League of Augsburg", "League of Augsburg"], "answer_start": [194, 194, 194]}, "prediction_text": "League of Augsburg"}
{"answers": {"text": ["Dutch Republic", "Dutch Republic", "Dutch Republic"], "answer_start": [332, 332, 332]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["1672", "1672", "1672"], "answer_start": [169, 169, 169]}, "prediction_text": "1672"}
{"answers": {"text": ["Edict of Fontainebleau", "Edict of Fontainebleau", "the Edict of Fontainebleau"], "answer_start": [300, 300, 296]}, "prediction_text": "Edict of Nantes"}
{"answers": {"text": ["1685", "1685", "1685"], "answer_start": [324, 324, 324]}, "prediction_text": "1685"}
{"answers": {"text": ["Louis XIV", "Louis XIV", "Louis XIV"], "answer_start": [221, 221, 221]}, "prediction_text": "Louis XIV"}
{"answers": {"text": ["500,000", "500,000", "roughly 500,000"], "answer_start": [508, 508, 500]}, "prediction_text": "Approximately 500,000"}
{"answers": {"text": ["Catholic Church in France", "Catholic Church in France", "The Catholic Church in France"], "answer_start": [4, 4, 0]}, "prediction_text": "Catholic Church"}
{"answers": {"text": ["St. Bartholomew's Day massacre", "St. Bartholomew's Day massacre", "St. Bartholomew's Day massacre"], "answer_start": [209, 209, 209]}, "prediction_text": "St. Bartholomew's Day massacre"}
{"answers": {"text": ["5,000 to 30,000", "5,000 to 30,000", "5,000 to 30,000"], "answer_start": [245, 245, 245]}, "prediction_text": "5,000 to 30,000"}
{"answers": {"text": ["their own militia", "the Huguenots had their own militia"], "answer_start": [509, 491]}, "prediction_text": "They had their own militia."}
{"answers": {"text": ["some of the Huguenots were nobles trying to establish separate centers of power in southern France", "political reasons", "some of the Huguenots were nobles trying to establish separate centers of power in southern France"], "answer_start": [349, 310, 349]}, "prediction_text": "Political reasons"}
{"answers": {"text": ["between 1621 and 1629", "between 1621 and 1629", "between 1621 and 1629"], "answer_start": [205, 205, 205]}, "prediction_text": "1621-1629"}
{"answers": {"text": ["southwestern France", "southwestern France", "mainly in southwestern France"], "answer_start": [184, 184, 174]}, "prediction_text": "southwestern France"}
{"answers": {"text": ["Henry IV", "Henry IV", "Henry IV"], "answer_start": [316, 316, 316]}, "prediction_text": "Henry IV"}
{"answers": {"text": ["Louis XIII", "Louis XIII", "Louis XIII"], "answer_start": [444, 444, 444]}, "prediction_text": "Louis XIII"}
{"answers": {"text": ["Huguenot rebellions", "Huguenot rebellions", "the Huguenot rebellions"], "answer_start": [143, 143, 139]}, "prediction_text": "Three civil wars"}
{"answers": {"text": ["one million", "Approximately one million", "Approximately one million"], "answer_start": [14, 0, 0]}, "prediction_text": "Approximately one million"}
{"answers": {"text": ["2%", "2%", "2%"], "answer_start": [70, 70, 70]}, "prediction_text": "Approximately 2%"}
{"answers": {"text": ["Alsace", "Alsace", "Alsace"], "answer_start": [117, 117, 117]}, "prediction_text": "northeast France"}
{"answers": {"text": ["C\u00e9vennes", "C\u00e9vennes", "C\u00e9vennes mountain region"], "answer_start": [152, 152, 152]}, "prediction_text": "C\u00e9vennes mountain region"}
{"answers": {"text": ["Australia", "Australia", "Australia"], "answer_start": [444, 283, 283]}, "prediction_text": "France"}
{"answers": {"text": ["New Rochelle", "New Rochelle", "New Rochelle"], "answer_start": [226, 226, 226]}, "prediction_text": "New Rochelle"}
{"answers": {"text": ["New Paltz", "New Paltz", "New Paltz"], "answer_start": [271, 271, 271]}, "prediction_text": "New Rochelle"}
{"answers": {"text": ["\"Huguenot Street Historic District\" in New Paltz", "Huguenot Street Historic District", "The \"Huguenot Street Historic District\" in New Paltz"], "answer_start": [286, 287, 282]}, "prediction_text": "New Paltz"}
{"answers": {"text": ["the oldest street in the United States of America", "the oldest street in the United States of America", "the oldest street in the United States of America"], "answer_start": [402, 402, 402]}, "prediction_text": "Oldest street in the United States of America"}
{"answers": {"text": ["Staten Island", "Staten Island", "Staten Island"], "answer_start": [515, 515, 515]}, "prediction_text": "New York"}
{"answers": {"text": ["the Dutch Republic", "Dutch Republic", "Dutch Republic"], "answer_start": [45, 49, 49]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["an estimated total of 75,000 to 100,000 people", "75,000 to 100,000", "75,000 to 100,000"], "answer_start": [113, 135, 135]}, "prediction_text": "200 refugees"}
{"answers": {"text": ["ca. 2 million", "2 million", "2 million"], "answer_start": [367, 371, 371]}, "prediction_text": "2 million"}
{"answers": {"text": ["Amsterdam and the area of West Frisia", "Amsterdam and the area of West Frisia", "Amsterdam and the area of West Frisia"], "answer_start": [508, 508, 508]}, "prediction_text": "West Frisia and Amsterdam"}
{"answers": {"text": ["the revocation of the Edict of Nantes", "Edict of Nantes", "the revocation of the Edict of Nantes"], "answer_start": [6, 28, 6]}, "prediction_text": "Edict of Nantes"}
{"answers": {"text": ["Tours", "Tours", "Tours"], "answer_start": [367, 367, 367]}, "prediction_text": "Tours (in Tours)"}
{"answers": {"text": ["Huguon", "Huguon", "Huguon"], "answer_start": [123, 123, 123]}, "prediction_text": "The Gate of Hugo"}
{"answers": {"text": ["the ghost of le roi Huguet", "ghost of le roi Huguet", "the ghost of le roi Huguet"], "answer_start": [169, 173, 169]}, "prediction_text": "The ghost of le roi Huguet"}
{"answers": {"text": ["pr\u00e9tendus r\u00e9form\u00e9s", "pr\u00e9tendus r\u00e9form\u00e9s", "pr\u00e9tendus r\u00e9form\u00e9s"], "answer_start": [382, 382, 382]}, "prediction_text": "Pr\u00e9tendus r\u00e9form\u00e9s"}
{"answers": {"text": ["night", "night", "at night"], "answer_start": [456, 456, 453]}, "prediction_text": "Night"}
{"answers": {"text": ["Canterbury", "Canterbury", "Canterbury"], "answer_start": [48, 48, 48]}, "prediction_text": "Canterbury"}
{"answers": {"text": ["The Weavers", "The Weavers", "The Weavers"], "answer_start": [191, 191, 191]}, "prediction_text": "Turnagain Lane"}
{"answers": {"text": ["economic separation", "economic separation", "worked as weavers"], "answer_start": [649, 649, 172]}, "prediction_text": "Economic separation"}
{"answers": {"text": ["Kent, particularly Sandwich, Faversham and Maidstone", "Sandwich, Faversham and Maidstone", "Sandwich, Faversham and Maidstone"], "answer_start": [767, 786, 786]}, "prediction_text": "Sandwich, Faversham, Maidstone"}
{"answers": {"text": ["a restaurant", "restaurant", "a restaurant"], "answer_start": [339, 341, 339]}, "prediction_text": "A weaving school"}
{"answers": {"text": ["Cork City", "Cork City", "Cork City"], "answer_start": [342, 342, 342]}, "prediction_text": "Cork City"}
{"answers": {"text": ["Dublin, Cork, Youghal and Waterford", "Dublin, Cork, Youghal and Waterford", "Dublin, Cork, Youghal and Waterford"], "answer_start": [42, 42, 42]}, "prediction_text": "Dublin, Cork, Youghal, Waterford"}
{"answers": {"text": ["Dublin", "Dublin", "Dublin"], "answer_start": [375, 375, 375]}, "prediction_text": "Dublin, named after a High Sheriff and one of the founders of the Bank of Ireland."}
{"answers": {"text": ["a High Sheriff and one of the founders of the Bank of Ireland", "High Sheriff", "a High Sheriff and one of the founders of the Bank of Ireland"], "answer_start": [395, 397, 395]}, "prediction_text": "One of the founders of the Bank of Ireland."}
{"answers": {"text": ["1696", "1696", "1696"], "answer_start": [505, 505, 505]}, "prediction_text": "1696"}
{"answers": {"text": ["brain drain", "brain drain", "brain drain"], "answer_start": [46, 46, 46]}, "prediction_text": "Brain drain"}
{"answers": {"text": ["New France", "New France", "New France"], "answer_start": [227, 227, 227]}, "prediction_text": "New France"}
{"answers": {"text": ["non-Catholics", "non-Catholics", "non-Catholics"], "answer_start": [200, 200, 200]}, "prediction_text": "Non-Catholics"}
{"answers": {"text": ["Seven Years' War", "Seven Years' War", "Seven Years' War"], "answer_start": [481, 481, 481]}, "prediction_text": "Seven Years' War"}
{"answers": {"text": ["1759-60", "1759-60", "1759-60"], "answer_start": [634, 634, 634]}, "prediction_text": "1759-60"}
{"answers": {"text": ["Henry of Navarre", "Henry of Navarre", "Henry of Navarre"], "answer_start": [157, 157, 157]}, "prediction_text": "Henry IV"}
{"answers": {"text": ["1598", "1598", "1598"], "answer_start": [146, 146, 146]}, "prediction_text": "1598"}
{"answers": {"text": ["granted the Protestants equality with Catholics", "granted the Protestants equality", "granted the Protestants equality with Catholics under the throne and a degree of religious and political freedom within their domains"], "answer_start": [390, 390, 390]}, "prediction_text": "Reaffirmed Catholicism as the state religion."}
{"answers": {"text": ["the founding of new Protestant churches", "founding of new Protestant churches in Catholic-controlled regions", "the founding of new Protestant churches in Catholic-controlled regions"], "answer_start": [595, 599, 595]}, "prediction_text": "founding new Protestant churches"}
{"answers": {"text": ["Protestantism", "Protestantism", "Protestantism"], "answer_start": [246, 246, 246]}, "prediction_text": "Protestantism"}
{"answers": {"text": ["education of children as Catholics", "education of children as Catholics", "required education of children as Catholics"], "answer_start": [53, 53, 44]}, "prediction_text": "Education of children as Catholics."}
{"answers": {"text": ["prohibited emigration", "prohibited emigration", "prohibited emigration"], "answer_start": [93, 93, 93]}, "prediction_text": "Forced education of children as Catholics."}
{"answers": {"text": ["Four thousand", "Four thousand", "Four thousand"], "answer_start": [442, 442, 442]}, "prediction_text": "Four thousand"}
{"answers": {"text": ["\"new converts\"", "\"new converts\"", "new converts"], "answer_start": [750, 750, 751]}, "prediction_text": "New converts"}
{"answers": {"text": ["Holland, Prussia, and South Africa", "Holland, Prussia, and South Africa", "Britain as well as Holland, Prussia, and South Africa"], "answer_start": [406, 406, 387]}, "prediction_text": "Holland, Prussia, and South Africa."}
{"answers": {"text": ["Switzerland and the Netherlands", "Switzerland and the Netherlands.", "Switzerland and the Netherlands"], "answer_start": [71, 71, 71]}, "prediction_text": "Switzerland and the Netherlands"}
{"answers": {"text": ["1555", "1555", "1555"], "answer_start": [201, 201, 201]}, "prediction_text": "1555"}
{"answers": {"text": ["France Antarctique", "France Antarctique", "France Antarctique"], "answer_start": [215, 215, 215]}, "prediction_text": "Antarctique"}
{"answers": {"text": ["1560", "1560", "1560"], "answer_start": [581, 581, 581]}, "prediction_text": "1560"}
{"answers": {"text": ["the Guanabara Confession of Faith", "Guanabara Confession of Faith", "the Guanabara Confession of Faith"], "answer_start": [905, 909, 905]}, "prediction_text": "The Guanabara Confession of Faith"}
{"answers": {"text": ["Afrikaans", "Afrikaans", "Afrikaans"], "answer_start": [116, 116, 116]}, "prediction_text": "Afrikaans"}
{"answers": {"text": ["wine industry", "wine", "The wine industry"], "answer_start": [748, 748, 744]}, "prediction_text": "Wine industry"}
{"answers": {"text": ["Western Cape province", "Western Cape province"], "answer_start": [25, 25]}, "prediction_text": "Western Cape province"}
{"answers": {"text": ["surnames", "names", "surnames"], "answer_start": [141, 81, 141]}, "prediction_text": "French Huguenot ancestry"}
{"answers": {"text": ["Paul Revere", "Paul Revere", "Paul Revere"], "answer_start": [0, 0, 0]}, "prediction_text": "Jack Jouett"}
{"answers": {"text": ["Henry Laurens", "Henry Laurens", "Henry Laurens"], "answer_start": [57, 57, 57]}, "prediction_text": "Henry Laurens"}
{"answers": {"text": ["Charleston, South Carolina", "Charleston", "Charleston, South Carolina"], "answer_start": [467, 467, 467]}, "prediction_text": "Charleston, South Carolina"}
{"answers": {"text": ["Manakin Episcopal Church", "Manakin Episcopal Church", "Manakin Episcopal Church"], "answer_start": [569, 569, 569]}, "prediction_text": "Manakin Episcopal Church"}
{"answers": {"text": ["Texas", "Texas", "Texas"], "answer_start": [715, 715, 715]}, "prediction_text": "Texas"}
{"answers": {"text": ["lace", "lace", "British lace"], "answer_start": [79, 79, 71]}, "prediction_text": "British lace industry"}
{"answers": {"text": ["'Bucks Point'", "Bucks Point", "Bucks Point"], "answer_start": [523, 524, 524]}, "prediction_text": "Mechlin lace"}
{"answers": {"text": ["twenty-five widows who settled in Dover", "twenty-five widows who settled in Dover", "twenty-five widows who settled in Dover"], "answer_start": [331, 331, 331]}, "prediction_text": "19th century sources"}
{"answers": {"text": ["first half of the eighteenth century", "first half of the eighteenth century", "first half of the eighteenth century"], "answer_start": [702, 702, 702]}, "prediction_text": "First half of the eighteenth century"}
{"answers": {"text": ["Dorotheenstadt and Friedrichstadt", "Dorotheenstadt and Friedrichstadt", "Dorotheenstadt and Friedrichstadt"], "answer_start": [57, 57, 57]}, "prediction_text": "Dorotheenstadt and Friedrichstadt"}
{"answers": {"text": ["one-fifth", "one-fifth", "one-fifth"], "answer_start": [101, 101, 101]}, "prediction_text": "One-fifth of the city's population"}
{"answers": {"text": ["in protest against the occupation of Prussia by Napoleon", "in protest", "in protest against the occupation of Prussia by Napoleon"], "answer_start": [299, 299, 299]}, "prediction_text": "Protest against the occupation of Prussia by Napoleon."}
{"answers": {"text": ["1806-07", "1806-07.", "1806-07"], "answer_start": [359, 359, 359]}, "prediction_text": "1806-07"}
{"answers": {"text": ["Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden", "Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden", "Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden"], "answer_start": [480, 480, 480]}, "prediction_text": "Stockholm, Hamburg, Frankfurt, Helsinki, Emden"}
{"answers": {"text": ["Prussia", "Great Elector Frederick William", "Prussia"], "answer_start": [175, 201, 175]}, "prediction_text": "France"}
{"answers": {"text": ["C\u00e9vennes", "C\u00e9vennes", "C\u00e9vennes region in the south"], "answer_start": [407, 407, 407]}, "prediction_text": "The C\u00e9vennes region"}
{"answers": {"text": ["Camisards", "Camisards", "the Camisards"], "answer_start": [494, 494, 490]}, "prediction_text": "Camisards"}
{"answers": {"text": ["the Catholic Church in the region", "Catholic Church", "the Catholic Church in the region"], "answer_start": [538, 542, 538]}, "prediction_text": "Catholic Church"}
{"answers": {"text": ["1702 and 1709", "1702 and 1709", "1702 and 1709"], "answer_start": [699, 699, 699]}, "prediction_text": "1702 to 1709"}
{"answers": {"text": ["Jacksonville", "Jacksonville", "Jacksonville"], "answer_start": [172, 172, 172]}, "prediction_text": "Jacksonville"}
{"answers": {"text": ["Jean Ribault", "Jean Ribault", "Jean Ribault"], "answer_start": [60, 60, 60]}, "prediction_text": "Jean Ribault"}
{"answers": {"text": ["Fort Caroline", "Fort Caroline", "Fort Caroline"], "answer_start": [105, 105, 105]}, "prediction_text": "Fort Caroline"}
{"answers": {"text": ["Spanish", "Spanish", "Spanish"], "answer_start": [486, 609, 609]}, "prediction_text": "The French army"}
{"answers": {"text": ["1565", "1565", "1565"], "answer_start": [347, 347, 347]}, "prediction_text": "September 1565"}
{"answers": {"text": ["Charlesfort", "Charlesfort", "Charlesfort"], "answer_start": [216, 216, 216]}, "prediction_text": "Charlesfort"}
{"answers": {"text": ["Parris Island", "Southeastern U.S.", "Parris Island"], "answer_start": [231, 170, 231]}, "prediction_text": "St. Augustine"}
{"answers": {"text": ["Pedro Men\u00e9ndez de Avil\u00e9s", "Pedro Men\u00e9ndez de Avil\u00e9s", "Pedro Men\u00e9ndez de Avil\u00e9s"], "answer_start": [667, 667, 667]}, "prediction_text": "Pedro Men\u00e9ndez de Avil\u00e9s"}
{"answers": {"text": ["1562", "1562", "1564"], "answer_start": [77, 77, 344]}, "prediction_text": "1562"}
{"answers": {"text": ["The Wars of Religion", "The Wars of Religion", "The Wars of Religion"], "answer_start": [262, 262, 262]}, "prediction_text": "War at home"}
{"answers": {"text": ["Virginia", "Virginia", "Virginia"], "answer_start": [80, 80, 80]}, "prediction_text": "Lower Norfolk County"}
{"answers": {"text": ["Lower Norfolk County", "Lower Norfolk County", "Lower Norfolk County"], "answer_start": [147, 147, 147]}, "prediction_text": "Lower Norfolk County"}
{"answers": {"text": ["Manakin Town", "Manakin Town", "Manakin Town"], "answer_start": [322, 322, 322]}, "prediction_text": "Manakin Town"}
{"answers": {"text": ["390", "390", "390"], "answer_start": [556, 556, 556]}, "prediction_text": "390 settlers"}
{"answers": {"text": ["12 May 1705", "1705", "12 May 1705"], "answer_start": [420, 427, 420]}, "prediction_text": "1705"}
{"answers": {"text": ["1568\u20131609", "1568\u20131609", "1568\u20131609"], "answer_start": [121, 121, 121]}, "prediction_text": "1568\u20131609"}
{"answers": {"text": ["Spain", "Spain", "Spain"], "answer_start": [71, 71, 71]}, "prediction_text": "Huguenots"}
{"answers": {"text": ["\"Apologie\"", "Apologie\" of William the Silent", "Apologie"], "answer_start": [241, 242, 242]}, "prediction_text": "The \"Apologie\" of William the Silent"}
{"answers": {"text": ["William the Silent", "Pierre L'Oyseleur", "William the Silent"], "answer_start": [490, 365, 255]}, "prediction_text": "William the Silent"}
{"answers": {"text": ["Calvinist", "Calvinist", "Walloon"], "answer_start": [531, 531, 775]}, "prediction_text": "Calvinist"}
{"answers": {"text": ["Foreign Protestants Naturalization Act", "Foreign Protestants Naturalization Act,", "Foreign Protestants Naturalization Act"], "answer_start": [46, 46, 46]}, "prediction_text": "Foreign Protestants Naturalization Act"}
{"answers": {"text": ["1708", "1708", "1708"], "answer_start": [26, 26, 26]}, "prediction_text": "1708"}
{"answers": {"text": ["50,000", "50,000", "50,000"], "answer_start": [99, 99, 99]}, "prediction_text": "50,000"}
{"answers": {"text": ["Andrew Lortie", "Andrew Lortie", "Andrew Lortie"], "answer_start": [317, 317, 317]}, "prediction_text": "Andrew Lortie"}
{"answers": {"text": ["the doctrine of transubstantiation", "doctrine of transubstantiation during Mass", "the Pope and the doctrine of transubstantiation"], "answer_start": [495, 499, 482]}, "prediction_text": "Transubstantiation"}
{"answers": {"text": ["Williamite war", "Williamite", "the Williamite war"], "answer_start": [269, 269, 265]}, "prediction_text": "Williamite war"}
{"answers": {"text": ["William of Orange", "William of Orange", "William of Orange"], "answer_start": [244, 244, 244]}, "prediction_text": "William of Orange"}
{"answers": {"text": ["Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal", "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal", "Dublin, Cork, Portarlington, Lisburn, Waterford and Youghal"], "answer_start": [420, 420, 420]}, "prediction_text": "Dublin, Cork, Portarlington, Lisburn, Waterford"}
{"answers": {"text": ["flax cultivation", "flax", "flax cultivation"], "answer_start": [579, 579, 579]}, "prediction_text": "Flax cultivation"}
{"answers": {"text": ["Irish linen industry", "linen", "Irish linen"], "answer_start": [618, 624, 618]}, "prediction_text": "Irish linen industry"}
{"answers": {"text": ["Prince Louis de Cond\u00e9", "Louis de Cond\u00e9", "Prince Louis de Cond\u00e9"], "answer_start": [0, 7, 0]}, "prediction_text": "Count Ludwig von Nassau-Saarbr\u00fccken"}
{"answers": {"text": ["Count Ludwig von Nassau-Saarbr\u00fccken", "Ludwig von Nassau-Saarbr\u00fccken", "Count Ludwig von Nassau-Saarbr\u00fccken"], "answer_start": [92, 98, 92]}, "prediction_text": "Count Ludwig von Nassau-Saarbr\u00fccken"}
{"answers": {"text": ["glass-making", "glass-making", "glass-making"], "answer_start": [352, 352, 352]}, "prediction_text": "Glass-making"}
{"answers": {"text": ["1890s", "1890s", "1890s"], "answer_start": [754, 754, 754]}, "prediction_text": "1890s"}
{"answers": {"text": ["1604", "1604", "1604"], "answer_start": [189, 189, 189]}, "prediction_text": "1604"}
{"answers": {"text": ["Electorate of Brandenburg and Electorate of the Palatinate", "the Electorate of Brandenburg and Electorate of the Palatinate", "the Electorate of Brandenburg and Electorate of the Palatinate"], "answer_start": [158, 154, 154]}, "prediction_text": "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic, the Electorate of Brandenburg, the Duchy of Prussia, the Channel Islands, and Ireland."}
{"answers": {"text": ["Protestant", "Protestant", "Protestant"], "answer_start": [42, 42, 42]}, "prediction_text": "Protestantism"}
{"answers": {"text": ["Quebec", "Quebec", "Quebec"], "answer_start": [468, 468, 468]}, "prediction_text": "The British Columbia area"}
{"answers": {"text": ["Dutch Cape Colony", "Dutch Cape Colony", "Dutch Cape Colony"], "answer_start": [337, 337, 337]}, "prediction_text": "The Dutch East Indies"}
{"answers": {"text": ["they were accepted and allowed to worship freely", "allowed to worship freely", "they were accepted and allowed to worship freely"], "answer_start": [482, 505, 482]}, "prediction_text": "Free worship and acceptance."}
{"answers": {"text": ["Hugues Capet", "Hugues Capet", "Hugues Capet"], "answer_start": [265, 265, 265]}, "prediction_text": "Hugues Capet"}
{"answers": {"text": ["The \"Hugues hypothesis\"", "\"Hugues hypothesis\"", "Hugues hypothesis"], "answer_start": [188, 192, 193]}, "prediction_text": "\"Hugues hypothesis\""}
{"answers": {"text": ["Janet Gray", "Janet Gray", "Janet Gray"], "answer_start": [442, 442, 442]}, "prediction_text": "Janet Gray"}
{"answers": {"text": ["little Hugos, or those who want Hugo", "little Hugos", "little Hugos, or those who want Hugo."], "answer_start": [555, 555, 555]}, "prediction_text": "A noble man"}
{"answers": {"text": ["double or triple non-French linguistic origins", "non-French linguistic origins"], "answer_start": [24, 41]}, "prediction_text": "\"Hugues hypothesis\""}
{"answers": {"text": ["Jacques Lefevre", "Jacques Lefevre", "Jacques Lefevre"], "answer_start": [104, 104, 104]}, "prediction_text": "Jacques Lefevre"}
{"answers": {"text": ["University of Paris", "University of Paris", "University of Paris"], "answer_start": [375, 375, 375]}, "prediction_text": "University of Paris"}
{"answers": {"text": ["1530", "1523", "1530"], "answer_start": [513, 453, 513]}, "prediction_text": "1523"}
{"answers": {"text": ["William Farel", "William Farel", "William Farel"], "answer_start": [519, 519, 519]}, "prediction_text": "Jean Cauvin"}
{"answers": {"text": ["Jean Cauvin (John Calvin)", "Jean Cauvin", "Jean Cauvin"], "answer_start": [663, 663, 663]}, "prediction_text": "Jean Cauvin"}
{"answers": {"text": ["24 August \u2013 3 October 1572", "24 August \u2013 3 October 1572", "24 August \u2013 3 October 1572"], "answer_start": [62, 62, 62]}, "prediction_text": "August 24, 1572"}
{"answers": {"text": ["Catholics", "Catholics", "Catholics"], "answer_start": [90, 90, 90]}, "prediction_text": "Catholics"}
{"answers": {"text": ["Nearly 3,000", "Nearly 3,000", "Nearly 3,000"], "answer_start": [352, 352, 352]}, "prediction_text": "3,000"}
{"answers": {"text": ["1573", "1573", "1573"], "answer_start": [773, 773, 773]}, "prediction_text": "1573"}
{"answers": {"text": ["almost 25,000", "almost 25,000", "almost 25,000"], "answer_start": [636, 636, 636]}, "prediction_text": "Almost 25,000"}
{"answers": {"text": ["Louis XIV", "Louis XIV", "Louis XIV"], "answer_start": [0, 0, 0]}, "prediction_text": "Louis XIV"}
{"answers": {"text": ["acted increasingly aggressively to force the Huguenots to convert", "aggressively", "increasingly aggressively"], "answer_start": [40, 59, 46]}, "prediction_text": "He imposed penalties, closed Huguenot schools, excluded Huguenot professions."}
{"answers": {"text": ["he sent missionaries, backed by a fund to financially reward converts", "missionaries", "At first he sent missionaries, backed by a fund to financially reward converts to Catholicism"], "answer_start": [116, 124, 107]}, "prediction_text": "Sent missionaries, funded converts."}
{"answers": {"text": ["closed Huguenot schools", "closed Huguenot schools", "closed Huguenot schools and excluded them from favored professions"], "answer_start": [229, 229, 229]}, "prediction_text": "He issued the Edict of Fontainebleau, revoking the Edict of Nantes and declaring Protestantism illegal."}
{"answers": {"text": ["dragonnades", "dragonnades", "dragonnades"], "answer_start": [323, 323, 323]}, "prediction_text": "Dragonnades"}
{"answers": {"text": ["Westchester", "Westchester", "Westchester"], "answer_start": [39, 39, 39]}, "prediction_text": "Westchester"}
{"answers": {"text": ["\"Bauffet's Point\"", "Bauffet's Point", "Bauffet's Point"], "answer_start": [235, 236, 236]}, "prediction_text": "Davenports Neck"}
{"answers": {"text": ["John Pell, Lord of Pelham Manor", "John Pell", "John Pell"], "answer_start": [435, 435, 435]}, "prediction_text": "John Pell"}
{"answers": {"text": ["La Rochelle", "La Rochelle", "La Rochelle"], "answer_start": [593, 593, 593]}, "prediction_text": "La Rochelle"}
{"answers": {"text": ["Trinity-St. Paul's Episcopal Church", "Trinity-St. Paul's Episcopal Church", "Trinity-St. Paul's Episcopal Church"], "answer_start": [986, 986, 986]}, "prediction_text": "Trinity-St. Paul's Episcopal Church"}
{"answers": {"text": ["affiliated with other Protestant denominations", "affiliated with other Protestant denominations", "affiliated with other Protestant denominations with more numerous members"], "answer_start": [80, 80, 80]}, "prediction_text": "Adapted quickly and often"}
{"answers": {"text": ["married outside their immediate French communities", "married outside their immediate French communities", "adapted quickly and often married outside their immediate French communities"], "answer_start": [195, 195, 169]}, "prediction_text": "Adapted quickly and often married outside their French communities."}
{"answers": {"text": ["E.I. du Pont", "E.I. du Pont", "E.I. du Pont"], "answer_start": [599, 599, 599]}, "prediction_text": "E.I. du Pont"}
{"answers": {"text": ["into the nineteenth century", "well into the nineteenth century", "well into the nineteenth century"], "answer_start": [388, 383, 383]}, "prediction_text": "Many generations"}
{"answers": {"text": ["Eleutherian gunpowder mills", "Eleutherian gunpowder mills.", "Eleutherian"], "answer_start": [660, 660, 660]}, "prediction_text": "Eleutherian gunpowder mills"}
{"answers": {"text": ["Pierre Bayle", "Pierre Bayle", "Pierre Bayle"], "answer_start": [67, 67, 67]}, "prediction_text": "Pierre Bayle"}
{"answers": {"text": ["Rotterdam", "Rotterdam", "Rotterdam"], "answer_start": [104, 104, 104]}, "prediction_text": "Rotterdam"}
{"answers": {"text": ["Historical and Critical Dictionary", "Historical and Critical Dictionary", "Historical and Critical Dictionary"], "answer_start": [186, 186, 186]}, "prediction_text": "Historical and Critical Dictionary"}
{"answers": {"text": ["US Library of Congress", "US Library of Congress", "US Library of Congress"], "answer_start": [273, 273, 273]}, "prediction_text": "US Library of Congress"}
{"answers": {"text": ["Saint Nicolas", "Saint Nicolas", "Saint Nicolas"], "answer_start": [696, 696, 696]}, "prediction_text": "Saint Nicolas"}
{"answers": {"text": ["The French Protestant Church of London", "The French Protestant Church of London", "The French Protestant Church of London"], "answer_start": [0, 0, 0]}, "prediction_text": "Soho Square"}
{"answers": {"text": ["1550", "1550", "1550"], "answer_start": [75, 75, 75]}, "prediction_text": "1550"}
{"answers": {"text": ["Soho Square", "Soho Square", "Soho Square"], "answer_start": [102, 102, 102]}, "prediction_text": "Soho Square"}
{"answers": {"text": ["Shoreditch", "Shoreditch", "Shoreditch"], "answer_start": [144, 144, 144]}, "prediction_text": "Soho Square"}
{"answers": {"text": ["1724", "1724", "1724"], "answer_start": [447, 447, 447]}, "prediction_text": "1724"}
{"answers": {"text": ["Lutheran and Reformed", "Lutheran and Reformed", "Lutheran and Reformed"], "answer_start": [57, 57, 57]}, "prediction_text": "Lutheran and Reformed"}
{"answers": {"text": ["Germany and Scandinavia", "Germany and Scandinavia", "Germany and Scandinavia"], "answer_start": [89, 89, 89]}, "prediction_text": "Germany, Scandinavia"}
{"answers": {"text": ["Edict of Potsdam", "Edict of Potsdam", "Edict of Potsdam"], "answer_start": [270, 270, 270]}, "prediction_text": "Edict of Potsdam"}
{"answers": {"text": ["Elector of Brandenburg and Duke of Prussia", "Elector of Brandenburg and Duke of Prussia", "Elector of Brandenburg and Duke of Prussia"], "answer_start": [402, 402, 402]}, "prediction_text": "Elector of Brandenburg and Duke of Prussia"}
{"answers": {"text": ["Huguenots furnished two new regiments", "two new regiments", "furnished two new regiments of his army"], "answer_start": [450, 470, 460]}, "prediction_text": "Helped Frederick William's army expand."}
{"answers": {"text": ["Frederick William", "Frederick William", "Frederick William"], "answer_start": [0, 0, 0]}, "prediction_text": "Frederick William"}
{"answers": {"text": ["Theodor Fontane", "Theodor Fontane", "Theodor Fontane"], "answer_start": [268, 268, 268]}, "prediction_text": "Theodor Fontane"}
{"answers": {"text": ["Adolf Galland", "Adolf Galland", "Adolf Galland"], "answer_start": [403, 403, 403]}, "prediction_text": "Luftwaffe General and fighter ace Adolf Galland"}
{"answers": {"text": ["Lothar de Maizi\u00e8re", "Lothar de Maizi\u00e8re", "Lothar de Maizi\u00e8re"], "answer_start": [588, 588, 588]}, "prediction_text": "Thomas de Maizi\u00e8re"}
{"answers": {"text": ["Federal Minister of the Interior", "Minister of the Interior", "Federal Minister of the Interior"], "answer_start": [668, 676, 668]}, "prediction_text": "Federal Minister of the Interior"}
{"answers": {"text": ["solar", "solar power", "solar power, nuclear power or geothermal energy", "solar"], "answer_start": [149, 149, 149, 149]}, "prediction_text": "Solar power"}
{"answers": {"text": ["Rankine", "Rankine cycle", "Rankine cycle", "Rankine cycle"], "answer_start": [283, 283, 283, 283]}, "prediction_text": "Rankine cycle"}
{"answers": {"text": ["steam", "steam", "steam", "steam"], "answer_start": [348, 348, 348, 348]}, "prediction_text": "Steam"}
{"answers": {"text": ["high", "high", "high pressure", "high"], "answer_start": [385, 385, 385, 385]}, "prediction_text": "High pressure"}
{"answers": {"text": ["external combustion", "external combustion", "external combustion engines", "external combustion"], "answer_start": [18, 18, 18, 18]}, "prediction_text": "External combustion engines"}
{"answers": {"text": ["atmospheric engine", "atmospheric engine", "atmospheric engine", "the atmospheric engine"], "answer_start": [117, 117, 117, 113]}, "prediction_text": "atmospheric engine"}
{"answers": {"text": ["Thomas Newcomen", "Thomas Newcomen", "Thomas Newcomen", "Thomas Newcomen"], "answer_start": [149, 149, 149, 149]}, "prediction_text": "Thomas Newcomen"}
{"answers": {"text": ["1712", "around 1712", "1712", "1712"], "answer_start": [172, 165, 172, 172]}, "prediction_text": "1712"}
{"answers": {"text": ["steam pump", "steam pump", "steam pump", "steam pump"], "answer_start": [214, 214, 214, 214]}, "prediction_text": "Atmospheric engine"}
{"answers": {"text": ["Papin", "Papin", "Papin", "Papin"], "answer_start": [256, 256, 256, 256]}, "prediction_text": "Thomas Newcomen"}
{"answers": {"text": ["United Kingdom", "United Kingdom", "United Kingdom"], "answer_start": [93, 93, 93]}, "prediction_text": "United Kingdom"}
{"answers": {"text": ["21 February 1804", "21 February 1804", "21 February 1804"], "answer_start": [116, 116, 116]}, "prediction_text": "February 21, 1804"}
{"answers": {"text": ["Abercynon", "Abercynon in south Wales", "Abercynon"], "answer_start": [309, 309, 309]}, "prediction_text": "Abercynon in south Wales"}
{"answers": {"text": ["Wales", "south Wales", "Wales"], "answer_start": [328, 322, 328]}, "prediction_text": "Wales"}
{"answers": {"text": ["south", "south", "south"], "answer_start": [322, 322, 322]}, "prediction_text": "South Wales"}
{"answers": {"text": ["water pump", "water pump", "water pump"], "answer_start": [58, 58, 58]}, "prediction_text": "Water pump"}
{"answers": {"text": ["multi-stage centrifugal", "multi-stage centrifugal", "multi-stage centrifugal pumps"], "answer_start": [190, 190, 190]}, "prediction_text": "Multi-stage centrifugal pumps"}
{"answers": {"text": ["1850s", "1850s", "1850s"], "answer_start": [417, 417, 417]}, "prediction_text": "1850s"}
{"answers": {"text": ["steam locomotives", "steam locomotives", "steam locomotives"], "answer_start": [485, 485, 485]}, "prediction_text": "Steam locomotives"}
{"answers": {"text": ["lower-pressure boiler feed water", "water", "lower-pressure boiler feed water"], "answer_start": [279, 306, 279]}, "prediction_text": "Lower-pressure boiler feed water"}
{"answers": {"text": ["three", "three or four", "three"], "answer_start": [204, 204, 204]}, "prediction_text": "Three or four expansion stages."}
{"answers": {"text": ["quadruple expansion engines", "quadruple", "quadruple expansion engines"], "answer_start": [263, 263, 263]}, "prediction_text": "Triple and quadruple expansion engines"}
{"answers": {"text": ["19th", "19th", "19th"], "answer_start": [729, 729, 729]}, "prediction_text": "Late 19th century"}
{"answers": {"text": ["marine triple expansion", "marine triple expansion", "marine triple expansion engines"], "answer_start": [805, 805, 805]}, "prediction_text": "Yarrow-Schlick-Tweedy engines"}
{"answers": {"text": ["Olympic", "Olympic", "Olympic class"], "answer_start": [1178, 1178, 1178]}, "prediction_text": "Olympic class"}
{"answers": {"text": ["Corliss", "patent valve", "Corliss"], "answer_start": [849, 87, 849]}, "prediction_text": "Corliss and later poppet valve gears"}
{"answers": {"text": ["Joy", "Joy", "Joy"], "answer_start": [820, 820, 820]}, "prediction_text": "Poppet valve gears"}
{"answers": {"text": ["lengthening rubbing surfaces of the valve", "lengthening rubbing surfaces", "lengthening rubbing surfaces of the valve"], "answer_start": [461, 461, 461]}, "prediction_text": "By lengthening rubbing surfaces."}
{"answers": {"text": ["Lead fusible plugs", "Lead fusible plugs", "Lead fusible plugs"], "answer_start": [0, 0, 0]}, "prediction_text": "Lead fusible plugs"}
{"answers": {"text": ["melts", "melts", "the lead melts"], "answer_start": [179, 179, 170]}, "prediction_text": "Lead melts and steam escapes."}
{"answers": {"text": ["steam escapes", "steam escapes,", "the steam escapes"], "answer_start": [193, 193, 189]}, "prediction_text": "Steam escapes."}
{"answers": {"text": ["manually suppress the fire", "manually suppress the fire", "manually suppress the fire"], "answer_start": [244, 244, 244]}, "prediction_text": "manually suppress the fire."}
{"answers": {"text": ["dampening the fire", "dampening the fire", "dampening the fire"], "answer_start": [344, 344, 344]}, "prediction_text": "Little effect on dampening the fire."}
{"answers": {"text": ["James Watt", "James Watt", "James Watt", "James Watt"], "answer_start": [8, 8, 8, 8]}, "prediction_text": "James Watt"}
{"answers": {"text": ["rotary", "rotary", "rotary motion", "continuous rotary motion"], "answer_start": [68, 68, 68, 57]}, "prediction_text": "Rotary motion"}
{"answers": {"text": ["ten", "ten-horsepower", "ten-horsepower", "ten"], "answer_start": [90, 90, 90, 90]}, "prediction_text": "Ten horsepower"}
{"answers": {"text": ["1883", "1883", "1883", "1883"], "answer_start": [267, 267, 267, 267]}, "prediction_text": "1883"}
{"answers": {"text": ["Industrial Revolution", "Industrial Revolution", "Industrial Revolution", "the Industrial Revolution"], "answer_start": [386, 386, 386, 382]}, "prediction_text": "Industrial Revolution"}
{"answers": {"text": ["first", "first century AD", "first century AD", "first century AD"], "answer_start": [61, 61, 61, 61]}, "prediction_text": "Early centuries AD"}
{"answers": {"text": ["Hero of Alexandria", "Hero of Alexandria", "Hero of Alexandria", "Hero of Alexandria"], "answer_start": [176, 176, 176, 176]}, "prediction_text": "Hero of Alexandria"}
{"answers": {"text": ["Greek", "Greek", "Greek", "Greek"], "answer_start": [156, 156, 156, 156]}, "prediction_text": "Greek"}
{"answers": {"text": ["Giovanni Branca", "Giovanni Branca", "Giovanni Branca", "Giovanni Branca"], "answer_start": [458, 458, 458, 458]}, "prediction_text": "Giovanni Branca"}
{"answers": {"text": ["1606", "1606", "1606", "1606"], "answer_start": [532, 532, 532, 532]}, "prediction_text": "1690"}
{"answers": {"text": ["compound", "compound", "compound engines"], "answer_start": [33, 33, 33]}, "prediction_text": "Compound engines"}
{"answers": {"text": ["expansions", "expansions", "expansions"], "answer_start": [254, 254, 254]}, "prediction_text": "Double and triple expansion stages"}
{"answers": {"text": ["shipping", "shipping", "shipping"], "answer_start": [335, 335, 335]}, "prediction_text": "Shipping"}
{"answers": {"text": ["internal combustion engines", "internal combustion engines", "internal combustion engines"], "answer_start": [546, 546, 546]}, "prediction_text": "Internal combustion engines"}
{"answers": {"text": ["coal", "coal"], "answer_start": [399, 399]}, "prediction_text": "Coal"}
{"answers": {"text": ["steam turbines", "steam turbines", "steam turbines"], "answer_start": [68, 68, 68]}, "prediction_text": "Steam turbines"}
{"answers": {"text": ["late", "late part", "late"], "answer_start": [99, 99, 99]}, "prediction_text": "Late part of the 19th century"}
{"answers": {"text": ["several hundred", "several hundred horsepower", "several hundred"], "answer_start": [238, 238, 238]}, "prediction_text": "Above several hundred horsepower"}
{"answers": {"text": ["90", "90%", "90%"], "answer_start": [691, 691, 691]}, "prediction_text": "90%"}
{"answers": {"text": ["electric", "electric", "electric"], "answer_start": [624, 702, 624]}, "prediction_text": "Large ships"}
{"answers": {"text": ["burning combustible materials", "burning combustible materials", "burning combustible materials"], "answer_start": [120, 120, 120]}, "prediction_text": "Burning combustible materials with an appropriate supply of air."}
{"answers": {"text": ["combustion chamber", "combustion chamber", "combustion chamber"], "answer_start": [220, 220, 220]}, "prediction_text": "Firebox"}
{"answers": {"text": ["solar", "solar", "solar"], "answer_start": [321, 321, 321]}, "prediction_text": "Solar energy"}
{"answers": {"text": ["electric", "electric heating element", "electric"], "answer_start": [475, 475, 475]}, "prediction_text": "Electric heating element"}
{"answers": {"text": ["steam engine indicator", "steam engine indicator", "steam engine indicator"], "answer_start": [81, 81, 81]}, "prediction_text": "Steam engine indicator"}
{"answers": {"text": ["1851", "1851", "1851"], "answer_start": [135, 135, 135]}, "prediction_text": "1862"}
{"answers": {"text": ["Charles Porter", "Charles Porter", "Charles Porter"], "answer_start": [241, 241, 241]}, "prediction_text": "Charles Richard and exhibited at London Exhibition"}
{"answers": {"text": ["Charles Richard", "Charles Richard", "Charles Richard"], "answer_start": [259, 259, 259]}, "prediction_text": "Charles Richard"}
{"answers": {"text": ["London Exhibition", "London Exhibition", "London Exhibition"], "answer_start": [292, 292, 292]}, "prediction_text": "London Exhibition"}
{"answers": {"text": ["90", "90\u00b0", "90\u00b0"], "answer_start": [123, 123, 123]}, "prediction_text": "90\u00b0 out of phase"}
{"answers": {"text": ["180", "180\u00b0", "180\u00b0"], "answer_start": [313, 313, 313]}, "prediction_text": "90\u00b0"}
{"answers": {"text": ["90", "90\u00b0 to each other", "90\u00b0"], "answer_start": [343, 343, 343]}, "prediction_text": "90\u00b0 out of phase"}
{"answers": {"text": ["counterflow", "counterflow", "counterflow"], "answer_start": [95, 95, 95]}, "prediction_text": "Counterflow"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [234, 234, 234]}, "prediction_text": "Four events"}
{"answers": {"text": ["one", "one", "one"], "answer_start": [204, 204, 204]}, "prediction_text": "One crank rotations"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [279, 279, 279]}, "prediction_text": "Four events"}
{"answers": {"text": ["expansion", "expansion", "expansion"], "answer_start": [304, 304, 304]}, "prediction_text": "Admission"}
{"answers": {"text": ["Quasiturbine", "Quasiturbine", "Quasiturbine"], "answer_start": [905, 905, 905]}, "prediction_text": "Quasiturbine"}
{"answers": {"text": ["counterflow", "counterflow", "counterflow"], "answer_start": [74, 74, 74]}, "prediction_text": "Counterflow cycle"}
{"answers": {"text": ["port", "additional port", "an additional port"], "answer_start": [401, 390, 387]}, "prediction_text": "Additional port uncovered by the piston."}
{"answers": {"text": ["oscillating cylinder", "oscillating cylinder", "oscillating"], "answer_start": [3, 3, 3]}, "prediction_text": "Simple expansion steam engine"}
{"answers": {"text": ["trunnion", "trunnion", "trunnion"], "answer_start": [334, 334, 334]}, "prediction_text": "Trunnion"}
{"answers": {"text": ["models", "models", "models"], "answer_start": [387, 387, 387]}, "prediction_text": "Models and ships"}
{"answers": {"text": ["ships", "ships", "ships"], "answer_start": [488, 488, 488]}, "prediction_text": "Ships"}
{"answers": {"text": ["recycled continuously", "recycled continuously", "recycled continuously"], "answer_start": [101, 101, 101]}, "prediction_text": "Reuse continuously"}
{"answers": {"text": ["open loop", "open loop", "open loop"], "answer_start": [138, 138, 138]}, "prediction_text": "A separate source of water"}
{"answers": {"text": ["Mercury", "Mercury", "Mercury"], "answer_start": [455, 455, 455]}, "prediction_text": "Mercury vapor"}
{"answers": {"text": ["water", "water", "water"], "answer_start": [293, 293, 293]}, "prediction_text": "Mercury"}
{"answers": {"text": ["working fluid", "working fluid", "the working fluid"], "answer_start": [60, 60, 56]}, "prediction_text": "Working fluid pressure"}
{"answers": {"text": ["565", "565 \u00b0C", "565 \u00b0C"], "answer_start": [274, 274, 274]}, "prediction_text": "565 \u00b0C (the creep limit)"}
{"answers": {"text": ["stainless steel", "stainless steel", "stainless steel"], "answer_start": [301, 301, 301]}, "prediction_text": "Stainless steel"}
{"answers": {"text": ["63%", "63%", "63%"], "answer_start": [415, 415, 415]}, "prediction_text": "About 63%"}
{"answers": {"text": ["30 \u00b0C", "30 \u00b0C", "30 \u00b0C"], "answer_start": [356, 356, 356]}, "prediction_text": "Around 30 \u00b0C"}
{"answers": {"text": ["Steam engines", "Steam engines", "Steam engines", "Steam engines"], "answer_start": [0, 0, 0, 0]}, "prediction_text": "Steam engines"}
{"answers": {"text": ["steamboats", "steamboats", "steamboats and road vehicles", "steamboats"], "answer_start": [271, 271, 271, 271]}, "prediction_text": "Railway locomotives"}
{"answers": {"text": ["Stanley Steamer", "Stanley Steamer", "Stanley Steamer", "Stanley Steamer"], "answer_start": [515, 515, 515, 515]}, "prediction_text": "Stanley Steamer"}
{"answers": {"text": ["factories", "factories", "factories", "factories"], "answer_start": [144, 144, 144, 144]}, "prediction_text": "factories, mills, and mines."}
{"answers": {"text": ["increase in the land available for cultivation", "increase in the land available for cultivation", "farm tractors", "an increase in the land available for cultivation"], "answer_start": [336, 336, 437, 333]}, "prediction_text": "Increase in land available for cultivation."}
{"answers": {"text": ["Catch Me Who Can", "Catch Me Who Can", "Catch Me Who Can"], "answer_start": [90, 90, 90]}, "prediction_text": "Catch Me Who Can"}
{"answers": {"text": ["Matthew Murray", "Matthew Murray", "Matthew Murray"], "answer_start": [192, 192, 192]}, "prediction_text": "Matthew Murray"}
{"answers": {"text": ["twin-cylinder", "twin-cylinder", "twin-cylinder"], "answer_start": [154, 154, 154]}, "prediction_text": "Three-cylinder locomotive"}
{"answers": {"text": ["Middleton Railway", "Middleton Railway", "Middleton Railway"], "answer_start": [251, 251, 251]}, "prediction_text": "Middleton Railway"}
{"answers": {"text": ["Stockton and Darlington", "Stockton and Darlington Railway", "Stockton and Darlington Railway"], "answer_start": [325, 325, 325]}, "prediction_text": "Stockton and Darlington Railway"}
{"answers": {"text": ["Arthur Woolf", "Arthur Woolf", "Arthur Woolf"], "answer_start": [102, 102, 102]}, "prediction_text": "Arthur Woolf"}
{"answers": {"text": ["British", "British", "British"], "answer_start": [85, 85, 85]}, "prediction_text": "British"}
{"answers": {"text": ["torque variability", "torque variability", "torque variability"], "answer_start": [661, 661, 661]}, "prediction_text": "Efficiency"}
{"answers": {"text": ["cylinder volume", "cylinder", "cylinder volume"], "answer_start": [761, 761, 761]}, "prediction_text": "A larger cylinder volume"}
{"answers": {"text": ["90", "90%", "90%"], "answer_start": [81, 81, 81]}, "prediction_text": "About 90%"}
{"answers": {"text": ["reciprocating steam engines", "reciprocating", "reciprocating steam engines"], "answer_start": [826, 826, 826]}, "prediction_text": "reciprocating engines"}
{"answers": {"text": ["gas turbines", "gas turbines", "gas turbines"], "answer_start": [908, 908, 908]}, "prediction_text": "Gas turbines"}
{"answers": {"text": ["steam turbines", "steam turbines with reduction gearing", "steam turbines"], "answer_start": [575, 575, 575]}, "prediction_text": "Steam engines"}
{"answers": {"text": ["reduction", "reduction", "reduction"], "answer_start": [595, 595, 595]}, "prediction_text": "Direct connected to their driving turbines."}
{"answers": {"text": ["Rankine cycle", "The Rankine cycle", "The Rankine cycle"], "answer_start": [4, 0, 0]}, "prediction_text": "Rankine cycle"}
{"answers": {"text": ["removed in a condenser", "removed in a condenser", "removed in a condenser"], "answer_start": [478, 478, 478]}, "prediction_text": "Exhaust steam is removed."}
{"answers": {"text": ["1990s", "1990s", "1990s"], "answer_start": [589, 589, 589]}, "prediction_text": "1990s"}
{"answers": {"text": ["biomass", "biomass", "biomass"], "answer_start": [717, 717, 717]}, "prediction_text": "Solar plants"}
{"answers": {"text": ["Scottish", "Scottish", "Scottish"], "answer_start": [808, 808, 808]}, "prediction_text": "Scottish"}
{"answers": {"text": ["duty", "duty"], "answer_start": [70, 70]}, "prediction_text": "By duty (duty-based energy efficiency)"}
{"answers": {"text": ["17", "17.", "17"], "answer_start": [529, 529, 529]}, "prediction_text": "25 million"}
{"answers": {"text": ["7 million", "7 million", "7 million"], "answer_start": [378, 378, 378]}, "prediction_text": "25 million (low-pressure)"}
{"answers": {"text": ["94", "94 pounds", "94 pounds"], "answer_start": [300, 300, 300]}, "prediction_text": "94 pounds"}
{"answers": {"text": ["Watt", "Watt", "Watt"], "answer_start": [121, 121, 121]}, "prediction_text": "Watt"}
{"answers": {"text": ["steam turbines", "internal combustion engines", "Reciprocating piston", "steam turbines"], "answer_start": [308, 159, 0, 308]}, "prediction_text": "Electric motors"}
{"answers": {"text": ["Reciprocating piston", "steam turbines", "electric motors and internal combustion", "Reciprocating piston type"], "answer_start": [0, 308, 139, 0]}, "prediction_text": "Reciprocating piston type steam engines"}
{"answers": {"text": ["turbine", "turbine type", "electric motors", "turbine type"], "answer_start": [428, 428, 139, 428]}, "prediction_text": "Turbine-type steam engines"}
{"answers": {"text": ["internal combustion", "internal combustion", "internal combustion"], "answer_start": [159, 159, 159]}, "prediction_text": "Electric motors"}
{"answers": {"text": ["Thomas Savery", "Thomas Savery.", "Thomas Savery", "Thomas Savery"], "answer_start": [81, 81, 81, 81]}, "prediction_text": "Thomas Savery"}
{"answers": {"text": ["water pump", "water pump", "vacuum", "water pump"], "answer_start": [48, 48, 133, 48]}, "prediction_text": "A water pump"}
{"answers": {"text": ["1698", "1698", "1698", "1698"], "answer_start": [73, 73, 73, 73]}, "prediction_text": "1698"}
{"answers": {"text": ["Bento de Moura Portugal", "Bento de Moura Portugal", "Bento de Moura Portugal", "Bento de Moura Portugal"], "answer_start": [555, 555, 555, 555]}, "prediction_text": "Bento de Moura Portugal"}
{"answers": {"text": ["John Smeaton", "John Smeaton", "John Smeaton", "John Smeaton"], "answer_start": [698, 698, 698, 698]}, "prediction_text": "John Smeaton"}
{"answers": {"text": ["Richard Trevithick", "Richard Trevithick", "Richard Trevithick", "Richard Trevithick"], "answer_start": [12, 12, 12, 12]}, "prediction_text": "Richard Trevithick"}
{"answers": {"text": ["Oliver Evans", "Oliver Evans", "Oliver Evans", "Oliver Evans"], "answer_start": [48, 48, 48, 48]}, "prediction_text": "Richard Trevithick"}
{"answers": {"text": ["1802", "1802", "1802", "1802"], "answer_start": [170, 170, 170, 170]}, "prediction_text": "1802"}
{"answers": {"text": ["transport", "transport", "transport applications", "transport"], "answer_start": [289, 289, 289, 289]}, "prediction_text": "Transport applications"}
{"answers": {"text": ["power", "power", "power source"], "answer_start": [460, 460, 460]}, "prediction_text": "Power for small, faster, or more powerful engines."}
{"answers": {"text": ["Energiprojekt AB", "Energiprojekt AB", "Energiprojekt AB"], "answer_start": [219, 219, 219]}, "prediction_text": "Energiprojekt AB"}
{"answers": {"text": ["Sweden", "Sweden", "Sweden"], "answer_start": [239, 239, 239]}, "prediction_text": "Sweden"}
{"answers": {"text": ["5", "5-cylinder", "5"], "answer_start": [439, 439, 439]}, "prediction_text": "5 cylinders"}
{"answers": {"text": ["8.8", "8.8", "8.8"], "answer_start": [521, 521, 521]}, "prediction_text": "4 kg (8.8 lb)"}
{"answers": {"text": ["27-30", "27-30%", "27-30%"], "answer_start": [385, 385, 385]}, "prediction_text": "27-30%"}
{"answers": {"text": ["surface condensers", "surface condensers", "surface condensers"], "answer_start": [60, 60, 60]}, "prediction_text": "Surface condensers"}
{"answers": {"text": ["automobile radiator", "automobile radiator", "an automobile radiator"], "answer_start": [395, 395, 392]}, "prediction_text": "An automobile radiator"}
{"answers": {"text": ["where water is costly", "where water is costly", "locations where water is costly"], "answer_start": [440, 440, 430]}, "prediction_text": "Coal-fired power plants"}
{"answers": {"text": ["wet", "wet", "wet"], "answer_start": [476, 476, 476]}, "prediction_text": "Dry cooling tower"}
{"answers": {"text": ["3600", "3600", "3600"], "answer_start": [921, 921, 921]}, "prediction_text": "About 3600 cubic meters"}
{"answers": {"text": ["centrifugal governor", "centrifugal governor", "centrifugal governor"], "answer_start": [4, 4, 4]}, "prediction_text": "A centrifugal governor"}
{"answers": {"text": ["Boulton", "Boulton", "Boulton"], "answer_start": [106, 106, 106]}, "prediction_text": "Boulton & Watt"}
{"answers": {"text": ["flour mill", "flour mill", "a flour mill"], "answer_start": [127, 127, 125]}, "prediction_text": "At a flour mill"}
{"answers": {"text": ["cotton spinning", "operations requiring constant speed", "cotton spinning"], "answer_start": [608, 563, 608]}, "prediction_text": "Cotton spinning"}
{"answers": {"text": ["hold a set speed", "hold a set speed", "hold a set speed"], "answer_start": [200, 200, 200]}, "prediction_text": "Holding constant speed"}
{"answers": {"text": ["1880", "1880", "1880"], "answer_start": [124, 124, 124]}, "prediction_text": "After 1880"}
{"answers": {"text": ["railway locomotives", "railway locomotives", "railway locomotives"], "answer_start": [164, 164, 164]}, "prediction_text": "Railway locomotives"}
{"answers": {"text": ["complicated", "complicated", "complicated"], "answer_start": [216, 216, 216]}, "prediction_text": "Complexity and not common."}
{"answers": {"text": ["1930", "1930", "1930"], "answer_start": [423, 423, 423]}, "prediction_text": "1930"}
{"answers": {"text": ["road engines", "road engines", "road engines"], "answer_start": [65, 65, 65]}, "prediction_text": "Railway locomotives"}
{"answers": {"text": ["shortening the cutoff", "\"shortening the cutoff\"", "shortening the cutoff"], "answer_start": [274, 273, 274]}, "prediction_text": "\"Shortening the cutoff\""}
{"answers": {"text": ["kick back", "kick back", "kick back"], "answer_start": [751, 751, 751]}, "prediction_text": "Kick back"}
{"answers": {"text": ["evacuate the cylinder", "evacuate the cylinder", "evacuate the cylinder"], "answer_start": [682, 682, 682]}, "prediction_text": "C choking cylinder."}
{"answers": {"text": ["fixed", "fixed", "fixed"], "answer_start": [40, 40, 40]}, "prediction_text": "One direction"}
{"answers": {"text": ["Jer\u00f3nimo de Ayanz y Beaumont", "Jer\u00f3nimo de Ayanz y Beaumont", "Jer\u00f3nimo de Ayanz y Beaumont", "Jer\u00f3nimo de Ayanz y Beaumont"], "answer_start": [135, 135, 135, 135]}, "prediction_text": "Jer\u00f3nimo de Ayanz y Beaumont"}
{"answers": {"text": ["Spanish", "Spanish", "Spanish", "Spanish"], "answer_start": [118, 118, 118, 118]}, "prediction_text": "Spanish"}
{"answers": {"text": ["1606", "1606", "1606", "1606"], "answer_start": [212, 212, 212, 212]}, "prediction_text": "1606"}
{"answers": {"text": ["1698", "1698", "1698", "1698"], "answer_start": [221, 221, 221, 221]}, "prediction_text": "1698"}
{"answers": {"text": ["1712", "1712", "1712", "1712"], "answer_start": [591, 591, 591, 591]}, "prediction_text": "1712"}
{"answers": {"text": ["rotating discs", "rotating discs", "rotating discs"], "answer_start": [48, 48, 48]}, "prediction_text": "Rotors are used in a variety of applications, including nuclear power, ship propeller, and ship propulsion."}
{"answers": {"text": ["drive shaft", "a drive shaft", "drive shaft"], "answer_start": [77, 75, 77]}, "prediction_text": "One or more rotors (rotating discs)"}
{"answers": {"text": ["static discs", "static discs)", "static discs"], "answer_start": [128, 128, 128]}, "prediction_text": "Stabilizing discs"}
{"answers": {"text": ["turbine casing", "turbine casing", "the turbine casing"], "answer_start": [155, 155, 151]}, "prediction_text": "Rotors are attached to stators."}
{"answers": {"text": ["3600 revolutions per minute", "3600 revolutions per minute", "3600 revolutions per minute"], "answer_start": [1061, 1061, 1061]}, "prediction_text": "3600 revolutions per minute (RPM)"}
{"answers": {"text": ["lower", "lower", "lower", "lower"], "answer_start": [96, 96, 96, 96]}, "prediction_text": "Lower power-to-weight ratio."}
{"answers": {"text": ["electric motors", "electric motors", "internal combustion engines or electric motors", "electric motors"], "answer_start": [232, 232, 201, 232]}, "prediction_text": "Electric motors"}
{"answers": {"text": ["steam turbine", "steam turbine", "steam turbine plant", "steam turbine plant"], "answer_start": [297, 297, 297, 297]}, "prediction_text": "Steam turbine plants"}
{"answers": {"text": ["Advanced Steam", "Advanced Steam movement", "cogeneration processes", "Advanced Steam movement"], "answer_start": [581, 581, 506, 581]}, "prediction_text": "Advanced Steam movement"}
{"answers": {"text": ["pollution", "pollution", "Advanced Steam movement", "pollution"], "answer_start": [432, 432, 581, 432]}, "prediction_text": "Pollution and fuel sources."}
{"answers": {"text": ["Wankel", "Wankel", "the Wankel engine"], "answer_start": [82, 82, 78]}, "prediction_text": "Wankel engine"}
{"answers": {"text": ["cylinders and valve gear", "cylinders and valve gear", "cylinders and valve gear"], "answer_start": [112, 112, 112]}, "prediction_text": "cylinders and valve gear."}
{"answers": {"text": ["thermal expansion", "thermal expansion", "thermal expansion"], "answer_start": [509, 509, 509]}, "prediction_text": "Thermal expansion"}
{"answers": {"text": ["1775", "1763\u20131775", "1775", "1775"], "answer_start": [61, 56, 61, 61]}, "prediction_text": "1763\u20131775"}
{"answers": {"text": ["condenser", "a separate condenser", "condenser", "a separate condenser"], "answer_start": [125, 114, 125, 114]}, "prediction_text": "A separate condenser"}
{"answers": {"text": ["half", "half as much", "half as much coal", "half"], "answer_start": [174, 174, 174, 174]}, "prediction_text": "Half as much coal"}
{"answers": {"text": ["Newcomen's", "Newcomen's", "Newcomen's and Watt's", "Newcomen"], "answer_start": [230, 242, 242, 242]}, "prediction_text": "Newcomen's"}
{"answers": {"text": ["piston", "a piston", "piston", "a piston"], "answer_start": [342, 340, 342, 340]}, "prediction_text": "The piston"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [33, 33, 33]}, "prediction_text": "Two mechanisms"}
{"answers": {"text": ["plug valve", "plug valve", "a plug valve"], "answer_start": [286, 286, 284]}, "prediction_text": "A plug valve"}
{"answers": {"text": ["adjustable spring-loaded", "adjustable spring-loaded", "adjustable spring-loaded valve"], "answer_start": [642, 642, 642]}, "prediction_text": "Adjustable spring-loaded valve"}
{"answers": {"text": ["seal", "seal", "a seal"], "answer_start": [754, 754, 752]}, "prediction_text": "A seal illegally is broken."}
{"answers": {"text": ["more power", "more power", "greater steam pressure and more power"], "answer_start": [569, 569, 542]}, "prediction_text": "More power"}
{"answers": {"text": ["Corliss steam engine", "Corliss", "the Corliss steam engine"], "answer_start": [42, 42, 38]}, "prediction_text": "Corliss steam engine"}
{"answers": {"text": ["1849", "1849", "1849"], "answer_start": [76, 76, 76]}, "prediction_text": "1849"}
{"answers": {"text": ["30%", "30% less steam", "30%"], "answer_start": [386, 386, 386]}, "prediction_text": "30% less"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [94, 94, 94]}, "prediction_text": "Four valves"}
{"answers": {"text": ["Rumford medal", "Rumford medal", "the Rumford medal"], "answer_start": [238, 238, 234]}, "prediction_text": "Rumford medal"}
{"answers": {"text": ["thermodynamic", "thermodynamic theory", "thermodynamic theory"], "answer_start": [56, 56, 56]}, "prediction_text": "Thermodynamic theory"}
{"answers": {"text": ["Watt", "Watt", "Watt"], "answer_start": [333, 333, 333]}, "prediction_text": "Watt"}
{"answers": {"text": ["condenser", "separate condenser", "the separate condenser"], "answer_start": [401, 392, 388]}, "prediction_text": "separate condenser"}
{"answers": {"text": ["Joseph Black", "Joseph Black", "Joseph Black"], "answer_start": [502, 502, 502]}, "prediction_text": "Joseph Black"}
{"answers": {"text": ["latent heat", "latent heat", "latent heat"], "answer_start": [442, 442, 442]}, "prediction_text": "Rankine cycle"}
{"answers": {"text": ["during the compression stage relatively little work is required to drive the pump", "relatively little work is required to drive the pump,", "during the compression stage relatively little work is required to drive the pump"], "answer_start": [76, 105, 76]}, "prediction_text": "Less work required to drive pump."}
{"answers": {"text": ["liquid", "liquid phase", "liquid"], "answer_start": [190, 190, 190]}, "prediction_text": "Liquid phase"}
{"answers": {"text": ["1% to 3%", "1% to 3%", "1% to 3%"], "answer_start": [287, 287, 287]}, "prediction_text": "1% to 3%"}
{"answers": {"text": ["1500 \u00b0C", "1500 \u00b0C", "1500 \u00b0C"], "answer_start": [532, 532, 532]}, "prediction_text": "1500 \u00b0C"}
{"answers": {"text": ["injector", "condensers", "injector"], "answer_start": [54, 112, 54]}, "prediction_text": "An injector"}
{"answers": {"text": ["recover the latent heat of vaporisation", "recover the latent heat of vaporisation", "recover the latent heat of vaporisation"], "answer_start": [152, 152, 152]}, "prediction_text": "Recirculate water"}
{"answers": {"text": ["superheaters", "superheaters", "superheaters"], "answer_start": [197, 197, 197]}, "prediction_text": "Superheaters"}
{"answers": {"text": ["bunker", "bunker", "bunker"], "answer_start": [478, 478, 478]}, "prediction_text": "Bunker"}
{"answers": {"text": ["stoking", "Mechanical stoker", "a chain or screw stoking mechanism"], "answer_start": [378, 507, 361]}, "prediction_text": "A chain or screw stoker"}
{"answers": {"text": ["feed water", "water", "feed water"], "answer_start": [63, 68, 63]}, "prediction_text": "Feed water"}
{"answers": {"text": ["British", "British", "British"], "answer_start": [265, 265, 265]}, "prediction_text": "British"}
{"answers": {"text": ["dreadnought battleships", "dreadnought battleships", "dreadnought battleships"], "answer_start": [361, 361, 361]}, "prediction_text": "HMS Dreadnought"}
{"answers": {"text": ["ocean liners", "ocean liners", "ocean liners"], "answer_start": [390, 390, 390]}, "prediction_text": "Ocean liners"}
{"answers": {"text": ["1905", "1905", "1905"], "answer_start": [423, 423, 423]}, "prediction_text": "1905"}
{"answers": {"text": ["water", "water", "water"], "answer_start": [67, 67, 67]}, "prediction_text": "Water"}
{"answers": {"text": ["turbine", "turbine", "a turbine connected to an electrical generator"], "answer_start": [104, 104, 102]}, "prediction_text": "A turbine"}
{"answers": {"text": ["electrical generator", "electrical generator", "a turbo generator set with propulsion provided by electric motors"], "answer_start": [128, 128, 354]}, "prediction_text": "An electrical generator"}
{"answers": {"text": ["turbo-electric transmission", "turbo-electric transmission,", "turbo-electric transmission"], "answer_start": [302, 302, 302]}, "prediction_text": "Turbo-electric transmission"}
{"answers": {"text": ["Britain", "Britain", "Britain"], "answer_start": [644, 644, 644]}, "prediction_text": "Sweden"}
{"answers": {"text": ["practical Carnot cycle", "practical Carnot cycle", "a practical Carnot cycle"], "answer_start": [48, 48, 46]}, "prediction_text": "Practical Carnot cycle"}
{"answers": {"text": ["in the condenser", "in the condenser", "in the condenser"], "answer_start": [240, 240, 240]}, "prediction_text": "In the condenser"}
{"answers": {"text": ["constant pressure", "constant pressure", "constant pressure"], "answer_start": [272, 272, 272]}, "prediction_text": "Constant pressure and isothermal (constant temperature) processes in the Rankine cycle."}
{"answers": {"text": ["isothermal", "isothermal", "isothermal"], "answer_start": [326, 326, 326]}, "prediction_text": "Isothermal"}
{"answers": {"text": ["liquid", "a liquid", "gaseous"], "answer_start": [506, 504, 704]}, "prediction_text": "As a liquid"}
{"answers": {"text": ["8", "8", "8", "8", "8"], "answer_start": [61, 61, 61, 61, 61]}, "prediction_text": "8"}
{"answers": {"text": ["helium", "helium", "helium", "helium", "helium"], "answer_start": [331, 331, 331, 331, 331]}, "prediction_text": "Hydrogen"}
{"answers": {"text": ["two atoms", "two", "two", "two", "two"], "answer_start": [377, 377, 377, 377, 377]}, "prediction_text": "Two atoms"}
{"answers": {"text": ["almost half", "almost half", "half", "almost half", "half"], "answer_start": [788, 788, 795, 788, 795]}, "prediction_text": "Almost half"}
{"answers": {"text": ["Diatomic oxygen", "Diatomic oxygen", "Diatomic oxygen gas", "Diatomic oxygen", "Diatomic oxygen gas"], "answer_start": [485, 485, 485, 485, 485]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["20.8%", "20.8%", "20.8%", "20.8%", "20.8%"], "answer_start": [517, 517, 517, 517, 517]}, "prediction_text": "20.8%"}
{"answers": {"text": ["Oxygen", "Oxygen", "Oxygen", "Oxygen", "Oxygen"], "answer_start": [661, 661, 661, 661, 661]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["8", "8", "8", "8", "8"], "answer_start": [61, 61, 61, 61, 61]}, "prediction_text": "8"}
{"answers": {"text": ["monitoring of atmospheric oxygen levels show a global downward trend", "down", "down", "down", "downward"], "answer_start": [559, 613, 613, 613, 613]}, "prediction_text": "Down"}
{"answers": {"text": ["By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium", "oxygen is the third-most abundant element in the universe, after hydrogen and helium", "oxygen is the third-most abundant element in the universe, after hydrogen and helium", "oxygen is the third-most abundant element in the universe, after hydrogen and helium", "By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium."], "answer_start": [244, 253, 253, 253, 244]}, "prediction_text": "Hydrogen, helium, and oxygen"}
{"answers": {"text": ["8", "8", "8", "8", "8"], "answer_start": [61, 61, 61, 61, 61]}, "prediction_text": "8"}
{"answers": {"text": ["chalcogen", "chalcogen", "chalcogen", "chalcogen", "the chalcogen group"], "answer_start": [86, 86, 86, 86, 82]}, "prediction_text": "Chalcogen group"}
{"answers": {"text": ["oxides", "oxides", "oxides", "oxide compounds", "oxide"], "answer_start": [216, 216, 216, 737, 737]}, "prediction_text": "Oxides"}
{"answers": {"text": ["third", "third-most", "third", "third-most", "third"], "answer_start": [267, 267, 267, 267, 267]}, "prediction_text": "Third-most abundant"}
{"answers": {"text": ["dioxygen", "diatomic gas", "dioxygen", "dioxygen", "dioxygen"], "answer_start": [415, 450, 415, 415, 415]}, "prediction_text": "Dioxygen"}
{"answers": {"text": ["photosynthesis", "photosynthesis", "photosynthesis", "photosynthesis", "photosynthesis"], "answer_start": [392, 392, 392, 392, 392]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["sunlight", "sunlight", "sunlight", "the energy of sunlight", "sunlight"], "answer_start": [433, 433, 433, 419, 433]}, "prediction_text": "sunlight"}
{"answers": {"text": ["high-altitude ozone layer", "ozone", "ozone layer", "ozone"], "answer_start": [724, 659, 738, 659]}, "prediction_text": "Helps biospher from UV."}
{"answers": {"text": ["oxygen", "oxygen", "oxygen", "oxygen", "oxygen"], "answer_start": [127, 268, 127, 127, 268]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["water", "water", "organic molecules", "inorganic compounds", "mass"], "answer_start": [294, 294, 22, 151, 240]}, "prediction_text": "In animal shells, teeth, and bone."}
{"answers": {"text": ["photosynthesis", "living organisms", "photosynthesis", "photosynthesis", "photosynthesis"], "answer_start": [392, 605, 392, 392, 392]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["water", "water", "water", "water", "water"], "answer_start": [465, 465, 465, 465, 465]}, "prediction_text": "From sunlight"}
{"answers": {"text": ["ozone", "ozone", "ozone", "ozone"], "answer_start": [738, 659, 659, 659]}, "prediction_text": "Oxygen (O3)"}
{"answers": {"text": ["Robert Boyle", "Robert Boyle", "Boyle", "Robert Boyle"], "answer_start": [26, 26, 33, 26]}, "prediction_text": "Robert Boyle"}
{"answers": {"text": ["John Mayow", "John Mayow", "Mayow", "John Mayow"], "answer_start": [100, 100, 105, 100]}, "prediction_text": "John Mayow"}
{"answers": {"text": ["nitroaereus", "nitroaereus", "nitroaereus", "nitroaereus"], "answer_start": [485, 485, 485, 485]}, "prediction_text": "Nitroaereus"}
{"answers": {"text": ["1679", "1679", "1679", "1679"], "answer_start": [117, 117, 117, 117]}, "prediction_text": "1679"}
{"answers": {"text": ["Robert Boyle", "Robert Boyle", "Boyle", "Robert Boyle"], "answer_start": [26, 26, 33, 26]}, "prediction_text": "John Mayow"}
{"answers": {"text": ["nitroaereus", "spiritus nitroaereus", "spiritus nitroaereus", "spiritus nitroaereus or just nitroaereus"], "answer_start": [234, 205, 205, 205]}, "prediction_text": "Spiritus nitroaereus"}
{"answers": {"text": ["17th century", "17th", "17th", "late 17th century"], "answer_start": [12, 12, 12, 7]}, "prediction_text": "1641\u20131679"}
{"answers": {"text": ["respiration", "respiration", "respiration", "respiration"], "answer_start": [517, 517, 517, 517]}, "prediction_text": "respiration"}
{"answers": {"text": ["John Mayow", "John Mayow", "Mayow", "John Mayow"], "answer_start": [100, 100, 105, 100]}, "prediction_text": "John Mayow"}
{"answers": {"text": ["Joseph Priestley", "Priestley", "Joseph Priestley", "Joseph Priestley", "Priestley"], "answer_start": [85, 551, 85, 85, 551]}, "prediction_text": "Joseph Priestley"}
{"answers": {"text": ["clergyman", "clergyman", "clergyman", "clergyman", "clergyman"], "answer_start": [75, 75, 75, 75, 75]}, "prediction_text": "British clergyman"}
{"answers": {"text": ["HgO", "HgO", "HgO", "HgO", "HgO"], "answer_start": [138, 138, 138, 138, 138]}, "prediction_text": "HgO"}
{"answers": {"text": ["mercuric oxide (HgO)", "mercuric oxide", "mercuric oxide", "mercuric oxide (HgO)", "mercuric oxide"], "answer_start": [122, 122, 122, 122, 122]}, "prediction_text": "HgO"}
{"answers": {"text": ["mercuric oxide", "mercuric oxide", "mercuric oxide", "mercuric oxide (HgO)", "mercuric oxide"], "answer_start": [122, 122, 122, 122, 122]}, "prediction_text": "HgO"}
{"answers": {"text": ["dephlogisticated air", "dephlogisticated air", "dephlogisticated air", "dephlogisticated air", "\"dephlogisticated air"], "answer_start": [196, 196, 196, 196, 195]}, "prediction_text": "\"Dephlogisticated air\""}
{"answers": {"text": ["1775", "1775", "1775", "1775", "1775"], "answer_start": [587, 587, 587, 587, 587]}, "prediction_text": "1775"}
{"answers": {"text": ["published his findings first", "he published his findings first", "he published his findings first", "he published his findings first", "Because he published his findings first"], "answer_start": [779, 776, 776, 776, 768]}, "prediction_text": "He published his findings first."}
{"answers": {"text": ["active", "more active and lived longer", "was more active and lived longer", "more active and lived longer while breathing it", "was more active and lived longer"], "answer_start": [294, 289, 285, 289, 285]}, "prediction_text": "Lovedlier life"}
{"answers": {"text": ["Leonardo da Vinci", "Leonardo da Vinci", "Leonardo da Vinci", "Leonardo da Vinci", "da Vinci"], "answer_start": [529, 529, 529, 529, 538]}, "prediction_text": "Leonardo da Vinci"}
{"answers": {"text": ["Philo of Byzantium", "Philo of Byzantium", "Philo", "Philo", "Philo of Byzantium"], "answer_start": [146, 146, 190, 146, 146]}, "prediction_text": "Philo of Byzantium"}
{"answers": {"text": ["2nd century BCE", "2nd century BCE", "2nd century BCE", "2nd century BCE", "2nd century BCE"], "answer_start": [103, 103, 103, 103, 103]}, "prediction_text": "2nd century BCE"}
{"answers": {"text": ["incorrectly", "incorrectly", "incorrectly", "incorrectly", "incorrectly"], "answer_start": [347, 347, 347, 347, 347]}, "prediction_text": "Parts of air are consumed during combustion."}
{"answers": {"text": ["Philo of Byzantium", "Philo of Byzantium", "Philo", "Philo", "Philo of Byzantium"], "answer_start": [146, 146, 190, 146, 146]}, "prediction_text": "Philo of Byzantium"}
{"answers": {"text": ["fire", "the classical element fire", "fire", "the classical element fire", "fire"], "answer_start": [446, 424, 446, 424, 446]}, "prediction_text": "Classical element fire"}
{"answers": {"text": ["Pneumatica", "Pneumatica", "Pneumatica", "Pneumatica", "Pneumatica"], "answer_start": [178, 178, 178, 178, 178]}, "prediction_text": "Pneumatica"}
{"answers": {"text": ["Leonardo da Vinci", "Leonardo da Vinci", "Leonardo da Vinci", "Leonardo da Vinci", "da Vinci"], "answer_start": [529, 529, 529, 529, 538]}, "prediction_text": "Leonardo da Vinci"}
{"answers": {"text": ["air", "air", "air", "air"], "answer_start": [600, 600, 600, 600]}, "prediction_text": "Part of air"}
{"answers": {"text": ["heat or a spark", "oxygen", "an ignition event", "an ignition event, such as heat or a spark", "an ignition event"], "answer_start": [195, 31, 168, 168, 168]}, "prediction_text": "Oxygen is needed."}
{"answers": {"text": ["Oxygen is the oxidant", "the oxidant", "oxidant", "oxidant", "oxidant"], "answer_start": [245, 255, 259, 259, 259]}, "prediction_text": "Source of chemical energy"}
{"answers": {"text": ["compounds of oxygen with a high oxidative", "compounds of oxygen with a high oxidative potential", "compounds of oxygen with a high oxidative potential", "compounds of oxygen with a high oxidative potential", "compounds of oxygen with a high oxidative potential"], "answer_start": [398, 398, 398, 398, 398]}, "prediction_text": "Oxygen compounds"}
{"answers": {"text": ["Oxygen", "Oxygen", "Oxygen", "Oxygen", "Oxygen"], "answer_start": [245, 245, 245, 245, 245]}, "prediction_text": "Peroxides"}
{"answers": {"text": ["ignition event", "ignition event", "an ignition event", "ignition event", "an ignition event"], "answer_start": [171, 171, 168, 171, 168]}, "prediction_text": "A spark or heat is needed to trigger combustion."}
{"answers": {"text": ["oxidant", "the oxidant", "oxidant", "the oxidant", "oxidant"], "answer_start": [259, 255, 259, 255, 259]}, "prediction_text": "Oxygen is the oxidant."}
{"answers": {"text": ["rapid combustion", "rapid combustion", "rapid combustion", "rapid combustion", "rapid combustion"], "answer_start": [46, 46, 46, 46, 46]}, "prediction_text": "Rapid combustion"}
{"answers": {"text": ["chemical energy", "chemical energy", "chemical energy", "most of the chemical energy"], "answer_start": [325, 325, 325, 313]}, "prediction_text": "Oxygen the basis for combustion."}
{"answers": {"text": ["compounds of oxygen", "peroxides, chlorates, nitrates, perchlorates, and dichromates", "peroxides, chlorates, nitrates, perchlorates, and dichromates", "peroxides, chlorates, nitrates, perchlorates, and dichromates", "peroxides, chlorates, nitrates, perchlorates, and dichromates"], "answer_start": [398, 459, 459, 459, 459]}, "prediction_text": "Peroxides, chlorates, nitrates, perchlorates."}
{"answers": {"text": ["pure O"], "answer_start": [435]}, "prediction_text": "Pure O"}
{"answers": {"text": ["oxygen", "oxygen", "oxygen"], "answer_start": [160, 160, 160]}, "prediction_text": "Concentrated O"}
{"answers": {"text": ["1\u20443", "1\u20443", "1\u20443", "1\u20443", "1\u20443 normal pressure"], "answer_start": [507, 507, 507, 507, 507]}, "prediction_text": "1\u20443 normal pressure"}
{"answers": {"text": ["special training", "special training", "special training to ensure that ignition sources are minimized", "special training", "special training"], "answer_start": [252, 252, 252, 252, 252]}, "prediction_text": "Training is required."}
{"answers": {"text": ["combustion", "combustion", "combustion", "combustion", "combustion"], "answer_start": [28, 28, 28, 28, 28]}, "prediction_text": "combustion"}
{"answers": {"text": ["storage vessels", "fire", "ensure that ignition sources are minimized", "special training to ensure that ignition sources are minimized"], "answer_start": [93, 320, 272, 252]}, "prediction_text": "Preventive measures are needed."}
{"answers": {"text": ["special training", "special training", "special training to ensure that ignition sources are minimized", "special training", "special training"], "answer_start": [252, 252, 252, 252, 252]}, "prediction_text": "Fuel and O"}
{"answers": {"text": ["Apollo 1 crew", "the Apollo 1 crew", "the Apollo 1 crew", "Apollo 1 crew", "the Apollo 1 crew"], "answer_start": [341, 337, 337, 341, 337]}, "prediction_text": "Apollo 1 crew"}
{"answers": {"text": ["oxides of silicon", "silicon", "silicon"], "answer_start": [148, 158, 158]}, "prediction_text": "Oxides of silicon"}
{"answers": {"text": ["carbon dioxide", "carbon dioxide", "carbon dioxide", "carbon dioxide"], "answer_start": [71, 71, 71, 71]}, "prediction_text": "Carbon dioxide (CO 2 )"}
{"answers": {"text": ["mantle", "mantle", "mantle", "The Earth's mantle", "mantle"], "answer_start": [508, 508, 508, 496, 508]}, "prediction_text": "Silicates of magnesium and iron."}
{"answers": {"text": ["carbon dioxide", "carbon dioxide"], "answer_start": [71, 71]}, "prediction_text": "Carbon dioxide"}
{"answers": {"text": ["Earth's crustal rock", "crustal rock", "Earth's crust", "The Earth's crust", "crustal rock"], "answer_start": [98, 106, 384, 94, 106]}, "prediction_text": "Earth's crust"}
{"answers": {"text": ["Earth's mantle", "The Earth's mantle", "mantle", "The Earth's mantle", "mantle"], "answer_start": [500, 496, 508, 496, 508]}, "prediction_text": "Earth's mantle"}
{"answers": {"text": ["mantle", "The Earth's mantle", "mantle", "The Earth's mantle", "mantle"], "answer_start": [508, 496, 508, 496, 508]}, "prediction_text": "Earth's mantle"}
{"answers": {"text": ["complex silicates", "complex silicates", "silicates", "silicates", "silicates (in silicate minerals)"], "answer_start": [454, 454, 462, 462, 462]}, "prediction_text": "Aluminium, aluminium, iron, calcium carbonate."}
{"answers": {"text": ["monatomic", "monatomic", "monatomic", "monatomic", "monatomic"], "answer_start": [72, 72, 72, 72, 72]}, "prediction_text": "Monatomic and atomic ratios"}
{"answers": {"text": ["simplest", "simplest", "simplest", "simplest", "the simplest"], "answer_start": [138, 138, 138, 138, 134]}, "prediction_text": "Simple atomic ratios"}
{"answers": {"text": ["HO", "HO", "HO", "HO", "HO"], "answer_start": [243, 243, 243, 243, 243]}, "prediction_text": "HO, 8 times more than hydrogen."}
{"answers": {"text": ["hydrogen", "hydrogen", "hydrogen", "hydrogen", "hydrogen"], "answer_start": [456, 456, 456, 456, 456]}, "prediction_text": "Hydrogen"}
{"answers": {"text": ["Avogadro's law", "Avogadro's law", "Avogadro's law", "the correct interpretation of water's composition", "Avogadro's law"], "answer_start": [613, 613, 613, 534, 613]}, "prediction_text": "Avogadro's law"}
{"answers": {"text": ["phlogiston", "phlogiston", "phlogiston", "phlogiston", "phlogiston"], "answer_start": [237, 112, 112, 112, 112]}, "prediction_text": "Phlogiston"}
{"answers": {"text": ["non-combustible", "non-combustible substances that corrode", "wood", "wood"], "answer_start": [132, 132, 530, 530]}, "prediction_text": "Wood or coal"}
{"answers": {"text": ["Air", "Air", "Air", "Air", "a substance like wood gains overall weight in burning"], "answer_start": [210, 210, 210, 210, 513]}, "prediction_text": "No quantitative experiments were conducted."}
{"answers": {"text": ["metals", "metals", "metals", "metals", "metals"], "answer_start": [711, 711, 711, 711, 711]}, "prediction_text": "Wood"}
{"answers": {"text": ["become lighter", "appear to become lighter", "appear to become lighter", "appear to become lighter and seem to lose something in the process", "lighter"], "answer_start": [441, 431, 431, 431, 448]}, "prediction_text": "Loss of phlogiston"}
{"answers": {"text": ["covalent double bond", "a covalent double bond", "a covalent double bond that results from the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms", "a covalent double bond", "a covalent double bond that results from the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms"], "answer_start": [182, 180, 180, 180, 180]}, "prediction_text": "As a covalent double bond"}
{"answers": {"text": ["two", "two", "two", "two", "two"], "answer_start": [367, 367, 367, 367, 367]}, "prediction_text": "Two oxygen atoms are bonded to each other."}
{"answers": {"text": ["Aufbau", "Aufbau", "Aufbau", "Aufbau", "Aufbau"], "answer_start": [459, 459, 459, 459, 459]}, "prediction_text": "Covalent double bond"}
{"answers": {"text": ["chemically", "chemically", "a covalent double bond", "a covalent double bond", "a covalent double bond"], "answer_start": [43, 43, 180, 180, 180]}, "prediction_text": "Through chemical bonding"}
{"answers": {"text": ["molecular orbitals", "filling of molecular orbitals", "the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms", "the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms", "the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms"], "answer_start": [236, 225, 221, 221, 221]}, "prediction_text": "Fill of molecular orbitals"}
{"answers": {"text": ["1773", "1773", "1773", "1773", "1773 or earlier"], "answer_start": [76, 76, 76, 76, 76]}, "prediction_text": "1773 or earlier"}
{"answers": {"text": ["1774", "1774", "1774", "1774", "1774"], "answer_start": [131, 131, 131, 131, 131]}, "prediction_text": "1774"}
{"answers": {"text": ["work was published first", "his work was published first", "his work was published first", "his work was published first", "published first"], "answer_start": [187, 183, 183, 183, 196]}, "prediction_text": "Antoine Lavoisier's experiments with oxygen"}
{"answers": {"text": ["Antoine Lavoisier", "Antoine Lavoisier", "Antoine Lavoisier", "Antoine Lavoisier", "Lavoisier"], "answer_start": [251, 251, 251, 251, 259]}, "prediction_text": "Joseph Priestley"}
{"answers": {"text": ["phlogiston theory", "phlogiston theory of combustion and corrosion", "phlogiston theory of combustion and corrosion", "phlogiston theory of combustion and corrosion", "phlogiston theory"], "answer_start": [337, 337, 337, 337, 337]}, "prediction_text": "Phlogiston theory"}
{"answers": {"text": ["spin triplet state", "spin triplet state", "spin triplet state", "spin triplet state", "a spin triplet state"], "answer_start": [353, 353, 353, 353, 351]}, "prediction_text": "Double bond"}
{"answers": {"text": ["triplet oxygen", "O", "triplet oxygen", "triplet oxygen", "triplet oxygen"], "answer_start": [435, 404, 435, 435, 435]}, "prediction_text": "Triplet oxygen"}
{"answers": {"text": ["unpaired electrons", "its unpaired electrons", "its unpaired electrons", "Because of its unpaired electrons", "unpaired electrons"], "answer_start": [595, 591, 591, 580, 595]}, "prediction_text": "Pairing electron spins"}
{"answers": {"text": ["spontaneous", "spontaneous combustion", "spontaneous", "spontaneous", "spontaneous combustion"], "answer_start": [726, 726, 726, 726, 726]}, "prediction_text": "spontaneous combustion"}
{"answers": {"text": ["antibonding", "antibonding", "antibonding", "antibonding", "antibonding"], "answer_start": [504, 504, 504, 504, 504]}, "prediction_text": "Antibonding"}
{"answers": {"text": ["air", "air", "air", "part of the trapped air", "air"], "answer_start": [149, 234, 234, 214, 234]}, "prediction_text": "Air rushed in."}
{"answers": {"text": ["weight", "weight", "weight", "that increase was the same as the weight of the air that rushed back in", "the tin had increased in weight and that increase was the same as the weight of the air that rushed back in"], "answer_start": [301, 301, 301, 312, 276]}, "prediction_text": "Increased in weight."}
{"answers": {"text": ["weight", "weight", "weight", "weight", "weight"], "answer_start": [346, 301, 346, 346, 346]}, "prediction_text": "Azote"}
{"answers": {"text": ["1777", "1777", "1777", "1777", "1777"], "answer_start": [507, 507, 507, 507, 507]}, "prediction_text": "1777"}
{"answers": {"text": ["azote", "azote", "azote", "azote", "azote"], "answer_start": [640, 640, 640, 640, 640]}, "prediction_text": "Tin"}
{"answers": {"text": ["ozone", "ozone", "ozone", "Trioxygen", "Ozone"], "answer_start": [36, 36, 36, 0, 118]}, "prediction_text": "Trioxygen"}
{"answers": {"text": ["allotrope", "allotrope", "allotrope", "allotrope", "allotrope"], "answer_start": [65, 65, 65, 65, 65]}, "prediction_text": "Ozone is a reactive part of oxygen."}
{"answers": {"text": ["lung tissue", "lung tissue", "lung tissue", "lung", "lung tissue"], "answer_start": [105, 105, 105, 105, 105]}, "prediction_text": "Ozone damages lung tissue."}
{"answers": {"text": ["protective radiation shield", "protective radiation shield", "protective radiation shield", "radiation shield", "a protective radiation shield"], "answer_start": [375, 375, 375, 386, 373]}, "prediction_text": "As a radiation shield"}
{"answers": {"text": ["UV", "ultraviolet", "UV", "ultraviolet (UV)", "ultraviolet"], "answer_start": [293, 229, 293, 229, 229]}, "prediction_text": "UV radiation"}
{"answers": {"text": ["dioxygen", "dioxygen", "dioxygen", "dioxygen"], "answer_start": [60, 60, 60, 60]}, "prediction_text": "Dioxygen"}
{"answers": {"text": ["O2"], "answer_start": [155]}, "prediction_text": "Dioxygen"}
{"answers": {"text": ["major", "major", "major", "a major part", "major"], "answer_start": [100, 100, 100, 98, 100]}, "prediction_text": "Dioxygen"}
{"answers": {"text": ["energy content", "its energy content", "energy content", "energy content", "its energy content"], "answer_start": [406, 402, 406, 406, 402]}, "prediction_text": "Exothermic reaction"}
{"answers": {"text": ["cellular respiration", "cellular respiration", "cellular respiration", "in cellular respiration", "cellular respiration"], "answer_start": [479, 479, 479, 476, 479]}, "prediction_text": "Cellular respiration"}
{"answers": {"text": ["James Dewar", "James Dewar", "James Dewar", "Dewar", "James Dewar"], "answer_start": [25, 25, 25, 31, 25]}, "prediction_text": "James Dewar"}
{"answers": {"text": ["1891", "1891", "1891", "1891", "1891"], "answer_start": [3, 3, 3, 3, 3]}, "prediction_text": "1895"}
{"answers": {"text": ["1895", "1895", "1895", "1895", "1895"], "answer_start": [185, 185, 185, 185, 185]}, "prediction_text": "1895"}
{"answers": {"text": ["oxyacetylene", "oxyacetylene welding", "oxyacetylene welding", "oxyacetylene welding", "oxyacetylene"], "answer_start": [430, 430, 430, 430, 430]}, "prediction_text": "Oxyacetylene welding"}
{"answers": {"text": ["Oxygen", "Oxygen", "Oxygen", "Oxygen", "Oxygen"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["temperature", "temperature", "temperature", "temperature", "temperature"], "answer_start": [253, 253, 253, 253, 253]}, "prediction_text": "Temperature-dependent"}
{"answers": {"text": ["6.04 milliliters", "6.04 milliliters", "6.04 milliliters", "6.04 milliliters", "6.04 milliliters"], "answer_start": [441, 441, 441, 441, 441]}, "prediction_text": "6.04 mL (50% more)"}
{"answers": {"text": ["seawater", "seawater", "seawater", "seawater", "sea water"], "answer_start": [492, 492, 492, 492, 659]}, "prediction_text": "At 25 \u00b0C and 1 standard atmosphere (101.3 kPa) of air."}
{"answers": {"text": ["twice", "50% more", "about twice as much", "twice as much", "twice"], "answer_start": [286, 579, 280, 286, 286]}, "prediction_text": "14.6 mg\u00b7L\u22121"}
{"answers": {"text": ["most abundant", "most", "most abundant", "most abundant", "most abundant"], "answer_start": [14, 14, 14, 14, 14]}, "prediction_text": "Third most abundant chemical element"}
{"answers": {"text": ["third", "third", "third", "third most abundant", "third"], "answer_start": [112, 112, 112, 112, 112]}, "prediction_text": "Third most abundant chemical element"}
{"answers": {"text": ["0.9%", "0.9%", "About 0.9%", "0.9%", "0.9%"], "answer_start": [199, 199, 193, 199, 199]}, "prediction_text": "About 0.9%"}
{"answers": {"text": ["world's oceans", "the world's oceans", "in the Earth's biosphere, air, sea and land", "oceans", "the world's oceans"], "answer_start": [321, 317, 53, 329, 317]}, "prediction_text": "Earth's crust"}
{"answers": {"text": ["ultraviolet radiation", "ultraviolet radiation", "ultraviolet radiation impacting oxygen-containing molecules", "ultraviolet radiation impacting oxygen-containing molecules", "ultraviolet radiation impacting oxygen-containing molecules such as carbon dioxide"], "answer_start": [760, 760, 760, 760, 760]}, "prediction_text": "Through ultraviolet radiation"}
{"answers": {"text": ["late 19th", "19th", "19th", "late 19th century", "19th"], "answer_start": [7, 12, 12, 7, 12]}, "prediction_text": "Late 19th century"}
{"answers": {"text": ["compressing and cooling", "compressing and cooling", "cascade method", "compressing and cooling it", "compressing and cooling"], "answer_start": [106, 106, 142, 106, 106]}, "prediction_text": "By compressing and cooling it."}
{"answers": {"text": ["Raoul Pierre Pictet", "Raoul Pierre Pictet", "Pierre Pictet", "Pictet", "Raoul Pierre Pictet"], "answer_start": [186, 186, 192, 199, 186]}, "prediction_text": "Raoul Pierre Pictet"}
{"answers": {"text": ["few drops", "a few drops", "a few drops", "a few drops", "Only a few drops"], "answer_start": [594, 592, 592, 592, 587]}, "prediction_text": "No meaningful analysis could be conducted."}
{"answers": {"text": ["March 29, 1883", "March 29, 1883", "March 29, 1883", "March 29, 1883", "March 29, 1883"], "answer_start": [752, 752, 752, 752, 752]}, "prediction_text": "March 29, 1883"}
{"answers": {"text": ["Sun", "the Sun", "the Sun", "Sun", "the Sun"], "answer_start": [212, 208, 208, 212, 208]}, "prediction_text": "The Sun"}
{"answers": {"text": ["oxygen-16", "oxygen-16", "oxygen-16", "oxygen-16", "oxygen-16"], "answer_start": [442, 442, 442, 442, 442]}, "prediction_text": "Oxygen-16"}
{"answers": {"text": ["Genesis spacecraft", "Genesis", "Genesis", "Genesis", "Genesis"], "answer_start": [373, 373, 373, 373, 373]}, "prediction_text": "Genesis spacecraft"}
{"answers": {"text": ["unknown", "an unknown process", "unknown", "unknown", "an unknown process"], "answer_start": [505, 502, 505, 505, 502]}, "prediction_text": "An unknown process"}
{"answers": {"text": ["Earth", "Earth", "Earth", "the Earth", "Earth"], "answer_start": [643, 643, 643, 639, 643]}, "prediction_text": "The Earth"}
{"answers": {"text": ["Singlet", "Singlet oxygen", "Singlet oxygen", "Singlet", "Singlet oxygen"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Singlet oxygen"}
{"answers": {"text": ["organic molecules", "common organic molecules", "common organic molecules", "common organic molecules", "common organic molecules"], "answer_start": [165, 158, 158, 158, 158]}, "prediction_text": "Molecular oxygen"}
{"answers": {"text": ["photosynthesis", "photosynthesis", "photosynthesis", "photosynthesis", "photosynthesis"], "answer_start": [279, 279, 279, 279, 279]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["photolysis of ozone", "photolysis of ozone", "photolysis of ozone by light of short wavelength", "photolysis of ozone by light of short wavelength", "photolysis"], "answer_start": [371, 371, 371, 371, 371]}, "prediction_text": "Photolysis of ozone by light of short wavelength"}
{"answers": {"text": ["Carotenoids", "Carotenoids", "Carotenoids", "Carotenoids", "Carotenoids"], "answer_start": [476, 476, 476, 476, 476]}, "prediction_text": "Carotenoids"}
{"answers": {"text": ["Paleoclimatologists", "Paleoclimatologists", "Paleoclimatologists", "Paleoclimatologists", "Paleoclimatologists"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Paleoclimatologists"}
{"answers": {"text": ["climate", "climate", "temperatures", "climate", "what the climate was like millions of years ago"], "answer_start": [135, 135, 401, 135, 126]}, "prediction_text": "Lower global temperatures"}
{"answers": {"text": ["12%", "12%", "12%", "12%", "12%"], "answer_start": [344, 344, 344, 344, 344]}, "prediction_text": "12% heavier"}
{"answers": {"text": ["oxygen-18", "oxygen-18", "oxygen-16", "oxygen-18", "oxygen-18"], "answer_start": [585, 585, 523, 585, 585]}, "prediction_text": "Oxygen-18"}
{"answers": {"text": ["lower global temperatures", "periods of lower global temperatures", "lower temperatures", "periods of lower global temperatures", "lower global temperatures"], "answer_start": [433, 422, 395, 422, 433]}, "prediction_text": "Lower temperatures"}
{"answers": {"text": ["687 and 760 nm", "687 and 760 nm", "687 and 760 nm", "687 and 760 nm", "687 and 760 nm"], "answer_start": [83, 83, 83, 83, 83]}, "prediction_text": "687 nm"}
{"answers": {"text": ["carbon cycle", "plant health status", "the carbon cycle", "plant health status", "carbon cycle"], "answer_start": [635, 245, 631, 245, 635]}, "prediction_text": "Carbon cycle"}
{"answers": {"text": ["satellite platform", "a satellite platform", "satellites", "a satellite platform", "satellite"], "answer_start": [272, 270, 653, 270, 272]}, "prediction_text": "From vegetation canopies"}
{"answers": {"text": ["global", "a global scale", "global", "global", "a global scale"], "answer_start": [669, 667, 669, 669, 667]}, "prediction_text": "Global scale"}
{"answers": {"text": ["remote sensing", "remote", "remote", "remote sensing", "remote"], "answer_start": [104, 104, 104, 104, 104]}, "prediction_text": "Satellite platform"}
{"answers": {"text": ["paramagnetic", "paramagnetic", "paramagnetic", "paramagnetic", "paramagnetic"], "answer_start": [39, 39, 39, 39, 39]}, "prediction_text": "Magnetic character"}
{"answers": {"text": ["Liquid oxygen", "liquid oxygen", "liquid oxygen", "oxygen", "liquid oxygen"], "answer_start": [299, 409, 409, 416, 409]}, "prediction_text": "Liquid oxygen"}
{"answers": {"text": ["unpaired electrons", "unpaired electrons", "unpaired electrons", "unpaired electrons in the molecule", "unpaired electrons"], "answer_start": [195, 195, 195, 195, 195]}, "prediction_text": "Unpaired electrons"}
{"answers": {"text": ["magnetic field", "magnetic", "magnetic", "magnetic field", "magnetic"], "answer_start": [135, 171, 135, 135, 135]}, "prediction_text": "Magnetic field"}
{"answers": {"text": ["powerful magnet", "a powerful magnet", "a powerful magnet", "a powerful magnet", "magnet"], "answer_start": [486, 484, 484, 484, 495]}, "prediction_text": "A powerful magnet"}
{"answers": {"text": ["dangerous by-products", "the immune system", "hypersensitive response of plants against pathogen attack", "dangerous by-products of oxygen use in organisms"], "answer_start": [91, 150, 325, 91]}, "prediction_text": "Peroxide, superoxide, and singlet oxygen."}
{"answers": {"text": ["destroy invading microbes", "to destroy invading microbes", "destroy invading microbes", "to destroy invading microbes", "destroy invading microbes"], "answer_start": [239, 236, 239, 236, 239]}, "prediction_text": "To destroy invading microbes."}
{"answers": {"text": ["pathogen attack", "pathogen attack", "pathogen attack", "pathogen attack", "pathogen"], "answer_start": [367, 367, 367, 367, 367]}, "prediction_text": "Against pathogen attack"}
{"answers": {"text": ["anaerobic", "obligately anaerobic organisms", "obligately anaerobic", "obligately anaerobic", "obligately anaerobic organisms"], "answer_start": [414, 403, 403, 403, 403]}, "prediction_text": "Anaerobic organisms"}
{"answers": {"text": ["2.5 billion years ago", "2.5 billion years ago", "about 2.5 billion years ago", "about 2.5 billion years ago", "2.5 billion years ago during the Great Oxygenation Event"], "answer_start": [541, 541, 535, 535, 541]}, "prediction_text": "About 2.5 billion years ago"}
{"answers": {"text": ["90.20 K", "90.20 K", "90.20 K (\u2212182.95 \u00b0C, \u2212297.31 \u00b0F)", "90.20 K", "90.20 K (\u2212182.95 \u00b0C, \u2212297.31 \u00b0F)"], "answer_start": [20, 20, 20, 20, 20]}, "prediction_text": "90.20 K (\u2212182.95 \u00b0C, \u2212297.31 \u00b0F)"}
{"answers": {"text": ["clear", "clear substances with a light sky-blue color", "clear", "clear", "clear"], "answer_start": [133, 133, 133, 133, 133]}, "prediction_text": "Clearness is due to absorption in red."}
{"answers": {"text": ["liquefied air", "liquefied air", "liquefied air", "air", "liquefied air"], "answer_start": [384, 384, 384, 394, 384]}, "prediction_text": "Liquid nitrogen"}
{"answers": {"text": ["liquid nitrogen", "liquid nitrogen", "liquid nitrogen", "liquid nitrogen", "nitrogen"], "answer_start": [468, 468, 468, 468, 475]}, "prediction_text": "Liquid nitrogen"}
{"answers": {"text": ["combustible materials", "combustible materials", "combustible", "combustible", "combustible materials"], "answer_start": [560, 560, 560, 560, 560]}, "prediction_text": "combustible materials"}
{"answers": {"text": ["water", "in solution in the world's water bodies", "the world's water bodies"], "answer_start": [51, 24, 39]}, "prediction_text": "In solution"}
{"answers": {"text": ["lower", "lower", "lower", "lower", "lower temperatures"], "answer_start": [100, 100, 100, 100, 100]}, "prediction_text": "Lower temperatures"}
{"answers": {"text": ["higher oxygen content", "higher oxygen content", "higher oxygen content", "higher oxygen content", "due to their higher oxygen content"], "answer_start": [255, 255, 255, 255, 242]}, "prediction_text": "Higher oxygen content."}
{"answers": {"text": ["algae", "algae", "algae", "algae", "algae"], "answer_start": [369, 369, 369, 369, 369]}, "prediction_text": "algae"}
{"answers": {"text": ["biochemical oxygen demand", "biochemical oxygen demand", "measuring the water's biochemical oxygen demand", "biochemical oxygen demand", "measuring the water's biochemical oxygen demand"], "answer_start": [591, 591, 569, 591, 569]}, "prediction_text": "Water biochemical oxygen demand"}
{"answers": {"text": ["3.5 billion years ago", "about 3.5 billion years ago", "about 3.5 billion years ago", "3.5 billion years ago", "about 3.5 billion years ago"], "answer_start": [128, 122, 122, 128, 122]}, "prediction_text": "About 3.5 billion years ago."}
{"answers": {"text": ["Paleoproterozoic", "Paleoproterozoic", "Paleoproterozoic", "Paleoproterozoic", "the Paleoproterozoic eon"], "answer_start": [215, 215, 215, 215, 211]}, "prediction_text": "3.0 to 2.3 billion years ago"}
{"answers": {"text": ["banded iron formations", "banded iron formations", "banded iron formations", "banded iron formations", "banded iron"], "answer_start": [401, 401, 401, 401, 401]}, "prediction_text": "Banded iron formations"}
{"answers": {"text": ["1.7 billion years ago", "1.7 billion years ago", "1.7 billion years ago", "1.7 billion years ago", "around 1.7 billion years ago"], "answer_start": [576, 576, 576, 576, 569]}, "prediction_text": "Around 1.7 billion years ago."}
{"answers": {"text": ["3\u20132.7 billion years ago", "3\u20132.7 billion years ago", "3\u20132.7 billion years ago", "3\u20132.7 billion years ago", "3\u20132.7 billion years ago"], "answer_start": [510, 510, 510, 510, 510]}, "prediction_text": "Around 1.7 billion years ago."}
{"answers": {"text": ["oxygen cycle", "the oxygen cycle", "oxygen cycle", "oxygen cycle", "the oxygen cycle"], "answer_start": [77, 73, 77, 77, 73]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["biogeochemical", "biogeochemical", "biogeochemical", "biogeochemical cycle", "biogeochemical"], "answer_start": [96, 96, 96, 96, 96]}, "prediction_text": "Biogeochemical cycle"}
{"answers": {"text": ["three", "three", "three", "three main reservoirs", "three"], "answer_start": [173, 173, 173, 173, 173]}, "prediction_text": "Three places"}
{"answers": {"text": ["photosynthesis", "photosynthesis", "photosynthesis", "photosynthesis", "photosynthesis"], "answer_start": [304, 304, 304, 304, 304]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["oxygen", "oxygen", "oxygen", "oxygen", "oxygen"], "answer_start": [396, 288, 396, 396, 396]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["zeolite molecular sieves", "zeolite molecular sieves", "passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves", "passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves, which absorbs the nitrogen", "passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves"], "answer_start": [127, 127, 53, 53, 53]}, "prediction_text": "Pressure swing adsorption"}
{"answers": {"text": ["90% to 93%", "90% to 93%", "90% to 93%", "90% to 93%", "90% to 93%"], "answer_start": [214, 214, 214, 214, 214]}, "prediction_text": "90% to 93%"}
{"answers": {"text": ["nitrogen", "nitrogen", "nitrogen", "nitrogen", "nitrogen"], "answer_start": [171, 246, 171, 171, 171]}, "prediction_text": "Nitrogen"}
{"answers": {"text": ["non-cryogenic", "non-cryogenic", "non-cryogenic", "non-cryogenic", "non-cryogenic"], "answer_start": [717, 717, 717, 717, 717]}, "prediction_text": "Vacuum swing adsorption"}
{"answers": {"text": ["major method", "increasingly", "major method", "increasingly"], "answer_start": [10, 686, 10, 686]}, "prediction_text": "90% to 93% O2 gas"}
{"answers": {"text": ["water", "water", "water", "water"], "answer_start": [56, 56, 56, 56]}, "prediction_text": "Water"}
{"answers": {"text": ["oxygen and hydrogen", "oxygen and hydrogen", "molecular oxygen and hydrogen", "molecular oxygen and hydrogen", "Oxygen gas"], "answer_start": [77, 77, 67, 67, 0]}, "prediction_text": "Oxygen gas"}
{"answers": {"text": ["DC", "DC electricity", "DC", "DC electricity"], "answer_start": [98, 98, 98, 98]}, "prediction_text": "High pressure or an electric current"}
{"answers": {"text": ["oxides and oxoacids", "oxides and oxoacids", "oxides and oxoacids", "oxides and oxoacids", "oxides and oxoacids"], "answer_start": [535, 535, 535, 535, 535]}, "prediction_text": "Water"}
{"answers": {"text": ["Chemical", "Chemical", "Chemical", "chemical oxygen generators or oxygen candles", "Chemical"], "answer_start": [556, 556, 556, 607, 556]}, "prediction_text": "Chemical catalysts"}
{"answers": {"text": ["recreational", "recreational", "recreational"], "answer_start": [54, 54, 54]}, "prediction_text": "In oxygen bars"}
{"answers": {"text": ["mild euphoric", "a supposed mild euphoric", "a supposed mild euphoric", "euphoric"], "answer_start": [22, 11, 11, 27]}, "prediction_text": "Induced performance boost."}
{"answers": {"text": ["performance", "performance", "performance", "performance", "a \"boost\" in performance"], "answer_start": [406, 406, 406, 406, 393]}, "prediction_text": "Performance"}
{"answers": {"text": ["placebo", "placebo", "placebo", "a placebo effect", "placebo"], "answer_start": [461, 461, 461, 459, 461]}, "prediction_text": "Performance boost"}
{"answers": {"text": ["aerobic", "aerobic", "aerobic", "aerobic", "aerobic exercise"], "answer_start": [612, 612, 612, 612, 612]}, "prediction_text": "aerobic exercise"}
{"answers": {"text": ["Hyperbaric (high-pressure) medicine", "special oxygen chambers", "oxygen chambers", "oxygen chambers", "oxygen chambers"], "answer_start": [0, 41, 49, 49, 49]}, "prediction_text": "Carbon monoxide poisoning devices"}
{"answers": {"text": ["carbon monoxide", "carbon monoxide", "carbon monoxide", "carbon monoxide", "carbon monoxide"], "answer_start": [345, 345, 345, 345, 345]}, "prediction_text": "Carbon monoxide"}
{"answers": {"text": ["anaerobic bacteria", "anaerobic bacteria", "anaerobic bacteria", "anaerobic bacteria", "anaerobic bacteria"], "answer_start": [427, 427, 427, 427, 427]}, "prediction_text": "Carbon monoxide"}
{"answers": {"text": ["Decompression sickness", "bubbles of inert gas, mostly nitrogen and helium, forming in their blood", "Decompression sickness", "decompression sickness (the 'bends')", "Decompression sickness"], "answer_start": [523, 617, 523, 206, 523]}, "prediction_text": "Decompression sickness occurs."}
{"answers": {"text": ["Oxygen therapy", "Oxygen therapy", "Oxygen therapy", "Oxygen therapy", "Oxygen therapy"], "answer_start": [314, 314, 314, 314, 314]}, "prediction_text": "Oxygen therapy"}
{"answers": {"text": ["heart", "the heart", "heart", "the heart", "heart"], "answer_start": [307, 303, 307, 303, 373]}, "prediction_text": "Heart"}
{"answers": {"text": ["oxygen supplementation", "oxygen supplementation", "oxygen supplementation", "Oxygen therapy", "Oxygen therapy"], "answer_start": [71, 71, 71, 314, 314]}, "prediction_text": "Oxygen supplementation"}
{"answers": {"text": ["respiration", "respiration", "respiration", "respiration", "respiration"], "answer_start": [55, 55, 55, 55, 55]}, "prediction_text": "Receptivity to blood flow"}
{"answers": {"text": ["gaseous oxygen.", "gaseous oxygen", "gaseous oxygen", "oxygen", "gaseous oxygen"], "answer_start": [547, 547, 547, 555, 547]}, "prediction_text": "Gaseous oxygen"}
{"answers": {"text": ["electronegativity", "electronegativity", "electronegativity", "electronegativity", "electronegativity"], "answer_start": [11, 11, 11, 11, 11]}, "prediction_text": "Electonegativity"}
{"answers": {"text": ["oxides", "oxides", "oxides", "oxides", "oxides"], "answer_start": [111, 111, 111, 111, 111]}, "prediction_text": "Non-stoichiometric compounds"}
{"answers": {"text": ["FeO", "FeO", "FeO", "FeO", "FeO"], "answer_start": [473, 473, 473, 473, 473]}, "prediction_text": "W\u00fcstite is a non-stoichiometric compound with metal less than the chemical formula."}
{"answers": {"text": ["oxide", "a thin film of oxide", "a thin film of oxide", "oxide", "a thin film of oxide"], "answer_start": [253, 238, 238, 253, 238]}, "prediction_text": "Oxides form on metals."}
{"answers": {"text": ["corrosion", "further corrosion", "further corrosion", "further corrosion", "corrosion"], "answer_start": [303, 295, 295, 295, 303]}, "prediction_text": "Cracks and corrosion."}
{"answers": {"text": ["cabin depressurization", "cabin depressurization", "cabin depressurization", "cabin depressurization", "depressurization"], "answer_start": [251, 251, 251, 251, 257]}, "prediction_text": "Cushion depressurization"}
{"answers": {"text": ["chemical", "chemical oxygen", "chemical", "chemical oxygen generators", "chemical"], "answer_start": [312, 312, 312, 312, 312]}, "prediction_text": "Exothermic reaction"}
{"answers": {"text": ["exothermic", "exothermic", "exothermic", "exothermic", "exothermic reaction"], "answer_start": [595, 595, 595, 595, 595]}, "prediction_text": "Exothermic reaction"}
{"answers": {"text": ["oxygen gas", "oxygen", "oxygen", "oxygen", "oxygen"], "answer_start": [560, 560, 560, 560, 560]}, "prediction_text": "Oxygen gas"}
{"answers": {"text": ["storage", "storage", "storage methods", "storage", "storage methods"], "answer_start": [7, 7, 7, 7, 7]}, "prediction_text": "Storage and transportation."}
{"answers": {"text": ["insulated tankers", "insulated tankers", "insulated tankers", "specially insulated tankers"], "answer_start": [179, 179, 179, 169]}, "prediction_text": "In smaller cylinders"}
{"answers": {"text": ["liquid", "as a liquid", "liquid", "as a liquid in specially insulated tankers"], "answer_start": [159, 154, 159, 154]}, "prediction_text": "In insulated tankers"}
{"answers": {"text": ["compressed gas", "compressed gas", "compressed gas;", "compressed gas", "compressed gas"], "answer_start": [691, 691, 691, 691, 691]}, "prediction_text": "Oxygen is stored and shipped in smaller cylinders."}
{"answers": {"text": ["hospitals", "hospitals", "hospitals", "hospitals", "hospitals"], "answer_start": [414, 414, 414, 414, 414]}, "prediction_text": "Hospitals and other institutions"}
{"answers": {"text": ["organic solvents", "organic solvents", "organic solvents", "solvents", "organic solvents"], "answer_start": [309, 309, 309, 317, 309]}, "prediction_text": "Acetone"}
{"answers": {"text": ["organic compounds", "organic", "solvents", "organic solvents"], "answer_start": [36, 36, 317, 309]}, "prediction_text": "Organic compounds"}
{"answers": {"text": ["feeder materials", "as feeder materials", "feeder materials", "feeder materials", "as feeder materials"], "answer_start": [546, 543, 546, 546, 543]}, "prediction_text": "Feeder materials in the manufacture of many different substances."}
{"answers": {"text": ["Epoxides", "Epoxides", "Epoxides", "Epoxides", "Epoxides"], "answer_start": [755, 755, 755, 755, 755]}, "prediction_text": "Epoxides"}
{"answers": {"text": ["important", "important", "important", "important"], "answer_start": [15, 616, 299, 299]}, "prediction_text": "Used as feeder materials in the synthesis of many different substances."}
{"answers": {"text": ["biomolecules", "biomolecules", "biomolecules", "biomolecules", "almost all biomolecules that are important to (or generated by) life"], "answer_start": [35, 35, 35, 35, 24]}, "prediction_text": "Organic compounds"}
{"answers": {"text": ["Only a few", "Only a few", "a few", "Only a few", "a few"], "answer_start": [94, 94, 99, 94, 99]}, "prediction_text": "Only a few common complex biomolecules"}
{"answers": {"text": ["carbohydrates", "carbohydrates", "carbohydrates", "carbohydrates", "carbohydrates"], "answer_start": [241, 241, 241, 241, 241]}, "prediction_text": "Carbonyl groups"}
{"answers": {"text": ["proteins", "proteins", "proteins", "proteins", "proteins"], "answer_start": [345, 345, 345, 345, 345]}, "prediction_text": "Carbonyl groups in fats and fatty acids."}
{"answers": {"text": ["bones", "bones", "bones", "bones", "bones"], "answer_start": [656, 656, 656, 656, 656]}, "prediction_text": "Bone"}
{"answers": {"text": ["Oxygen toxicity", "Oxygen toxicity", "Oxygen toxicity", "Oxygen toxicity", "Oxygen toxicity to the lungs and central nervous system"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Peripheral neuropathy"}
{"answers": {"text": ["pulmonary fibrosis", "permanent pulmonary fibrosis", "permanent pulmonary fibrosis", "permanent pulmonary fibrosis", "pulmonary fibrosis"], "answer_start": [238, 228, 228, 228, 238]}, "prediction_text": "Permanent pulmonary fibrosis"}
{"answers": {"text": ["160 kPa", "160 kPa", "160 kPa (about 1.6 atm)", "160 kPa (about 1.6 atm)", "160 kPa"], "answer_start": [307, 307, 307, 307, 307]}, "prediction_text": "21% O"}
{"answers": {"text": ["Acute oxygen toxicity", "Acute oxygen toxicity", "seizures", "seizures", "seizures"], "answer_start": [384, 384, 415, 415, 415]}, "prediction_text": "Acute oxygen toxicity"}
{"answers": {"text": ["seizures", "seizures", "seizures", "seizures", "seizures"], "answer_start": [415, 415, 415, 415, 415]}, "prediction_text": "Convulsions"}
{"answers": {"text": ["low total pressures", "low total pressures used", "low total pressures", "low total pressures", "the low total pressures used"], "answer_start": [145, 145, 145, 145, 141]}, "prediction_text": "Low total pressures used."}
{"answers": {"text": ["30 kPa", "about 30 kPa", "about 30 kPa", "30 kPa", "about 30 kPa (1.4 times normal)"], "answer_start": [266, 260, 260, 266, 260]}, "prediction_text": "About 30 kPa (1.4 times normal)"}
{"answers": {"text": ["1.4 times normal", "1.4 times", "1.4 times", "1.4 times normal", "1.4 times normal"], "answer_start": [274, 274, 274, 274, 274]}, "prediction_text": "About 30 kPa (1.4 times normal)"}
{"answers": {"text": ["no damage", "no damage", "no", "no", "no damage"], "answer_start": [124, 124, 124, 124, 124]}, "prediction_text": "No damage"}
{"answers": {"text": ["only marginally more", "marginally more than normal", "marginally more", "marginally more", "only marginally more"], "answer_start": [369, 374, 374, 374, 369]}, "prediction_text": "Less than normal sea-level O"}
{"answers": {"text": ["at elevated partial pressures", "elevated partial pressures", "at elevated partial pressures", "at elevated partial pressures", "elevated partial pressures"], "answer_start": [30, 33, 30, 30, 33]}, "prediction_text": "At elevated partial pressures"}
{"answers": {"text": ["50 kilopascals", "at partial pressures more than 50 kilopascals", "50 kilopascals", "more than 50 kilopascals", "at partial pressures more than 50 kilopascals"], "answer_start": [185, 154, 185, 175, 154]}, "prediction_text": "At partial pressures more than 50 kilopascals (kPa)"}
{"answers": {"text": ["50% oxygen", "about 50% oxygen composition at standard pressure", "about 50% oxygen composition at standard pressure"], "answer_start": [222, 216, 216]}, "prediction_text": "2.5 times normal sea-level O"}
{"answers": {"text": ["mechanical ventilators", "mechanical ventilators", "mechanical ventilators", "oxygen masks", "mechanical ventilators"], "answer_start": [383, 383, 383, 434, 383]}, "prediction_text": "Medical ventilators"}
{"answers": {"text": ["30%\u201350%", "30%\u201350%", "30%\u201350%", "30%\u201350%"], "answer_start": [501, 501, 501, 501]}, "prediction_text": "30%\u201350%"}
{"answers": {"text": ["October 1973", "October 1973", "October 1973", "October", "1973"], "answer_start": [29, 29, 29, 29, 37]}, "prediction_text": "October 1973"}
{"answers": {"text": ["nearly $12", "$12", "$12", "$12", "$12"], "answer_start": [305, 312, 312, 312, 312]}, "prediction_text": "US$3 per barrel"}
{"answers": {"text": ["1979", "1979", "1979", "1979", "1979"], "answer_start": [550, 550, 550, 550, 550]}, "prediction_text": "1979"}
{"answers": {"text": ["first oil shock", "shock", "shock", "first oil shock", "shock"], "answer_start": [516, 401, 401, 516, 401]}, "prediction_text": "\"Second oil shock\""}
{"answers": {"text": ["members of the Organization of Arab Petroleum Exporting Countries", "members of the Organization of Arab Petroleum Exporting Countries", "Organization of Arab Petroleum Exporting Countries", "members of the Organization of Arab Petroleum Exporting Countries", "OAPEC"], "answer_start": [51, 51, 66, 51, 118]}, "prediction_text": "Organization of Arab Petroleum Exporting Countries (OAPEC)"}
{"answers": {"text": ["to avoid being targeted by the boycott", "to avoid being targeted by the boycott", "to avoid being targeted by the boycott", "to avoid being targeted by the boycott", "to avoid being targeted by the boycott"], "answer_start": [208, 208, 208, 208, 208]}, "prediction_text": "To avoid being targeted by the boycott."}
{"answers": {"text": ["They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights.", "multilateral", "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "multilateral negotiations", "multilateral"], "answer_start": [430, 383, 430, 383, 383]}, "prediction_text": "Through multilateral negotiations"}
{"answers": {"text": ["January 18, 1974,", "January 18, 1974", "January 18, 1974", "January 18, 1974", "January 18, 1974"], "answer_start": [519, 519, 519, 519, 519]}, "prediction_text": "March 1974"}
{"answers": {"text": ["March 1974", "March 1974", "March 1974", "March 1974.", "March 1974"], "answer_start": [782, 782, 782, 782, 782]}, "prediction_text": "March 1974"}
{"answers": {"text": ["On August 15, 1971", "August 15, 1971", "August 15, 1971", "August 15, 1971", "August 15, 1971"], "answer_start": [0, 3, 3, 3, 3]}, "prediction_text": "August 15, 1971"}
{"answers": {"text": ["to \"float\" (rise and fall according to market demand)", "(rise and fall according to market demand", "rise and fall according to market demand", "rise and fall according to market demand", "rise and fall according to market demand"], "answer_start": [277, 288, 289, 289, 289]}, "prediction_text": "Rise and fall according to market demand."}
{"answers": {"text": ["industrialized nations increased their reserves", "industrialized nations increased their reserves (by expanding their money supplies) in amounts far greater than before", "industrialized nations increased their reserves", "industrialized nations increased their reserves", "the industrialized nations increased their reserves"], "answer_start": [560, 560, 560, 560, 556]}, "prediction_text": "Currency values fluctuated unpredictably."}
{"answers": {"text": ["In September 1971", "September 1971", "September 1971", "September 1971", "September 1971"], "answer_start": [843, 846, 846, 846, 846]}, "prediction_text": "From then on, oil producers' real income decreased."}
{"answers": {"text": ["oil was priced in dollars, oil producers' real income decreased", "Because oil was priced in dollars, oil producers' real income decreased.", "Because oil was priced in dollars, oil producers' real income decreased", "Because oil was priced in dollars, oil producers' real income decreased", "Because oil was priced in dollars, oil producers' real income decreased"], "answer_start": [778, 770, 770, 770, 770]}, "prediction_text": "From then on, oil producers' real income decreased."}
{"answers": {"text": ["risen by less than two percent per year", "less than two percent per year", "less than two percent per year", "by less than two percent per year", "less than two percent per year"], "answer_start": [159, 168, 168, 165, 168]}, "prediction_text": "Less than two percent per year."}
{"answers": {"text": ["After 1971", "1973\u20131974", "1971", "After 1971", "1971"], "answer_start": [37, 485, 43, 37, 43]}, "prediction_text": "1971"}
{"answers": {"text": ["1973\u20131974", "1974", "1973\u20131974", "1973\u20131974", "1973\u20131974"], "answer_start": [485, 490, 485, 485, 485]}, "prediction_text": "1973\u20131974"}
{"answers": {"text": ["Until the oil shock", "the oil shock", "the oil shock", "Until the oil shock", "the oil shock"], "answer_start": [200, 206, 206, 200, 206]}, "prediction_text": "Oil shock"}
{"answers": {"text": ["On October 6, 1973", "October 6, 1973", "October 6, 1973", "October 6, 1973", "October 6, 1973"], "answer_start": [0, 3, 3, 3, 3]}, "prediction_text": "October 6, 1973"}
{"answers": {"text": ["Iran", "Iran", "Iran", "Iran", "Iran"], "answer_start": [255, 255, 255, 255, 255]}, "prediction_text": "Iran"}
{"answers": {"text": ["ten times more", "ten", "a hundred", "ten"], "answer_start": [766, 766, 649, 766]}, "prediction_text": "Ten times more"}
{"answers": {"text": ["Iran", "Iran", "Iran", "Iran", "Iran"], "answer_start": [255, 255, 255, 255, 350]}, "prediction_text": "Iran"}
{"answers": {"text": ["renewal of hostilities in the Arab\u2013Israeli conflict", "renewal of hostilities", ".", "the Arab\u2013Israeli conflict released the underlying economic pressure on oil prices"], "answer_start": [133, 133, 323, 159]}, "prediction_text": "To discuss Iran's oil price increase."}
{"answers": {"text": ["In response to American aid to Israel", "In response to American aid to Israel", "In response to American aid to Israel", "In response to American aid to Israel", "American aid to Israel"], "answer_start": [0, 0, 0, 0, 15]}, "prediction_text": "To counter American aid to Israel."}
{"answers": {"text": ["October 16, 1973,", "October 16, 1973", "October 16, 1973", "October 16, 1973", "October 16, 1973"], "answer_start": [42, 42, 42, 42, 42]}, "prediction_text": "October 16, 1973"}
{"answers": {"text": ["until their economic and political objectives were met", "In response to American aid to Israel", "OPEC raised the posted price of oil", "until their economic and political objectives were met"], "answer_start": [308, 0, 60, 308]}, "prediction_text": "To prevent Israel's collapse."}
{"answers": {"text": ["$2.2 billion", "$2.2 billion", "$2.2 billion", "$2.2 billion", "$2.2 billion"], "answer_start": [419, 419, 419, 419, 419]}, "prediction_text": "$2.2 billion"}
{"answers": {"text": ["American aid to Israel", "Nixon requested Congress to appropriate $2.2 billion in emergency aid to Israel", "OAPEC proclaimed the embargo that curbed exports to various countries and blocked all oil deliveries to the US as a \"principal hostile country", "OAPEC proclaimed the embargo that curbed exports to various countries", "American aid to Israel"], "answer_start": [15, 379, 879, 879, 15]}, "prediction_text": "To \"principal hostile country\""}
{"answers": {"text": ["over 100 billion dollars", "over 100 billion dollars", "over 100 billion dollars", "over 100 billion dollars", "100 billion dollars"], "answer_start": [342, 342, 342, 342, 347]}, "prediction_text": "Over 100 billion dollars"}
{"answers": {"text": ["Al-Qaeda and the Taliban", "violent Sunni extremist groups such as Al-Qaeda and the Taliban", "Al-Qaeda and the Taliban", "Al-Qaeda and the Taliban", "Al-Qaeda and the Taliban"], "answer_start": [625, 586, 625, 625, 625]}, "prediction_text": "Sunni extremist groups"}
{"answers": {"text": ["Middle East", "Middle East", "Middle East", "Middle East", "Middle East"], "answer_start": [310, 310, 310, 310, 310]}, "prediction_text": "Middle East"}
{"answers": {"text": ["shrinking Western demand", "shrinking Western demand", "economies had been caught between higher oil prices and lower prices for their own export commodities", "economies had been caught between higher oil prices and lower prices for their own export commodities", "shrinking Western demand"], "answer_start": [198, 198, 90, 90, 198]}, "prediction_text": "Lower oil prices"}
{"answers": {"text": ["Wahhabism", "Wahhabism", "Wahhabism", "Wahhabism", "Wahhabism"], "answer_start": [462, 462, 462, 462, 462]}, "prediction_text": "Wahhabism"}
{"answers": {"text": ["distribution and price disruptions", "reduced productivity", "distribution and price disruptions", "distribution and price disruptions"], "answer_start": [417, 528, 417, 417]}, "prediction_text": "Energy production disruptions"}
{"answers": {"text": ["USSR", "USSR", "USSR", "USSR", "USSR"], "answer_start": [234, 234, 234, 234, 234]}, "prediction_text": "USSR"}
{"answers": {"text": ["1973", "1973", "1973", "1973"], "answer_start": [136, 136, 136, 136]}, "prediction_text": "1973"}
{"answers": {"text": ["Kissinger", "Kissinger", "Kissinger", "Kissinger's", "Kissinger"], "answer_start": [372, 372, 372, 372, 372]}, "prediction_text": "Kissinger"}
{"answers": {"text": ["The embargo", "The embargo", "The embargo", "The embargo", "embargo"], "answer_start": [0, 0, 0, 0, 4]}, "prediction_text": "embargo"}
{"answers": {"text": ["automobiles", "automobiles", "automobiles", "automobiles", "automobiles"], "answer_start": [237, 237, 237, 237, 237]}, "prediction_text": "Automobiles"}
{"answers": {"text": ["Macroeconomic problems", "Macroeconomic", "Macroeconomic", "Macroeconomic", "Macroeconomic"], "answer_start": [250, 250, 250, 250, 250]}, "prediction_text": "Oil companies searching for new ways to increase oil supplies."}
{"answers": {"text": ["Arctic", "Arctic", "Arctic", "the Arctic", "the Arctic"], "answer_start": [445, 445, 445, 441, 441]}, "prediction_text": "Arctic"}
{"answers": {"text": ["five to ten years", "five to ten years", "five to ten years", "five to ten years", "five to ten years"], "answer_start": [508, 508, 508, 508, 508]}, "prediction_text": "Five to ten years"}
{"answers": {"text": ["Netherlands", "Netherlands", "the Netherlands", "the Netherlands"], "answer_start": [109, 109, 105, 105]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["America", "America", "America", "America"], "answer_start": [229, 229, 229, 229]}, "prediction_text": "America"}
{"answers": {"text": ["UK", "UK", "The UK", "The UK"], "answer_start": [377, 377, 373, 373]}, "prediction_text": "The Netherlands"}
{"answers": {"text": ["Israel", "Israel", "Israelis", "the Israelis"], "answer_start": [568, 467, 467, 463]}, "prediction_text": "Israel"}
{"answers": {"text": ["Ted Heath", "Ted Heath", "Ted Heath", "Ted Heath"], "answer_start": [515, 515, 515, 515]}, "prediction_text": "Ted Heath"}
{"answers": {"text": ["UK", "UK", "UK", "the UK", "UK"], "answer_start": [56, 56, 56, 52, 56]}, "prediction_text": "Germany"}
{"answers": {"text": ["a series of strikes", "a series of strikes by coal miners and railroad workers", "a series of strikes by coal miners and railroad workers", "strikes by coal miners and railroad workers", "a series of strikes"], "answer_start": [104, 104, 104, 116, 104]}, "prediction_text": "Coal miners' strikes"}
{"answers": {"text": ["winter of 1973\u201374", "over the winter of 1973\u201374", "1973\u201374", "winter of 1973\u201374", "the winter of 1973\u201374"], "answer_start": [169, 160, 179, 169, 165]}, "prediction_text": "1973\u201374"}
{"answers": {"text": ["Germany", "Germany", "Italy", "Norway"], "answer_start": [325, 325, 334, 357]}, "prediction_text": "Sweden"}
{"answers": {"text": ["Sweden", "Sweden", "Sweden", "Sweden", "Sweden"], "answer_start": [411, 411, 411, 411, 411]}, "prediction_text": "Sweden"}
{"answers": {"text": ["Price controls", "Price controls", "Price controls", "Price controls", "Price controls"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Price controls"}
{"answers": {"text": ["encourage investment", "to encourage investment", "to encourage investment", "to encourage investment", "The system limited the price of \"old oil\""], "answer_start": [200, 197, 197, 197, 49]}, "prediction_text": "To encourage investment."}
{"answers": {"text": ["Price controls", "Price controls", "promote oil exploration", "discouraged development of alternative energies", "The system limited the price of \"old oil\""], "answer_start": [0, 0, 394, 315, 49]}, "prediction_text": "To promote alternative energies."}
{"answers": {"text": ["rationing", "rationing", "rationing", "rationing", "rationing"], "answer_start": [445, 445, 445, 445, 445]}, "prediction_text": "rationing (as in many countries)"}
{"answers": {"text": ["William E. Simon", "William E. Simon", "William E. Simon", "William E. Simon", "William E. Simon"], "answer_start": [21, 21, 21, 21, 21]}, "prediction_text": "William E. Simon"}
{"answers": {"text": ["In 1973", "1973", "1973", "1973", "1973"], "answer_start": [0, 3, 3, 3, 3]}, "prediction_text": "1973"}
{"answers": {"text": ["coordinate the response to the embargo", "to coordinate the response to the embargo", "to coordinate the response to the embargo", "to coordinate the response to the embargo", "to coordinate the response to the embargo"], "answer_start": [132, 129, 129, 129, 129]}, "prediction_text": "To coordinate response to embargo."}
{"answers": {"text": ["last week of February 1974,", "20%", "20", "20%", "20%"], "answer_start": [445, 473, 473, 473, 473]}, "prediction_text": "20%"}
{"answers": {"text": ["55 mph", "55 mph", "55 mph", "55 mph", "55 mph"], "answer_start": [70, 70, 70, 70, 70]}, "prediction_text": "55 mph (about 88 km/h)"}
{"answers": {"text": ["Emergency Highway Energy Conservation Act", "Emergency Highway Energy Conservation Act", "Emergency Highway Energy Conservation Act", "Emergency Highway Energy Conservation Act", "Emergency Highway Energy Conservation Act"], "answer_start": [117, 117, 117, 117, 117]}, "prediction_text": "Emergency Highway Energy Conservation Act"}
{"answers": {"text": ["Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton"], "answer_start": [370, 370, 370, 370, 370]}, "prediction_text": "Bill Clinton"}
{"answers": {"text": ["November 28, 1995", "November 28, 1995", "November 28, 1995", "November 28, 1995", "November 28, 1995"], "answer_start": [351, 351, 351, 351, 351]}, "prediction_text": "November 28, 1995"}
{"answers": {"text": ["1977", "1977", "1977", "1977", "1977"], "answer_start": [229, 229, 229, 229, 229]}, "prediction_text": "1977"}
{"answers": {"text": ["energy crisis", "The energy crisis", "energy crisis", "energy crisis", "The energy crisis"], "answer_start": [4, 0, 4, 4, 0]}, "prediction_text": "Energy crisis"}
{"answers": {"text": ["market and technology realities", "market and technology realities", "market and technology realities", "market and technology realities", "market and technology realities"], "answer_start": [290, 290, 290, 290, 290]}, "prediction_text": "Market and technology realities"}
{"answers": {"text": ["congresses and presidents", "congresses and presidents", "congresses and presidents", "congresses and presidents", "congresses and presidents"], "answer_start": [452, 452, 452, 452, 452]}, "prediction_text": "Presidents"}
{"answers": {"text": ["U.S", "U.S.", "U.S.", "U.S", "the U.S."], "answer_start": [50, 50, 50, 50, 46]}, "prediction_text": "Under-developed countries"}
{"answers": {"text": ["British Prime Minister Edward Heath", "British", "British", "British"], "answer_start": [523, 523, 363, 363]}, "prediction_text": "Britain"}
{"answers": {"text": ["10 years", "10 years", "10 years", "10 years", "10 years"], "answer_start": [1121, 1121, 1121, 1121, 1121]}, "prediction_text": "10 years"}
{"answers": {"text": ["Arabs and much of the rest of the Third World", "the Arabs and much of the rest of the Third World", "Arabs", "Arabs and much of the rest of the Third World", "the Arabs and much of the rest of the Third World"], "answer_start": [1230, 1226, 1230, 1230, 1226]}, "prediction_text": "Arabs"}
{"answers": {"text": ["Japan", "Japan", "Japan", "Japan", "Japan"], "answer_start": [60, 60, 60, 60, 60]}, "prediction_text": "Japan"}
{"answers": {"text": ["71%", "71%", "71", "71%", "71%"], "answer_start": [110, 110, 110, 110, 110]}, "prediction_text": "71%"}
{"answers": {"text": ["5% production cut", "declared Japan a \"nonfriendly\" country", "declared Japan a \"nonfriendly\" country", "declared Japan a \"nonfriendly\" country", "declared Japan a \"nonfriendly\" country"], "answer_start": [330, 224, 224, 224, 224]}, "prediction_text": "Declared Japan a \"nonfriendly\" country."}
{"answers": {"text": ["November 22", "November 22", "November 22", "November 22,", "November 22"], "answer_start": [381, 381, 381, 381, 381]}, "prediction_text": "December 25"}
{"answers": {"text": ["December 25", "December 25", "December 25", "December 25", "December 25"], "answer_start": [643, 643, 643, 643, 643]}, "prediction_text": "December 25, 1973"}
{"answers": {"text": ["USSR's invasion", "Afghanistan", "USSR's", "USSR", "Afghanistan"], "answer_start": [4, 23, 4, 4, 23]}, "prediction_text": "USSR's invasion of Afghanistan"}
{"answers": {"text": ["Saudi Arabia and Iran", "Saudi Arabia and Iran", "Saudi Arabia and Iran", "Saudi Arabia and Iran", "Saudi Arabia and Iran"], "answer_start": [175, 175, 175, 175, 175]}, "prediction_text": "Saudi Arabia and Iran"}
{"answers": {"text": ["Saudi Arabia", "Saudi Arabia", "Saudi Arabia", "Saudi Arabia", "Saudi Arabia"], "answer_start": [175, 175, 175, 175, 175]}, "prediction_text": "Saudi Arabia"}
{"answers": {"text": ["January 1979", "1979", "1979", "1979", "January 1979"], "answer_start": [696, 1296, 704, 704, 696]}, "prediction_text": "January 1979"}
{"answers": {"text": ["November 1979", "November 1979", "November 1979", "November 1979", "November 1979"], "answer_start": [1287, 1287, 1287, 1287, 1287]}, "prediction_text": "November 1979"}
{"answers": {"text": ["large cars", "large", "large", "large"], "answer_start": [34, 34, 34, 34]}, "prediction_text": "Large cars"}
{"answers": {"text": ["Japanese imports", "Japan", "Japanese", "Japanese", "Japanese"], "answer_start": [46, 46, 399, 399, 46]}, "prediction_text": "Japan"}
{"answers": {"text": ["V8 and six cylinder engines", "V8 and six cylinder", "V8 and six cylinder", "V8 and six cylinder", "V8 and six cylinder"], "answer_start": [370, 370, 370, 370, 370]}, "prediction_text": "V8 and six cylinder engines."}
{"answers": {"text": ["Japan", "Japan", "Japanese", "Japanese", "Japanese"], "answer_start": [399, 399, 399, 399, 46]}, "prediction_text": "Japan"}
{"answers": {"text": ["A decade after the 1973", "1981", "1981", "A decade after the 1973 oil crisis", "1981"], "answer_start": [413, 491, 491, 413, 491]}, "prediction_text": "1981"}
{"answers": {"text": ["Toyota Corona Mark II", "Corona Mark II", "Toyota Corona Mark II", "Corona Mark II"], "answer_start": [153, 160, 153, 160]}, "prediction_text": "Toyota Corona Mark II"}
{"answers": {"text": ["power steering", "air conditioning", "air conditioning", "power windows"], "answer_start": [295, 277, 277, 334]}, "prediction_text": "Passenger space and amenities added without increasing price."}
{"answers": {"text": ["Lexus", "Lexus", "Lexus", "Acura", "Lexus"], "answer_start": [598, 598, 598, 591, 598]}, "prediction_text": "Acura, Lexus, Infiniti"}
{"answers": {"text": ["Toyota Hilux", "Hilux", "Hilux", "Toyota Hilux", "Hilux"], "answer_start": [44, 51, 51, 44, 51]}, "prediction_text": "Toyota Hilux and Datsun Truck"}
{"answers": {"text": ["Dodge D-50", "Dodge D-50", "Dodge D-50", "Dodge D-50", "Dodge D-50"], "answer_start": [208, 208, 208, 208, 208]}, "prediction_text": "Dodge D-50"}
{"answers": {"text": ["Ford, Chrysler, and GM", "Ford, Chrysler, and GM", "Ford, Chrysler, and GM, respectively", "Ford", "Ford, Chrysler, and GM"], "answer_start": [309, 309, 309, 309, 309]}, "prediction_text": "Ford"}
{"answers": {"text": ["captive import policy", "captive import", "captive import", "captive import", "captive import"], "answer_start": [485, 485, 485, 485, 485]}, "prediction_text": "American captive import policy"}
{"answers": {"text": ["An increase in imported cars", "An increase in imported cars into North America", "An increase in imported cars into North America", "An increase in imported cars", "An increase in imported cars"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "To reduce import costs."}
{"answers": {"text": ["at least four passengers", "four", "at least four passengers", "at least four", "four"], "answer_start": [291, 300, 291, 291, 300]}, "prediction_text": "Four passengers"}
{"answers": {"text": ["1985", "1985", "1985", "1985", "1985"], "answer_start": [338, 338, 338, 338, 338]}, "prediction_text": "1985"}
{"answers": {"text": ["Lincoln Continental,", "Cadillac DeVille", "Cadillac DeVille", "Cadillac DeVille"], "answer_start": [720, 658, 658, 658]}, "prediction_text": "Cadillac DeVille"}
{"answers": {"text": ["Chevrolet Bel Air", "lower price models such as the Chevrolet Bel Air, and Ford Galaxie 500", "lower price models", "Chevrolet Bel Air, and Ford Galaxie 500", "Chevrolet Bel Air, and Ford Galaxie 500"], "answer_start": [921, 890, 890, 921, 921]}, "prediction_text": "Cadillac DeVille, Fleetwood, Buick Electra, Oldsmobile 98, Lincoln Continental, Mercury Marquis, and various other luxury oriented sedans."}
{"answers": {"text": ["1979", "1979", "1979", "1979", "1979"], "answer_start": [275, 275, 275, 275, 275]}, "prediction_text": "1979 (for Chrysler's full-sized luxury sedans)"}
{"answers": {"text": ["1981", "1981", "1981", "1981", "1981"], "answer_start": [469, 469, 469, 469, 469]}, "prediction_text": "1981"}
{"answers": {"text": ["Mustang I", "the 1974 Mustang I", "Mustang I", "1974 Mustang I", "1974 Mustang I"], "answer_start": [141, 132, 141, 136, 136]}, "prediction_text": "1974 Mustang I"}
{"answers": {"text": ["1981", "1981", "1981", "1981", "1981"], "answer_start": [47, 47, 47, 47, 47]}, "prediction_text": "1981"}
{"answers": {"text": ["1980s", "during the 1980s", "1980s", "1980s", "1980s"], "answer_start": [419, 408, 419, 419, 419]}, "prediction_text": "1980s"}
{"answers": {"text": ["recover market share", "trying to recover market share", "recover market share", "to recover market share", "recover market share"], "answer_start": [185, 175, 185, 182, 185]}, "prediction_text": "To recover market share."}
{"answers": {"text": ["nearly $40 per barrel", "nearly $40 per barrel", "$40 per barrel", "$40 per barrel", "$40 per barrel"], "answer_start": [375, 375, 382, 382, 382]}, "prediction_text": "$40 per barrel"}
{"answers": {"text": ["Project Mercury", "spacecraft", "Project Mercury", "Apollo", "Project Apollo"], "answer_start": [361, 328, 361, 4, 34]}, "prediction_text": "Project Mercury"}
{"answers": {"text": ["National Aeronautics and Space Administration (NASA)", "National Aeronautics and Space Administration (NASA", "Apollo", "Project Mercury", "Apollo program"], "answer_start": [123, 123, 4, 361, 4]}, "prediction_text": "National Aeronautics and Space Administration (NASA)"}
{"answers": {"text": ["1968", "1969", "1962", "1968", "1969"], "answer_start": [752, 238, 701, 752, 238]}, "prediction_text": "1968"}
{"answers": {"text": ["Dwight D. Eisenhower", "John F. Kennedy's", "John F. Kennedy's", "Dwight D. Eisenhower", "Dwight D. Eisenhower"], "answer_start": [275, 457, 457, 275, 275]}, "prediction_text": "Dwight D. Eisenhower"}
{"answers": {"text": ["two", "rst", "two", "two", "two-man"], "answer_start": [677, 393, 677, 677, 677]}, "prediction_text": "Three people"}
{"answers": {"text": ["1961 to 1972", "1961 to 1972", "1961 to 1972", "1961 to 1972", "Apollo ran from 1961 to 1972"], "answer_start": [16, 16, 16, 16, 0]}, "prediction_text": "From 1961 to 1972."}
{"answers": {"text": ["Gemini program", "Gemini", "Gemini", "Gemini", "Gemini program"], "answer_start": [63, 63, 128, 63, 63]}, "prediction_text": "Gemini program"}
{"answers": {"text": ["Soviet Union", "Apollo Applications Program", "Soviet Union", "Soviet Union", "Soviet Union"], "answer_start": [542, 349, 542, 542, 542]}, "prediction_text": "Soviet Union"}
{"answers": {"text": ["Skylab", "Skylab", "Skylab", "Skylab", "Skylab"], "answer_start": [397, 397, 397, 397, 397]}, "prediction_text": "Skylab"}
{"answers": {"text": ["1967", "1967", "1967", "1967", "1967"], "answer_start": [107, 107, 107, 107, 107]}, "prediction_text": "1967"}
{"answers": {"text": ["prelaunch test", "prelaunch", "prelaunch test", "prelaunch test"], "answer_start": [169, 169, 169, 169]}, "prediction_text": "Prelaunch test"}
{"answers": {"text": ["Budget cuts", "oxygen tank explosion", "Budget cuts", "Budget cuts", "Budget cuts"], "answer_start": [347, 513, 347, 347, 347]}, "prediction_text": "Oxygen tank explosion"}
{"answers": {"text": ["Five", "six", "Five", "Five", "Five of the remaining six missions"], "answer_start": [402, 424, 402, 402, 402]}, "prediction_text": "Five launches were successful."}
{"answers": {"text": ["oxygen tank explosion in transit to the Moon", "disabled the command spacecraft's propulsion and life support", "oxygen tank explosion in transit to the Moon", "oxygen tank explosion", "oxygen tank explosion in transit"], "answer_start": [513, 565, 513, 513, 513]}, "prediction_text": "The crew returned safely."}
{"answers": {"text": ["Apollo 8", "Apollo 8", "Apollo 8", "Apollo 8", "Apollo 8"], "answer_start": [122, 122, 122, 122, 122]}, "prediction_text": "Apollo 8"}
{"answers": {"text": ["Apollo 17", "Apollo 17", "Apollo 17", "Apollo 17", "Apollo 17"], "answer_start": [212, 212, 212, 212, 212]}, "prediction_text": "Apollo 17"}
{"answers": {"text": ["382 kg", "382", "382", "382", "382 kg"], "answer_start": [346, 346, 346, 346, 346]}, "prediction_text": "842 kgs"}
{"answers": {"text": ["avionics, telecommunications, and computers", "NASA's current human spaceflight capability, and funded construction of its Johnson Space Center and Kennedy Space Center", "avionics, telecommunications, and computers", "avionics, telecommunications, and computers.", "rocketry and manned spaceflight, including avionics, telecommunications, and computers"], "answer_start": [753, 516, 753, 753, 710]}, "prediction_text": "Technology incidental to rocketry and manned spaceflight."}
{"answers": {"text": ["one", "three", "one", "one", "one astronaut"], "answer_start": [165, 234, 165, 165, 165]}, "prediction_text": "Three people"}
{"answers": {"text": ["three", "three", "three", "three astronauts"], "answer_start": [234, 234, 234, 234]}, "prediction_text": "Three people"}
{"answers": {"text": ["Abe Silverstein", "Abe Silverstein", "Abe Silverstein", "Abe Silverstein", "NASA manager Abe Silverstein"], "answer_start": [458, 458, 458, 458, 445]}, "prediction_text": "Abe Silverstein"}
{"answers": {"text": ["manned lunar landings", "manned lunar landings", "lunar landings", "ferrying crews to a space station, circumlunar flights, and eventual manned lunar landings"], "answer_start": [348, 348, 355, 279]}, "prediction_text": "Lunar landings"}
{"answers": {"text": ["early 1960", "1960", "1960", "1960", "early 1960"], "answer_start": [73, 605, 605, 79, 73]}, "prediction_text": "Early 1960"}
{"answers": {"text": ["1960", "1960", "1960", "1960", "July 1960"], "answer_start": [8, 8, 8, 8, 3]}, "prediction_text": "1960"}
{"answers": {"text": ["Maxime Faget", "Hugh L. Dryden", "Maxime Faget", "Maxime Faget", "Maxime Faget"], "answer_start": [617, 40, 617, 617, 617]}, "prediction_text": "Maxime Faget"}
{"answers": {"text": ["three", "three", "three", "three", "three study contracts"], "answer_start": [426, 426, 426, 426, 426]}, "prediction_text": "Three study contracts"}
{"answers": {"text": ["Hugh L. Dryden", "Maxime Faget", "Hugh L. Dryden", "Hugh L. Dryden", "Hugh L. Dryden"], "answer_start": [40, 617, 40, 40, 40]}, "prediction_text": "Hugh L. Dryden"}
{"answers": {"text": ["John F. Kennedy", "John F. Kennedy", "John F. Kennedy", ", John F. Kennedy", "John F. Kennedy"], "answer_start": [18, 18, 18, 16, 18]}, "prediction_text": "John F. Kennedy"}
{"answers": {"text": ["Soviet Union", "Soviet Union", "Soviet Union", "Soviet Union", "Soviet Union"], "answer_start": [117, 117, 117, 117, 117]}, "prediction_text": "Soviet Union"}
{"answers": {"text": ["massive financial commitment", "massive financial commitment", "massive financial commitment", "financial commitment", "massive financial commitment"], "answer_start": [789, 789, 789, 797, 789]}, "prediction_text": "The massive financial commitment required by a manned Moon landing."}
{"answers": {"text": ["James E. Webb", "James E. Webb", "James E. Webb", "James E. Webb", "James E. Webb"], "answer_start": [903, 903, 903, 903, 903]}, "prediction_text": "James E. Webb"}
{"answers": {"text": ["missile gap", "first but, first and, first if, but first period", "missile gap", "missile gap"], "answer_start": [257, 518, 257, 257]}, "prediction_text": "Missile gap"}
{"answers": {"text": ["Yuri Gagarin", "Yuri Gagarin", "Yuri Gagarin", "Yuri Gagarin", "Yuri Gagarin"], "answer_start": [36, 36, 36, 36, 36]}, "prediction_text": "Yuri Gagarin"}
{"answers": {"text": ["Soviet Union", "Soviet", "Soviet Union", "Soviet Union", "Soviet Union"], "answer_start": [181, 19, 181, 181, 181]}, "prediction_text": "Soviet Union"}
{"answers": {"text": ["one day", "one", "one", "one", "one day"], "answer_start": [262, 262, 262, 262, 262]}, "prediction_text": "One day"}
{"answers": {"text": ["refusing to make a commitment", "refusing to make a commitment", "refusing to make a commitment", "refusing to make a commitment on America's response"], "answer_start": [453, 453, 453, 453]}, "prediction_text": "Denied commitment"}
{"answers": {"text": ["April 20", "April 20", "April", "April", "April 20"], "answer_start": [3, 3, 3, 3, 3]}, "prediction_text": "April 20"}
{"answers": {"text": ["Lyndon B. Johnson", "Lyndon B. Johnson", "Lyndon B. Johnson", "Lyndon B. Johnson", "Lyndon B. Johnson"], "answer_start": [51, 51, 51, 51, 51]}, "prediction_text": "Lyndon B. Johnson"}
{"answers": {"text": ["approximately one week", "one week", "one week", "one week", "one week"], "answer_start": [224, 238, 238, 238, 238]}, "prediction_text": "Approximately one week"}
{"answers": {"text": ["neither making maximum effort nor achieving results necessary", "are neither making maximum effort nor achieving results necessary", "we are neither making maximum effort nor achieving results necessary if this country is to reach a position of leadership", "we are neither making maximum effort nor achieving results necessary"], "answer_start": [278, 274, 271, 271]}, "prediction_text": "Johnson responded to Kennedy's memo with \"We are neither making maximum effort nor achieving results necessary if this country is to reach a position of leadership.\""}
{"answers": {"text": ["Robert R. Gilruth", "Robert R. Gilruth's", "Robert R. Gilruth's", "Robert R. Gilruth", "Robert R. Gilruth"], "answer_start": [82, 82, 82, 82, 82]}, "prediction_text": "Robert R. Gilruth"}
{"answers": {"text": ["NASA's Langley Research Center", "Houston", "NASA's Langley Research Center", "Langley Research Center", "Langley"], "answer_start": [184, 353, 184, 191, 191]}, "prediction_text": "Langley Research Center"}
{"answers": {"text": ["Houston, Texas", "Houston", "Houston, Texas", "Houston, Texas", "Houston"], "answer_start": [353, 353, 353, 353, 353]}, "prediction_text": "Houston, Texas"}
{"answers": {"text": ["Rice University", "Rice", "Rice University", "Rice University"], "answer_start": [388, 388, 388, 388]}, "prediction_text": "Rice University"}
{"answers": {"text": ["Florida", "Florida", "Florida", "Florida"], "answer_start": [618, 618, 618, 618]}, "prediction_text": "Florida"}
{"answers": {"text": ["Merritt Island", "Florida", "Merritt Island", "Merritt Island", "Merritt Island"], "answer_start": [444, 82, 444, 444, 444]}, "prediction_text": "Merritt Island"}
{"answers": {"text": ["Kurt H. Debus", "construction of the center was conducted by Kurt H. Debus, a member of Dr. Wernher von Braun's", "Kurt H. Debus", "Kurt H. Debus", "Kurt H. Debus,"], "answer_start": [532, 488, 532, 532, 532]}, "prediction_text": "Kurt H. Debus"}
{"answers": {"text": ["Director", "Director", "Director", "first Director", "Director"], "answer_start": [653, 653, 653, 647, 653]}, "prediction_text": "Director"}
{"answers": {"text": ["Kennedy", "Kennedy", "Kennedy", "Kennedy", "Kennedy"], "answer_start": [837, 837, 837, 837, 837]}, "prediction_text": "Dr. Wernher von Braun"}
{"answers": {"text": ["three", "several", "three", "three pads", "three"], "answer_start": [338, 299, 338, 338, 338]}, "prediction_text": "Three pad plans were originally planned."}
{"answers": {"text": ["Apollo spacecraft", "Apollo", "Apollo", "Apollo"], "answer_start": [602, 602, 602, 602]}, "prediction_text": "Apollo spacecraft"}
{"answers": {"text": ["250,000 feet", "250,000 feet", "250,000", "250,000 feet", "250,000 feet ("], "answer_start": [721, 721, 721, 721, 721]}, "prediction_text": "250,000 feet (76 km)"}
{"answers": {"text": ["130 million cubic foot", "130 million cubic foot", "3.7 million cubic meter", "3.7 million cubic meter", "130 million cubic foot"], "answer_start": [67, 67, 91, 91, 67]}, "prediction_text": "130 million cubic meter (3.7 million cubic meter)"}
{"answers": {"text": ["Dr. George E. Mueller", "Mueller", "George E. Mueller", "Dr. George E. Mueller", "George E. Mueller"], "answer_start": [167, 216, 171, 167, 171]}, "prediction_text": "Dr. George E. Mueller"}
{"answers": {"text": ["July 23, 1963", "1963", "July 23, 1963", "July 23, 1963", "July 23, 1963,"], "answer_start": [486, 495, 486, 486, 486]}, "prediction_text": "July 23, 1963"}
{"answers": {"text": ["D. Brainerd Holmes", "Robert Seamans", "Brainerd Holmes", "D. Brainerd Holmes", "D. Brainerd Holmes"], "answer_start": [637, 412, 640, 637, 637]}, "prediction_text": "D. Brainerd Holmes"}
{"answers": {"text": ["Mueller", "Brainerd Holmes", "Mueller", "Mueller", "Mueller"], "answer_start": [888, 640, 888, 888, 888]}, "prediction_text": "Mueller"}
{"answers": {"text": ["Air Force missile projects", "Air Force missile projects", "Air Force missile projects", "missile projects", "Air Force missile projects"], "answer_start": [36, 36, 36, 46, 36]}, "prediction_text": "Air Force missile projects"}
{"answers": {"text": ["United States Air Force", "Air Force", "Air Force", "Air Force", "Air Force"], "answer_start": [153, 167, 167, 36, 167]}, "prediction_text": "United States Air Force"}
{"answers": {"text": ["General Samuel C. Phillips", "Bernard A. Schriever", "Samuel C. Phillips", "Samuel C. Phillips", "General Samuel C. Phillips"], "answer_start": [217, 379, 225, 225, 217]}, "prediction_text": "General Samuel C. Phillips"}
{"answers": {"text": ["January 1964, until it achieved the first manned landing in July 1969", "1964, until it achieved the first manned landing in July 1969,", "from January 1964, until it achieved the first manned landing in July 1969", "January 1964, until it achieved the first manned landing in July 1969", "January 1964, until it achieved the first manned landing in July 1969,"], "answer_start": [588, 596, 583, 588, 588]}, "prediction_text": "From January 1964, until July 1969."}
{"answers": {"text": ["Apollo Program Director", "Apollo Program Director", "Apollo Program Director", "Apollo Program Director", "Apollo Program Director"], "answer_start": [514, 514, 514, 514, 514]}, "prediction_text": "Apollo Program Director"}
{"answers": {"text": ["a rendezvous \u2014let alone a docking", "rendezvous", "rendezvous", "rendezvous", "docking"], "answer_start": [105, 107, 107, 107, 131]}, "prediction_text": "A rendezvous or docking."}
{"answers": {"text": ["1961", "1960", "1961", "1961", "1961"], "answer_start": [9, 396, 9, 9, 9]}, "prediction_text": "Early 1961"}
{"answers": {"text": ["Robert Seamans", "Robert Seamans", "Robert Seamans", "Robert Seamans", "Robert Seamans;"], "answer_start": [599, 599, 599, 599, 599]}, "prediction_text": "Robert Seamans"}
{"answers": {"text": ["Nicholas E. Golovin", "Nicholas E. Golovin", "Nicholas E. Golovin", "Nicholas E. Golovin", "Nicholas E. Golovin", "Nicholas E. Golovin"], "answer_start": [89, 89, 89, 89, 89, 89]}, "prediction_text": "Nicholas E. Golovin"}
{"answers": {"text": ["July 1961", "1961", "1961", "July 1961", "July 1961", "1961"], "answer_start": [112, 117, 117, 112, 112, 117]}, "prediction_text": "July 1961"}
{"answers": {"text": ["Manned Spacecraft Center", "Manned Spacecraft Center", "Manned Spacecraft Center", "Manned Spacecraft Center"], "answer_start": [578, 578, 578, 578]}, "prediction_text": "Manned Spacecraft Center"}
{"answers": {"text": ["Joseph Shea", "Joseph Shea,", "Joseph Shea,", "Joseph Shea", "Joseph Shea", ", Joseph Shea"], "answer_start": [720, 720, 720, 720, 720, 718]}, "prediction_text": "Joseph Shea"}
{"answers": {"text": ["Marshall Space Flight Center", "Marshall Space Flight Center", "Marshall Space Flight Center", "Marshall Space Flight Center", "Marshall Space Flight Center (MSFC)", "Marshall Space Flight Center"], "answer_start": [780, 780, 780, 780, 780, 780]}, "prediction_text": "Marshall Space Flight Center (MSFC)"}
{"answers": {"text": ["Jerome Wiesner", "Wiesner", "Jerome Wiesner", "Jerome Wiesner", "Jerome Wiesner"], "answer_start": [106, 113, 106, 106, 106]}, "prediction_text": "Jerome Wiesner"}
{"answers": {"text": ["Golovin", "Golovin", "Golovin", "Golovin", "Golovin"], "answer_start": [282, 282, 282, 282, 282]}, "prediction_text": "Golovin"}
{"answers": {"text": ["NASA", "NASA", "NASA", "NASA"], "answer_start": [304, 304, 304, 304]}, "prediction_text": "NASA"}
{"answers": {"text": ["July 11, 1962", "1962", "July 11, 1962", "July 11, 1962", "July 11, 1962"], "answer_start": [569, 578, 569, 569, 569]}, "prediction_text": "July 11, 1962"}
{"answers": {"text": ["Wiesner", "Wiesner", "Wiesner", "Wiesner", "Wiesner"], "answer_start": [0, 149, 0, 0, 0]}, "prediction_text": "Wiesner"}
{"answers": {"text": ["\"No, that's no good\"", "\"No, that's no good", "No, that's no good", "No, that's no good", "\"No, that's no good"], "answer_start": [169, 169, 170, 170, 169]}, "prediction_text": "\"No, that's no good\""}
{"answers": {"text": ["Lunar Excursion Module", "Lunar Excursion Module", "Lunar Excursion Module", "Lunar Excursion Module", "Lunar Excursion Module"], "answer_start": [448, 448, 448, 448, 448]}, "prediction_text": "Lunar Excursion Module"}
{"answers": {"text": ["Grumman", "Grumman", "Grumman", "Grumman", "Grumman"], "answer_start": [736, 736, 736, 736, 736]}, "prediction_text": "Grumman"}
{"answers": {"text": ["spacecraft to be used as a \"lifeboat\"", "allowing the lander spacecraft to be used as a \"lifeboat", "allowing the lander spacecraft to be used as a \"lifeboat\"", "lifeboat", "allowing the lander spacecraft to be used as a \"lifeboat\""], "answer_start": [56, 36, 36, 84, 36]}, "prediction_text": "Allows for use as a lifeboat."}
{"answers": {"text": ["Apollo 13", "13", "Apollo 13", "Apollo 13", "Apollo 13"], "answer_start": [445, 452, 445, 445, 445]}, "prediction_text": "Apollo 13"}
{"answers": {"text": ["propulsion, electrical power and life support", "propulsion", "propulsion", "propulsion, electrical power and life support", "propulsion, electrical power and life support"], "answer_start": [559, 559, 559, 559, 559]}, "prediction_text": "propulsion, electrical power, life support."}
{"answers": {"text": ["1964", "1964", "1964", "1964", "1964"], "answer_start": [230, 230, 230, 230, 230]}, "prediction_text": "1964"}
{"answers": {"text": ["cone-shaped", "cone", "cone", "cone-shaped", "cone"], "answer_start": [52, 52, 52, 52, 52]}, "prediction_text": "cone-shaped"}
{"answers": {"text": ["Command/Service Module", "Command/Service Module (", "Command/Service Module", "Command/Service Module", "Command/Service Module"], "answer_start": [325, 325, 325, 325, 325]}, "prediction_text": "Command/Service Module"}
{"answers": {"text": ["two", "two", "two men", "two"], "answer_start": [771, 771, 771, 771]}, "prediction_text": "Two men"}
{"answers": {"text": ["three", "three", "three", "three astronauts", "three"], "answer_start": [70, 70, 70, 70, 70]}, "prediction_text": "Three astronauts"}
{"answers": {"text": ["ocean", "splashdown", "ocean", "ocean", "ocean"], "answer_start": [135, 526, 135, 135, 135]}, "prediction_text": "Moon"}
{"answers": {"text": ["ablative heat shield", "ablative heat shield", "ablative heat shield", "ablative heat shield", "ablative heat shield"], "answer_start": [341, 341, 341, 341, 341]}, "prediction_text": "ablative heat shield"}
{"answers": {"text": ["Parachutes", "Parachutes", "Parachutes", "Parachutes", "Parachutes"], "answer_start": [479, 479, 479, 479, 479]}, "prediction_text": "Parachutes were carried."}
{"answers": {"text": ["5,560 kg", "5,560", "5,560", "5,560 kg", "5,560"], "answer_start": [653, 653, 653, 653, 653]}, "prediction_text": "5,560 kg"}
{"answers": {"text": ["Service Module (SM)", "cylindrical Service Module", "Service Module", "cylindrical Service Module", "Service Module"], "answer_start": [14, 2, 14, 2, 14]}, "prediction_text": "A Service Module supported the Command Module with a propulsion engine and propellants."}
{"answers": {"text": ["high-gain S-band antenna", "high-gain S-band", "high-gain S-band", "high-gain S-band antenna", "S-band"], "answer_start": [218, 218, 218, 218, 228]}, "prediction_text": "High-gain S-band antenna"}
{"answers": {"text": ["discarded", "discarded", "discarded", "discarded", "discarded"], "answer_start": [416, 416, 416, 416, 416]}, "prediction_text": "Abandoned"}
{"answers": {"text": ["51,300 pounds", "51,300", "51,300 pounds", "23,300 kg", "51,300"], "answer_start": [578, 578, 578, 593, 578]}, "prediction_text": "51,300 pounds (23,300 kg)"}
{"answers": {"text": ["orbital scientific instrument package", "orbital scientific instrument", "orbital scientific instrument package", "scientific instrument package"], "answer_start": [342, 342, 342, 672]}, "prediction_text": "A lunar orbit scientific instrument package"}
{"answers": {"text": ["North American Aviation", "North American Aviation", "North American Aviation", "North American Aviation", "North American Aviation"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "North American Aviation"}
{"answers": {"text": ["twice the thrust", "twice the thrust required", "twice the thrust", "twice the thrust"], "answer_start": [320, 320, 320, 320]}, "prediction_text": "About twice the thrust required for translunar flight."}
{"answers": {"text": ["1964", "1964", "1964", "1964", "1964"], "answer_start": [435, 435, 435, 435, 435]}, "prediction_text": "1964"}
{"answers": {"text": ["Saturn V", "Saturn V", "Saturn V", "Saturn V"], "answer_start": [92, 92, 92, 92]}, "prediction_text": "Saturn V"}
{"answers": {"text": ["two", "two", "two", "two astronauts", "two"], "answer_start": [71, 71, 71, 71, 71]}, "prediction_text": "Two astronauts"}
{"answers": {"text": ["Not", "Command Module", "Not", "take them back to orbit to rendezvous with the Command Module", "Not designed to fly through the Earth's atmosphere or return to Earth"], "answer_start": [165, 149, 165, 102, 165]}, "prediction_text": "No, the LM was designed to descend to Earth only."}
{"answers": {"text": ["15,100 kg", "(15,100", "15,100", "15,100 kg", "15,100"], "answer_start": [710, 709, 710, 710, 710]}, "prediction_text": "33,300 pounds (15,100 kg)"}
{"answers": {"text": ["3 days", "3 days.", "over 3 days", "over 3 days", "3 days"], "answer_start": [870, 870, 865, 865, 870]}, "prediction_text": "Over 3 days"}
{"answers": {"text": ["Wernher von Braun", "Wernher von Braun", "Wernher von Braun", "Wernher von Braun", "Wernher von Braun"], "answer_start": [33, 33, 33, 33, 33]}, "prediction_text": "Wernher von Braun"}
{"answers": {"text": ["Army", "Army", "Army", "Army", "Army"], "answer_start": [258, 258, 258, 258, 258]}, "prediction_text": "Army"}
{"answers": {"text": ["June 11, 1962", "1962", "June 11, 1962", "June 11, 1962", "June 11, 1962"], "answer_start": [590, 599, 590, 590, 590]}, "prediction_text": "June 11, 1962"}
{"answers": {"text": ["dummy upper stages filled with water", "dummy upper stages", "dummy upper stages", "dummy upper stages filled with water", "dummy upper stages filled with water."], "answer_start": [101, 101, 101, 101, 101]}, "prediction_text": "Water filled upper stages"}
{"answers": {"text": ["1964 and 1965", "1964", "1964 and 1965", "1964 and 1965", "1964 and 1965"], "answer_start": [302, 302, 302, 302, 302]}, "prediction_text": "1964 and 1965"}
{"answers": {"text": ["Pegasus satellites", "Pegasus satellites,", "Pegasus satellites", "Pegasus satellites", "Pegasus satellites"], "answer_start": [395, 395, 395, 395, 395]}, "prediction_text": "Pegasus satellites"}
{"answers": {"text": ["frequency and severity of micrometeorite impacts", "translunar environment by measuring the frequency and severity of micrometeorite impacts.", "micrometeorite impacts", "safety of the translunar environment", "micrometeorite impacts."], "answer_start": [488, 448, 514, 434, 514]}, "prediction_text": "Frequency and severity of micrometeorite impacts."}
{"answers": {"text": ["Saturn IB", "S-IB", "Saturn IB", "Saturn IB", "Saturn IB"], "answer_start": [4, 59, 4, 4, 4]}, "prediction_text": "Saturn IB"}
{"answers": {"text": ["200,000 lbf", "200,000 lbf", "200,000 lbf", "200,000 lbf (890 kN) of thrust", "200,000 lbf"], "answer_start": [275, 275, 275, 275, 275]}, "prediction_text": "7,120 kN"}
{"answers": {"text": ["third stage", "third", "third stage", "second stage"], "answer_start": [358, 358, 358, 143]}, "prediction_text": "Third stage"}
{"answers": {"text": ["40,000 pounds", "40,000 pounds", "40,000 pounds", "40,000 pounds (18,100 kg)", "over 40,000 pounds"], "answer_start": [417, 417, 417, 417, 412]}, "prediction_text": "Over 40,000 pounds (18,100 kg)"}
{"answers": {"text": ["three-stage Saturn V", "Saturn V", "Saturn V", "Saturn V", "Saturn V"], "answer_start": [4, 16, 16, 16, 16]}, "prediction_text": "A CSM and LM."}
{"answers": {"text": ["33 feet", "33", "33", "33"], "answer_start": [92, 92, 92, 92]}, "prediction_text": "33 feet (10.1 m)"}
{"answers": {"text": ["three", "third", "three", "three-stage", "three"], "answer_start": [4, 506, 4, 4, 4]}, "prediction_text": "Three stages"}
{"answers": {"text": ["burned liquid hydrogen", "burned liquid hydrogen", "burned liquid hydrogen", "burned liquid hydrogen", "burned liquid hydrogen"], "answer_start": [474, 474, 474, 474, 474]}, "prediction_text": "Burning liquid hydrogen"}
{"answers": {"text": ["Mercury and Gemini", "Mercury", "Mercury and Gemini", "Project Mercury and Gemini", "Mercury and Gemini"], "answer_start": [51, 51, 51, 43, 51]}, "prediction_text": "Project Mercury and Gemini veterans"}
{"answers": {"text": ["All missions", "17", "All missions", "All"], "answer_start": [118, 517, 118, 118]}, "prediction_text": "Two missions"}
{"answers": {"text": ["Dr. Harrison Schmitt", "Harrison Schmitt", "Harrison Schmitt", "Harrison Schmitt", "Harrison Schmitt"], "answer_start": [375, 379, 379, 379, 379]}, "prediction_text": "Dr. Harrison Schmitt"}
{"answers": {"text": ["Apollo 17", "17", "Apollo 17", "Apollo 17", "Apollo 17"], "answer_start": [510, 517, 510, 510, 510]}, "prediction_text": "Apollo 17"}
{"answers": {"text": ["last mission", "last mission", "first NASA scientist astronaut to fly in space", "last mission,"], "answer_start": [496, 496, 418, 496]}, "prediction_text": "First lunar landing"}
{"answers": {"text": ["32", "32", "32", "32", "32"], "answer_start": [17, 17, 17, 17, 17]}, "prediction_text": "32 astronauts visited space on missions."}
{"answers": {"text": ["Distinguished Service Medal", "Distinguished Service Medal", "Distinguished Service Medal", "Distinguished Service Medal", "Distinguished Service Medal,"], "answer_start": [63, 63, 63, 63, 63]}, "prediction_text": "Distinguished service, ability, or courage medal"}
{"answers": {"text": ["1969", "1969", "1969", "1969", "1969"], "answer_start": [302, 302, 302, 302, 302]}, "prediction_text": "1969"}
{"answers": {"text": ["discipline problems", "discipline problems", "discipline problems", "discipline problems"], "answer_start": [552, 552, 552, 552]}, "prediction_text": "Discipline problems with Flight Director's orders."}
{"answers": {"text": ["Apollo 8", "Apollo 8", "Apollo 7", "Apollo 8", "Apollo 8"], "answer_start": [347, 347, 420, 347, 347]}, "prediction_text": "Apollo 8"}
{"answers": {"text": ["1966", "1966", "1966", "1966", "1966"], "answer_start": [67, 67, 67, 67, 67]}, "prediction_text": "1966"}
{"answers": {"text": ["265.7 nautical miles", "265.7", "492.1 km", "265.7"], "answer_start": [158, 158, 180, 158]}, "prediction_text": "265.7 nautical miles (492.1 km)"}
{"answers": {"text": ["25,700 km", "617.1", "1,142.9", "8,477 km", "(25,700 km"], "answer_start": [398, 314, 336, 230, 397]}, "prediction_text": "13,900 nautical miles (25,700 km)"}
{"answers": {"text": ["heat shield", "validated the Service Module engine and the Command Module heat shield.", "heat shield", "Service Module engine and the Command Module heat shield", "heat shield."], "answer_start": [514, 455, 514, 469, 514]}, "prediction_text": "Service Module engine and Command Module heat shield."}
{"answers": {"text": ["unmanned", "unmanned", "unmanned", "unmanned"], "answer_start": [9, 9, 9, 9]}, "prediction_text": "Eight people"}
{"answers": {"text": ["new Apollo spacesuit", "new Apollo spacesuit", "new Apollo spacesuit, designed to accommodate lunar extravehicular activity", "new Apollo spacesuit", "new Apollo spacesuit"], "answer_start": [348, 348, 348, 348, 348]}, "prediction_text": "Lunar Module Pilot (LMP) and Commander (CDR) Crew positions."}
{"answers": {"text": ["traditional visor helmet", "visor helmet", "visor helmet", "visor helmet", "visor helmet"], "answer_start": [435, 447, 447, 447, 447]}, "prediction_text": "Visor helmet"}
{"answers": {"text": ["a water-cooled undergarment", "water-cooled undergarment.", "water-cooled", "water-cooled undergarment", "water-cooled undergarment."], "answer_start": [571, 573, 573, 573, 573]}, "prediction_text": "Water-cooled undergarment"}
{"answers": {"text": ["Lunar Module Pilot", "Lunar Module Pilot", "Lunar Module Pilot", "Lunar Module Pilot", "Lunar Module Pilot"], "answer_start": [285, 285, 285, 285, 285]}, "prediction_text": "Lunar Module Pilot"}
{"answers": {"text": ["Deke Slayton", "Deke Slayton,", "Deke Slayton", "Deke Slayton", "Deke Slayton"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Deke Slayton"}
{"answers": {"text": ["Mercury", "Eisele", "Mercury", "Mercury astronaut", "Mercury"], "answer_start": [27, 248, 27, 27, 27]}, "prediction_text": "Gemini and Apollo programs"}
{"answers": {"text": ["1966", "1966", "1966", "January 1966", "1966"], "answer_start": [169, 498, 498, 161, 169]}, "prediction_text": "1966"}
{"answers": {"text": ["Donn F. Eisele", "Slayton", "Donn F. Eisele", "Grissom", "Eisele"], "answer_start": [240, 399, 240, 180, 269]}, "prediction_text": "Grissom"}
{"answers": {"text": ["AS-205", "Chaffee", "prime", "prime crew", "AS-205"], "answer_start": [759, 425, 744, 744, 759]}, "prediction_text": "Chaffee"}
{"answers": {"text": ["canceled", "canceled", "canceled", "canceled", "canceled"], "answer_start": [41, 41, 41, 41, 41]}, "prediction_text": "The validation of the CSM was accomplished on the 14-day first flight."}
{"answers": {"text": ["August 1967", "August 1967", "August 1967", "1967"], "answer_start": [355, 355, 355, 362]}, "prediction_text": "August 1967"}
{"answers": {"text": ["AS-205/208", "AS-205/208", "AS-205/208", "AS-205/208", "AS-205/208"], "answer_start": [321, 321, 321, 321, 321]}, "prediction_text": "Apollo 1 backup crew"}
{"answers": {"text": ["Apollo 1 backup crew", "promoted", "Apollo 1 backup crew", "Apollo 1 backup crew", "Apollo 1 backup crew."], "answer_start": [498, 405, 498, 498, 498]}, "prediction_text": "Apollo 1 backup crew"}
{"answers": {"text": ["Samuel Phillips", "Mueller", "Samuel Phillips", "Samuel Phillips", "Samuel Phillips"], "answer_start": [151, 115, 151, 151, 151]}, "prediction_text": "Samuel Phillips"}
{"answers": {"text": ["\"tiger team\"", "tiger", "tiger team", "tiger team", "\"tiger team\""], "answer_start": [177, 178, 178, 178, 177]}, "prediction_text": "\"Tiger team\""}
{"answers": {"text": ["1967", "1965", "1967", "1967", "1967"], "answer_start": [611, 60, 611, 611, 611]}, "prediction_text": "1967"}
{"answers": {"text": ["George Mueller", "Seamans", "George Mueller", "George Mueller", "Mueller"], "answer_start": [108, 472, 108, 108, 115]}, "prediction_text": "George Mueller"}
{"answers": {"text": ["altitude chamber", "altitude chamber", "altitude chamber", "altitude chamber"], "answer_start": [201, 201, 201, 201]}, "prediction_text": "North American"}
{"answers": {"text": ["Grissom, White, and Chaffee", "Apollo 1", "Grissom, White, and Chaffee", "Grissom, White, and Chaffee"], "answer_start": [0, 57, 0, 0]}, "prediction_text": "Grissom, White, and Chaffee"}
{"answers": {"text": ["launch countdown", "simulate a launch countdown on", "simulate a launch countdown", "simulate a launch countdown", "launch countdown"], "answer_start": [314, 303, 303, 303, 314]}, "prediction_text": "A more rigorous countdown simulation test."}
{"answers": {"text": ["North American", "North American", "North American", "North American"], "answer_start": [174, 174, 174, 174]}, "prediction_text": "North American"}
{"answers": {"text": ["strange odor in their spacesuits", "odor", "strange odor in their spacesuits", "strange odor", "strange odor in their spacesuits"], "answer_start": [129, 137, 129, 129, 129]}, "prediction_text": "Communication problems"}
{"answers": {"text": ["January 27, 1967", "1967", "January 27, 1967", "January 27, 1967", "January 27, 1967"], "answer_start": [43, 55, 43, 43, 43]}, "prediction_text": "January 27, 1967"}
{"answers": {"text": ["electrical fire", "ectrical fire", "delayed the sealing of the hatch", "electrical fire", "communications problems"], "answer_start": [326, 328, 169, 326, 209]}, "prediction_text": "The astronauts were asphyxiated before the hatch could be opened."}
{"answers": {"text": ["asphyxiated", "asphyxiated", "asphyxiated", "asphyxiated"], "answer_start": [589, 589, 589, 589]}, "prediction_text": "They were asphyxiated before the hatch could be opened."}
{"answers": {"text": ["100% oxygen", "electrical", "100% oxygen", "oxygen atmosphere", "100% oxygen"], "answer_start": [403, 326, 403, 408, 403]}, "prediction_text": "100% oxygen atmosphere"}
{"answers": {"text": ["both houses of Congress", "Congress", "both houses of Congress", "both houses of Congress", "both houses of Congress."], "answer_start": [64, 79, 64, 64, 64]}, "prediction_text": "Both houses of Congress"}
{"answers": {"text": ["deficiencies", "workmanship and quality control", "deficiencies existed in Command Module design, workmanship and quality control", "\"deficiencies existed in Command Module design, workmanship and quality control.\""], "answer_start": [194, 241, 194, 193]}, "prediction_text": "Deficiencies in CM design and workmanship."}
{"answers": {"text": ["George Low", "Low", "George Low", "George Low", "George Low."], "answer_start": [504, 511, 504, 504, 504]}, "prediction_text": "George Low"}
{"answers": {"text": ["immediately", "immediately", "immediately", "immediately"], "answer_start": [5, 5, 5, 5]}, "prediction_text": "Soon after the cabin fire incident"}
{"answers": {"text": ["nitrogen/oxygen mixture", "nitrogen/oxygen", "nitrogen/oxygen", "nitrogen/oxygen mixture", "nitrogen/oxygen"], "answer_start": [149, 149, 149, 149, 149]}, "prediction_text": "Nitrogen/oxygen mixture"}
{"answers": {"text": ["flammable cabin and space suit materials", "flammable cabin", "flammable", "flammable cabin and space suit materials", "flammable cabin and space suit materials."], "answer_start": [237, 237, 237, 237, 237]}, "prediction_text": "Space suit materials"}
{"answers": {"text": ["quick-release, outward opening door", "Block I plug-type hatch cover", "quick-release", "quick-release, outward opening door", "quick-release, outward opening door"], "answer_start": [374, 337, 374, 374, 374]}, "prediction_text": "A quick-release door"}
{"answers": {"text": ["discontinued", "discontinued", "unmanned Saturn V flights", "discontinued", "discontinued"], "answer_start": [416, 416, 495, 416, 416]}, "prediction_text": "NASA discontinued the program."}
{"answers": {"text": ["fire-resistant Block II", "Crew members", "fire-resistant Block II", "fire-resistant", "modified, fire-resistant Block II space suits,"], "answer_start": [573, 522, 573, 573, 563]}, "prediction_text": "modified, fire-resistant Block II space suits"}
{"answers": {"text": ["sequence", "manned lunar landing.", "had to be successfully accomplished", "sequence of mission types", "sequence"], "answer_start": [38, 130, 70, 38, 38]}, "prediction_text": "Unmanned Saturn V validation"}
{"answers": {"text": ["successful", "successfully accomplished", "successfully accomplished", "successfully accomplished"], "answer_start": [172, 172, 80, 80]}, "prediction_text": "Each mission had to be successfully accomplished before the next ones could be performed."}
{"answers": {"text": ["letters", "letters", "letters were used instead of numbers", "letters"], "answer_start": [319, 319, 319, 319]}, "prediction_text": "Letters"}
{"answers": {"text": ["AS-501", "AS-501", "AS-501", "AS-501", "AS-501"], "answer_start": [110, 110, 110, 110, 110]}, "prediction_text": "AS-501"}
{"answers": {"text": ["heat shield", "Service Module engine", "heat shield", "capability of the Command Module's heat shield to survive a trans-lunar reentry", "capability of the Command Module's heat shield to survive a trans-lunar reentry"], "answer_start": [248, 323, 248, 213, 213]}, "prediction_text": "The Service Module engine"}
{"answers": {"text": ["April 4, 1968", "1968", "April 4, 1968", "April 4, 1968", "April 4, 1968"], "answer_start": [450, 459, 450, 450, 450]}, "prediction_text": "April 4, 1968"}
{"answers": {"text": ["third unmanned test", "Apollo 6", "third unmanned test", "cancelling a third unmanned test", "third unmanned test."], "answer_start": [1365, 1288, 1365, 1352, 1365]}, "prediction_text": "Apollo 6 testing"}
{"answers": {"text": ["Apollo 5", "Apollo 5", "Apollo 5", "Apollo 5", "Apollo 5"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Apollo 5"}
{"answers": {"text": ["pad 37", "37", "37", "pad 37", "pad 37"], "answer_start": [89, 93, 93, 89, 89]}, "prediction_text": "Pad 37"}
{"answers": {"text": ["Grumman", "Low", "Grumman", "Grumman", "Grumman"], "answer_start": [474, 520, 474, 474, 474]}, "prediction_text": "George Low"}
{"answers": {"text": ["success", "success", "LM engines were successfully test-fired and restarted", "successfully"], "answer_start": [194, 194, 178, 194]}, "prediction_text": "A failure"}
{"answers": {"text": ["\"fire-in-the-hole\"", "fire-in-the-hole", "fire-in-the-hole", "fire-in-the-hole", "\"fire-in-the-hole\""], "answer_start": [372, 373, 373, 373, 372]}, "prediction_text": "\"Fire-in-the-hole\" test"}
{"answers": {"text": ["two Saturn IBs", "V", "two Saturn IBs", "Saturn V", "two Saturn IBs"], "answer_start": [136, 123, 136, 116, 136]}, "prediction_text": "Saturn V"}
{"answers": {"text": ["Zond 5", "Zond 5", "Zond 5", "Zond 5", "Zond 5"], "answer_start": [602, 602, 602, 602, 602]}, "prediction_text": "Zond 5"}
{"answers": {"text": ["Christmas Eve", "Christmas Eve", "Christmas Eve", "Christmas Eve"], "answer_start": [966, 966, 966, 966]}, "prediction_text": "Christmas Eve"}
{"answers": {"text": ["orbit the Moon", "orbit the Moon", "to orbit the Moon", "orbit the Moon", "orbit the Moon"], "answer_start": [370, 370, 367, 370, 370]}, "prediction_text": "Sending Apollo 8 to orbit the Moon instead."}
{"answers": {"text": ["human cosmonauts", "human cosmonauts", "human cosmonauts", "human cosmonauts"], "answer_start": [667, 667, 667, 667]}, "prediction_text": "Animals"}
{"answers": {"text": ["Gemini", "all-Gemini veteran", "Gemini", "all-Gemini veteran crew", "Gemini"], "answer_start": [63, 59, 63, 59, 63]}, "prediction_text": "Gemini program"}
{"answers": {"text": ["July 1969", "July", "July 1969", "July 20, 1969", "July 1969"], "answer_start": [43, 43, 43, 240, 43]}, "prediction_text": "July 1969"}
{"answers": {"text": ["black-and-white television", "automated scientific instruments", "black-and-white television", "black-and-white television", "black-and-white television"], "answer_start": [516, 455, 516, 516, 516]}, "prediction_text": "Black-and-white television"}
{"answers": {"text": ["Neil Armstrong, Michael Collins and Buzz Aldrin", "Neil Armstrong, Michael Collins and Buzz Aldrin", "Neil Armstrong, Michael Collins and Buzz Aldrin", "Neil Armstrong, Michael Collins and Buzz Aldrin", "Neil Armstrong, Michael Collins and Buzz Aldrin."], "answer_start": [97, 97, 97, 97, 97]}, "prediction_text": "Neil Armstrong, Michael Collins, Buzz Aldrin"}
{"answers": {"text": ["July 24", "July 24.", "July 24", "July 24", "July 24"], "answer_start": [592, 592, 592, 592, 592]}, "prediction_text": "July 24"}
{"answers": {"text": ["Apollo 12", "Apollo 12", "Apollo 12", "Apollo 12", "Apollo 12"], "answer_start": [107, 107, 107, 107, 107]}, "prediction_text": "Surveyor 3"}
{"answers": {"text": ["Surveyor 3", "Surveyor 3", "Surveyor 3", "Surveyor 3", "Surveyor 3"], "answer_start": [148, 148, 148, 148, 148]}, "prediction_text": "Surveyor 3"}
{"answers": {"text": ["returned to Earth", "color television camera", "returned to Earth", "removed some parts", "returned to Earth."], "answer_start": [575, 351, 575, 545, 575]}, "prediction_text": "Removed parts"}
{"answers": {"text": ["the Sun", "Sun", "the Sun", "the Sun", "pointed into the Sun."], "answer_start": [426, 430, 426, 426, 413]}, "prediction_text": "Ignited Sun"}
{"answers": {"text": ["Lunar Roving Vehicle (LRV)", "payload capacity", "Lunar Roving Vehicle", "lunar orbital sensors and cameras", "Lunar Roving Vehicle"], "answer_start": [577, 260, 577, 406, 577]}, "prediction_text": "Lunar Roving Vehicle (LRV)"}
{"answers": {"text": ["Block II spacesuit", "Block II spacesuit", "the mass of the CSM and LM", "Block II spacesuit"], "answer_start": [688, 688, 190, 688]}, "prediction_text": "Block II spacesuit"}
{"answers": {"text": ["eight", "five", "five", "eight", "eight"], "answer_start": [133, 230, 230, 133, 133]}, "prediction_text": "Eight more landing sites"}
{"answers": {"text": ["over three days", "three days.", "over three days", "over three days", "over three days"], "answer_start": [524, 529, 524, 524, 524]}, "prediction_text": "Over three days"}
{"answers": {"text": ["mass", "exploration area", "mass", "mass", "mass"], "answer_start": [194, 619, 194, 194, 194]}, "prediction_text": "Mass of the CSM and LM."}
{"answers": {"text": ["liquid oxygen tank exploded", "liquid oxygen tank exploded,", "liquid oxygen tank exploded", "liquid oxygen tank exploded", "liquid oxygen tank exploded, disabling the Service Module"], "answer_start": [263, 263, 263, 263, 263]}, "prediction_text": "A liquid oxygen tank exploded."}
{"answers": {"text": ["rookies", "Jack Swigert, and Fred Haise", "two rookies", "rookies"], "answer_start": [127, 163, 123, 127]}, "prediction_text": "Two rookies"}
{"answers": {"text": ["grounded", "oxygen tank was redesigned", "grounded", "Apollo was grounded", "grounded"], "answer_start": [634, 686, 634, 623, 634]}, "prediction_text": "Apollo was grounded again."}
{"answers": {"text": ["oxygen tank", "oxygen tank", "oxygen tank", "oxygen tank", "oxygen tank"], "answer_start": [686, 686, 686, 686, 686]}, "prediction_text": "Oxygen tank was redesigned."}
{"answers": {"text": ["April 1970", "April", "April 1970", "April 1970", "April 1970,"], "answer_start": [195, 195, 195, 195, 195]}, "prediction_text": "April 1970"}
{"answers": {"text": ["Apollo 20", "Saturn V to", "Apollo 20", "Apollo 20", "Apollo 20."], "answer_start": [255, 79, 255, 255, 255]}, "prediction_text": "Apollo 20"}
{"answers": {"text": ["began to shrink", "NASA also had to make funds available", "began to shrink", "began to shrink", "shrink"], "answer_start": [292, 348, 292, 292, 301]}, "prediction_text": "NASA's budget began to shrink."}
{"answers": {"text": ["museum exhibits", "museum exhibits", "museum exhibits", "museum exhibits", "museum exhibits"], "answer_start": [535, 535, 535, 535, 535]}, "prediction_text": "They became museum exhibits at John F. Kennedy Space Center."}
{"answers": {"text": ["1971", "1971", "1971", "1971", "1971"], "answer_start": [440, 440, 440, 440, 440]}, "prediction_text": "1971"}
{"answers": {"text": ["extremely old", "old", "extremely old", "extremely old", "old"], "answer_start": [38, 48, 38, 38, 48]}, "prediction_text": "Very old compared to Earth."}
{"answers": {"text": ["4.6 billion years", "4.6 billion years", ".2 billion years for the basaltic samples derived from the lunar maria, to about 4.6 billion years for samples derived from the highlands crust", "4.6 billion"], "answer_start": [243, 243, 162, 243]}, "prediction_text": "About 3.2 billion years old."}
{"answers": {"text": ["KREEP", "calcium-rich feldspar mineral anorthite,", "anorthite", "feldspar mineral anorthite", "KREEP"], "answer_start": [791, 659, 689, 672, 791]}, "prediction_text": "KREEP and anorthositic samples."}
{"answers": {"text": ["Genesis Rock", "Genesis", "Genesis Rock", "Genesis Rock", "anorthosite"], "answer_start": [503, 503, 503, 503, 604]}, "prediction_text": "Genesis Rock"}
{"answers": {"text": ["micrometeoroid impact craters", "micrometeoroid impact craters", "micrometeoroid impact craters", "micrometeoroid impact craters", "micrometeoroid impact craters"], "answer_start": [100, 100, 100, 100, 100]}, "prediction_text": "High pressure shock waves"}
{"answers": {"text": ["impact process effects", "micrometeoroid impact craters", "high pressure shock waves", "subjected to high pressure shock waves", "evidence of impact process effects"], "answer_start": [38, 100, 234, 221, 26]}, "prediction_text": "Evidence of impact process effects."}
{"answers": {"text": ["materials melted near an impact crater.", "materials melted near an impact crater", "materials melted near an impact crater", "materials melted near an impact crater", "materials melted near an impact crater."], "answer_start": [350, 350, 350, 350, 350]}, "prediction_text": "Material melted near an impact crater."}
{"answers": {"text": ["$170 billion", "170 billion", "170 billion", "$170 billion", "roughly $170 billion."], "answer_start": [131, 132, 132, 131, 123]}, "prediction_text": "$170 billion"}
{"answers": {"text": ["15", "15", "15", "15 Saturn V rockets", "15"], "answer_start": [214, 214, 214, 214, 214]}, "prediction_text": "16 rockets"}
{"answers": {"text": ["$20.4 billion", "20.4 billion,", "20.4 billion", "$20.4 billion", "$20.4 billion"], "answer_start": [615, 616, 616, 615, 615]}, "prediction_text": "$20.4 billion"}
{"answers": {"text": ["Apollo X", "Apollo Extension Series", "Apollo Extension Series", "Apollo X", "Apollo Extension Series"], "answer_start": [142, 117, 117, 142, 117]}, "prediction_text": "Apollo Extension Series"}
{"answers": {"text": ["Apollo Applications Program", "Apollo Applications Program", "Apollo Applications Program", "Apollo Applications Program", "Apollo Applications Program"], "answer_start": [514, 514, 514, 514, 514]}, "prediction_text": "Apollo Applications Program"}
{"answers": {"text": ["Venus", "Venus", "Venus", "Venus"], "answer_start": [809, 809, 809, 809]}, "prediction_text": "Venus"}
{"answers": {"text": ["1973", "1973", "1973", "1973", "1973"], "answer_start": [188, 188, 188, 188, 188]}, "prediction_text": "1973"}
{"answers": {"text": ["on the ground", "on the ground", "constructed complete on the ground", "on the ground"], "answer_start": [136, 136, 115, 136]}, "prediction_text": "In space"}
{"answers": {"text": ["February 8, 1974", "February 8, 1974,", "February 8, 1974", "February 8, 1974", "February 8, 1974"], "answer_start": [406, 406, 406, 406, 406]}, "prediction_text": "1979"}
{"answers": {"text": ["Apollo Telescope Mount", "Apollo Telescope Mount", "solar telescope", "Apollo Telescope Mount", "Apollo Telescope Mount"], "answer_start": [259, 259, 287, 259, 259]}, "prediction_text": "Solar Telescope Mount"}
{"answers": {"text": ["Lunar Reconnaissance Orbiter", "Japan Aerospace Exploration Agency's SELENE", "Reconnaissance Orbiter", "robotic Lunar Reconnaissance Orbiter", "Lunar Reconnaissance Orbiter"], "answer_start": [205, 9, 211, 197, 205]}, "prediction_text": "Lunar Reconnaissance Orbiter"}
{"answers": {"text": ["Apollo 11", "Apollo 11", "Apollo 11", "Apollo 11"], "answer_start": [579, 579, 579, 579]}, "prediction_text": "Apollo 11"}
{"answers": {"text": ["unknown", "retain their original colors", "unknown", "degree to which these flags retain their original colors remains unknown", "unknown"], "answer_start": [799, 762, 799, 734, 799]}, "prediction_text": "They retain their original colors."}
{"answers": {"text": ["Apollo 8", "Apollo 8", "Apollo 8", "Apollo 8", "Apollo 8"], "answer_start": [12, 12, 12, 12, 12]}, "prediction_text": "Apollo 8"}
{"answers": {"text": ["Book of Genesis", "Genesis", "Genesis", "Book of Genesis", "Genesis"], "answer_start": [141, 149, 149, 141, 149]}, "prediction_text": "Book of Genesis"}
{"answers": {"text": ["one-quarter", "one-quarter", "one-quarter", "one-quarter of the population", "one-quarter"], "answer_start": [195, 195, 195, 195, 195]}, "prediction_text": "One-quarter of the population saw the images."}
{"answers": {"text": ["inspiring end", "inspiring", "inspiring", "inspiring end", "inspiring"], "answer_start": [370, 370, 370, 370, 370]}, "prediction_text": "An inspiring end to 1968."}
{"answers": {"text": ["special Apollo TV camera", "Apollo TV camera", "Apollo TV", "Apollo TV camera", "Apollo TV camera"], "answer_start": [40, 48, 48, 48, 48]}, "prediction_text": "Apollo TV camera"}
{"answers": {"text": ["incompatible", "had to be converted", "incompatible", "format incompatible with broadcast TV", "incompatible"], "answer_start": [92, 160, 92, 85, 92]}, "prediction_text": "Compatibility with broadcast TV formats."}
{"answers": {"text": ["magnetic tape shortage", "remove massive numbers of magnetic tapes from the National Archives and Records Administration to be recorded over", "magnetic tape shortage", "magnetic tape shortage", "magnetic tape shortage"], "answer_start": [284, 324, 284, 284, 284]}, "prediction_text": "Magnetic tape shortage"}
{"answers": {"text": ["newer satellite data", "the National Archives and Records Administration", "newer satellite data", "satellite data", "satellite data"], "answer_start": [444, 370, 444, 450, 450]}, "prediction_text": "Lunar footage"}
{"answers": {"text": ["Stan Lebar", "Nafzger", "Stan Lebar", "Stan Lebar", "Stan Lebar"], "answer_start": [466, 602, 466, 466, 466]}, "prediction_text": "Stan Lebar"}
{"answers": {"text": ["Nafzger", "Nafzger", "Nafzger", "Nafzger", "Nafzger"], "answer_start": [102, 102, 102, 102, 102]}, "prediction_text": "Nafzger and Lowry Digital"}
{"answers": {"text": ["without destroying historical legitimacy", "Lowry Digital f", "without destroying historical legitimacy", "processed to remove random noise and camera shake without destroying historical legitimacy", "without destroying historical legitimacy"], "answer_start": [221, 126, 221, 171, 221]}, "prediction_text": "Lost legitimacy."}
{"answers": {"text": ["kinescope recordings", "kinescope", "kinescope recordings", "kinescope"], "answer_start": [330, 330, 330, 330]}, "prediction_text": "Kinescope recordings"}
{"answers": {"text": ["Lowry Digital", "CBS", "Lowry Digital", "Lowry Digital", "Lowry Digital"], "answer_start": [126, 308, 126, 126, 126]}, "prediction_text": "Nafzger and Lowry Digital"}
{"answers": {"text": ["black and white", "black and white,", "black and white", "remaining in black and white", "remaining in black and white,"], "answer_start": [414, 414, 414, 401, 401]}, "prediction_text": "They remained black and white."}
{"answers": {"text": ["primary law, secondary law and supplementary law.", "primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law"], "answer_start": [227, 227, 227, 227]}, "prediction_text": "Primary law, secondary law, and supplementary law."}
{"answers": {"text": ["a body of treaties and legislation", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states", "a body of treaties and legislation, such as Regulations and Directives", "a body of treaties and legislation, such as Regulations and Directives"], "answer_start": [22, 22, 22, 22]}, "prediction_text": "Body of treaties and legislation"}
{"answers": {"text": ["Treaties establishing the European Union", "the Treaties establishing the European Union", "primary law, secondary law and supplementary law", "the Treaties establishing the European Union"], "answer_start": [317, 313, 227, 313]}, "prediction_text": "Treaties and regulations"}
{"answers": {"text": ["regulations and directives", "regulations and directives which are based on the Treaties", "regulations and directives which are based on the Treaties", "regulations and directives which are based on the Treaties"], "answer_start": [385, 385, 385, 385]}, "prediction_text": "Regulations and directives"}
{"answers": {"text": ["European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union", "European Parliament and the Council of the European Union", "European Parliament and the Council of the European Union"], "answer_start": [514, 510, 514, 514]}, "prediction_text": "European Parliament and Council"}
{"answers": {"text": ["a body of treaties and legislation", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states", "a body of treaties and legislation, such as Regulations and Directives", "a body of treaties and legislation, such as Regulations and Directives"], "answer_start": [22, 22, 22, 22]}, "prediction_text": "Body of treaties and legislation"}
{"answers": {"text": ["direct effect or indirect effect", "direct effect or indirect effect on the laws of European Union member states", "direct effect or indirect effect", "direct effect or indirect effect"], "answer_start": [105, 105, 105, 105]}, "prediction_text": "Direct effect or indirect effect."}
{"answers": {"text": ["primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law"], "answer_start": [227, 227, 227, 227]}, "prediction_text": "Primary law, secondary law, and supplementary law."}
{"answers": {"text": ["European Parliament and the Council of the European Union", "the Treaties establishing the European Union", "European Parliament and the Council of the European Union", "European Parliament and the Council of the European Union"], "answer_start": [514, 313, 514, 514]}, "prediction_text": "European Parliament and Council"}
{"answers": {"text": ["primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law", "primary law, secondary law and supplementary law"], "answer_start": [227, 227, 227, 227]}, "prediction_text": "Primary law, secondary law, and supplementary law."}
{"answers": {"text": ["the Treaties establishing the European Union", "the Treaties establishing the European Union", "the Treaties establishing the European Union", "the Treaties establishing the European Union"], "answer_start": [313, 313, 313, 313]}, "prediction_text": "Treaties and regulations"}
{"answers": {"text": ["the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union", "European Parliament and the Council of the European Union", "European Parliament and the Council of the European Union"], "answer_start": [510, 510, 514, 514]}, "prediction_text": "European Parliament and Council"}
{"answers": {"text": ["three", "three", "three", "three"], "answer_start": [187, 187, 187, 187]}, "prediction_text": "Three sources"}
{"answers": {"text": ["courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union"], "answer_start": [37, 33, 33, 33]}, "prediction_text": "European Union law is applied by the courts of member states."}
{"answers": {"text": ["courts of member states", "the courts of member states", "the courts of member states", "the courts of member states"], "answer_start": [209, 205, 205, 205]}, "prediction_text": "European Commission"}
{"answers": {"text": ["Treaty on the Functioning of the European Union", "the Treaty on the Functioning of the European Union", "Treaty on the Functioning of the European Union", "Treaty on the Functioning of the European Union"], "answer_start": [430, 426, 430, 430]}, "prediction_text": "Treaty on the Functioning of the European Union"}
{"answers": {"text": ["The European Court of Justice", "The European Court of Justice", "The European Court of Justice", "The European Court of Justice"], "answer_start": [479, 479, 479, 479]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["international law", "case law by the Court of Justice", "case law by the Court of Justice", "case law by the Court of Justice"], "answer_start": [654, 620, 620, 620]}, "prediction_text": "Case law by the Court of Justice"}
{"answers": {"text": ["courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union"], "answer_start": [37, 33, 33, 33]}, "prediction_text": "Court of Justice of the European Union"}
{"answers": {"text": ["the Treaty on the Functioning of the European Union", "the Treaty on the Functioning of the European Union", "the Treaty on the Functioning of the European Union.", "the Treaty on the Functioning of the European Union"], "answer_start": [426, 426, 426, 426]}, "prediction_text": "Treaty on the Functioning of the European Union"}
{"answers": {"text": ["The European Court of Justice", "The European Court of Justice", "The European Court of Justice", "The European Court of Justice"], "answer_start": [479, 479, 479, 479]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["international law", "international law", "international law", "international law"], "answer_start": [654, 654, 654, 654]}, "prediction_text": "Case law by the Court of Justice"}
{"answers": {"text": ["the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union", "the courts of member states and the Court of Justice of the European Union"], "answer_start": [33, 33, 33, 33]}, "prediction_text": "The courts of member states"}
{"answers": {"text": ["the courts of member states", "the courts of member states", "the courts of member states", "the courts of member states"], "answer_start": [205, 205, 205, 205]}, "prediction_text": "European Commission"}
{"answers": {"text": ["The European Court of Justice", "The European Court of Justice", "The European Court of Justice", "The European Court of Justice"], "answer_start": [479, 479, 479, 479]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["case law by the Court of Justice, international law and general principles of European Union law", "general principles of European Union law", "case law by the Court of Justice", "case law by the Court of Justice"], "answer_start": [620, 676, 620, 620]}, "prediction_text": "Case law by the Court of Justice, international law, and general principles of European Union law."}
{"answers": {"text": ["Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)", "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)", "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)", "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)"], "answer_start": [204, 200, 200, 200]}, "prediction_text": "Treaty on European Union and Treaty on the Functioning of the European Union (TFEU)"}
{"answers": {"text": ["The European Commission", "The European Commission", "The European Commission", "The European Commission"], "answer_start": [553, 553, 553, 553]}, "prediction_text": "The European Commission"}
{"answers": {"text": ["citizens", "citizens", "citizens", "citizens"], "answer_start": [767, 767, 767, 767]}, "prediction_text": "Citizens"}
{"answers": {"text": ["The European Court of Justice", "The European Court of Justice", "The European Court of Justice", "The European Court of Justice"], "answer_start": [1179, 1179, 1179, 1179]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["The \"European Council\"", "The \"European Council\"", "The \"European Council\"", "The \"European Council\""], "answer_start": [932, 932, 932, 932]}, "prediction_text": "European Commission"}
{"answers": {"text": ["Treaty on European Union (TEU)", "Treaty on European Union (TEU)", "Treaty on European Union (TEU)", "Treaty on European Union (TEU)"], "answer_start": [98, 98, 98, 98]}, "prediction_text": "Treaty on European Union (TEU)"}
{"answers": {"text": ["the Faroe Islands", "the Faroe Islands", "the Faroe Islands", "the Faroe Islands"], "answer_start": [1002, 1002, 1002, 1002]}, "prediction_text": "Faroe Islands"}
{"answers": {"text": ["can interpret the Treaties, but it cannot rule on their validity", "The Court of Justice of the European Union can interpret the Treaties", "The Court of Justice of the European Union can interpret the Treaties", "The Court of Justice of the European Union can interpret the Treaties"], "answer_start": [1617, 1574, 1574, 1574]}, "prediction_text": "Interpretation of treaties"}
{"answers": {"text": ["if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional.", "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional", "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional", "if the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional"], "answer_start": [1804, 1804, 1804, 1804]}, "prediction_text": "In cases where the Treaty provisions have a direct effect and they are sufficiently clear, precise and unconditional."}
{"answers": {"text": ["as soon as they enter into force, unless stated otherwise", "Treaties apply as soon as they enter into force", "as soon as they enter into force", "as soon as they enter into force"], "answer_start": [1081, 1066, 1081, 1081]}, "prediction_text": "After entering into force"}
{"answers": {"text": ["Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)", "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)", "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)", "the Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)"], "answer_start": [98, 94, 94, 94]}, "prediction_text": "Treaty on European Union (TEU) and Treaty on the Functioning of the European Union (TFEU)"}
{"answers": {"text": ["Gibraltar and the \u00c5land islands", "Gibraltar and the \u00c5land islands", "Gibraltar and the \u00c5land islands", "Gibraltar and the \u00c5land islands"], "answer_start": [750, 750, 750, 750]}, "prediction_text": "Gibraltar and \u00c5land islands."}
{"answers": {"text": ["Treaties apply as soon as they enter into force, unless stated otherwise", "Treaties apply as soon as they enter into force, unless stated otherwise, and are generally concluded for an unlimited period", "as soon as they enter into force", "as soon as they enter into force"], "answer_start": [1066, 1066, 1081, 1081]}, "prediction_text": "Before entering into force"}
{"answers": {"text": ["The Court of Justice of the European Union can interpret the Treaties", "The Court of Justice of the European Union can interpret the Treaties", "The Court of Justice of the European Union", "The Court of Justice of the European Union"], "answer_start": [1574, 1574, 1574, 1574]}, "prediction_text": "The Court of Justice of the European Union"}
{"answers": {"text": ["with common rules for coal and steel, and then atomic energy", "with common rules for coal and steel", "with common rules for coal and steel", "with common rules for coal and steel"], "answer_start": [58, 58, 58, 58]}, "prediction_text": "Common rules for coal and steel, atomic energy, and the Treaty of Rome 1957."}
{"answers": {"text": ["Treaty of Rome 1957 and the Maastricht Treaty 1992", "the Treaty of Rome 1957 and the Maastricht Treaty 1992", "the Treaty of Rome 1957 and the Maastricht Treaty 1992 (now: TFEU)", "the Treaty of Rome 1957 and the Maastricht Treaty 1992 (now: TFEU)"], "answer_start": [191, 187, 187, 187]}, "prediction_text": "Treaty of Rome 1957 and Maastricht Treaty 1992."}
{"answers": {"text": ["1985", "1985", "1985", "1985"], "answer_start": [889, 889, 889, 889]}, "prediction_text": "1985"}
{"answers": {"text": ["in 1972 (though Norway did not end up joining)", "not", "not", "not"], "answer_start": [806, 833, 833, 833]}, "prediction_text": "No, Norway did not join the European Union."}
{"answers": {"text": ["Greenland", "Greenland", "Greenland", "Greenland"], "answer_start": [1184, 1184, 1184, 1184]}, "prediction_text": "Romania"}
{"answers": {"text": ["common rules for coal and steel, and then atomic energy", "common rules for coal and steel, and then atomic energy", "with common rules for coal and steel", "with common rules for coal and steel"], "answer_start": [63, 63, 58, 58]}, "prediction_text": "Common rules for coal and steel, atomic energy, and the Treaty of Rome 1957."}
{"answers": {"text": ["1992", "1992", "1992", "1992"], "answer_start": [237, 237, 237, 237]}, "prediction_text": "1992"}
{"answers": {"text": ["1986", "1986", "1986", "1986"], "answer_start": [430, 430, 430, 430]}, "prediction_text": "1986"}
{"answers": {"text": ["1972", "1972", "1972", "1972"], "answer_start": [809, 809, 809, 809]}, "prediction_text": "1985"}
{"answers": {"text": ["1985", "1985", "1985", "1985"], "answer_start": [1213, 1213, 1213, 1213]}, "prediction_text": "1985"}
{"answers": {"text": ["Following the Nice Treaty", "2004", "Following the Nice Treaty", "Following the Nice Treaty"], "answer_start": [0, 289, 0, 0]}, "prediction_text": "Nice Treaty"}
{"answers": {"text": ["referendum in France and the referendum in the Netherlands", "the referendum in France and the referendum in the Netherlands", "referendum in France and the referendum in the Netherlands", "the referendum in France and the referendum in the Netherlands"], "answer_start": [225, 221, 225, 221]}, "prediction_text": "France and Netherlands"}
{"answers": {"text": ["very similar", "very similar", "very similar", "very similar"], "answer_start": [421, 421, 421, 421]}, "prediction_text": "Officially identical"}
{"answers": {"text": ["an amending treaty", "an amending treaty", "an amending treaty", "an amending treaty"], "answer_start": [493, 493, 493, 493]}, "prediction_text": "Amending treaty"}
{"answers": {"text": ["altered the existing treaties", "it significantly altered the existing treaties", "significantly altered the existing treaties", "altered the existing treaties"], "answer_start": [543, 526, 529, 543]}, "prediction_text": "Replaced existing treaties."}
{"answers": {"text": ["there was an attempt to reform the constitutional law of the European Union and make it more transparent", "an attempt to reform the constitutional law of the European Union and make it more transparent", "there was an attempt to reform the constitutional law of the European Union and make it more transparent", "an attempt to reform the constitutional law of the European Union and make it more transparent"], "answer_start": [27, 37, 27, 37]}, "prediction_text": "Reform of the constitutional law of the European Union"}
{"answers": {"text": ["this would have also produced a single constitutional document", "this would have also produced a single constitutional document", "would have also produced a single constitutional document", "this would have also produced a single constitutional document"], "answer_start": [133, 133, 138, 133]}, "prediction_text": "A single constitutional document"}
{"answers": {"text": ["the referendum in France and the referendum in the Netherlands", "the referendum in France and the referendum in the Netherlands", "the referendum in France and the referendum in the Netherlands", "the referendum in France and the referendum in the Netherlands"], "answer_start": [221, 221, 221, 221]}, "prediction_text": "The Nice Treaty"}
{"answers": {"text": ["the Lisbon Treaty", "the Lisbon Treaty", "the Lisbon Treaty", "the Lisbon Treaty"], "answer_start": [372, 372, 372, 372]}, "prediction_text": "Lisbon Treaty"}
{"answers": {"text": ["The European Commission", "The European Commission", "The European Commission", "The European Commission"], "answer_start": [0, 0, 0, 0]}, "prediction_text": "European Commission"}
{"answers": {"text": ["the Commission", "The European Commission", "the Commission", "the Commission"], "answer_start": [487, 0, 487, 487]}, "prediction_text": "The Parliament (or the Council)"}
{"answers": {"text": ["The Commission's President", "The Commission's President", "The Commission's President", "The Commission's President ("], "answer_start": [793, 793, 793, 793]}, "prediction_text": "Parliament"}
{"answers": {"text": ["one Commissioner for each of the 28 member states", "one", "one", "one"], "answer_start": [1180, 1180, 1180, 1180]}, "prediction_text": "One Commissioner per member state."}
{"answers": {"text": ["Federica Mogherini", "Jean-Claude Juncker", "Jean-Claude Juncker", "Jean-Claude Juncker"], "answer_start": [1326, 864, 864, 864]}, "prediction_text": "Federica Mogherini"}
{"answers": {"text": ["Article 17(3)", "Article 17(3)", "Article 17(3)", "Article 17(3)"], "answer_start": [199, 199, 199, 199]}, "prediction_text": "Article 17(3) of the Treaty states that \"Commissioners should be completely independent and not take instructions from any Government.\""}
{"answers": {"text": ["The Commission's President", "The Commission's President", "The Commission's President", "The Commission's President"], "answer_start": [793, 793, 793, 793]}, "prediction_text": "The European Commission sets the agenda."}
{"answers": {"text": ["simple majority vote", "simple majority vote", "a simple majority vote", "a simple majority"], "answer_start": [945, 945, 943, 943]}, "prediction_text": "By a simple majority vote of the Council."}
{"answers": {"text": ["Ireland", "Ireland", "Ireland", "Ireland"], "answer_start": [1098, 1098, 1098, 1098]}, "prediction_text": "Ireland"}
{"answers": {"text": ["Commissioners", "Commissioners", "Commissioners", "Commissioners"], "answer_start": [1746, 1746, 1746, 1746]}, "prediction_text": "Commissioners are unelected subordinates of member state governments."}
{"answers": {"text": ["the Santer Commission", "the Santer Commission", "the Santer Commission", "the Santer Commission"], "answer_start": [255, 255, 255, 255]}, "prediction_text": "Santer Commission"}
{"answers": {"text": ["did in fact not break any law", "not", "not", "not"], "answer_start": [555, 567, 567, 567]}, "prediction_text": "Yes, the European Court of Justice ruled that a Commissioner giving a dentist a job did not break any law."}
{"answers": {"text": ["Committee of Independent Experts", "a Committee of Independent Experts", "Committee of Independent Experts", "Committee of Independent Experts"], "answer_start": [631, 629, 631, 631]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["European Council", "the European Council", "the European Council", "the European Council"], "answer_start": [1220, 1216, 1216, 1216]}, "prediction_text": "The European Council"}
{"answers": {"text": ["do not have voting rights", "not", "not", "not"], "answer_start": [1351, 1354, 1354, 1354]}, "prediction_text": "Yes, a Commissioner can sit in on ECB meetings."}
{"answers": {"text": ["1999", "1999", "1999", "1999"], "answer_start": [307, 307, 307, 307]}, "prediction_text": "1999"}
{"answers": {"text": ["Commission v Edith Cresson", "Commission v Edith Cresson", "Commission v Edith Cresson", "Commission v Edith Cresson"], "answer_start": [403, 403, 403, 403]}, "prediction_text": "Commission v Edith Cresson"}
{"answers": {"text": ["a Committee of Independent Experts", "a Committee of Independent Experts", "Committee of Independent Experts", "Committee of Independent Experts"], "answer_start": [629, 629, 631, 631]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["the European Anti-fraud Office", "the European Anti-fraud Office", "the European Anti-fraud Office", "the European Anti-fraud Office"], "answer_start": [801, 801, 801, 801]}, "prediction_text": "European Anti-fraud Office"}
{"answers": {"text": ["2012", "2012", "2012", "2012"], "answer_start": [836, 836, 836, 836]}, "prediction_text": "2012"}
{"answers": {"text": ["the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union"], "answer_start": [63, 63, 63, 63]}, "prediction_text": "European Parliament and Council of the European Union"}
{"answers": {"text": ["cannot initiate legislation against the Commission's wishes", "Parliament cannot initiate legislation against the Commission's wishes", "initiate legislation against the Commission's wishes", "cannot initiate legislation against the Commission's wishes"], "answer_start": [474, 463, 481, 474]}, "prediction_text": "Cannot initiate legislation against the Commission's wishes."}
{"answers": {"text": ["every five years", "every five years", "every five years", "every five years"], "answer_start": [1698, 1698, 1698, 1698]}, "prediction_text": "Every five years."}
{"answers": {"text": ["two-thirds majority", "a two-thirds majority", "a two-thirds majority", "a two-thirds majority"], "answer_start": [2742, 2740, 2740, 2740]}, "prediction_text": "Two-thirds majority"}
{"answers": {"text": ["the Commission and Council", "the Commission and Council", "the Commission and Council", "the European Parliament and the Council of the European Union"], "answer_start": [3090, 3090, 3090, 63]}, "prediction_text": "The Parliament and the Council."}
{"answers": {"text": ["the Commission", "the Commission", "the Commission", "the Commission"], "answer_start": [6, 6, 6, 6]}, "prediction_text": "European Parliament and the Council of the European Union"}
{"answers": {"text": ["the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union", "the European Parliament and the Council of the European Union"], "answer_start": [63, 63, 63, 63]}, "prediction_text": "European Parliament and the Council of the European Union"}
{"answers": {"text": ["1979", "1979", "1979", "1979"], "answer_start": [1184, 1184, 1184, 1184]}, "prediction_text": "1979"}
{"answers": {"text": ["every five years", "every five years", "every five years,", "every five years"], "answer_start": [1698, 1698, 1698, 1698]}, "prediction_text": "Every five years."}
{"answers": {"text": ["the conservative European People's Party", "European People's Party", "European People's Party", "European People's Party"], "answer_start": [2235, 2252, 2252, 2252]}, "prediction_text": "European People's Party"}
{"answers": {"text": ["different ministers of the member states", "ministers", "different ministers of the member states", "different ministers of the member states"], "answer_start": [70, 80, 70, 70]}, "prediction_text": "Ministers of member states"}
{"answers": {"text": ["Donald Tusk", "Poland Prime Minister Donald Tusk", "Donald Tusk", "Donald Tusk"], "answer_start": [443, 421, 443, 443]}, "prediction_text": "Donald Tusk"}
{"answers": {"text": ["inversely", "it is weighted inversely to member state size", "it is weighted inversely to member state size", "weighted inversely to member state size"], "answer_start": [980, 965, 965, 971]}, "prediction_text": "Weighted inversely to member state size."}
{"answers": {"text": ["352", "352 votes", "352", "352"], "answer_start": [1099, 1099, 1099, 1099]}, "prediction_text": "352 votes"}
{"answers": {"text": ["260", "260", "260", "260"], "answer_start": [1403, 1403, 1403, 1403]}, "prediction_text": "260 votes"}
{"answers": {"text": ["the Council", "the Council", "the Council", "the Council"], "answer_start": [36, 36, 36, 36]}, "prediction_text": "Council (or the secondary legislative body)"}
{"answers": {"text": ["each six months", "each six months", "each six months", "each six months"], "answer_start": [369, 369, 369, 369]}, "prediction_text": "Each six months."}
{"answers": {"text": ["352", "352", "352", "352"], "answer_start": [1099, 1099, 1414, 1414]}, "prediction_text": "352 votes"}
{"answers": {"text": ["at least 55 per cent of the Council members (not votes) representing 65 per cent of the population of the EU", "74 per cent, or 260 of the 352 votes", "74 per cent, or 260 of the 352 votes", "74 per cent, or 260 of the 352 votes"], "answer_start": [1249, 1387, 1387, 1387]}, "prediction_text": "260 votes"}
{"answers": {"text": ["a majority", "a Commission proposal", "a Commission proposal", "a Commission proposal"], "answer_start": [230, 173, 173, 173]}, "prediction_text": "A majority vote"}
{"answers": {"text": ["qualified majority", "qualified majority", "a majority", "a majority"], "answer_start": [336, 336, 230, 230]}, "prediction_text": "unanimity"}
{"answers": {"text": ["harder", "harder", "harder", "harder"], "answer_start": [861, 861, 861, 861]}, "prediction_text": "Harder to change EU law."}
{"answers": {"text": ["TEU articles 4 and 5", "TEU articles 4 and 5", "TEU articles 4 and 5", "TEU articles 4 and 5"], "answer_start": [1264, 1264, 1264, 1264]}, "prediction_text": "EU articles 4 and 5."}
{"answers": {"text": ["Court of Justice", "the Court of Justice", "the Court of Justice", "the Court of Justice"], "answer_start": [1625, 1621, 1621, 1621]}, "prediction_text": "Court of Justice"}
{"answers": {"text": ["TFEU article 294", "TFEU article 294", "TFEU article 294", "TFEU article 294"], "answer_start": [25, 25, 25, 25]}, "prediction_text": "TFEU article 294"}
{"answers": {"text": ["legislation can be blocked by a majority in Parliament, a minority in the Council, and a majority in the Commission", "unanimity", "unanimity", "a majority in Parliament"], "answer_start": [738, 382, 382, 768]}, "prediction_text": "A majority in Parliament."}
{"answers": {"text": ["TEU articles 4 and 5", "TEU articles 4 and 5", "TEU articles 4 and 5", "TEU articles 4 and 5"], "answer_start": [1264, 1264, 1264, 1264]}, "prediction_text": "TEU articles 4 and 5"}
{"answers": {"text": ["Conciliation Committee", "a \"Conciliation Committee\"", "a \"Conciliation Committee\"", "a \"Conciliation Committee\""], "answer_start": [486, 483, 483, 483]}, "prediction_text": "Parliament"}
{"answers": {"text": ["judicial branch", "The judicial branch", "The judicial branch", "The judicial branch"], "answer_start": [4, 0, 0, 0]}, "prediction_text": "The judicial branch"}
{"answers": {"text": ["Court of Justice of the European Union (CJEU)", "the Court of Justice of the European Union (CJEU)", "the Court of Justice of the European Union (CJEU)", "the Court of Justice of the European Union (CJEU)"], "answer_start": [203, 199, 199, 199]}, "prediction_text": "CJEU"}
{"answers": {"text": ["28", "28", "28", "28"], "answer_start": [707, 707, 707, 707]}, "prediction_text": "28 judges"}
{"answers": {"text": ["member state courts", "member state courts", "member state courts", "member state courts"], "answer_start": [1095, 1095, 1095, 1095]}, "prediction_text": "English Court of Appeal, German Bundesgerichtshof, Belgian Cour du travail, etc."}
{"answers": {"text": ["ensure that in the interpretation and application of the Treaties the law is observed", "\"ensure that in the interpretation and application of the Treaties the law is observed\"", "\"ensure that in the interpretation and application of the Treaties the law is observed\"", "\"ensure that in the interpretation and application of the Treaties the law is observed\""], "answer_start": [1304, 1303, 1303, 1303]}, "prediction_text": "Ensures that in the interpretation and application of the Treaties the law is observed."}
{"answers": {"text": ["by assuming the task of interpreting the treaties, and accelerating economic and political integration", "assuming the task of interpreting the treaties, and accelerating economic and political integration", "has the ability to expand and develop the law according to the principles it deems to be appropriate", "has the ability to expand and develop the law according to the principles it deems to be appropriate"], "answer_start": [89, 92, 1418, 1418]}, "prediction_text": "Assaults on treaties and accelerated economic and political integration."}
{"answers": {"text": ["the Court of Justice of the European Union", "the Court of Justice of the European Union (CJEU)", "the Court of Justice of the European Union (CJEU)", "the Court of Justice of the European Union (CJEU)"], "answer_start": [199, 199, 199, 199]}, "prediction_text": "CJEU"}
{"answers": {"text": ["Civil Service Tribunal", "Civil Service Tribunal", "Civil Service Tribunal", "Civil Service Tribunal"], "answer_start": [523, 523, 523, 523]}, "prediction_text": "Civil Service Tribunal"}
{"answers": {"text": ["three years", "three years", "three years", "three years"], "answer_start": [961, 961, 961, 961]}, "prediction_text": "Three years"}
{"answers": {"text": ["to \"ensure that in the interpretation and application of the Treaties the law is observed\"", "\"ensure that in the interpretation and application of the Treaties the law is observed\"", "\"ensure that in the interpretation and application of the Treaties the law is observed\"", "\"ensure that in the interpretation and application of the Treaties the law is observed\""], "answer_start": [1300, 1303, 1303, 1303]}, "prediction_text": "Ensures that in the interpretation and application of the Treaties the law is observed."}
{"answers": {"text": ["EU law", "EU law has primacy", "EU law has primacy", "EU law"], "answer_start": [399, 399, 399, 343]}, "prediction_text": "EU law"}
{"answers": {"text": ["nationalisation law was from 1962, and the treaty was in force from 1958", "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim", "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim", "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim"], "answer_start": [936, 924, 924, 924]}, "prediction_text": "Conflict of laws between different systems."}
{"answers": {"text": ["1964 and 1968", "1964 and 1968", "1964 and 1968", "1964 and 1968"], "answer_start": [2214, 2214, 2214, 2214]}, "prediction_text": "1964 and 1968."}
{"answers": {"text": ["the European Court of Justice and the highest national courts", "the European Court of Justice and the highest national courts", "the European Court of Justice and the highest national courts", "the European Court of Justice and the highest national courts"], "answer_start": [133, 133, 133, 133]}, "prediction_text": "European Court of Justice and national courts"}
{"answers": {"text": ["1964", "1964", "1964", "1964"], "answer_start": [446, 446, 446, 446]}, "prediction_text": "1964"}
{"answers": {"text": ["the Court of Justice", "the Court of Justice", "The Italian Constitutional Court", "The Italian Constitutional Court"], "answer_start": [1043, 1043, 870, 870]}, "prediction_text": "The Court of Justice argued that the Treaty of Rome did not prevent energy nationalism."}
{"answers": {"text": ["EU law", "EU law", "EU law", "EU law"], "answer_start": [59, 59, 59, 59]}, "prediction_text": "EU law takes precedence over national law."}
{"answers": {"text": ["foundational constitutional questions affecting democracy and human rights", "foundational constitutional questions affecting democracy and human rights", "foundational constitutional questions affecting democracy and human rights", "on foundational constitutional questions affecting democracy and human rights"], "answer_start": [199, 199, 199, 196]}, "prediction_text": "foundational constitutional questions affecting democracy and human rights."}
{"answers": {"text": ["1972", "1972", "1972", "1972"], "answer_start": [1297, 742, 742, 742]}, "prediction_text": "1972"}
{"answers": {"text": ["the ultimate authority of member states, its factual commitment to human rights, and the democratic will of the people.", "the ultimate authority of member states, its factual commitment to human rights, and the democratic will of the people", "the ultimate authority of member states", "the ultimate authority of member states"], "answer_start": [1966, 1966, 1966, 1966]}, "prediction_text": "The ultimate authority of member states, its factual commitment to human rights, and democratic will of the people."}
{"answers": {"text": ["if the EU does not comply with its basic constitutional rights and principles", "if the EU does not comply with its basic constitutional rights and principles", "if the EU does not comply with its basic constitutional rights and principles"], "answer_start": [1399, 1399, 1399]}, "prediction_text": "Fundamental principles of common law, and the democratic will of the people."}
{"answers": {"text": ["administrative law", "administrative law", "administrative law"], "answer_start": [77, 77, 77]}, "prediction_text": "Administrative law"}
{"answers": {"text": ["1986", "1986", "1986"], "answer_start": [688, 688, 688]}, "prediction_text": "1986"}
{"answers": {"text": ["All actions", "All actions by EU institutions can be subject to judicial review", "All actions"], "answer_start": [1095, 1095, 1095]}, "prediction_text": "Monetary damages"}
{"answers": {"text": ["constitutional law", "constitutional law", "constitutional law"], "answer_start": [6, 6, 6]}, "prediction_text": "Administrative law"}
{"answers": {"text": ["Van Gend en Loos v Nederlandse Administratie der Belastingen", "Van Gend en Loos v Nederlandse Administratie der Belastingen", "Van Gend en Loos v Nederlandse Administratie der Belastingen"], "answer_start": [165, 165, 165]}, "prediction_text": "In Van Gend en Loos v Nederlandse Administratie der Belastingen."}
{"answers": {"text": ["article 30", "TFEU article 30", "TFEU article 30"], "answer_start": [1087, 530, 530]}, "prediction_text": "Article 30 of the Treaty on the Functioning of the European Union (TFEU) states that no restrictions can be placed on trade."}
{"answers": {"text": ["a postal company", "a postal company", "a postal company"], "answer_start": [487, 487, 487]}, "prediction_text": "A postal company"}
{"answers": {"text": ["Treaty provisions", "EU Regulations are the same as Treaty provisions in this sense, because as TFEU article 288 states, they are \u2018directly applicable in all Member States\u2019", "they are \u2018directly applicable in all Member States\u2019"], "answer_start": [1332, 1301, 1401]}, "prediction_text": "Treaty provisions in this sense."}
{"answers": {"text": ["Directives", "Directives", "Directives"], "answer_start": [100, 100, 100]}, "prediction_text": "Directives do not allow citizens to sue other citizens."}
{"answers": {"text": ["4 weeks", "4 weeks paid holidays each year", "4 weeks paid"], "answer_start": [594, 594, 594]}, "prediction_text": "At least 4 weeks"}
{"answers": {"text": ["28 days", "more than 28 days", "more than 28 days"], "answer_start": [668, 658, 658]}, "prediction_text": "At least 28 days"}
{"answers": {"text": ["early 1990s", "the early 1990s", "early 1990s"], "answer_start": [1027, 1023, 1027]}, "prediction_text": "Early 1990s"}
{"answers": {"text": ["the member state cannot enforce conflicting laws, and a citizen may rely on the Directive in such an action", "the member state cannot enforce conflicting laws", "the member state cannot enforce conflicting laws"], "answer_start": [64, 64, 64]}, "prediction_text": "Member state cannot enforce conflicting laws."}
{"answers": {"text": ["a citizen or company can invoke a Directive, not just in a dispute with a public authority, but in a dispute with another citizen or company", "a citizen may rely on the Directive in such an action (so called \"vertical\" direct effect)", "a citizen may rely on the Directive in such an action"], "answer_start": [632, 118, 118]}, "prediction_text": "A citizen or company can invoke a Directive."}
{"answers": {"text": ["10 years", "10 years", "10 years"], "answer_start": [1506, 1506, 1506]}, "prediction_text": "10 years"}
{"answers": {"text": ["British Gas plc", "British Gas plc", "British Gas plc"], "answer_start": [2117, 2117, 2117]}, "prediction_text": "British Gas plc"}
{"answers": {"text": ["women retire at age 60 and men at 65", "women retire at age 60 and men at 65", "women retire at age 60 and men at 65"], "answer_start": [2145, 2145, 2145]}, "prediction_text": "At age 60."}
{"answers": {"text": ["national courts", "national courts", "national courts"], "answer_start": [8, 8, 8]}, "prediction_text": "Fourth, national courts"}
{"answers": {"text": ["incorporations would only be nullified for a fixed list of reasons", "incorporations would only be nullified for a fixed list of reasons", "incorporations would only be nullified for a fixed list of reasons"], "answer_start": [478, 478, 478]}, "prediction_text": "incorporations must only be nullified for a fixed list of reasons."}
{"answers": {"text": ["failed to set up an insurance fund for employees to claim unpaid wages if their employers had gone insolvent", "to set up an insurance fund for employees to claim unpaid wages if their employers had gone insolvent, as the Insolvency Protection Directive required", "to set up an insurance fund for employees to claim unpaid wages if their employers had gone insolvent, as the Insolvency Protection Directive required"], "answer_start": [939, 946, 946]}, "prediction_text": "Set up an insurance fund."}
{"answers": {"text": ["6 million Lira", "6 million Lira", "6 million Lira"], "answer_start": [1190, 1190, 1190]}, "prediction_text": "6 million Lira"}
{"answers": {"text": ["the European Court of Justice", "the European Court of Justice", "the European Court"], "answer_start": [83, 83, 83]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity"], "answer_start": [600, 600, 600]}, "prediction_text": "Fundamental rights, proportionality, legal certainty, equality before the law."}
{"answers": {"text": ["since the 1950s", "since the 1950s", "since the 1950s"], "answer_start": [115, 115, 115]}, "prediction_text": "Since the 1950s."}
{"answers": {"text": ["in Article 5", "the lawfulness of an action depends on whether it was appropriate and necessary to achieve the objectives legitimately pursued", "Article 5"], "answer_start": [539, 186, 542]}, "prediction_text": "In Article 5 of the EC Treaty"}
{"answers": {"text": ["the least onerous", "the least onerous must be adopted", "the least onerous must be adopted"], "answer_start": [374, 374, 374]}, "prediction_text": "The least onerous"}
{"answers": {"text": ["since the 1960s", "since the 1960s", "since the 1960s"], "answer_start": [130, 130, 130]}, "prediction_text": "Since the 1960s."}
{"answers": {"text": ["international law and public law", "international law and public law", "international law and public law"], "answer_start": [187, 187, 187]}, "prediction_text": "Legal certainty and good faith laws"}
{"answers": {"text": ["a proper legal basis", "a proper legal basis", "a proper legal basis"], "answer_start": [544, 544, 544]}, "prediction_text": "A proper legal basis."}
{"answers": {"text": ["the principles of legal certainty and good faith", "the principles of legal certainty and good faith", "the principles of legal certainty and good faith"], "answer_start": [936, 936, 936]}, "prediction_text": "In European Union law"}
{"answers": {"text": ["from the constitutional traditions common to the member states", "the constitutional traditions common to the member states", "the constitutional traditions common to the member states"], "answer_start": [284, 289, 289]}, "prediction_text": "Constitutional traditions common to member states."}
{"answers": {"text": ["fundamental rights recognised and protected in the constitutions of member states", "fundamental rights recognised and protected in the constitutions of member states", "fundamental rights recognised and protected in the constitutions of member states"], "answer_start": [440, 440, 440]}, "prediction_text": "Fundamental rights recognised and protected in the constitutions of member states."}
{"answers": {"text": ["None", "None", "None"], "answer_start": [0, 0, 0]}, "prediction_text": "None of the original treaties"}
{"answers": {"text": ["member states", "the European Convention on Human Rights", "the European Convention on Human Rights in 1950 and the establishment of the European Court of Human Rights"], "answer_start": [303, 393, 393]}, "prediction_text": "European Union institutions"}
{"answers": {"text": ["1950", "1950", "1950"], "answer_start": [436, 436, 436]}, "prediction_text": "1950"}
{"answers": {"text": ["European Court of Human Rights.", "the European Court of Human Rights", "European Court of Human Rights"], "answer_start": [470, 466, 470]}, "prediction_text": "European Court of Human Rights"}
{"answers": {"text": ["1999", "1999", "1999"], "answer_start": [764, 764, 764]}, "prediction_text": "1999"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [4, 4, 4]}, "prediction_text": "December 2007"}
{"answers": {"text": ["the Charter of Fundamental Rights of the European Union", "the Charter of Fundamental Rights of the European Union of 7", "the Charter of Fundamental Rights of the European Union"], "answer_start": [356, 167, 167]}, "prediction_text": "The Charter of Fundamental Rights of the European Union"}
{"answers": {"text": ["European Union law", "European Union law", "European Union law"], "answer_start": [657, 657, 657]}, "prediction_text": "European Union law"}
{"answers": {"text": ["European Court of Justice", "European Court of Justice", "the European Court of Justice"], "answer_start": [714, 714, 710]}, "prediction_text": "European Court of Justice"}
{"answers": {"text": ["1997 Treaty of Amsterdam", "the 1997 Treaty of Amsterdam", "the 1997 Treaty of Amsterdam"], "answer_start": [39, 35, 35]}, "prediction_text": "Treaty of Amsterdam"}
{"answers": {"text": ["1997", "1997", "1997"], "answer_start": [39, 39, 39]}, "prediction_text": "1997"}
{"answers": {"text": ["1989", "1989", "1989"], "answer_start": [167, 167, 167]}, "prediction_text": "1989"}
{"answers": {"text": ["30", "30", "30"], "answer_start": [481, 481, 481]}, "prediction_text": "30 general principles"}
{"answers": {"text": ["40", "40", "40"], "answer_start": [784, 784, 784]}, "prediction_text": "40 pieces of legislation"}
{"answers": {"text": ["11 of the then 12 member states", "11 of the then 12 member states", "11"], "answer_start": [55, 55, 55]}, "prediction_text": "11 member states adopted the Social Charter in 1989."}
{"answers": {"text": ["The UK", "UK", "UK"], "answer_start": [88, 92, 92]}, "prediction_text": "The UK"}
{"answers": {"text": ["the \"Social Chapter\"", "the \"Social Chapter\"", "\"Social Chapter\""], "answer_start": [337, 337, 341]}, "prediction_text": "Social Chapter"}
{"answers": {"text": ["1992", "1992", "1992"], "answer_start": [365, 365, 365]}, "prediction_text": "1992"}
{"answers": {"text": ["the election of the UK Labour Party to government", "the election of the UK Labour Party to government in 1997", "the election of the UK Labour Party to government"], "answer_start": [10, 10, 10]}, "prediction_text": "Labour Party election"}
{"answers": {"text": ["1997", "1997", "1997"], "answer_start": [63, 63, 63]}, "prediction_text": "1997"}
{"answers": {"text": ["Works Council Directive", "the 1994 Works Council Directive", "Works Council Directive"], "answer_start": [354, 345, 354]}, "prediction_text": "Works Council Directive"}
{"answers": {"text": ["1996", "1996", "1996"], "answer_start": [440, 440, 440]}, "prediction_text": "1996"}
{"answers": {"text": ["workforce consultation in businesses", "workforce consultation in businesses", "workforce consultation in businesses"], "answer_start": [394, 394, 394]}, "prediction_text": "Consultation in businesses."}
{"answers": {"text": ["France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany"], "answer_start": [101, 101, 101]}, "prediction_text": "France, Italy, Belgium, the Netherlands, Luxembourg, and Germany."}
{"answers": {"text": ["1951", "1951", "1951"], "answer_start": [168, 168, 168]}, "prediction_text": "1951"}
{"answers": {"text": ["cartels", "cartels", "cartels"], "answer_start": [425, 425, 425]}, "prediction_text": "cartels and article 66 made provisions for concentrations."}
{"answers": {"text": ["article 66", "66", "66"], "answer_start": [437, 445, 445]}, "prediction_text": "Article 66"}
{"answers": {"text": ["1957", "1957", "1957"], "answer_start": [718, 718, 718]}, "prediction_text": "1957"}
{"answers": {"text": ["Article 101(1)", "Article 101(1)", "Article 101(1)"], "answer_start": [69, 69, 69]}, "prediction_text": "Article 101(1)"}
{"answers": {"text": ["the abuse of dominant position", "the abuse of dominant position", "abuse of dominant position"], "answer_start": [528, 528, 532]}, "prediction_text": "Abuse of dominant position"}
{"answers": {"text": ["Articles 106 and 107", "Articles 106 and 107", "Articles 106 and 107"], "answer_start": [949, 949, 949]}, "prediction_text": "Articles 106 and 107"}
{"answers": {"text": ["Article 102", "Article 102", "Article 102"], "answer_start": [612, 612, 612]}, "prediction_text": "Article 102"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [82, 82, 82]}, "prediction_text": "2007"}
{"answers": {"text": ["1957", "1957", "since the Treaty of Rome 1957"], "answer_start": [174, 174, 149]}, "prediction_text": "Since the Treaty of Rome 1957."}
{"answers": {"text": ["consumer prices", "consumer prices", "reduce consumer prices"], "answer_start": [589, 589, 582]}, "prediction_text": "Consumer prices"}
{"answers": {"text": ["free trade", "free trade", "free trade"], "answer_start": [1975, 1975, 1975]}, "prediction_text": "Other values such as public health, consumer protection, labour rights, fair competition, and environmental improvement."}
{"answers": {"text": ["the Court of Justice", "the Court of Justice", "the Court of Justice"], "answer_start": [2135, 2135, 2135]}, "prediction_text": "The Court of Justice"}
{"answers": {"text": ["a customs union, and the principle of non-discrimination", "a customs union", "a customs union"], "answer_start": [64, 64, 64]}, "prediction_text": "Customs union and non-discrimination."}
{"answers": {"text": ["parallel importers like Mr Dassonville", "parallel importers", "parallel importers"], "answer_start": [839, 839, 839]}, "prediction_text": "Parallel importers"}
{"answers": {"text": ["private actors", "private actors", "private actors"], "answer_start": [1229, 1229, 1229]}, "prediction_text": "Private actors."}
{"answers": {"text": ["Commission v France", "Commission v France French", "Commission v France French"], "answer_start": [1262, 1262, 1262]}, "prediction_text": "In Procureur du Roi v Dassonville."}
{"answers": {"text": ["a protest that blocked heavy traffic", "a protest", "a protest"], "answer_start": [2366, 2366, 2366]}, "prediction_text": "protest that blocked heavy traffic passing over the A13, Brenner Autobahn, en route to Italy."}
{"answers": {"text": ["25", "25 per cent", "25 per cent"], "answer_start": [710, 710, 710]}, "prediction_text": "25%"}
{"answers": {"text": ["France", "France", "France"], "answer_start": [921, 921, 921]}, "prediction_text": "France"}
{"answers": {"text": ["2003", "2003", "2003"], "answer_start": [1790, 1790, 1790]}, "prediction_text": "2009"}
{"answers": {"text": ["cocoa butter", "cocoa butter", "cocoa butter"], "answer_start": [2007, 2007, 2007]}, "prediction_text": "cocoa butter alone"}
{"answers": {"text": ["motorcycles or mopeds pulling trailers", "motorcycles or mopeds pulling trailers", "motorcycles or mopeds pulling trailers"], "answer_start": [2568, 2568, 2568]}, "prediction_text": "Cocoa products"}
{"answers": {"text": ["Keck and Mithouard", "Keck and Mithouard", "Keck and Mithouard"], "answer_start": [291, 291, 291]}, "prediction_text": "Keck and Mithouard"}
{"answers": {"text": ["cut throat competition", "prevent cut throat competition", "prevent cut throat competition"], "answer_start": [498, 490, 490]}, "prediction_text": "Prevent cut throat competition."}
{"answers": {"text": ["Konsumentombudsmannen v De Agostini", "Konsumentombudsmannen v De Agostini", "Konsumentombudsmannen v De Agostini"], "answer_start": [990, 990, 990]}, "prediction_text": "Konsumentombudsmannen v De Agostini"}
{"answers": {"text": ["the Unfair Commercial Practices Directive", "the Unfair Commercial Practices Directive", "the Unfair Commercial Practices Directive"], "answer_start": [1866, 1866, 1866]}, "prediction_text": "Unfair Commercial Practices Directive"}
{"answers": {"text": ["to enable people to pursue their life goals in any country through free movement", "people to pursue their life goals in any country through free movement", "Since its foundation"], "answer_start": [42, 52, 0]}, "prediction_text": "People to pursue their life goals in any country."}
{"answers": {"text": ["the European Community", "the European Community", "the European Community"], "answer_start": [171, 171, 171]}, "prediction_text": "European Community"}
{"answers": {"text": ["citizenship", "\"citizenship\"", "\"citizenship\""], "answer_start": [401, 400, 400]}, "prediction_text": "\"citizenship\""}
{"answers": {"text": ["Steymann v Staatssecretaris van Justitie", "Steymann v Staatssecretaris van Justitie", "Steymann v Staatssecretaris van Justitie"], "answer_start": [1014, 1014, 1014]}, "prediction_text": "Steymann v Staatssecretaris van Justitie"}
{"answers": {"text": ["to stay, so long as there was at least an \"indirect quid pro quo\" for the work he did", "stay", "stay"], "answer_start": [1335, 1338, 1338]}, "prediction_text": "Stay, but not to the same extent as a citizen."}
{"answers": {"text": ["articles 1 to 7", "articles 1 to 7", "articles 1 to 7"], "answer_start": [40, 40, 40]}, "prediction_text": "Articles 1 to 7"}
{"answers": {"text": ["Jean-Marc Bosman", "the Belgian Football Association v Bosman", "Jean-Marc Bosman"], "answer_start": [374, 304, 374]}, "prediction_text": "Jean-Marc Bosman"}
{"answers": {"text": ["Gaelic", "Gaelic", "Gaelic"], "answer_start": [866, 866, 866]}, "prediction_text": "Gaelic"}
{"answers": {"text": ["Hendrix v Employee", "Hendrix v Employee Insurance Institute", "Hendrix v Employee Insurance Institute"], "answer_start": [2525, 2525, 2525]}, "prediction_text": "In Finanzamt K\u00f6ln Altstadt v Schumacker"}
{"answers": {"text": ["between 3 and 14 hours a week", "3 and 14 hours a week", "between 3 and 14 hours a week"], "answer_start": [2922, 2930, 2922]}, "prediction_text": "3 to 14 hours a week."}
{"answers": {"text": ["Citizenship of the EU", "Citizenship of the EU", "Citizenship of the EU"], "answer_start": [0, 0, 0]}, "prediction_text": "Citizenship of EU nationals"}
{"answers": {"text": ["the number of social services that people can access wherever they move", "the number of social services that people can access wherever they move", "the number of social services that people can access wherever they move"], "answer_start": [156, 156, 156]}, "prediction_text": "Social services access"}
{"answers": {"text": ["Commission v Austria", "Commission v Austria the Court", "Commission v Austria"], "answer_start": [380, 380, 380]}, "prediction_text": "Commission v Austria"}
{"answers": {"text": ["higher education", "higher education", "higher education"], "answer_start": [257, 257, 257]}, "prediction_text": "Higher education"}
{"answers": {"text": ["the Treaty on the Functioning of the European Union", "the Treaty on the Functioning of the European Union", "the Treaty on the Functioning of the European Union"], "answer_start": [92, 92, 92]}, "prediction_text": "Treaty on the Functioning of the European Union"}
{"answers": {"text": ["if they were non-discriminatory", "if they were non-discriminatory, \"justified by imperative requirements in the general interest\" and proportionately applied", "participate in economic life \"on a stable and continuous basis\""], "answer_start": [866, 866, 387]}, "prediction_text": "Non-discriminatory, justified by imperative requirements in the general interest."}
{"answers": {"text": ["Reyners v Belgium", "Reyners v Belgium the Court of Justice", "Reyners v Belgium"], "answer_start": [1389, 1389, 1389]}, "prediction_text": "In Reyners v Belgium."}
{"answers": {"text": ["article 49", "TFEU article 49", "article 49"], "answer_start": [1545, 1540, 1545]}, "prediction_text": "TFEU article 49 states that states are exempt from infringing on rights of establishment when they exercise official authority."}
{"answers": {"text": ["Commission v Italy", "Commission v Italy the Court of Justice", "Commission v Italy"], "answer_start": [1760, 1760, 1760]}, "prediction_text": "In Commission v Italy."}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [3, 3, 3]}, "prediction_text": "2006"}
{"answers": {"text": ["shipping toxic waste", "shipping toxic waste", "toxic waste"], "answer_start": [334, 334, 140]}, "prediction_text": "Shipping toxic waste"}
{"answers": {"text": ["October 2007", "2007", "2007"], "answer_start": [1024, 1032, 1032]}, "prediction_text": "October 2007"}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [552, 552, 552]}, "prediction_text": "2005 (Court of Justice ruling)"}
{"answers": {"text": ["to people who give services \"for remuneration\"", "people who give services \"for remuneration\", especially commercial or professional activity", "people who give services \"for remuneration\""], "answer_start": [64, 67, 67]}, "prediction_text": "People who give services for remuneration."}
{"answers": {"text": ["because Dutch law said only people established in the Netherlands could give legal advice", "Dutch law said only people established in the Netherlands could give legal advice", "Dutch law said only people established in the Netherlands could give legal advice"], "answer_start": [369, 377, 377]}, "prediction_text": "Dutch law said only people established in the Netherlands could give legal advice."}
{"answers": {"text": ["narcotic drugs", "narcotic drugs", "narcotic drugs"], "answer_start": [2318, 2318, 2318]}, "prediction_text": "Medical services"}
{"answers": {"text": ["the treatment", "treatment", "treatment"], "answer_start": [1124, 1128, 1128]}, "prediction_text": "Medical services"}
{"answers": {"text": ["the Daily Mail", "the Daily Mail", "Daily Mail"], "answer_start": [224, 224, 56]}, "prediction_text": "Daily Mail newspaper"}
{"answers": {"text": ["\u00a31", "\u00a31", "\u00a31"], "answer_start": [703, 703, 703]}, "prediction_text": "\u00a31 of capital"}
{"answers": {"text": ["200,000 Danish krone", "200,000 Danish krone", "200,000 Danish krone"], "answer_start": [827, 827, 827]}, "prediction_text": "\u00a31 of capital"}
{"answers": {"text": ["creditor protection, labour rights to participate in work, or the public interest in collecting taxes", "creditor protection, labour rights to participate in work, or the public interest in collecting taxes", "Denmark's minimum capital law"], "answer_start": [1888, 1888, 959]}, "prediction_text": "Corridors of freedom of establishment"}
{"answers": {"text": ["\u00dcberseering BV v Nordic Construction GmbH", "\u00dcberseering BV v Nordic Construction GmbH", "\u00dcberseering BV v Nordic Construction GmbH"], "answer_start": [1583, 1583, 1583]}, "prediction_text": "In Cartesio Oktat\u00f3 bt the Court of Justice affirmed again that because corporations are created by law, they are in principle subject to any rules for formation that a state of incorporation wishes to impose."}
{"answers": {"text": ["also known in English as Amazonia or the Amazon Jungle,", "Amazonia or the Amazon Jungle", "Amazonia"], "answer_start": [176, 201, 201]}, "prediction_text": "For\u00eat amazonienne"}
{"answers": {"text": ["5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest.", "5,500,000", "5,500,000"], "answer_start": [394, 394, 394]}, "prediction_text": "5,500,000 square kilometers"}
{"answers": {"text": ["This region includes territory belonging to nine nations.", "nine", "nine"], "answer_start": [471, 515, 515]}, "prediction_text": "Nine nations"}
{"answers": {"text": ["States or departments in four nations contain \"Amazonas\" in their names.", "four", "four"], "answer_start": [749, 774, 774]}, "prediction_text": "Nine nations"}
{"answers": {"text": ["The Amazon represents over half of the planet's remaining rainforests", "over half"], "answer_start": [822, 844]}, "prediction_text": "Over half of the planet's remaining rainforests"}
{"answers": {"text": ["Amazoneregenwoud", "Amazoneregenwoud", "Amazoneregenwoud"], "answer_start": [157, 157, 157]}, "prediction_text": "Amaz\u00f4nia"}
{"answers": {"text": ["The Amazon rainforest", "Amazon rainforest", "The Amazon"], "answer_start": [0, 4, 0]}, "prediction_text": "Amazonia"}
{"answers": {"text": ["Brazil", "Brazil", "Brazil"], "answer_start": [576, 576, 576]}, "prediction_text": "South America"}
{"answers": {"text": ["over half", "over half", "over half"], "answer_start": [844, 844, 844]}, "prediction_text": "Over half of the planet's remaining rainforests"}
{"answers": {"text": ["16,000", "16,000", "16,000"], "answer_start": [1042, 1042, 1042]}, "prediction_text": "390 billion trees"}
{"answers": {"text": ["moist broadleaf forest", "moist broadleaf forest", "tropical"], "answer_start": [237, 237, 948]}, "prediction_text": "Amaz\u00f4nia or Amazonia"}
{"answers": {"text": ["7,000,000 square kilometres (2,70", "7,000,000", "7,000,000 square kilometres"], "answer_start": [338, 338, 338]}, "prediction_text": "5,500,000 square kilometers"}
{"answers": {"text": ["nine nations", "nine", "nine"], "answer_start": [515, 515, 515]}, "prediction_text": "Nine nations"}
{"answers": {"text": ["Brazil", "Brazil", "Brazil"], "answer_start": [576, 576, 576]}, "prediction_text": "Brazil"}
{"answers": {"text": ["16,000 species", "16,000", "16,000"], "answer_start": [1042, 1042, 1042]}, "prediction_text": "390 billion"}
{"answers": {"text": ["the wetter climate may have allowed the tropical rainforest to spread out across the continent.", "wetter", "wetter"], "answer_start": [89, 93, 93]}, "prediction_text": "Tropical rainforest"}
{"answers": {"text": ["Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics.", "Climate fluctuations during the last 34 million years", "Climate fluctuations"], "answer_start": [246, 246, 246]}, "prediction_text": "Extensive rainforest expansion"}
{"answers": {"text": ["During the Oligocene, for example, the rainforest spanned a relatively narrow band.", "Oligocene", "Oligocene"], "answer_start": [357, 368, 368]}, "prediction_text": "During the Oligocene"}
{"answers": {"text": ["It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum.", "Middle Miocene", "at the last glacial maximum"], "answer_start": [441, 470, 530]}, "prediction_text": "Last glacial maximum"}
{"answers": {"text": ["However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.", "still managed to thrive"], "answer_start": [559, 583]}, "prediction_text": "Yes, it thrived."}
{"answers": {"text": ["the extinction of the dinosaurs and the wetter climate", "extinction of the dinosaurs and the wetter climate", "extinction of the dinosaurs"], "answer_start": [53, 57, 57]}, "prediction_text": "Extinction of dinosaurs and wetter climate."}
{"answers": {"text": ["45", "45\u00b0", "45\u00b0"], "answer_start": [241, 241, 241]}, "prediction_text": "45\u00b0"}
{"answers": {"text": ["Climate fluctuations", "Climate fluctuations", "Climate fluctuations"], "answer_start": [246, 246, 246]}, "prediction_text": "Extinction of dinosaurs and wetter climate."}
{"answers": {"text": ["Oligocene", "Oligocene", "Oligocene"], "answer_start": [368, 368, 368]}, "prediction_text": "Late Miocene"}
{"answers": {"text": ["It expanded", "expanded", "expanded"], "answer_start": [441, 444, 444]}, "prediction_text": "Expanded into the tropics."}
{"answers": {"text": ["Cretaceous\u2013Paleogene extinction event", "dinosaurs", "dinosaurs"], "answer_start": [14, 75, 75]}, "prediction_text": "Cretaceous\u2013Paleogene extinction event"}
{"answers": {"text": ["66\u201334 Mya", "66\u201334"], "answer_start": [190, 190]}, "prediction_text": "66\u201334 Mya"}
{"answers": {"text": ["Middle Miocene", "Middle Miocene", "Middle Miocene"], "answer_start": [470, 470, 470]}, "prediction_text": "Last glacial maximum"}
{"answers": {"text": ["last glacial maximum", "last glacial maximum", "last glacial maximum"], "answer_start": [537, 537, 537]}, "prediction_text": "Oligocene"}
{"answers": {"text": ["34 million years", "34 million", "34 million"], "answer_start": [283, 283, 283]}, "prediction_text": "34 million years"}
{"answers": {"text": ["During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Purus Arch.", "During the mid-Eocene", "mid-Eocene"], "answer_start": [0, 0, 11]}, "prediction_text": "Mid-Eocene"}
{"answers": {"text": ["Water on the eastern side flowed toward the Atlantic,", "toward the Atlantic", "toward the Atlantic"], "answer_start": [139, 172, 172]}, "prediction_text": "Towards the Atlantic"}
{"answers": {"text": ["Solim\u00f5es Basin", "Solim\u00f5es Basin", "Solim\u00f5es Basin"], "answer_start": [373, 373, 373]}, "prediction_text": "Solim\u00f5es Basin"}
{"answers": {"text": ["Within the last 5\u201310 million years", "Within the last 5\u201310 million years", "last 5\u201310 million years"], "answer_start": [389, 389, 400]}, "prediction_text": "Last 5\u201310 million years"}
{"answers": {"text": ["joining the easterly flow toward the Atlantic.", "the easterly flow", "easterly"], "answer_start": [479, 487, 491]}, "prediction_text": "The Amazonas Basin"}
{"answers": {"text": ["During the mid-Eocene", "During the mid-Eocene", "During the mid-Eocene"], "answer_start": [0, 0, 0]}, "prediction_text": "Mid-Eocene"}
{"answers": {"text": ["the Atlantic", "the Atlantic", "Atlantic"], "answer_start": [179, 179, 516]}, "prediction_text": "Pacific"}
{"answers": {"text": ["the Pacific", "the Pacific", "Pacific"], "answer_start": [231, 231, 235]}, "prediction_text": "Pacific"}
{"answers": {"text": ["Amazonas Basin", "Amazonas Basin", "Andes Mountains"], "answer_start": [254, 254, 277]}, "prediction_text": "The Andes Mountains"}
{"answers": {"text": ["the Solim\u00f5es Basin", "Solim\u00f5es Basin", "Solim\u00f5es Basin"], "answer_start": [369, 373, 373]}, "prediction_text": "Solim\u00f5es Basin"}
{"answers": {"text": ["the mid-Eocene", "the mid-Eocene", "mid-Eocene"], "answer_start": [7, 7, 11]}, "prediction_text": "Mid-Eocene"}
{"answers": {"text": ["Purus Arch", "along the middle", "Purus Arch"], "answer_start": [127, 86, 127]}, "prediction_text": "The Amazonas Basin"}
{"answers": {"text": ["the Atlantic", "the Atlantic", "Atlantic"], "answer_start": [179, 179, 183]}, "prediction_text": "To the Atlantic"}
{"answers": {"text": ["the Pacific", "the Pacific", "Pacific"], "answer_start": [231, 231, 235]}, "prediction_text": "Pacific"}
{"answers": {"text": ["Solim\u00f5es Basin", "Solim\u00f5es Basin", "Solim\u00f5es Basin"], "answer_start": [373, 373, 373]}, "prediction_text": "Solim\u00f5es Basin"}
{"answers": {"text": ["Last Glacial Maximum", "Last Glacial Maximum", "Last Glacial Maximum"], "answer_start": [130, 130, 130]}, "prediction_text": "Last Glacial Maximum"}
{"answers": {"text": ["rainfall in the basin during the LGM was lower than for the present", "rainfall in the basin during the LGM was lower than for the present", "rainfall in the basin during the LGM was lower"], "answer_start": [283, 283, 283]}, "prediction_text": "Lower rainfall in the basin during the LGM."}
{"answers": {"text": ["the rainforest was reduced to small, isolated refugia separated by open forest and grassland", "the rainforest was reduced to small, isolated refugia separated by open forest and grassland", "rainforest was reduced"], "answer_start": [544, 544, 548]}, "prediction_text": "Reduced rainfall in the basin during the LGM."}
{"answers": {"text": ["This debate has proved difficult", "difficult to resolve"], "answer_start": [777, 800]}, "prediction_text": "Difficult to resolve."}
{"answers": {"text": ["explanations are reasonably well supported", "by the available data", "reasonably well"], "answer_start": [969, 1012, 986]}, "prediction_text": "Both explanations are reasonably supported."}
{"answers": {"text": ["21,000", "21,000", "21,000"], "answer_start": [105, 105, 105]}, "prediction_text": "21,000 years"}
{"answers": {"text": ["the Last Glacial Maximum (LGM) and subsequent deglaciation", "rainfall in the basin during the LGM was lower than for the present", "rainfall"], "answer_start": [126, 283, 283]}, "prediction_text": "LGM and deglaciation"}
{"answers": {"text": ["sediment deposits", "sediment deposits", "sediment deposits"], "answer_start": [198, 198, 198]}, "prediction_text": "sediment deposits from Amazon basin and from Amazon Fan."}
{"answers": {"text": ["reduced moist tropical vegetation cover in the basin", "reduced moist tropical vegetation cover in the basin", "reduced moist tropical vegetation cover"], "answer_start": [398, 398, 398]}, "prediction_text": "Reduced moist tropical vegetation cover"}
{"answers": {"text": ["21,000", "21,000", "21,000"], "answer_start": [105, 105, 105]}, "prediction_text": "21,000 years ago"}
{"answers": {"text": ["sediment deposits", "sediment", "sediment"], "answer_start": [198, 198, 198]}, "prediction_text": "sediment deposits from Amazon basin"}
{"answers": {"text": ["moist tropical vegetation cover", "moist tropical", "tropical"], "answer_start": [406, 406, 412]}, "prediction_text": "moist tropical vegetation cover"}
{"answers": {"text": ["open forest and grassland", "open forest and grassland", "open forest and grassland"], "answer_start": [611, 611, 611]}, "prediction_text": "Open forest and grassland"}
{"answers": {"text": ["data sampling is biased away from the center of the Amazon basin", "practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin", "practical limitations of working in the rainforest"], "answer_start": [894, 833, 833]}, "prediction_text": "Practical limitations of working in the rainforest."}
{"answers": {"text": ["CALIPSO", "CALIPSO", "CALIPSO"], "answer_start": [7, 7, 7]}, "prediction_text": "CALIPSO"}
{"answers": {"text": ["182 million tons", "182 million", "an average 182 million"], "answer_start": [119, 119, 108]}, "prediction_text": "182 million tons"}
{"answers": {"text": ["1,600 miles", "1,600", "1,600 miles"], "answer_start": [224, 224, 224]}, "prediction_text": "1,600 miles (2,600 km)"}
{"answers": {"text": ["Amazon basin", "Amazon", "Amazon"], "answer_start": [427, 427, 427]}, "prediction_text": "Caribbean Sea"}
{"answers": {"text": ["132 million tons", "132 million tons", "132 million"], "answer_start": [441, 441, 441]}, "prediction_text": "43 million tons"}
{"answers": {"text": ["NASA's CALIPSO satellite", "NASA's CALIPSO satellite", "satellite"], "answer_start": [0, 0, 15]}, "prediction_text": "CALIPSO satellite"}
{"answers": {"text": ["182 million tons", "182 million tons", "182 million tons"], "answer_start": [119, 119, 119]}, "prediction_text": "182 million tons"}
{"answers": {"text": ["27.7 million tons", "27.7 million tons", "27.7 million tons"], "answer_start": [381, 381, 381]}, "prediction_text": "182 million tons"}
{"answers": {"text": ["132 million tons", "132 million tons", "132 million tons"], "answer_start": [441, 441, 441]}, "prediction_text": "182 million tons"}
{"answers": {"text": ["43 million tons", "43 million tons", "43 million tons"], "answer_start": [485, 485, 485]}, "prediction_text": "132 million tons"}
{"answers": {"text": ["CALIPSO", "CALIPSO", "CALIPSO"], "answer_start": [7, 7, 7]}, "prediction_text": "CALIPSO"}
{"answers": {"text": ["NASA", "NASA", "NASA's"], "answer_start": [0, 0, 0]}, "prediction_text": "NASA"}
{"answers": {"text": ["182 million tons", "182 million tons", "182 million tons"], "answer_start": [119, 119, 119]}, "prediction_text": "182 million tons"}
{"answers": {"text": ["1,600 miles", "1,600", "1,600"], "answer_start": [224, 224, 224]}, "prediction_text": "1,600 miles (2,600 km)"}
{"answers": {"text": ["27.7 million tons", "27.7 million", "27.7 million tons"], "answer_start": [381, 381, 381]}, "prediction_text": "132 million tons"}
{"answers": {"text": ["Man and Culture in a Counterfeit Paradise", "Amazonia: Man and Culture in a Counterfeit Paradise", "Amazonia: Man and Culture in a Counterfeit Paradise."], "answer_start": [287, 277, 277]}, "prediction_text": "Amazonia: Man and Culture in a Counterfeit Paradise"}
{"answers": {"text": ["0.52/sq mi", "0.52", "0.52/sq mi"], "answer_start": [409, 409, 409]}, "prediction_text": "0.52/sq mi"}
{"answers": {"text": ["agriculture", "agriculture", "agriculture"], "answer_start": [498, 498, 498]}, "prediction_text": "Hunting and agriculture."}
{"answers": {"text": ["anthropological", "anthropological", "recent anthropological"], "answer_start": [562, 562, 555]}, "prediction_text": "Anthropological findings"}
{"answers": {"text": ["5 million", "5 million", "5 million"], "answer_start": [655, 655, 655]}, "prediction_text": "5 million"}
{"answers": {"text": ["the poor soil", "poor soil", "poor soil."], "answer_start": [170, 174, 174]}, "prediction_text": "Poor soil"}
{"answers": {"text": ["Betty Meggers", "Betty Meggers", "Betty Meggers"], "answer_start": [198, 198, 198]}, "prediction_text": "Betty Meggers"}
{"answers": {"text": ["0.2", "0.2", "0.2"], "answer_start": [371, 371, 371]}, "prediction_text": "0.52 inhabitants per square kilometre."}
{"answers": {"text": ["Amazonia: Man and Culture in a Counterfeit Paradise", "Amazonia: Man and Culture in a Counterfeit Paradise", "Amazonia: Man and Culture in a Counterfeit Paradise"], "answer_start": [277, 277, 277]}, "prediction_text": "Amazonia: Man and Culture in a Counterfeit Paradise"}
{"answers": {"text": ["Betty Meggers", "Betty Meggers", "Betty Meggers"], "answer_start": [198, 198, 198]}, "prediction_text": "Betty Meggers"}
{"answers": {"text": ["Amazonia: Man and Culture in a Counterfeit Paradise", "Amazonia: Man and Culture in a Counterfeit Paradise", "Amazonia: Man and Culture in a Counterfeit Paradise"], "answer_start": [277, 277, 277]}, "prediction_text": "Amazonia: Man and Culture in a Counterfeit Paradise"}
{"answers": {"text": ["0.2 inhabitants per square kilometre", "0.2 inhabitants", "0.2 inhabitants per square kilometre"], "answer_start": [371, 371, 371]}, "prediction_text": "0.52/sq mi"}
{"answers": {"text": ["5 million people", "5 million", "Some 5 million"], "answer_start": [655, 655, 650]}, "prediction_text": "5 million"}
{"answers": {"text": ["200,000.", "less than 200,000", "less than 200,000"], "answer_start": [895, 885, 885]}, "prediction_text": "Less than 200,000"}
{"answers": {"text": ["Francisco de Orellana", "Francisco de Orellana", "Francisco de Orellana"], "answer_start": [64, 64, 64]}, "prediction_text": "Francisco de Orellana"}
{"answers": {"text": ["1540s", "1540s", "1540s"], "answer_start": [317, 317, 317]}, "prediction_text": "1540s"}
{"answers": {"text": ["diseases from Europe", "the spread of diseases from Europe", "spread of diseases from Europe"], "answer_start": [399, 385, 389]}, "prediction_text": "Smallpox spread"}
{"answers": {"text": ["1970s", "Since the 1970s", "1970s"], "answer_start": [449, 439, 449]}, "prediction_text": "Since 1977."}
{"answers": {"text": ["AD 0\u20131250", "between AD 0\u20131250", "AD 0\u20131250"], "answer_start": [530, 522, 530]}, "prediction_text": "AD 0\u20131250"}
{"answers": {"text": ["Francisco de Orellana", "Francisco de Orellana", "Francisco de Orellana"], "answer_start": [64, 64, 64]}, "prediction_text": "Francisco de Orellana"}
{"answers": {"text": ["1542", "1542", "1542"], "answer_start": [89, 89, 89]}, "prediction_text": "1542"}
{"answers": {"text": ["AD 0\u20131250", "between AD 0\u20131250", "AD 0\u20131250"], "answer_start": [530, 522, 530]}, "prediction_text": "AD 0\u20131250"}
{"answers": {"text": ["Ondemar Dias", "Ondemar Dias", "Ondemar Dias"], "answer_start": [594, 594, 594]}, "prediction_text": "Alceu Ranzi"}
{"answers": {"text": ["11,000 years", "at least 11,000 years", "at least 11,000 years"], "answer_start": [892, 883, 883]}, "prediction_text": "11,000 years"}
{"answers": {"text": ["black earth", "black earth", "black earth"], "answer_start": [13, 13, 13]}, "prediction_text": "Black earth"}
{"answers": {"text": ["large areas", "over large areas", "over large areas"], "answer_start": [53, 48, 48]}, "prediction_text": "Over large areas"}
{"answers": {"text": ["agriculture and silviculture", "allowed agriculture and silviculture", "agriculture and silviculture"], "answer_start": [199, 191, 199]}, "prediction_text": "Agriculture and silviculture."}
{"answers": {"text": ["Xingu tribe", "Xingu", "Xingu"], "answer_start": [464, 464, 464]}, "prediction_text": "Xingu tribe"}
{"answers": {"text": ["Michael Heckenberger and colleagues of the University of Florida", "Michael Heckenberger and colleagues of the University of Florida", "Michael Heckenberger and colleagues of the University of Florida"], "answer_start": [577, 577, 577]}, "prediction_text": "Michael Heckenberger and colleagues of the University of Florida"}
{"answers": {"text": ["Terra preta (black earth)", "Terra preta", "black earth"], "answer_start": [0, 0, 13]}, "prediction_text": "Black earth"}
{"answers": {"text": ["agriculture and silviculture", "agriculture and silviculture", "agriculture and silviculture"], "answer_start": [199, 199, 199]}, "prediction_text": "Agriculture and silviculture"}
{"answers": {"text": ["Xingu tribe", "Xingu", "Xingu"], "answer_start": [464, 464, 464]}, "prediction_text": "Xingu tribe"}
{"answers": {"text": ["Michael Heckenberger and colleagues", "Michael Heckenberger and colleagues of the University of Florida", "Michael Heckenberger"], "answer_start": [577, 577, 577]}, "prediction_text": "Michael Heckenberger"}
{"answers": {"text": ["roads, bridges and large plazas", "roads, bridges and large plazas", "roads, bridges and large plazas"], "answer_start": [672, 672, 672]}, "prediction_text": "Large plazas"}
{"answers": {"text": ["2.5 million", "2.5 million", "2.5 million"], "answer_start": [28, 28, 28]}, "prediction_text": "About 2.5 million"}
{"answers": {"text": ["One in five", "One in five", "One in five"], "answer_start": [283, 283, 283]}, "prediction_text": "Birds and mammals"}
{"answers": {"text": ["40,000", "40,000", "40,000"], "answer_start": [137, 137, 137]}, "prediction_text": "40,000 plant species"}
{"answers": {"text": ["one in five", "2,200", "2,200"], "answer_start": [375, 159, 159]}, "prediction_text": "1,294"}
{"answers": {"text": ["96,660 and 128,843", "between 96,660 and 128,843", "128,843"], "answer_start": [479, 471, 490]}, "prediction_text": "96,660"}
{"answers": {"text": ["2.5 million", "about 2.5 million", "2.5 million"], "answer_start": [28, 22, 28]}, "prediction_text": "About 2.5 million species"}
{"answers": {"text": ["2,000", "some 2,000", "2,000"], "answer_start": [94, 89, 94]}, "prediction_text": "428 mammals"}
{"answers": {"text": ["40,000", "tens of thousands", "tens of thousands"], "answer_start": [137, 56, 56]}, "prediction_text": "40,000 plant species"}
{"answers": {"text": ["378", "378", "378"], "answer_start": [219, 219, 219]}, "prediction_text": "428 reptiles"}
{"answers": {"text": ["One in five", "1,294", "One in five of all the bird species in the world"], "answer_start": [283, 173, 283]}, "prediction_text": "One in five"}
{"answers": {"text": ["62 acres", "quarter square", "quarter square", "62"], "answer_start": [114, 88, 88, 114]}, "prediction_text": "One square kilometer"}
{"answers": {"text": ["1,100", "more than 1,100", "more than 1,100", "1,100"], "answer_start": [168, 158, 158, 168]}, "prediction_text": "One square kilometer (247 acres)"}
{"answers": {"text": ["90,790", "about 90,790", "about 90,790", "90,790"], "answer_start": [282, 276, 276, 282]}, "prediction_text": "About 90,790 tonnes"}
{"answers": {"text": ["356 \u00b1 47 tonnes per hectare", "356 \u00b1 47 tonnes per hectare", "356 \u00b1 47 tonnes per hectare", "356 \u00b1 47 tonnes per hectare"], "answer_start": [356, 356, 356, 356]}, "prediction_text": "356 \u00b1 47 tonnes per hectare"}
{"answers": {"text": ["438,000", "438,000", "438,000", "438,000 species"], "answer_start": [407, 407, 407, 407]}, "prediction_text": "438,000"}
{"answers": {"text": ["highest on Earth", "the highest", "the highest", "highest"], "answer_start": [41, 37, 37, 41]}, "prediction_text": "Highest on Earth"}
{"answers": {"text": ["1,100", "more than 1,100", "more than 1,100", "1,100"], "answer_start": [168, 158, 158, 168]}, "prediction_text": "One square kilometer (62 acres)"}
{"answers": {"text": ["90,790 tonnes", "about 90,790", "about 90,790", "90,790 tonnes"], "answer_start": [282, 276, 276, 282]}, "prediction_text": "About 90,790 tonnes"}
{"answers": {"text": ["356 \u00b1 47 tonnes", "356 \u00b1 47 tonnes", "356 \u00b1 47 tonnes", "356 \u00b1 47 tonnes"], "answer_start": [356, 356, 356, 356]}, "prediction_text": "356 \u00b1 47 tonnes"}
{"answers": {"text": ["438,000", "438,000", "438,000", "438,000"], "answer_start": [407, 407, 407, 407]}, "prediction_text": "438,000"}
{"answers": {"text": ["electric eels", "electric eels", "electric eels"], "answer_start": [168, 168, 168]}, "prediction_text": "Electric eels"}
{"answers": {"text": ["black caiman", "black caiman", "black caiman"], "answer_start": [110, 110, 110]}, "prediction_text": "Black caiman"}
{"answers": {"text": ["piranha", "piranha", "piranha"], "answer_start": [241, 241, 241]}, "prediction_text": "Piranha"}
{"answers": {"text": ["lipophilic alkaloid toxins", "lipophilic alkaloid toxins", "lipophilic alkaloid toxins"], "answer_start": [331, 331, 331]}, "prediction_text": "Lipophilic alkaloids"}
{"answers": {"text": ["Vampire bats", "Vampire", "Vampire"], "answer_start": [434, 434, 434]}, "prediction_text": "Vampire bats"}
{"answers": {"text": ["Deforestation", "Deforestation", "Deforestation"], "answer_start": [0, 0, 0]}, "prediction_text": "Deforestation"}
{"answers": {"text": ["the early 1960s", "early 1960s", "1960s"], "answer_start": [180, 184, 190]}, "prediction_text": "Early 1960s"}
{"answers": {"text": ["slash and burn method", "slash and burn", "slash and burn"], "answer_start": [368, 368, 368]}, "prediction_text": "Slash and burn"}
{"answers": {"text": ["loss of soil fertility and weed invasion", "loss of soil fertility and weed invasion", "soil fertility and weed invasion"], "answer_start": [478, 478, 486]}, "prediction_text": "Loss of soil fertility and weed invasion."}
{"answers": {"text": ["areas cleared of forest are visible to the naked eye", "areas cleared of forest", "areas cleared of forest are visible to the naked eye"], "answer_start": [785, 785, 785]}, "prediction_text": "Visible from outer space."}
{"answers": {"text": ["415,000", "415,000 to 587,000", "415,000"], "answer_start": [77, 77, 77]}, "prediction_text": "415,000 square kilometres"}
{"answers": {"text": ["587,000", "587,000", "587,000"], "answer_start": [88, 88, 88]}, "prediction_text": "160,000 square kilometres"}
{"answers": {"text": ["pasture for cattle", "pasture for cattle", "pasture for cattle"], "answer_start": [180, 180, 180]}, "prediction_text": "Cattle pasture"}
{"answers": {"text": ["second-largest global producer", "second", "second-largest"], "answer_start": [352, 352, 352]}, "prediction_text": "Second-largest"}
{"answers": {"text": ["91%", "91", "91%"], "answer_start": [261, 261, 261]}, "prediction_text": "91%"}
{"answers": {"text": ["soy farmers", "soy", "soy"], "answer_start": [13, 13, 13]}, "prediction_text": "Soy farmers"}
{"answers": {"text": ["increased settlement and deforestation", "increased settlement and deforestation", "increased settlement and deforestation"], "answer_start": [218, 218, 218]}, "prediction_text": "Increased settlement and deforestation."}
{"answers": {"text": ["8,646 sq mi", "22,392 km2 or 8,646 sq mi", "8,646"], "answer_start": [326, 312, 326]}, "prediction_text": "18% higher"}
{"answers": {"text": ["deforestation has declined", "declined significantly", "declined significantly"], "answer_start": [442, 460, 460]}, "prediction_text": "Declined significantly."}
{"answers": {"text": ["18% higher", "18%", "18%"], "answer_start": [352, 352, 352]}, "prediction_text": "18% higher"}
{"answers": {"text": ["loss of biodiversity", "biodiversity", "biodiversity"], "answer_start": [38, 46, 46]}, "prediction_text": "Biodiversity loss"}
{"answers": {"text": ["destruction of the forest", "destruction of the forest", "destruction of the forest"], "answer_start": [81, 81, 81]}, "prediction_text": "Destruction of forest"}
{"answers": {"text": ["carbon contained within the vegetation", "carbon contained within the vegetation", "carbon"], "answer_start": [142, 142, 142]}, "prediction_text": "Carbon contained within vegetation"}
{"answers": {"text": ["10% of the carbon stores", "10%", "10%"], "answer_start": [323, 323, 267]}, "prediction_text": "1.1 \u00d7 1011 metric tonnes"}
{"answers": {"text": ["1.1 \u00d7 1011 metric tonnes", "1.1 \u00d7 1011", "1.1 \u00d7 1011"], "answer_start": [378, 378, 378]}, "prediction_text": "1.1 \u00d7 1011 metric tonnes"}
{"answers": {"text": ["reduced rainfall and increased temperatures", "severely reduced rainfall and increased temperatures", "severely reduced rainfall and increased temperatures"], "answer_start": [168, 159, 159]}, "prediction_text": "Reduced rainfall and increased temperatures."}
{"answers": {"text": ["greenhouse gas emissions", "greenhouse gas", "greenhouse gas"], "answer_start": [54, 54, 54]}, "prediction_text": "greenhouse gas emissions"}
{"answers": {"text": ["2100", "by 2100", "2100"], "answer_start": [284, 281, 284]}, "prediction_text": "2100"}
{"answers": {"text": ["though the 21st century", "though the 21st century", "though the 21st century"], "answer_start": [546, 546, 546]}, "prediction_text": "21st century"}
{"answers": {"text": ["climate change in addition to deforestation", "climate change in addition to deforestation", "climate change in addition to deforestation"], "answer_start": [573, 573, 573]}, "prediction_text": "Climate change, deforestation."}
{"answers": {"text": ["indigenous territories", "indigenous", "indigenous"], "answer_start": [3, 3, 3]}, "prediction_text": "Peruvian Amazon indigenous peoples' rainforest communities"}
{"answers": {"text": ["community-based conservation", "community-based", "community-based"], "answer_start": [502, 502, 502]}, "prediction_text": "Ethno-biology and community-based conservation efforts."}
{"answers": {"text": ["deforestation and ecocide", "deforestation and ecocide", "deforestation and ecocide"], "answer_start": [54, 54, 54]}, "prediction_text": "Ecocide and deforestation"}
{"answers": {"text": ["Urarina", "Urarina", "Urarina"], "answer_start": [201, 201, 201]}, "prediction_text": "Urarina"}
{"answers": {"text": ["lowland South American", "lowland South American peoples", "South American"], "answer_start": [413, 413, 421]}, "prediction_text": "Urarina"}
{"answers": {"text": ["remote sensing", "remote sensing", "remote sensing"], "answer_start": [11, 11, 11]}, "prediction_text": "Remote sensing"}
{"answers": {"text": ["Trio Tribe", "Trio", "Trio"], "answer_start": [249, 249, 249]}, "prediction_text": "Trio Tribe"}
{"answers": {"text": ["southern Suriname", "southern Suriname", "southern Suriname"], "answer_start": [292, 292, 292]}, "prediction_text": "Southern Suriname"}
{"answers": {"text": ["to help strengthen their territorial claims", "map out their ancestral lands to help strengthen their territorial claims", "map out their ancestral lands"], "answer_start": [341, 311, 311]}, "prediction_text": "Map ancestral lands"}
{"answers": {"text": ["to protect their tribal lands from commercial interests", "to protect their tribal lands from commercial interests", "protect their tribal lands from commercial interests"], "answer_start": [118, 118, 121]}, "prediction_text": "To protect their tribal lands"}
{"answers": {"text": ["tree growth", "tree growth"], "answer_start": [102, 102]}, "prediction_text": "Trees in mature forest"}
{"answers": {"text": ["carbon related emissions", "carbon related", "carbon related"], "answer_start": [54, 54, 54]}, "prediction_text": "Carbon emission"}
{"answers": {"text": ["Tatiana Kuplich", "Tatiana Kuplich", "Tatiana Kuplich"], "answer_start": [178, 178, 178]}, "prediction_text": "Tatiana Kuplich"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [173, 173, 173]}, "prediction_text": "2006"}
{"answers": {"text": ["Synthetic aperture radar (SAR)", "Synthetic aperture", "Synthetic aperture radar"], "answer_start": [504, 504, 504]}, "prediction_text": "Synthetic aperture radar"}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [3, 3, 3]}, "prediction_text": "2005"}
{"answers": {"text": ["Brazilian National Institute of Amazonian Research", "Brazilian National Institute of Amazonian Research", "Brazilian National Institute of Amazonian Research"], "answer_start": [386, 386, 386]}, "prediction_text": "Brazilian National Institute of Amazonian Research"}
{"answers": {"text": ["deforestation", "deforestation on regional climate", "deforestation"], "answer_start": [514, 514, 514]}, "prediction_text": "deforestation"}
{"answers": {"text": ["savanna or desert", "desert", "savanna or desert"], "answer_start": [710, 721, 710]}, "prediction_text": "Savanna or desert."}
{"answers": {"text": ["Woods Hole Research Center", "Woods Hole Research Center", "Woods Hole Research Center"], "answer_start": [246, 246, 246]}, "prediction_text": "Woods Hole Research Center"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [3, 3, 3]}, "prediction_text": "2010"}
{"answers": {"text": ["1,160,000", "1,160,000", "1,160,000"], "answer_start": [151, 151, 151]}, "prediction_text": "734,000 square miles (1,900,000 km2)"}
{"answers": {"text": ["three epicenters", "three epicenters", "three"], "answer_start": [284, 284, 284]}, "prediction_text": "approximate 1,160,000 square miles (3,000,000 km2)"}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [339, 339, 339]}, "prediction_text": "2005"}
{"answers": {"text": ["1.5 gigatons", "1.5 gigatons", "1.5 gigatons"], "answer_start": [483, 483, 483]}, "prediction_text": "1.5 gigatons"}
{"answers": {"text": ["comb jellies", "comb jellies", "comb jellies"], "answer_start": [151, 151, 151]}, "prediction_text": "Ctenophora is a phylum of animals that live in marine waters worldwide."}
{"answers": {"text": ["marine waters worldwide.", "marine waters worldwide", "marine waters"], "answer_start": [201, 201, 201]}, "prediction_text": "In marine waters worldwide."}
{"answers": {"text": ["a few millimeters to 1.5 m (4 ft 11 in) in size.", "a few millimeters to 1.5 m (4 ft 11 in) in size", "a few millimeters to 1.5 m"], "answer_start": [415, 415, 415]}, "prediction_text": "Few millimeters to 1.5 m (4 ft 11 in)"}
{"answers": {"text": ["phylum of animals that live in marine waters", "a phylum of animals", "comb jellies"], "answer_start": [170, 168, 151]}, "prediction_text": "A phylum of animals that live in marine waters worldwide."}
{"answers": {"text": ["\u2018combs\u2019 \u2013 groups of cilia", "cilia", "cilia"], "answer_start": [264, 284, 371]}, "prediction_text": "Cilia for swimming."}
{"answers": {"text": ["water flow through the body cavity", "water flow", "water flow through the body cavity"], "answer_start": [801, 801, 801]}, "prediction_text": "Jelly cells"}
{"answers": {"text": ["1.5 m (4 ft 11 in)", "a few millimeters to 1.5 m"], "answer_start": [436, 415]}, "prediction_text": "One meter (approximately 4 ft 11 in)"}
{"answers": {"text": ["\u2018combs\u2019 \u2013 groups of cilia", "combs", "the \u2018combs\u2019"], "answer_start": [264, 265, 260]}, "prediction_text": "Combs"}
{"answers": {"text": ["comb jellies", "comb jellies", "comb jellies"], "answer_start": [151, 151, 151]}, "prediction_text": "Ctenophora is a phylum of animals that live in marine waters worldwide."}
{"answers": {"text": ["1.5 m (4 ft 11 in)", "1.5 m (4 ft 11 in)", "a few millimeters to 1.5 m"], "answer_start": [436, 436, 415]}, "prediction_text": "1.5 m (4 ft 11 in)"}
{"answers": {"text": ["water flow through the body cavity", "\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'", "water flow through the body cavity"], "answer_start": [801, 90, 801]}, "prediction_text": "Water flow through the body cavity"}
{"answers": {"text": ["\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'", "\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'", "kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'"], "answer_start": [90, 90, 96]}, "prediction_text": "Comb"}
{"answers": {"text": ["marine waters", "marine waters worldwide", "marine waters"], "answer_start": [201, 201, 201]}, "prediction_text": "Worldwide"}
{"answers": {"text": ["ten times their own weight", "ten times their own weight", "ten times their own weight"], "answer_start": [300, 300, 300]}, "prediction_text": "Ten times their own weight"}
{"answers": {"text": ["100\u2013150", "100\u2013150", "100\u2013150"], "answer_start": [342, 342, 342]}, "prediction_text": "100\u2013150 species"}
{"answers": {"text": ["possibly another 25", "25", "25"], "answer_start": [383, 400, 400]}, "prediction_text": "25 species"}
{"answers": {"text": ["100\u2013150 species", "100\u2013150", "100\u2013150"], "answer_start": [342, 342, 342]}, "prediction_text": "100\u2013150 species"}
{"answers": {"text": ["tentilla", "tentilla", "tentilla"], "answer_start": [552, 552, 552]}, "prediction_text": "Little tentacles"}
{"answers": {"text": ["ten times their own weight", "ten times their own weight", "ten times their own weight"], "answer_start": [300, 300, 300]}, "prediction_text": "Ten times its own weight"}
{"answers": {"text": ["tentacles", "tentacles", "tentacles"], "answer_start": [824, 824, 824]}, "prediction_text": "tentacles and prey."}
{"answers": {"text": ["groups of large, stiffened cilia", "stiffened cilia", "stiffened cilia"], "answer_start": [896, 913, 913]}, "prediction_text": "Large mouths"}
{"answers": {"text": ["ten times their own weight", "ten times their own weight", "ten times their own weight"], "answer_start": [300, 300, 300]}, "prediction_text": "Ten times their own weight"}
{"answers": {"text": ["tentilla", "tentilla", "tentilla"], "answer_start": [552, 552, 552]}, "prediction_text": "Little tentacles"}
{"answers": {"text": ["groups of large, stiffened cilia", "stiffened cilia", "stiffened cilia"], "answer_start": [896, 913, 913]}, "prediction_text": "Large mouths"}
{"answers": {"text": ["colloblasts", "retractable tentacles fringed with tentilla", "colloblasts"], "answer_start": [604, 517, 604]}, "prediction_text": "Huge mouths"}
{"answers": {"text": ["100\u2013150 species", "100\u2013150", "100\u2013150 species have been validated"], "answer_start": [342, 342, 342]}, "prediction_text": "100\u2013150 species"}
{"answers": {"text": ["Most species are hermaphrodites", "hermaphrodites", "hermaphrodites"], "answer_start": [0, 17, 17]}, "prediction_text": "Single animal"}
{"answers": {"text": ["miniature cydippids", "miniature cydippids", "miniature cydippids"], "answer_start": [533, 533, 533]}, "prediction_text": "Planktonic and in some species, miniature."}
{"answers": {"text": ["In at least some species, juveniles are capable of reproduction before reaching the adult size", "juveniles are capable of reproduction", "juveniles are capable of reproduction"], "answer_start": [886, 912, 912]}, "prediction_text": "Yes, juveniles are capable of reproduction."}
{"answers": {"text": ["can produce both eggs and sperm, meaning it can fertilize its own egg", "it can fertilize its own egg", "a single animal can produce both eggs and sperm"], "answer_start": [48, 89, 32]}, "prediction_text": "They produce both eggs and sperm at the same time."}
{"answers": {"text": ["can produce both eggs and sperm at the same time", "produce both eggs and sperm at the same time", "produce both eggs and sperm at the same time"], "answer_start": [183, 187, 187]}, "prediction_text": "Produce both eggs and sperm simultaneously."}
{"answers": {"text": ["sequential", "sequential hermaphrodites", "simultaneous"], "answer_start": [244, 244, 148]}, "prediction_text": "Synchronous hermaphrodites"}
{"answers": {"text": ["platyctenids", "platyctenids", "platyctenids"], "answer_start": [372, 372, 372]}, "prediction_text": "Platyctenids eggs"}
{"answers": {"text": ["hermaphroditism and early reproduction", "hermaphroditism and early reproduction", "combination of hermaphroditism and early reproduction"], "answer_start": [1011, 1011, 996]}, "prediction_text": "Hermaphroditism and early reproduction."}
{"answers": {"text": ["a single animal can produce both eggs and sperm", "a single animal can produce both eggs and sperm", "a single animal can produce both eggs and sperm"], "answer_start": [32, 32, 32]}, "prediction_text": "A single animal can produce both eggs and sperm."}
{"answers": {"text": ["can produce both eggs and sperm at the same time.", "can produce both eggs and sperm", "produce both eggs and sperm at the same time"], "answer_start": [183, 183, 187]}, "prediction_text": "They can produce both eggs and sperm simultaneously."}
{"answers": {"text": ["the eggs and sperm mature at different times", "eggs and sperm mature at different times", "eggs and sperm mature at different times"], "answer_start": [280, 284, 284]}, "prediction_text": "Produces both eggs and sperm at the same time."}
{"answers": {"text": ["platyctenids", "platyctenids", "platyctenids"], "answer_start": [372, 372, 372]}, "prediction_text": "Platyctenids"}
{"answers": {"text": ["beroids", "beroids", "beroids"], "answer_start": [634, 634, 634]}, "prediction_text": "Beroids"}
{"answers": {"text": ["the Black Sea", "Black Sea", "Black Sea"], "answer_start": [474, 478, 478]}, "prediction_text": "Black Sea"}
{"answers": {"text": ["Mnemiopsis", "Mnemiopsis", "Mnemiopsis"], "answer_start": [424, 424, 424]}, "prediction_text": "Mnemiopsis"}
{"answers": {"text": ["over-fishing and long-term environmental changes", "over-fishing and long-term environmental changes", "long-term environmental changes"], "answer_start": [680, 680, 697]}, "prediction_text": "Over-fishing and long-term environmental changes."}
{"answers": {"text": ["other ctenophores", "ctenophores", "other ctenophores"], "answer_start": [877, 883, 877]}, "prediction_text": "Other ctenophores"}
{"answers": {"text": ["Mnemiopsis", "Mnemiopsis", "Mnemiopsis"], "answer_start": [424, 424, 424]}, "prediction_text": "Mnemiopsis"}
{"answers": {"text": ["fish larvae and organisms", "fish larvae and organisms that would otherwise have fed the fish", "fish larvae and organisms that would otherwise have fed the fish"], "answer_start": [559, 559, 559]}, "prediction_text": "Fish larvae"}
{"answers": {"text": ["In bays", "bays", "bays"], "answer_start": [141, 144, 144]}, "prediction_text": "In coastal locations"}
{"answers": {"text": ["In bays", "bays", "bays"], "answer_start": [141, 144, 144]}, "prediction_text": "In coastal locations"}
{"answers": {"text": ["planktonic plants", "planktonic plants", "a vital part of marine food chains"], "answer_start": [342, 342, 372]}, "prediction_text": "Planktonic plants"}
{"answers": {"text": ["Mnemiopsis", "Mnemiopsis", "Mnemiopsis"], "answer_start": [424, 424, 424]}, "prediction_text": "Mnemiopsis"}
{"answers": {"text": ["causing fish stocks to collapse", "causing fish stocks to collapse", "causing fish stocks to collapse"], "answer_start": [512, 512, 512]}, "prediction_text": "Over-fishing and long-term environmental changes."}
{"answers": {"text": ["introduction of Beroe", "accidental introduction of Beroe"], "answer_start": [805, 794]}, "prediction_text": "Overfishing and environmental changes promoted growth of the mnemiopsis population."}
{"answers": {"text": ["66 million years ago", "515 million years ago", "66 million years ago"], "answer_start": [760, 226, 760]}, "prediction_text": "66 million years ago"}
{"answers": {"text": ["monophyletic", "monophyletic", "\"cydippids\" are not monophyletic"], "answer_start": [859, 859, 839]}, "prediction_text": "Monophyletic"}
{"answers": {"text": ["515 million years", "66 million years ago", "515 million years"], "answer_start": [226, 760, 226]}, "prediction_text": "About 515 million years ago."}
{"answers": {"text": ["tentacles", "tentacles", "tentacles"], "answer_start": [100, 100, 100]}, "prediction_text": "tentacles"}
{"answers": {"text": ["515 million years", "66 million years", "515 million years"], "answer_start": [226, 760, 226]}, "prediction_text": "Early Cambrian"}
{"answers": {"text": ["Cretaceous\u2013Paleogene extinction", "the Cretaceous\u2013Paleogene extinction", "Cretaceous\u2013Paleogene extinction"], "answer_start": [722, 718, 722]}, "prediction_text": "Cretaceous\u2013Paleogene extinction event"}
{"answers": {"text": ["monophyletic", "monophyletic", "monophyletic"], "answer_start": [859, 859, 859]}, "prediction_text": "Monophyletic"}
{"answers": {"text": ["tentacles", "tentacles", "tentacles"], "answer_start": [100, 100, 100]}, "prediction_text": "No tentacles"}
{"answers": {"text": ["cnidarians", "Ctenophores", "cnidarians"], "answer_start": [89, 0, 89]}, "prediction_text": "Ctenophores"}
{"answers": {"text": ["by having colloblasts", "having colloblasts", "colloblasts"], "answer_start": [446, 449, 456]}, "prediction_text": "Colloblasts are sticky and adhere to prey."}
{"answers": {"text": ["bilaterians", "bilaterians", "bilaterians"], "answer_start": [155, 155, 155]}, "prediction_text": "Sponges"}
{"answers": {"text": ["Ctenophores", "Ctenophores", "Ctenophores"], "answer_start": [0, 0, 0]}, "prediction_text": "Ctenophores"}
{"answers": {"text": ["colloblasts", "colloblasts", "colloblasts"], "answer_start": [456, 456, 456]}, "prediction_text": "Colloblasts"}
{"answers": {"text": ["cnidarians", "cnidarians", "cnidarians"], "answer_start": [89, 89, 89]}, "prediction_text": "Ctenophores"}
{"answers": {"text": ["colloblasts", "colloblasts", "colloblasts"], "answer_start": [456, 456, 456]}, "prediction_text": "Cell bound by inter-cell connections and carpet-like basement membranes."}
{"answers": {"text": ["colloblasts", "colloblasts", "colloblasts"], "answer_start": [456, 456, 456]}, "prediction_text": "Colloblasts"}
{"answers": {"text": ["ctenophores and cnidarians", "ctenophores and cnidarians", "ctenophores and cnidarians"], "answer_start": [230, 230, 230]}, "prediction_text": "Ctenophores"}
{"answers": {"text": ["bilaterians", "bilaterians", "bilaterians"], "answer_start": [155, 155, 155]}, "prediction_text": "Sponges"}
{"answers": {"text": ["mesoglea", "mesoglea", "mesoglea"], "answer_start": [144, 144, 144]}, "prediction_text": "mesoglea"}
{"answers": {"text": ["diploblastic", "ctenophores", "diploblastic"], "answer_start": [337, 29, 337]}, "prediction_text": "Diploblastic"}
{"answers": {"text": ["sponges and cnidarians, ctenophores", "ctenophores", "cnidarians and ctenophores"], "answer_start": [5, 29, 156]}, "prediction_text": "Ctenophores"}
{"answers": {"text": ["sponges", "sponges", "sponges"], "answer_start": [362, 362, 362]}, "prediction_text": "Sponges"}
{"answers": {"text": ["cilia", "cilia", "cilia"], "answer_start": [133, 133, 133]}, "prediction_text": "\"Hairs\""}
{"answers": {"text": ["method of locomotion", "their main method of locomotion", "locomotion"], "answer_start": [163, 152, 173]}, "prediction_text": "Stacking and movement of cilia."}
{"answers": {"text": ["ctenes", "ctenes", "ctenes"], "answer_start": [314, 314, 314]}, "prediction_text": "\"ctenes\""}
{"answers": {"text": ["comb-bearing", "\"comb\" and the Greek suffix -\u03c6\u03bf\u03c1\u03bf\u03c2 meaning \"carrying\"", "comb-bearing"], "answer_start": [450, 512, 450]}, "prediction_text": "Comb-bearing"}
{"answers": {"text": ["Pleurobrachia", "Pleurobrachia", "Pleurobrachia"], "answer_start": [590, 590, 590]}, "prediction_text": "Pleurobrachia"}
{"answers": {"text": ["oceanic species", "oceanic species", "oceanic species"], "answer_start": [190, 293, 190]}, "prediction_text": "Coastal species"}
{"answers": {"text": ["to withstand waves and swirling sediment particles", "to withstand waves and swirling sediment particles", "to withstand waves and swirling sediment particles"], "answer_start": [127, 127, 127]}, "prediction_text": "They are fragile."}
{"answers": {"text": ["Pleurobrachia, Beroe and Mnemiopsis", "Pleurobrachia, Beroe and Mnemiopsis", "Pleurobrachia, Beroe and Mnemiopsis"], "answer_start": [475, 475, 475]}, "prediction_text": "Pleurobrachia"}
{"answers": {"text": ["epithelium", "epithelium", "epithelium"], "answer_start": [536, 536, 536]}, "prediction_text": "epithelium"}
{"answers": {"text": ["bioluminescence", "bioluminescence", "bioluminescence"], "answer_start": [945, 945, 945]}, "prediction_text": "Bioluminescence"}
{"answers": {"text": ["pharynx", "pharynx", "pharynx"], "answer_start": [76, 76, 76]}, "prediction_text": "A mouth that can be closed by muscles."}
{"answers": {"text": ["a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals.", "a system of internal canals", "the gastrodermis"], "answer_start": [27, 151, 548]}, "prediction_text": "Mouth and pharynx"}
{"answers": {"text": ["the mouth and pharynx;", "the mouth and pharynx", "the mouth and pharynx"], "answer_start": [254, 254, 254]}, "prediction_text": "Mouth and pharynx"}
{"answers": {"text": ["swimming-plates", "swimming-plates", "swimming-plates"], "answer_start": [56, 56, 56]}, "prediction_text": "swimming-plates"}
{"answers": {"text": ["also called \"ctenes\" or \"comb plates", "\"ctenes\" or \"comb plates\"", "ctenes"], "answer_start": [424, 436, 437]}, "prediction_text": "\"ctenes\" or \"comb plates\""}
{"answers": {"text": ["supporting function", "suspected to have a supporting function", "a supporting function"], "answer_start": [773, 753, 771]}, "prediction_text": "Reverse direction."}
{"answers": {"text": ["in the direction in which the mouth is pointing,", "the direction in which the mouth is pointing", "direction in which the mouth is pointing"], "answer_start": [941, 944, 948]}, "prediction_text": "Away from predators"}
{"answers": {"text": ["2 millimeters (0.079 in)", "2 millimeters", "2 millimeters"], "answer_start": [546, 546, 546]}, "prediction_text": "Up to 2 millimeters (0.079 in)"}
{"answers": {"text": ["osmotic pressure", "It is uncertain", "rely on osmotic pressure"], "answer_start": [109, 0, 101]}, "prediction_text": "They use osmotic pressure to adapt."}
{"answers": {"text": ["the mesoglea", "mesoglea", "mesoglea"], "answer_start": [328, 332, 332]}, "prediction_text": "Mesoglea"}
{"answers": {"text": ["increase its bulk and decrease its density", "increase its bulk and decrease its density", "increase its bulk and decrease its density"], "answer_start": [344, 344, 344]}, "prediction_text": "Increases density."}
{"answers": {"text": ["pump water out of the mesoglea", "pump", "pump water out of the mesoglea"], "answer_start": [488, 313, 488]}, "prediction_text": "Pump water out of mesoglea."}
{"answers": {"text": ["aboral organ", "aboral organ", "aboral organ"], "answer_start": [42, 42, 42]}, "prediction_text": "Aboral organ"}
{"answers": {"text": ["at the opposite end from the mouth", "the opposite end from the mouth", "opposite end from the mouth"], "answer_start": [56, 59, 63]}, "prediction_text": "Opposite end of the mouth"}
{"answers": {"text": ["a transparent dome made of long, immobile cilia", "a transparent dome made of long, immobile cilia", "transparent dome made of long, immobile cilia"], "answer_start": [303, 303, 305]}, "prediction_text": "A transparent dome"}
{"answers": {"text": ["a statocyst", "statocyst", "statocyst"], "answer_start": [115, 117, 117]}, "prediction_text": "A statocyst"}
{"answers": {"text": ["a balance sensor", "a balance sensor consisting of a statolith", "a balance sensor consisting of a statolith"], "answer_start": [128, 128, 128]}, "prediction_text": "A balance sensor."}
{"answers": {"text": ["sea gooseberry", "sea gooseberry", "sea gooseberry"], "answer_start": [159, 159, 159]}, "prediction_text": "Pleurobrachia"}
{"answers": {"text": ["a pair of long, slender tentacles", "long, slender tentacles", "a pair of long, slender tentacles"], "answer_start": [350, 360, 350]}, "prediction_text": "Long, slender tentacles"}
{"answers": {"text": ["more or less rounded", "egg-shaped", "more or less rounded"], "answer_start": [42, 208, 42]}, "prediction_text": "Cydippid shape"}
{"answers": {"text": ["a sheath", "a sheath", "a sheath into which it can be withdrawn"], "answer_start": [400, 400, 400]}, "prediction_text": "Sheath"}
{"answers": {"text": ["at the narrow end", "the narrow end", "at the narrow end"], "answer_start": [239, 242, 239]}, "prediction_text": "At the narrow end"}
{"answers": {"text": ["tentilla", "tentilla", "tentilla"], "answer_start": [65, 65, 65]}, "prediction_text": "Little tentacles"}
{"answers": {"text": ["specialized mushroom-shaped cells in the outer layer of the epidermis", "specialized mushroom-shaped cells in the outer layer of the epidermis", "specialized mushroom-shaped cells in the outer layer of the epidermis"], "answer_start": [297, 297, 297]}, "prediction_text": "Microscopic cells in the outer layer of the epidermis."}
{"answers": {"text": ["they contain striated muscle,", "they contain striated muscle", "they contain striated muscle"], "answer_start": [1150, 1150, 1150]}, "prediction_text": "They have striated muscle."}
{"answers": {"text": ["three types of movement", "three", "three"], "answer_start": [1369, 1369, 1369]}, "prediction_text": "Three types of movements."}
{"answers": {"text": ["capturing prey", "capturing prey", "capturing prey"], "answer_start": [1410, 1410, 1410]}, "prediction_text": "Capture prey"}
{"answers": {"text": ["eight rows", "eight", "eight"], "answer_start": [10, 10, 10]}, "prediction_text": "Eight rows"}
{"answers": {"text": ["from near the mouth to the opposite end", "near the mouth to the opposite end", "near the mouth to the opposite end"], "answer_start": [39, 44, 44]}, "prediction_text": "Near the mouth to the opposite end"}
{"answers": {"text": ["evenly round the body", "evenly", "evenly round the body"], "answer_start": [95, 95, 95]}, "prediction_text": "In a metachronal rhythm"}
{"answers": {"text": ["ciliary groove", "a ciliary groove", "a ciliary groove"], "answer_start": [233, 231, 231]}, "prediction_text": "Water disturbances"}
{"answers": {"text": ["lobes", "lobes", "lobes"], "answer_start": [26, 26, 26]}, "prediction_text": "Lobates"}
{"answers": {"text": ["gelatinous projections edged with cilia that produce water currents", "gelatinous projections edged with cilia", "gelatinous projections edged with cilia"], "answer_start": [417, 417, 417]}, "prediction_text": "Four auricles in lobes."}
{"answers": {"text": ["four", "four", "four"], "answer_start": [402, 402, 402]}, "prediction_text": "Four auricles"}
{"answers": {"text": ["help direct microscopic prey toward the mouth", "produce water currents that help direct microscopic prey toward the mouth", "produce water currents that help direct microscopic prey toward the mouth"], "answer_start": [490, 462, 462]}, "prediction_text": "Produce water currents"}
{"answers": {"text": ["suspended planktonic prey", "suspended planktonic prey", "planktonic prey"], "answer_start": [608, 608, 618]}, "prediction_text": "Stabilized planktonic prey"}
{"answers": {"text": ["by clapping their lobes", "clapping their lobes", "clapping their lobes"], "answer_start": [515, 518, 518]}, "prediction_text": "Claps lobes."}
{"answers": {"text": ["jet of expelled water drives them backwards very quickly.", "jet of expelled water drives them backwards very quickly", "expelled water drives them backwards very quickly"], "answer_start": [552, 552, 559]}, "prediction_text": "They grow larger."}
{"answers": {"text": ["nerves", "nerves rather than by water disturbances created by the cilia", "nerves"], "answer_start": [679, 679, 679]}, "prediction_text": "Nerves"}
{"answers": {"text": ["water disturbances created by the cilia", "water disturbances created by the cilia", "water disturbances created by the cilia"], "answer_start": [701, 701, 701]}, "prediction_text": "Nerves"}
{"answers": {"text": ["Nuda", "Nuda", "Nuda"], "answer_start": [27, 27, 27]}, "prediction_text": "Nuda"}
{"answers": {"text": ["The Beroida", "Beroida", "Beroida"], "answer_start": [0, 4, 4]}, "prediction_text": "Beroida"}
{"answers": {"text": ["zip\" the mouth shut when the animal is not feeding,", "\"zip\" the mouth shut when the animal is not feeding", "\"zip\" the mouth shut when the animal is not feeding"], "answer_start": [514, 513, 513]}, "prediction_text": "Zips the mouth shut when not feeding."}
{"answers": {"text": ["\"zip\" the mouth shut", "streamlines the front of the animal", "tight closure streamlines the front of the animal"], "answer_start": [513, 656, 642]}, "prediction_text": "Focused on prey."}
{"answers": {"text": ["large pharynx", "large cilia", "\"macrocilia\""], "answer_start": [71, 228, 158]}, "prediction_text": "Large pharynx"}
{"answers": {"text": ["The Cestida", "Cestida", "Cestida"], "answer_start": [0, 4, 4]}, "prediction_text": "Cestidae"}
{"answers": {"text": ["Cestum veneris", "Cestum veneris", "up to 1.5 meters (4.9 ft) long"], "answer_start": [512, 512, 580]}, "prediction_text": "Cestum veneris"}
{"answers": {"text": ["belt animals", "belt animals", "\"belt animals\""], "answer_start": [14, 14, 13]}, "prediction_text": "Belt animals"}
{"answers": {"text": ["by undulating their bodies as well as by the beating of their comb-rows.", "undulating their bodies", "by undulating their bodies as well as by the beating of their comb-rows"], "answer_start": [346, 349, 346]}, "prediction_text": "undulating bodies as well as comb-rows."}
{"answers": {"text": ["Velamen parallelum", "Velamen parallelum", "Velamen parallelum"], "answer_start": [654, 654, 654]}, "prediction_text": "Velamen parallelum"}
{"answers": {"text": ["a pair of tentilla-bearing tentacles", "tentilla-bearing tentacles", "a pair of tentilla-bearing tentacles"], "answer_start": [89, 99, 89]}, "prediction_text": "Tentilla-bearing tentacles"}
{"answers": {"text": ["cling to and creep on surfaces", "as a muscular \"foot\"", "as a muscular \"foot\""], "answer_start": [154, 222, 222]}, "prediction_text": "Ctenophore use"}
{"answers": {"text": ["comb-rows", "comb-rows", "comb-rows"], "answer_start": [294, 294, 294]}, "prediction_text": "Comb-rows"}
{"answers": {"text": ["on rocks, algae, or the body surfaces of other invertebrates", "rocks, algae, or the body surfaces of other invertebrates", "rocks, algae, or the body surfaces of other invertebrates"], "answer_start": [356, 359, 359]}, "prediction_text": "On rocks, algae, or the body surfaces of other invertebrates."}
{"answers": {"text": ["via pores in the epidermis", "pores in the epidermis", "via pores in the epidermis"], "answer_start": [341, 345, 341]}, "prediction_text": "Through pores in epidermis."}
{"answers": {"text": ["internal fertilization and keep the eggs in brood chambers until they hatch.", "internal fertilization", "internal fertilization"], "answer_start": [433, 433, 433]}, "prediction_text": "Self-fertilization"}
{"answers": {"text": ["Mnemiopsis", "Mnemiopsis", "Mnemiopsis"], "answer_start": [580, 580, 580]}, "prediction_text": "Mnemiopsis"}
{"answers": {"text": ["in the parts of the internal canal network under the comb rows", "the parts of the internal canal network under the comb rows", "internal canal network under the comb rows"], "answer_start": [245, 248, 265]}, "prediction_text": "In the internal canal network"}
{"answers": {"text": ["external", "external", "external"], "answer_start": [386, 386, 386]}, "prediction_text": "Exeternal in most species."}
{"answers": {"text": ["tentacles and tentacle sheaths", "tentacles and tentacle sheaths", "tentacles and tentacle sheaths"], "answer_start": [228, 228, 228]}, "prediction_text": "tentacles and tentacle sheaths"}
{"answers": {"text": ["among the plankton", "among the plankton", "among the plankton"], "answer_start": [462, 462, 462]}, "prediction_text": "Sea-floor"}
{"answers": {"text": ["after dropping to the sea-floor", "after dropping to the sea-floor", "after dropping to the sea-floor"], "answer_start": [604, 604, 604]}, "prediction_text": "By metamorphosis after dropping to sea-floor."}
{"answers": {"text": ["more like true larvae", "true larvae", "like true larvae"], "answer_start": [426, 436, 431]}, "prediction_text": "True larvae"}
{"answers": {"text": ["Beroe", "Beroe", "Beroe"], "answer_start": [185, 185, 185]}, "prediction_text": "Beroe"}
{"answers": {"text": ["they produce secretions (ink) that luminesce", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "they produce secretions (ink) that luminesce"], "answer_start": [112, 112, 112]}, "prediction_text": "Produce secretions."}
{"answers": {"text": ["are disturbed,", "disturbed", "are disturbed"], "answer_start": [97, 101, 97]}, "prediction_text": "At the same wavelengths as their bodies."}
{"answers": {"text": ["ink", "ink", "ink"], "answer_start": [137, 137, 137]}, "prediction_text": "ink"}
{"answers": {"text": ["Juveniles will luminesce more brightly", "Juveniles", "Juveniles"], "answer_start": [203, 203, 203]}, "prediction_text": "Adults secretions luminesce brighter."}
{"answers": {"text": ["Almost all ctenophores are predators", "predators", "predators"], "answer_start": [0, 27, 27]}, "prediction_text": "Vegetarian"}
{"answers": {"text": ["jellyfish", "jellyfish", "jellyfish"], "answer_start": [479, 479, 479]}, "prediction_text": "Other ctenophores"}
{"answers": {"text": ["incorporate their prey's nematocysts (stinging cells) into their own tentacles instead of colloblasts", "incorporate their prey's nematocysts (stinging cells) into their own tentacles", "incorporate their prey's nematocysts (stinging cells) into their own tentacles"], "answer_start": [493, 493, 493]}, "prediction_text": "They attach themselves to salps."}
{"answers": {"text": ["smaller, weaker swimmers such as rotifers and mollusc and crustacean larvae.", "smaller, weaker swimmers such as rotifers and mollusc and crustacean larvae", "rotifers and mollusc and crustacean larvae"], "answer_start": [1556, 1556, 1589]}, "prediction_text": "Smaller, weaker swimmers."}
{"answers": {"text": ["Lampea", "Lampea", "Lampea"], "answer_start": [1018, 1018, 1018]}, "prediction_text": "Lampea"}
{"answers": {"text": ["their low ratio of organic matter to salt and water", "their low ratio of organic matter to salt and water", "low ratio of organic matter to salt and water"], "answer_start": [92, 92, 98]}, "prediction_text": "Low ratio of organic matter to salt and water."}
{"answers": {"text": ["chum salmon", "chum salmon", "chum salmon"], "answer_start": [386, 386, 386]}, "prediction_text": "Oncorhynchus keta"}
{"answers": {"text": ["ctenophores", "other ctenophores", "other ctenophores"], "answer_start": [618, 612, 612]}, "prediction_text": "Other ctenophores"}
{"answers": {"text": ["the Red Sea", "the Red Sea", "blooms in the Red Sea"], "answer_start": [1089, 1089, 1079]}, "prediction_text": "Red Sea"}
{"answers": {"text": ["ctenophores,", "ctenophores", "ctenophores"], "answer_start": [682, 682, 682]}, "prediction_text": "Ctenophores"}
{"answers": {"text": ["ctenophore Mnemiopsis leidyi", "Mnemiopsis leidyi", "the Western Atlantic ctenophore Mnemiopsis leidyi was accidentally introduced"], "answer_start": [58, 69, 37]}, "prediction_text": "Mnemiopsis eating both fish larvae and small crustaceans."}
{"answers": {"text": ["via the ballast tanks of ships", "via the ballast tanks of ships", "the ballast tanks of ships"], "answer_start": [150, 150, 154]}, "prediction_text": "Through ballast tanks of ships."}
{"answers": {"text": ["by the accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata,", "the accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata", "the accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata, and by a cooling of the local climate from 1991 to 1993"], "answer_start": [925, 928, 928]}, "prediction_text": "By accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata."}
{"answers": {"text": ["in the late 1980s", "the late 1980s", "late 1980s"], "answer_start": [19, 22, 26]}, "prediction_text": "Late 1980s"}
{"answers": {"text": ["significantly slowed the animal's metabolism", "slowed the animal's metabolism", "significantly slowed the animal's metabolism"], "answer_start": [1083, 1097, 1083]}, "prediction_text": "Slowens metabolism."}
{"answers": {"text": ["Because of their soft, gelatinous bodies", "their soft, gelatinous bodies", "their soft, gelatinous bodies"], "answer_start": [0, 11, 11]}, "prediction_text": "Due to soft, gelatinous bodies."}
{"answers": {"text": ["comb jelly.", "comb jelly", "a comb jelly"], "answer_start": [1213, 1213, 1211]}, "prediction_text": "A comb jelly."}
{"answers": {"text": ["Cambrian period.", "mid-Cambrian period", "mid-Cambrian period"], "answer_start": [564, 560, 560]}, "prediction_text": "Mid-Cambrian period"}
{"answers": {"text": ["Three additional putative species", "Three", "Three"], "answer_start": [413, 413, 413]}, "prediction_text": "About 505 million years ago."}
{"answers": {"text": ["lacked tentacles", "tentacles", "tentacles"], "answer_start": [602, 609, 609]}, "prediction_text": "tentacles"}
{"answers": {"text": ["515 million years", "about 515 million years", "515 million years"], "answer_start": [115, 109, 115]}, "prediction_text": "About 515 million years ago"}
{"answers": {"text": ["Cambrian sessile frond-like fossil Stromatoveris", "Stromatoveris", "sessile frond-like"], "answer_start": [10, 45, 19]}, "prediction_text": "Early Cambrian fossils"}
{"answers": {"text": ["Stromatoveris", "Stromatoveris", "Stromatoveris"], "answer_start": [346, 346, 346]}, "prediction_text": "Stromatoveris"}
{"answers": {"text": ["Vendobionta", "ctenophores", "Vendobionta"], "answer_start": [157, 390, 157]}, "prediction_text": "Vendobionta"}
{"answers": {"text": ["Ediacaran period", "Ediacaran period", "Ediacaran period"], "answer_start": [186, 186, 186]}, "prediction_text": "Ediacaran period"}
{"answers": {"text": ["all other animals", "Bilateria", "Bilateria"], "answer_start": [929, 276, 344]}, "prediction_text": "Bilateria, Cnidaria, Cnidaria, Placozoa, Bilateria, and all other animal phyla."}
{"answers": {"text": ["Porifera", "Porifera", "Porifera"], "answer_start": [1328, 1328, 1328]}, "prediction_text": "Porifera"}
{"answers": {"text": ["beroids", "beroids", "beroids"], "answer_start": [40, 40, 40]}, "prediction_text": "Beroids"}
{"answers": {"text": ["monophyletic", "monophyletic", "monophyletic"], "answer_start": [819, 317, 317]}, "prediction_text": "Monophyletic"}
{"answers": {"text": ["65.5 million years ago", "65.5 million years ago", "65.5 million years ago"], "answer_start": [1272, 1272, 1272]}, "prediction_text": "65.5 million years ago"}
{"answers": {"text": ["Richard Harbison", "Richard Harbison", "Richard Harbison"], "answer_start": [223, 223, 223]}, "prediction_text": "Richard Harbison"}
{"answers": {"text": ["Fresno", "Fresno", "Fresno"], "answer_start": [0, 0, 0]}, "prediction_text": "Fresno"}
{"answers": {"text": ["220 miles (350 km)", "220 miles (350 km)", "220 miles (350 km)"], "answer_start": [432, 432, 432]}, "prediction_text": "220 miles (350 km)"}
{"answers": {"text": ["ash tree", "ash tree", "ash tree"], "answer_start": [605, 605, 605]}, "prediction_text": "\"ash tree\""}
{"answers": {"text": ["ash leaf", "ash leaf", "an ash leaf"], "answer_start": [634, 634, 631]}, "prediction_text": "An ash leaf"}
{"answers": {"text": ["(/\u02c8fr\u025bzno\u028a/ FREZ-noh)", "FREZ-noh", "FREZ-noh"], "answer_start": [7, 19, 19]}, "prediction_text": "FREZ-noh"}
{"answers": {"text": ["1872", "1872", "1872"], "answer_start": [3, 3, 3]}, "prediction_text": "1872"}
{"answers": {"text": ["the convenience of the railroad and worried about flooding", "drawn by the convenience of the railroad and worried about flooding", "the convenience of the railroad and worried about flooding"], "answer_start": [294, 285, 294]}, "prediction_text": "Flooding concerns"}
{"answers": {"text": ["1885", "1885", "1885"], "answer_start": [420, 420, 420]}, "prediction_text": "1931"}
{"answers": {"text": ["47 streetcars", "47", "47"], "answer_start": [471, 471, 471]}, "prediction_text": "47 streetcars"}
{"answers": {"text": ["store", "store", "store"], "answer_start": [199, 166, 199]}, "prediction_text": "Central Pacific Railroad"}
{"answers": {"text": ["2.7%", "2.7%", "2.7%"], "answer_start": [214, 214, 214]}, "prediction_text": "2.7%"}
{"answers": {"text": ["Chinatown", "Chinatown", "Chinatown"], "answer_start": [242, 242, 242]}, "prediction_text": "Chinatown"}
{"answers": {"text": ["Pinedale", "Pinedale", "Pinedale"], "answer_start": [357, 357, 357]}, "prediction_text": "Pinedale"}
{"answers": {"text": ["an interim facility for the relocation of Fresno area Japanese Americans to internment camps", "an interim facility for the relocation of Fresno area Japanese Americans to internment camps", "an interim facility for the relocation of Fresno area Japanese Americans to internment camps"], "answer_start": [442, 442, 442]}, "prediction_text": "Temporary facility for relocation of Japanese Americans to internment camps."}
{"answers": {"text": ["an assembly center", "an assembly center", "an assembly center"], "answer_start": [580, 580, 580]}, "prediction_text": "An assembly center"}
{"answers": {"text": ["BankAmericard", "BankAmericard", "BankAmericard"], "answer_start": [65, 65, 65]}, "prediction_text": "BankAmericard"}
{"answers": {"text": ["BankAmericard", "BankAmericard", "BankAmericard"], "answer_start": [65, 152, 152]}, "prediction_text": "BankAmericard"}
{"answers": {"text": ["to revolve a balance", "a financial instrument that was usable across a large number of merchants and also allowed cardholders to revolve a balance", "revolve a balance"], "answer_start": [330, 227, 333]}, "prediction_text": "Revolve a balance"}
{"answers": {"text": ["1976", "1976", "1976"], "answer_start": [423, 423, 423]}, "prediction_text": "1976"}
{"answers": {"text": ["Visa Inc.", "Visa Inc.", "Visa Inc."], "answer_start": [507, 507, 507]}, "prediction_text": "Visa Inc."}
{"answers": {"text": ["Bill Aken", "Bill Aken", "Bill Aken"], "answer_start": [107, 107, 107]}, "prediction_text": "Bill Aken"}
{"answers": {"text": ["Bob Gallion", "Bob Gallion", "Bob Gallion"], "answer_start": [133, 133, 133]}, "prediction_text": "Bill Aken and Bob Gallion"}
{"answers": {"text": ["Madera", "Madera", "Madera"], "answer_start": [323, 323, 323]}, "prediction_text": "Madera"}
{"answers": {"text": ["The Fresno Barn", "The Fresno Barn", "the old country-western show at The Fresno Barn"], "answer_start": [510, 510, 478]}, "prediction_text": "The Fresno Barn"}
{"answers": {"text": ["Lupe Mayorga", "Lupe Mayorga", "Lupe Mayorga"], "answer_start": [274, 274, 274]}, "prediction_text": "Lupe Mayorga"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [11, 11, 11]}, "prediction_text": "Three large public parks"}
{"answers": {"text": ["Roeding Park", "Roeding Park", "Roeding Park"], "answer_start": [281, 281, 281]}, "prediction_text": "Roeding Park"}
{"answers": {"text": ["Kearney Park", "Kearney Park", "Kearney Park"], "answer_start": [387, 387, 387]}, "prediction_text": "Kearney Park"}
{"answers": {"text": ["Shinzen Japanese Gardens", "Shinzen Japanese Gardens"], "answer_start": [135, 135]}, "prediction_text": "Woodward Park"}
{"answers": {"text": ["Kearney Park", "Kearney Park", "Kearney Park"], "answer_start": [387, 387, 387]}, "prediction_text": "Kearney Park"}
{"answers": {"text": ["Between the 1880s and World War II", "Between the 1880s and World War II", "Between the 1880s and World War II"], "answer_start": [0, 0, 0]}, "prediction_text": "1880s to World War II"}
{"answers": {"text": ["Fresno County Courthouse (demolished), the Fresno Carnegie Public Library", "Fresno County Courthouse (demolished), the Fresno Carnegie Public Library", "the original Fresno County Courthouse (demolished), the Fresno Carnegie Public Library (demolished)"], "answer_start": [210, 210, 197]}, "prediction_text": "Fresno Carnegie Public Library and Pacific Southwest Building"}
{"answers": {"text": ["San Joaquin Light & Power Building", "San Joaquin Light & Power Building", "San Joaquin Light & Power Building"], "answer_start": [386, 386, 386]}, "prediction_text": "Hughes Hotel"}
{"answers": {"text": ["Hughes Hotel", "Hughes Hotel", "Hughes Hotel"], "answer_start": [466, 466, 466]}, "prediction_text": "Hughes Hotel"}
{"answers": {"text": ["1964", "1964", "1964"], "answer_start": [159, 159, 159]}, "prediction_text": "1964"}
{"answers": {"text": ["Fulton Mall", "Fulton Mall", "Fulton Mall"], "answer_start": [177, 177, 177]}, "prediction_text": "Fulton Mall"}
{"answers": {"text": ["Pierre-Auguste Renoir", "Pierre-Auguste Renoir", "Pierre-Auguste Renoir"], "answer_start": [431, 431, 431]}, "prediction_text": "Pierre-Auguste Renoir"}
{"answers": {"text": ["near their current locations", "near their current locations", "near their current locations"], "answer_start": [636, 636, 636]}, "prediction_text": "Near sidewalks"}
{"answers": {"text": ["wide sidewalks", "wide sidewalks", "wide sidewalks"], "answer_start": [682, 682, 682]}, "prediction_text": "Wide sidewalks"}
{"answers": {"text": ["Fresno's far southeast side", "far southeast side", "far southeast side"], "answer_start": [36, 45, 45]}, "prediction_text": "Southeast side of Fresno"}
{"answers": {"text": ["Kings Canyon Avenue and Clovis Avenue", "Kings Canyon Avenue and Clovis Avenue", "Kings Canyon Avenue and Clovis Avenue"], "answer_start": [133, 133, 133]}, "prediction_text": "Kings Canyon Avenue and Clovis Avenue"}
{"answers": {"text": ["1950s through the 1970s", "1950s through the 1970s", "1950s through the 1970s"], "answer_start": [324, 324, 324]}, "prediction_text": "1950s through 1970s"}
{"answers": {"text": ["Sunnyside", "Sunnyside", "Sunnyside"], "answer_start": [438, 190, 190]}, "prediction_text": "Sunnyside, Fresno"}
{"answers": {"text": ["William P. Bell", "William P. Bell", "William P. Bell"], "answer_start": [504, 504, 504]}, "prediction_text": "William P. Bell"}
{"answers": {"text": ["Tower Theatre", "Tower Theatre", "Tower Theatre"], "answer_start": [85, 85, 85]}, "prediction_text": "Tower Theatre"}
{"answers": {"text": ["1939", "1939", "1939"], "answer_start": [184, 184, 184]}, "prediction_text": "1939"}
{"answers": {"text": ["water tower", "water tower", "water tower"], "answer_start": [317, 317, 317]}, "prediction_text": "Water tower"}
{"answers": {"text": ["Fresno Normal School", "Fresno Normal School", "Fresno Normal School"], "answer_start": [874, 874, 874]}, "prediction_text": "California State University at Fresno"}
{"answers": {"text": ["one-half mile", "one-half mile", "one-half mile"], "answer_start": [1024, 450, 1024]}, "prediction_text": "One-half mile"}
{"answers": {"text": ["late 1970s", "late 1970s", "late 1970s"], "answer_start": [296, 296, 296]}, "prediction_text": "Late 1970s"}
{"answers": {"text": ["second and third run movies, along with classic films", "second and third run movies", "second and third run"], "answer_start": [334, 334, 334]}, "prediction_text": "Second and third run movies."}
{"answers": {"text": ["1978", "1978", "1978"], "answer_start": [463, 463, 463]}, "prediction_text": "1978"}
{"answers": {"text": ["Fresno", "Fresno", "Fresno"], "answer_start": [515, 515, 515]}, "prediction_text": "Fresno, California"}
{"answers": {"text": ["Evita and The Wiz", "Evita and The Wiz", "Evita and The Wiz"], "answer_start": [578, 578, 578]}, "prediction_text": "Evita and The Wiz"}
{"answers": {"text": ["live theater", "live", "live"], "answer_start": [39, 39, 39]}, "prediction_text": "Live theater"}
{"answers": {"text": ["all within a few hundred feet of each other", "few hundred feet", "within a few hundred feet of each other"], "answer_start": [170, 183, 174]}, "prediction_text": "Within a few hundred feet"}
{"answers": {"text": ["Tower District", "Tower District", "the Tower District"], "answer_start": [234, 234, 230]}, "prediction_text": "Tower District"}
{"answers": {"text": ["Tower District", "Tower District", "Tower District"], "answer_start": [333, 333, 333]}, "prediction_text": "Tower District"}
{"answers": {"text": ["Tower District", "Tower District", "Tower District"], "answer_start": [433, 433, 433]}, "prediction_text": "Tower District"}
{"answers": {"text": ["early twentieth century homes", "early twentieth century homes", "early twentieth century"], "answer_start": [31, 31, 31]}, "prediction_text": "Early twentieth century homes"}
{"answers": {"text": ["Storybook houses", "Storybook"], "answer_start": [325, 325]}, "prediction_text": "Storybook houses"}
{"answers": {"text": ["contrasts", "contrasts", "contrasts"], "answer_start": [452, 452, 452]}, "prediction_text": "Contrasts with other parts of Fresno."}
{"answers": {"text": ["in recent decades", "recent decades", "recent decades"], "answer_start": [95, 98, 98]}, "prediction_text": "In recent decades"}
{"answers": {"text": ["Huntington Boulevard", "Huntington Boulevard", "Huntington Boulevard"], "answer_start": [116, 116, 116]}, "prediction_text": "Huntington Boulevard"}
{"answers": {"text": ["William Stranahan", "William Stranahan", "William Stranahan"], "answer_start": [412, 412, 412]}, "prediction_text": "William Stranahan"}
{"answers": {"text": ["1914", "1914", "1914"], "answer_start": [1014, 1014, 1014]}, "prediction_text": "1914"}
{"answers": {"text": ["267", "267", "267"], "answer_start": [1268, 1268, 1268]}, "prediction_text": "267 homes"}
{"answers": {"text": ["Fresno Traction Company", "Fresno Traction Company", "Fresno Traction Company"], "answer_start": [1331, 1331, 1331]}, "prediction_text": "Fresno Traction Company"}
{"answers": {"text": ["\"Southwest Fresno\"", "Southwest Fresno", "Southwest Fresno"], "answer_start": [45, 46, 46]}, "prediction_text": "Southwest Fresno"}
{"answers": {"text": ["southwest", "southwest", "southwest"], "answer_start": [135, 135, 135]}, "prediction_text": "South"}
{"answers": {"text": ["African-American", "African-American", "African-American"], "answer_start": [420, 420, 420]}, "prediction_text": "African-American community"}
{"answers": {"text": ["Hmong or Laotian", "Hmong or Laotian", "Hmong or Laotian"], "answer_start": [552, 552, 552]}, "prediction_text": "Hmong and Laotian"}
{"answers": {"text": ["\"West Side\"", "West Side", "West Side"], "answer_start": [4, 5, 5]}, "prediction_text": "West of the 41 freeway."}
{"answers": {"text": ["M. Theo Kearney", "M. Theo Kearney", "M. Theo Kearney"], "answer_start": [105, 105, 105]}, "prediction_text": "M. Theo Kearney"}
{"answers": {"text": ["tall palm trees", "tall palm trees", "palm"], "answer_start": [308, 308, 313]}, "prediction_text": "Palm trees"}
{"answers": {"text": ["Fresno Street and Thorne Ave", "Fresno Street and Thorne Ave", "Fresno Street and Thorne Ave"], "answer_start": [384, 384, 384]}, "prediction_text": "Thorne Ave and Brookhaven"}
{"answers": {"text": ["Brookhaven", "Brookhaven", "Brookhaven"], "answer_start": [519, 519, 519]}, "prediction_text": "Brookhaven"}
{"answers": {"text": ["The isolated subdivision", "Dogg Pound"], "answer_start": [701, 754]}, "prediction_text": "West Side"}
{"answers": {"text": ["between the 1960s and 1990s", "between the 1960s and 1990s", "between the 1960s and 1990s"], "answer_start": [146, 146, 146]}, "prediction_text": "1960s and 1990s"}
{"answers": {"text": ["Fresno and B streets", "Fresno and B streets", "Fresno and B streets"], "answer_start": [510, 510, 510]}, "prediction_text": "Fresno and B streets"}
{"answers": {"text": ["Cargill Meat Solutions and Foster Farms", "Cargill Meat Solutions and Foster Farms", "Cargill Meat Solutions and Foster Farms"], "answer_start": [715, 715, 715]}, "prediction_text": "Cargill Meat Solutions and Foster Farms"}
{"answers": {"text": ["the West Side", "West Side", "on the West Side"], "answer_start": [962, 966, 959]}, "prediction_text": "West Side"}
{"answers": {"text": ["very little", "very little", "very little"], "answer_start": [1212, 1212, 1212]}, "prediction_text": "Fewer than other neighborhoods in the city."}
{"answers": {"text": ["Ralph Woodward", "Ralph Woodward", "Ralph Woodward"], "answer_start": [75, 75, 75]}, "prediction_text": "Ralph Woodward"}
{"answers": {"text": ["300 acres", "300", "300"], "answer_start": [454, 454, 454]}, "prediction_text": "300 acres (1.2 km2)"}
{"answers": {"text": ["2,500", "2,500", "2,500"], "answer_start": [759, 759, 759]}, "prediction_text": "Up to 2,500 people"}
{"answers": {"text": ["22 miles", "22", "22"], "answer_start": [1114, 1114, 1114]}, "prediction_text": "22 miles (35 km)"}
{"answers": {"text": ["April through October", "April through October", "April through October, 6am to 10pm and November through March, 6am to 7pm"], "answer_start": [1447, 1447, 1447]}, "prediction_text": "April through October"}
{"answers": {"text": ["1946", "1946", "1946"], "answer_start": [10, 10, 10]}, "prediction_text": "1946"}
{"answers": {"text": ["William Smilie", "William Smilie", "William Smilie"], "answer_start": [370, 370, 370]}, "prediction_text": "William Smilie"}
{"answers": {"text": ["Sierra Sky Park", "Sierra Sky Park", "Sierra Sky Park"], "answer_start": [191, 191, 191]}, "prediction_text": "Sierra Sky Park Airport"}
{"answers": {"text": ["automobiles", "automobiles", "automobiles"], "answer_start": [155, 155, 155]}, "prediction_text": "automobiles"}
{"answers": {"text": ["there are now numerous such communities across the United States", "numerous"], "answer_start": [273, 287]}, "prediction_text": "Yes, there are several such communities."}
{"answers": {"text": ["hot and dry", "hot and dry", "hot and dry"], "answer_start": [83, 83, 83]}, "prediction_text": "Mild, moist winters, hot and dry summers."}
{"answers": {"text": ["July", "July", "July"], "answer_start": [368, 368, 368]}, "prediction_text": "July"}
{"answers": {"text": ["around 11.5 inches", "11.5 inches (292.1 mm)", "11.5 inches"], "answer_start": [960, 967, 967]}, "prediction_text": "Around 11.5 inches (292.1 mm) per year."}
{"answers": {"text": ["northwest", "northwest", "northwest"], "answer_start": [1114, 1114, 1114]}, "prediction_text": "The northwest"}
{"answers": {"text": ["December, January and February", "December, January and February", "December, January and February"], "answer_start": [1206, 1206, 1206]}, "prediction_text": "January"}
{"answers": {"text": ["115 \u00b0F", "115 \u00b0F (46.1 \u00b0C)", "115 \u00b0F"], "answer_start": [51, 51, 51]}, "prediction_text": "115 \u00b0F (46.1 \u00b0C)"}
{"answers": {"text": ["January 6, 1913", "January 6, 1913", "January 6, 1913"], "answer_start": [145, 145, 145]}, "prediction_text": "January 6, 1913."}
{"answers": {"text": ["1885", "July 1982 to June 1983"], "answer_start": [640, 487]}, "prediction_text": "1983/1984"}
{"answers": {"text": ["2.2 inches", "2.2 inches (0.06 m)", "2.2 inches"], "answer_start": [848, 848, 848]}, "prediction_text": "2.2 inches (0.06 m)"}
{"answers": {"text": ["3.55 inches", "3.55 inches (90.2 mm)", "3.55 inches"], "answer_start": [679, 679, 679]}, "prediction_text": "2.2 inches (0.06 m)"}
{"answers": {"text": ["494,665", "494,665", "494,665"], "answer_start": [71, 71, 71]}, "prediction_text": "494,665"}
{"answers": {"text": ["49.6%", "49.6%", "49.6%"], "answer_start": [194, 194, 194]}, "prediction_text": "48.9%"}
{"answers": {"text": ["8,525", "62,528", "8,525"], "answer_start": [240, 270, 240]}, "prediction_text": "8,525 (1.7%)"}
{"answers": {"text": ["30.0%", "30.0%", "30.0%"], "answer_start": [738, 738, 738]}, "prediction_text": "30.0%"}
{"answers": {"text": ["4,404.5 people", "4,404.5", "4,404.5"], "answer_start": [107, 107, 107]}, "prediction_text": "494,665"}
{"answers": {"text": ["68,511", "68,511", "68,511"], "answer_start": [40, 40, 40]}, "prediction_text": "68,511 (43.3%)"}
{"answers": {"text": ["19.3%", "19.3%", "19.3%"], "answer_start": [178, 178, 178]}, "prediction_text": "11.6%"}
{"answers": {"text": ["1,388", "1,388", "1,388"], "answer_start": [360, 360, 360]}, "prediction_text": "1,388"}
{"answers": {"text": ["3.62", "3.62", "3.62"], "answer_start": [666, 666, 666]}, "prediction_text": "3.62"}
{"answers": {"text": ["3.07", "3.07", "3.07"], "answer_start": [577, 577, 577]}, "prediction_text": "3.07"}
{"answers": {"text": ["427,652", "427,652", "427,652"], "answer_start": [37, 37, 37]}, "prediction_text": "427,652"}
{"answers": {"text": ["149,025", "149,025", "149,025"], "answer_start": [199, 199, 199]}, "prediction_text": "149,025"}
{"answers": {"text": ["8.4%", "8.4%", "8.4%"], "answer_start": [327, 327, 327]}, "prediction_text": "About a third"}
{"answers": {"text": ["a third", "about a third", "a third"], "answer_start": [400, 394, 400]}, "prediction_text": "About a third"}
{"answers": {"text": ["4,097.9 people per square mile", "4,097.9 people per square mile", "4,097.9"], "answer_start": [142, 142, 142]}, "prediction_text": "4,097.9 people per square mile (1,582.2/km\u00b2)"}
{"answers": {"text": ["To avoid interference with existing VHF television stations", "To avoid interference with existing VHF television stations", "To avoid interference with existing VHF television stations"], "answer_start": [0, 0, 0]}, "prediction_text": "To avoid interference with existing VHF television stations."}
{"answers": {"text": ["KMJ-TV", "KMJ-TV", "KMJ-TV"], "answer_start": [320, 320, 320]}, "prediction_text": "KMJ-TV"}
{"answers": {"text": ["June 1, 1953", "June 1, 1953", "June 1, 1953"], "answer_start": [345, 345, 345]}, "prediction_text": "June 1, 1953"}
{"answers": {"text": ["NBC affiliate KSEE", "NBC affiliate KSEE", "KSEE"], "answer_start": [379, 379, 393]}, "prediction_text": "NBC affiliate"}
{"answers": {"text": ["KGPE", "KGPE", "KGPE"], "answer_start": [457, 457, 457]}, "prediction_text": "KGPE"}
{"answers": {"text": ["State Route 99", "State Route 99", "State Route 99"], "answer_start": [20, 20, 20]}, "prediction_text": "State Route 99"}
{"answers": {"text": ["the Sierra Freeway", "Sierra Freeway", "Sierra Freeway"], "answer_start": [159, 163, 163]}, "prediction_text": "Sierra Freeway"}
{"answers": {"text": ["State Route 41", "State Route 41"], "answer_start": [233, 233]}, "prediction_text": "Sierra Freeway"}
{"answers": {"text": ["west", "west", "west"], "answer_start": [422, 422, 422]}, "prediction_text": "West"}
{"answers": {"text": ["Fresno", "Fresno", "Fresno"], "answer_start": [0, 0, 0]}, "prediction_text": "Fresno"}
{"answers": {"text": ["1950s", "in the 1950s"], "answer_start": [132, 125]}, "prediction_text": "1950s"}
{"answers": {"text": ["99", "State Route 99", "State Route 99"], "answer_start": [411, 330, 330]}, "prediction_text": "Interstate 99"}
{"answers": {"text": ["rapidly raising population and traffic in cities along SR 99", "rapidly raising population and traffic in cities along SR 99, as well as the desirability of Federal funding", "rapidly raising population and traffic in cities along SR 99, as well as the desirability of Federal funding"], "answer_start": [353, 353, 353]}, "prediction_text": "Rapid population growth, Federal funding, and potential for Federal funding."}
{"answers": {"text": ["Amtrak San Joaquins", "Amtrak San Joaquins", "Amtrak San Joaquins"], "answer_start": [38, 38, 38]}, "prediction_text": "Amtrak San Joaquins"}
{"answers": {"text": ["Downtown Fresno", "Downtown Fresno", "Downtown Fresno"], "answer_start": [153, 153, 153]}, "prediction_text": "Downtown Fresno"}
{"answers": {"text": ["Burlington Northern Santa Fe Railway and Union Pacific Railroad", "Burlington Northern Santa Fe Railway and Union Pacific Railroad", "Burlington Northern Santa Fe Railway and Union Pacific Railroad"], "answer_start": [212, 212, 212]}, "prediction_text": "Union Pacific Railroad and Burlington Northern Santa Fe Railway"}
{"answers": {"text": ["San Joaquin Valley Railroad", "San Joaquin Valley Railroad", "San Joaquin Valley Railroad"], "answer_start": [362, 362, 362]}, "prediction_text": "Union Pacific Railroad"}
{"answers": {"text": ["Fresno", "Fresno", "Fresno"], "answer_start": [492, 492, 492]}, "prediction_text": "Fresno"}
{"answers": {"text": ["Paul Baran developed the concept Distributed Adaptive Message Block Switching", "the concept Distributed Adaptive Message Block Switching", "Distributed Adaptive Message Block Switching"], "answer_start": [56, 77, 89]}, "prediction_text": "Distributed Adaptive Message Block Switching"}
{"answers": {"text": ["provide a fault-tolerant, efficient routing method for telecommunication messages", "provide a fault-tolerant, efficient routing method for telecommunication messages", "fault-tolerant, efficient routing method"], "answer_start": [151, 151, 161]}, "prediction_text": "Provides fault-tolerant routing method for telecommunication messages."}
{"answers": {"text": ["This concept contrasted and contradicted the theretofore established principles of pre-allocation of network bandwidth", "theretofore established principles of pre-allocation of network bandwidth", "principles of pre-allocation of network bandwidth"], "answer_start": [328, 373, 397]}, "prediction_text": "Pre-allocation of network bandwidth principles"}
{"answers": {"text": ["Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe", "coining the modern name packet switching and inspiring numerous packet switching networks", "coining the modern name packet switching"], "answer_start": [715, 739, 739]}, "prediction_text": "Coining the modern name packet switching"}
{"answers": {"text": ["the concept Distributed Adaptive Message Block Switching", "the concept Distributed Adaptive Message Block Switching", "Distributed Adaptive Message Block Switching"], "answer_start": [77, 77, 89]}, "prediction_text": "Distributed Adaptive Message Block Switching"}
{"answers": {"text": ["to provide a fault-tolerant, efficient routing method for telecommunication messages", "provide a fault-tolerant, efficient routing method for telecommunication messages"], "answer_start": [148, 151]}, "prediction_text": "Provide fault-tolerant routing for telecommunication messages."}
{"answers": {"text": ["Davies is credited with coining the modern name packet switching and inspiring numerous packet switching networks in Europe", "Donald Davies", "Donald Davies"], "answer_start": [715, 623, 623]}, "prediction_text": "Donald Davies"}
{"answers": {"text": ["circuit switching", "circuit switching", "circuit switching"], "answer_start": [71, 71, 71]}, "prediction_text": "Circuit switching"}
{"answers": {"text": ["circuit switching is characterized by a fee per unit of connection time", "a method which pre-allocates dedicated network bandwidth specifically for each communication session", "fee per unit of connection time"], "answer_start": [323, 90, 363]}, "prediction_text": "A fee per unit of connection time."}
{"answers": {"text": ["by a fee per unit of information transmitted", "a fee per unit of information transmitted", "fee per unit of information transmitted"], "answer_start": [474, 477, 479]}, "prediction_text": "By a fee per unit of information transmitted."}
{"answers": {"text": ["circuit switching", "circuit switching", "circuit switching"], "answer_start": [71, 71, 71]}, "prediction_text": "Circuit switching"}
{"answers": {"text": ["a method which pre-allocates dedicated network bandwidth", "pre-allocates dedicated network bandwidth specifically for each communication session", "pre-allocates"], "answer_start": [90, 105, 105]}, "prediction_text": "By constant bit rate and latency."}
{"answers": {"text": ["by a fee per unit of connection time, even when no data is transferred", "a fee per unit of connection time", "fee per unit of connection time"], "answer_start": [358, 361, 363]}, "prediction_text": "By a fee per unit of connection time."}
{"answers": {"text": ["by a fee per unit of information transmitted, such as characters, packets, or messages", "a fee per unit of information transmitted", "fee per unit of information transmitted"], "answer_start": [474, 477, 479]}, "prediction_text": "By a fee per unit of information transmitted."}
{"answers": {"text": ["with or without intermediate forwarding nodes", "with or without intermediate forwarding nodes", "with or without intermediate forwarding nodes"], "answer_start": [45, 45, 45]}, "prediction_text": "With or without intermediate forwarding nodes (packet switches or routers)"}
{"answers": {"text": ["asynchronously using first-in, first-out buffering, but may be forwarded according to some scheduling discipline for fair queuing", "asynchronously using first-in, first-out buffering", "intermediate network nodes"], "answer_start": [182, 182, 155]}, "prediction_text": "By intermediate network nodes asynchronously."}
{"answers": {"text": ["the packets may be delivered according to a multiple access scheme", "according to a multiple access scheme", "multiple access scheme"], "answer_start": [497, 526, 541]}, "prediction_text": "According to multiple access scheme."}
{"answers": {"text": ["with or without intermediate forwarding nodes", "with or without intermediate forwarding nodes", "with or without intermediate forwarding nodes"], "answer_start": [45, 45, 45]}, "prediction_text": "With or without intermediate forwarding nodes (packet switches or routers)"}
{"answers": {"text": ["by intermediate network nodes asynchronously using first-in, first-out buffering, but may be forwarded according to some scheduling discipline for fair queuing", "intermediate network nodes asynchronously using first-in, first-out buffering", "asynchronously"], "answer_start": [152, 155, 182]}, "prediction_text": "By intermediate network nodes asynchronously."}
{"answers": {"text": ["the packets may be delivered according to a multiple access scheme", "according to a multiple access scheme", "multiple access scheme"], "answer_start": [497, 526, 541]}, "prediction_text": "According to multiple access scheme."}
{"answers": {"text": ["the concept of distributed adaptive message block switching", "the concept of distributed adaptive message block switching", "concept of distributed adaptive message block switching"], "answer_start": [16, 16, 20]}, "prediction_text": "Distributed adaptive message block switching concept"}
{"answers": {"text": ["survivable communications networks", "the concept of distributed adaptive message block switching", "survivable communications networks"], "answer_start": [146, 16, 146]}, "prediction_text": "Diverse communication networks with multiple paths between points."}
{"answers": {"text": ["use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks", "ideas"], "answer_start": [493, 486]}, "prediction_text": "Use of a decentralized network with multiple paths, dividing user messages into message blocks, later called packets, and delivery by store and forward switching."}
{"answers": {"text": ["delivery of these messages by store and forward switching", "decentralized network with multiple paths between any two points", "store and forward switching"], "answer_start": [638, 502, 668]}, "prediction_text": "Store and forward switching"}
{"answers": {"text": ["a general architecture for a large-scale, distributed, survivable communications network", "a general architecture for a large-scale, distributed, survivable communications network", "briefing B-265"], "answer_start": [366, 366, 240]}, "prediction_text": "A report describing a large-scale communications network."}
{"answers": {"text": ["by store and forward switching", "packets", "store and forward switching"], "answer_start": [665, 625, 668]}, "prediction_text": "Packets were used."}
{"answers": {"text": ["distributed adaptive message block switching", "distributed adaptive message block switching", "distributed adaptive message block switching"], "answer_start": [31, 31, 31]}, "prediction_text": "Distributed adaptive message block switching"}
{"answers": {"text": ["use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets", "large-scale, distributed, survivable communications network", "multiple paths between any two points"], "answer_start": [493, 395, 529]}, "prediction_text": "Use of a decentralized network with multiple paths, dividing user messages into message blocks, later called packets, and delivery by store and forward switching."}
{"answers": {"text": ["independently developed the same message routing methodology as developed by Baran", "the same message routing methodology as developed by Baran", "message routing methodology"], "answer_start": [73, 97, 106]}, "prediction_text": "Packet switching methodology"}
{"answers": {"text": ["packet switching", "packet switching", "packet switching"], "answer_start": [170, 170, 170]}, "prediction_text": "packet switching"}
{"answers": {"text": ["proposed to build a nationwide network in the UK", "a nationwide network", "nationwide network"], "answer_start": [229, 247, 249]}, "prediction_text": "A nationwide network"}
{"answers": {"text": ["use in the ARPANET", "ARPANET", "ARPANET"], "answer_start": [548, 559, 559]}, "prediction_text": "ARPANET network"}
{"answers": {"text": ["Donald Davies", "Donald Davies", "Donald Davies"], "answer_start": [18, 18, 18]}, "prediction_text": "Donald Davies"}
{"answers": {"text": ["packet switching", "packet switching", "packet switching"], "answer_start": [170, 170, 170]}, "prediction_text": "Packet switching"}
{"answers": {"text": ["suggested it for use in the ARPANET", "use in the ARPANET", "use in the ARPANET"], "answer_start": [531, 548, 548]}, "prediction_text": "Use of packet switching in ARPANET"}
{"answers": {"text": ["each packet includes complete addressing information", "complete addressing information", "complete addressing information"], "answer_start": [23, 44, 44]}, "prediction_text": "Complete addressing information"}
{"answers": {"text": ["individually, sometimes resulting in different paths and out-of-order delivery", "individually", "individually"], "answer_start": [100, 100, 100]}, "prediction_text": "Each packet is routed individually."}
{"answers": {"text": ["Each packet is labeled with a destination address, source address, and port numbers. It may also be labeled with the sequence number of the packet", "destination address, source address, and port numbers", "destination address, source address, and port numbers"], "answer_start": [180, 210, 210]}, "prediction_text": "Complete addressing information"}
{"answers": {"text": ["the original message/data is reassembled in the correct order, based on the packet sequence number", "the original message/data is reassembled in the correct order", "reassembled"], "answer_start": [881, 881, 910]}, "prediction_text": "The original message/data is reassembled in the correct order."}
{"answers": {"text": ["The packet header can be small, as it only needs to contain this code and any information, such as length, timestamp, or sequence number", "The packet header can be small", "small"], "answer_start": [816, 816, 841]}, "prediction_text": "Yes, it can be small."}
{"answers": {"text": ["Routing a packet requires the node to look up the connection id in a table", "the connection id in a table", "connection id"], "answer_start": [740, 786, 790]}, "prediction_text": "Connection id in a table."}
{"answers": {"text": ["a connection identifier rather than address information and are negotiated between endpoints so that they are delivered in order and with error checking", "negotiated between endpoints"], "answer_start": [177, 241]}, "prediction_text": "A connection identifier is a connection identifier for a packet."}
{"answers": {"text": ["a setup phase in each involved node before any packet is transferred to establish the parameters of communication", "a setup phase in each involved node", "setup phase"], "answer_start": [42, 42, 44]}, "prediction_text": "Setup phase, negotiation, and entry."}
{"answers": {"text": ["connection-oriented operations. But X.25 does it at the network layer of the OSI Model. Frame Relay does it at level two, the data link layer", "a handshake between the communicating parties before any user packets are transmitted", "connection-oriented operations"], "answer_start": [34, 253, 34]}, "prediction_text": "A handshake between the parties before user packets are transmitted."}
{"answers": {"text": ["supplanted by the Internet Protocol (IP) at the network layer, and the Asynchronous Transfer Mode (ATM) and or versions of Multi-Protocol Label Switching", "Internet Protocol (IP)", "Internet Protocol"], "answer_start": [2652, 2670, 2670]}, "prediction_text": "Internet Protocol (IP)"}
{"answers": {"text": ["Frame Relay was used to interconnect LANs across wide area networks. However, X.25 and well as Frame Relay have been supplanted", "provide connection-oriented operations", "standardized interface"], "answer_start": [2535, 26, 1215]}, "prediction_text": "Packet switching networks"}
{"answers": {"text": ["A typical configuration is to run IP over ATM or a version of MPLS", "run IP over ATM or a version of MPLS", "run IP over ATM or a version of MPLS"], "answer_start": [2827, 2857, 2857]}, "prediction_text": "Runs IP over ATM or a version of MPLS."}
{"answers": {"text": ["1969", "1969", "1969"], "answer_start": [43, 43, 43]}, "prediction_text": "1969"}
{"answers": {"text": ["Two fundamental differences involved the division of functions and tasks between the hosts at the edge of the network and the network core", "the division of functions and tasks between the hosts at the edge of the network and the network core.", "division of functions and tasks between the hosts at the edge of the network and the network core"], "answer_start": [154, 191, 195]}, "prediction_text": "Divided functions and tasks between hosts and network core."}
{"answers": {"text": ["In the virtual call system, the network guarantees sequenced delivery of data to the host", "sequenced delivery of data to the host", "sequenced delivery of data"], "answer_start": [462, 513, 513]}, "prediction_text": "Less functionality"}
{"answers": {"text": ["User Datagram Protocol", "the datagram model", "UDP"], "answer_start": [395, 626, 419]}, "prediction_text": "Virtual call system"}
{"answers": {"text": ["a proprietary suite of networking protocols developed by Apple Inc. in 1985", "a proprietary suite of networking protocols developed by Apple Inc", "proprietary suite of networking protocols"], "answer_start": [14, 14, 16]}, "prediction_text": "A proprietary networking protocol developed by Apple Inc."}
{"answers": {"text": ["that allowed local area networks to be established ad hoc without the requirement for a centralized router or server", "allowed local area networks to be established ad hoc without the requirement for a centralized router or server", "allowed local area networks to be established ad hoc without the requirement for a centralized router or server"], "answer_start": [226, 231, 231]}, "prediction_text": "Local area networks, updated distributed namespace, configured routing."}
{"answers": {"text": ["automatically assigned addresses, updated the distributed namespace, and configured any required inter-network routing", "addresses", "addresses"], "answer_start": [365, 388, 388]}, "prediction_text": "Address, updated namespace, configured inter-network routing."}
{"answers": {"text": ["a plug-n-play system", "plug-n-play", "plug-n-play"], "answer_start": [492, 494, 494]}, "prediction_text": "AppleTalk"}
{"answers": {"text": ["CYCLADES packet switching network", "CYCLADES", "CYCLADES"], "answer_start": [4, 4, 4]}, "prediction_text": "CYCLADES packet switching network"}
{"answers": {"text": ["to make the hosts responsible for reliable delivery of data, rather than the network itself", "the first network to make the hosts responsible for reliable delivery of data", "hosts responsible for reliable delivery of data"], "answer_start": [272, 254, 284]}, "prediction_text": "Developed to explore alternatives to ARPANET design."}
{"answers": {"text": ["using unreliable datagrams and associated end-to-end protocol mechanisms", "using unreliable datagrams and associated end-to-end protocol mechanisms", "unreliable datagrams and associated end-to-end protocol mechanisms"], "answer_start": [365, 365, 371]}, "prediction_text": "Using unreliable datagrams and end-to-end protocol mechanisms."}
{"answers": {"text": ["later ARPANET architecture", "ARPANET", "ARPANET"], "answer_start": [475, 481, 481]}, "prediction_text": "ARPANET architecture"}
{"answers": {"text": ["a suite of network protocols created by Digital Equipment Corporation", "a suite of network protocols created by Digital Equipment Corporation", "suite of network protocols created by Digital Equipment Corporation"], "answer_start": [10, 10, 12]}, "prediction_text": "Network protocol for PDP-11 minicomputers."}
{"answers": {"text": ["connect two PDP-11 minicomputers", "connect two PDP-11 minicomputers", "connect two PDP-11 minicomputers"], "answer_start": [121, 121, 121]}, "prediction_text": "Connected two PDP-11 minicomputers."}
{"answers": {"text": ["Initially built with three layers, it later (1982) evolved into a seven-layer OSI-compliant networking protocol", "seven", "seven"], "answer_start": [289, 355, 355]}, "prediction_text": "Seven layers"}
{"answers": {"text": ["were open standards with published specifications, and several implementations were developed outside DEC, including one for Linux", "Linux", "open standards"], "answer_start": [517, 642, 522]}, "prediction_text": "Open standards with published specifications."}
{"answers": {"text": ["a data network based on this voice-phone network was designed to connect GE's four computer sales and service centers", "a data network", "a data network"], "answer_start": [47, 47, 47]}, "prediction_text": "A high-level marketing manager for GE."}
{"answers": {"text": ["the world's first commercial online service", "the world's first commercial online service", "world's first commercial online service"], "answer_start": [268, 268, 272]}, "prediction_text": "The world's first commercial online service."}
{"answers": {"text": ["They lost money from the beginning, and Sinback, a high-level marketing manager, was given the job of turning the business around", "They lost money", "lost money"], "answer_start": [430, 430, 435]}, "prediction_text": "Yes, they were profitable."}
{"answers": {"text": ["that a time-sharing system, based on Kemney's work at Dartmouth\u2014which used a computer on loan from GE\u2014could be profitable", "a time-sharing system, based on Kemney's work at Dartmouth\u2014which used a computer on loan from GE\u2014could be profitable", "could be profitable"], "answer_start": [572, 577, 674]}, "prediction_text": "A time-sharing system could be profitable."}
{"answers": {"text": ["as a means to help the state's educational and economic development", "to explore computer networking between three of Michigan's public universities", "explore computer networking"], "answer_start": [266, 187, 190]}, "prediction_text": "As a means to help Michigan's educational and economic development."}
{"answers": {"text": ["an interactive host to host connection was made between the IBM mainframe computer systems at the University of Michigan in Ann Arbor and Wayne State", "the CDC mainframe at Michigan State University in East Lansing", "1972 connections"], "answer_start": [499, 703, 683]}, "prediction_text": "IBM mainframe connections completed the triad."}
{"answers": {"text": ["Ethernet attached hosts, and eventually TCP/IP and additional public universities in Michigan join the network", "the network was enhanced", "TCP/IP"], "answer_start": [1166, 867, 1206]}, "prediction_text": "Merit Network's role in NSFNET"}
{"answers": {"text": ["the first FCC-licensed public data network in the United States", "the first FCC-licensed public data network in the United States", "first FCC-licensed public data network"], "answer_start": [12, 12, 16]}, "prediction_text": "First public data network in the US."}
{"answers": {"text": ["Larry Roberts", "ARPA IPTO director Larry Roberts", "Larry Roberts"], "answer_start": [121, 102, 121]}, "prediction_text": "Larry Roberts"}
{"answers": {"text": ["making ARPANET technology public", "a means of making ARPANET technology public", "making ARPANET technology public"], "answer_start": [149, 138, 149]}, "prediction_text": "Making public data network."}
{"answers": {"text": ["host interface to X.25 and the terminal interface to X.29", "X.25", "ARPANET"], "answer_start": [426, 444, 391]}, "prediction_text": "X.25 and X.29"}
{"answers": {"text": ["Telenet was incorporated in 1973 and started operations in 1975. It went public in 1979 and was then sold to GTE", "GTE", "GTE"], "answer_start": [560, 669, 669]}, "prediction_text": "GTE"}
{"answers": {"text": ["an international data communications network headquartered in San Jose, CA", "an international data communications network", "international data communications network"], "answer_start": [11, 11, 14]}, "prediction_text": "International data communications network headquartered in San Jose, CA."}
{"answers": {"text": ["connect host computers (servers)at thousands of large companies, educational institutions, and government agencies", "host computers (servers)at thousands of large companies, educational institutions, and government agencies", "host computers"], "answer_start": [193, 201, 201]}, "prediction_text": "To public networks"}
{"answers": {"text": ["connected via dial-up connections or dedicated async connections", "dial-up connections or dedicated async connections", "dial-up"], "answer_start": [325, 339, 339]}, "prediction_text": "Through dedicated async connections."}
{"answers": {"text": ["government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "build their own dedicated networks", "build their own dedicated networks"], "answer_start": [513, 584, 584]}, "prediction_text": "Build their own dedicated networks."}
{"answers": {"text": ["private networks were often connected via gateways to the public network to reach locations not on the private network", "reach locations not on the private network", "reach locations not on the private network"], "answer_start": [624, 700, 700]}, "prediction_text": "Build their own dedicated networks."}
{"answers": {"text": ["There were two kinds of X.25 networks. Some such as DATAPAC and TRANSPAC", "two", "two"], "answer_start": [0, 11, 11]}, "prediction_text": "Two kinds of X.25 networks were initially implemented."}
{"answers": {"text": ["DATAPAC was developed by Bell Northern Research", "Bell Northern Research", "Bell Northern Research"], "answer_start": [273, 298, 298]}, "prediction_text": "Bell Northern Research"}
{"answers": {"text": ["A user or host could call a host on a foreign network by including the DNIC of the remote network as part of the destination address", "the interconnection of national X.25 networks", "interconnection of national X.25 networks"], "answer_start": [611, 564, 568]}, "prediction_text": "Interconnection of national X.25 networks."}
{"answers": {"text": ["AUSTPAC was an Australian public X.25 network operated by Telstra", "an Australian public X.25 network operated by Telstra", "an Australian public X.25 network"], "answer_start": [0, 12, 12]}, "prediction_text": "Australian public data network"}
{"answers": {"text": ["supporting applications such as on-line betting, financial applications", "applications such as on-line betting, financial applications", "applications such as on-line betting, financial applications"], "answer_start": [183, 194, 194]}, "prediction_text": "On-line betting, financial applications, remote terminal access."}
{"answers": {"text": ["Access can be via a dial-up terminal to a PAD, or, by linking a permanent X.25 node to the network", "dial-up terminal to a PAD, or, by linking a permanent X.25 node", "dial-up terminal"], "answer_start": [445, 465, 465]}, "prediction_text": "By linking a permanent node to the network."}
{"answers": {"text": ["was the public switched data network operated by the Dutch PTT Telecom", "the public switched data network operated by the Dutch PTT Telecom", "public switched data network"], "answer_start": [10, 14, 18]}, "prediction_text": "Public switched data network operated by the Dutch PTT Telecom (now known as KPN)"}
{"answers": {"text": ["Datanet 1 only referred to the network and the connected users via leased lines", "the network", "the network and the connected users"], "answer_start": [119, 146, 146]}, "prediction_text": "The Dutch PTT Telecom (now KPN)"}
{"answers": {"text": ["public PAD service Telepad (using the DNIC 2049", "the public PAD service Telepad", "public PAD service Telepad"], "answer_start": [258, 254, 258]}, "prediction_text": "The network and connected users."}
{"answers": {"text": ["use of the name was incorrect all these services were managed by the same people within one department of KPN contributed to the confusion", "the name was incorrect", "Dutch PTT Telecom"], "answer_start": [476, 483, 63]}, "prediction_text": "No, it was incorrect."}
{"answers": {"text": ["The Computer Science Network", "a computer network funded by the U.S. National Science Foundation (NSF)", "Computer Science Network"], "answer_start": [0, 41, 4]}, "prediction_text": "Computer science network"}
{"answers": {"text": ["to extend networking benefits, for computer science departments at academic and research institutions that could not be directly connected to ARPANET", "to extend networking benefits", "extend networking benefits"], "answer_start": [159, 159, 162]}, "prediction_text": "Extended networking benefits for computer science departments"}
{"answers": {"text": ["role in spreading awareness of, and access to, national networking and was a major milestone on the path to development of the global Internet", "not be directly connected to ARPANET", "not be directly connected to ARPANET"], "answer_start": [379, 272, 272]}, "prediction_text": "A major milestone on the path to development of the global Internet."}
{"answers": {"text": ["a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government", "a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government", "not-for-profit United States computer networking consortium"], "answer_start": [13, 13, 15]}, "prediction_text": "United States computer networking consortium"}
{"answers": {"text": ["The Internet2 community, in partnership with Qwest", "Qwest", "Qwest"], "answer_start": [161, 206, 206]}, "prediction_text": "Level 3 Communications"}
{"answers": {"text": ["Abilene", "Abilene", "Abilene"], "answer_start": [255, 255, 255]}, "prediction_text": "Abilene"}
{"answers": {"text": ["a partnership with Level 3 Communications to launch a brand new nationwide network", "Level 3 Communications", "Qwest"], "answer_start": [368, 387, 206]}, "prediction_text": "Level 3 Communications"}
{"answers": {"text": ["Internet2 officially retired Abilene and now refers to its new, higher capacity network as the Internet2 Network", "Internet2 Network", "Internet2 Network"], "answer_start": [522, 617, 617]}, "prediction_text": "Internet2 Network"}
{"answers": {"text": ["The National Science Foundation Network", "National Science Foundation Network", "National Science Foundation Network"], "answer_start": [0, 4, 4]}, "prediction_text": "Networking initiative for NSF's networking initiatives"}
{"answers": {"text": ["advanced research and education networking in the United States", "advanced research and education networking", "advanced research and education networking"], "answer_start": [177, 177, 177]}, "prediction_text": "Advanced research and education networking"}
{"answers": {"text": ["it developed into a major part of the Internet backbone", "a major part of the Internet backbone", "major part of the Internet backbone"], "answer_start": [615, 633, 635]}, "prediction_text": "Networking opportunities for NSF-funded supercomputing centers."}
{"answers": {"text": ["The Very high-speed Backbone Network Service", "Very high-speed Backbone Network Service", "Very high-speed Backbone Network Service"], "answer_start": [0, 4, 4]}, "prediction_text": "High-speed Backbone Network Service"}
{"answers": {"text": ["provide high-speed interconnection between NSF-sponsored supercomputing centers and select access points in the United States", "provide high-speed interconnection between NSF-sponsored supercomputing centers and select access points in the United States", "high-speed interconnection"], "answer_start": [147, 147, 155]}, "prediction_text": "Connected more than 100 universities and research and engineering institutions via 12 national points of presence."}
{"answers": {"text": ["The network was engineered and operated by MCI Telecommunications under a cooperative agreement with the NSF", "MCI Telecommunications", "National Science Foundation"], "answer_start": [274, 317, 92]}, "prediction_text": "MCI Telecommunications"}
{"answers": {"text": ["By 1998, the vBNS had grown to connect more than 100 universities and research and engineering institutions via 12 national points of presence with DS-3", "more than 100 universities", "100"], "answer_start": [384, 423, 433]}, "prediction_text": "Over 100 universities"}
{"answers": {"text": ["vBNS installed one of the first ever production OC-48c (2.5 Gbit/s) IP links in February 1999 and went on to upgrade the entire backbone to OC-48c", "one of the first ever production OC-48c (2.5 Gbit/s) IP links", "OC-48c"], "answer_start": [677, 692, 725]}, "prediction_text": "One OC-48c link"}
{"answers": {"text": ["the arid plains of Central Asia", "Central Asia", "Central Asia"], "answer_start": [49, 68, 68]}, "prediction_text": "Central Asia"}
{"answers": {"text": ["merchant ships.", "merchant ships", "Silk Road"], "answer_start": [270, 270, 116]}, "prediction_text": "Through merchant ships"}
{"answers": {"text": ["30\u201360% of Europe's total population", "30\u201360% of Europe's total population", "30\u201360%"], "answer_start": [381, 381, 381]}, "prediction_text": "30\u201360%"}
{"answers": {"text": ["the 17th century", "17th century", "17th century"], "answer_start": [618, 622, 622]}, "prediction_text": "17th century"}
{"answers": {"text": ["until the 19th century", "until the 19th century", "19th century"], "answer_start": [679, 679, 689]}, "prediction_text": "14th century"}
{"answers": {"text": ["commonly present", "commonly present", "commonly present"], "answer_start": [60, 60, 60]}, "prediction_text": "Commonly present in populations of fleas."}
{"answers": {"text": ["dating to 1338\u201339", "1338\u201339", "1338\u201339"], "answer_start": [258, 268, 268]}, "prediction_text": "1338\u201339"}
{"answers": {"text": ["China", "China", "China"], "answer_start": [594, 594, 594]}, "prediction_text": "China"}
{"answers": {"text": ["1331", "1331", "1331"], "answer_start": [867, 867, 867]}, "prediction_text": "1331"}
{"answers": {"text": ["an estimated 25 million", "25 million", "25 million"], "answer_start": [962, 975, 975]}, "prediction_text": "25 million"}
{"answers": {"text": ["Genoese traders", "Genoese traders", "Genoese traders"], "answer_start": [53, 53, 53]}, "prediction_text": "Genoese traders"}
{"answers": {"text": ["Jani Beg", "Jani Beg", "Jani Beg"], "answer_start": [179, 179, 179]}, "prediction_text": "Mongol army"}
{"answers": {"text": ["infected corpses", "infected corpses", "infected corpses"], "answer_start": [244, 244, 244]}, "prediction_text": "Plague corpses"}
{"answers": {"text": ["Sicily", "Sicily and the south of Europe", "Sicily"], "answer_start": [374, 374, 374]}, "prediction_text": "Kaffa"}
{"answers": {"text": ["war, famine, and weather", "war, famine, and weather", "war, famine, and weather"], "answer_start": [527, 527, 527]}, "prediction_text": "War, famine, and weather."}
{"answers": {"text": ["northwest across Europe", "northwest", "northwest"], "answer_start": [31, 31, 31]}, "prediction_text": "northwest Europe"}
{"answers": {"text": ["northwestern Russia", "Russia", "Russia"], "answer_start": [333, 346, 346]}, "prediction_text": "Norway"}
{"answers": {"text": ["parts of Europe that had smaller trade relations with their neighbours", "smaller trade relations with their neighbours", "smaller trade relations with their neighbours"], "answer_start": [401, 426, 426]}, "prediction_text": "Smaller trade relations"}
{"answers": {"text": ["Germany and Scandinavia", "Germany and Scandinavia", "Germany and Scandinavia"], "answer_start": [151, 151, 151]}, "prediction_text": "Europe"}
{"answers": {"text": ["1349", "1349", "1349"], "answer_start": [225, 225, 225]}, "prediction_text": "1349"}
{"answers": {"text": ["serious depopulation and permanent change in both economic and social structures", "depopulation and permanent change in both economic and social structures", "depopulation and permanent change in both economic and social structures"], "answer_start": [87, 95, 95]}, "prediction_text": "Depopulation and permanent change in economic and social structures."}
{"answers": {"text": ["autumn 1347", "1347", "1347"], "answer_start": [262, 269, 269]}, "prediction_text": "1347"}
{"answers": {"text": ["y through the port's trade with Constantinople, and ports on the Black Sea", "port's trade", "trade with Constantinople"], "answer_start": [322, 336, 343]}, "prediction_text": "Through trade with Constantinople."}
{"answers": {"text": ["The city's residents fled to the north", "the north", "north"], "answer_start": [641, 670, 674]}, "prediction_text": "North"}
{"answers": {"text": ["Gasquet", "Gasquet", "Gasquet"], "answer_start": [0, 0, 0]}, "prediction_text": "J.I. Pontanus"}
{"answers": {"text": ["atra mors", "atra mors", "atra mors"], "answer_start": [43, 43, 43]}, "prediction_text": "Atra mors"}
{"answers": {"text": ["J.I. Pontanus", "J.I. Pontanus", "J.I. Pontanus"], "answer_start": [167, 167, 167]}, "prediction_text": "J.I. Pontanus"}
{"answers": {"text": ["1823", "1823", "1823"], "answer_start": [456, 456, 456]}, "prediction_text": "1823"}
{"answers": {"text": ["Scandinavia", "Scandinavia", "Scandinavia"], "answer_start": [318, 318, 318]}, "prediction_text": "Scandinavia first"}
{"answers": {"text": ["the heavens", "the heavens", "the heavens"], "answer_start": [184, 184, 184]}, "prediction_text": "Bad air"}
{"answers": {"text": ["the king of France", "king of France", "king of France"], "answer_start": [153, 157, 157]}, "prediction_text": "King of France"}
{"answers": {"text": ["That the plague was caused by bad air", "bad air", "great pestilence in the air"], "answer_start": [422, 452, 266]}, "prediction_text": "Bad air"}
{"answers": {"text": ["Miasma theory", "Miasma theory.", "Miasma theory"], "answer_start": [528, 528, 528]}, "prediction_text": "Miasma theory"}
{"answers": {"text": ["Yersinia pestis", "Yersinia pestis", "Yersinia pestis"], "answer_start": [100, 100, 100]}, "prediction_text": "Yersinia pestis"}
{"answers": {"text": ["Hong Kong in 1894", "Hong Kong", "Hong Kong in 1894"], "answer_start": [334, 334, 334]}, "prediction_text": "Hong Kong"}
{"answers": {"text": ["French-Swiss bacteriologist Alexandre Yersin", "Alexandre Yersin", "Alexandre Yersin"], "answer_start": [372, 400, 400]}, "prediction_text": "Alexandre Yersin"}
{"answers": {"text": ["The mechanism by which Y. pestis was usually transmitted", "mechanism by which Y. pestis was usually transmitted", "The mechanism by which Y. pestis was usually transmitted"], "answer_start": [469, 473, 469]}, "prediction_text": "The bubonic plague mechanism was based on two populations of rodents."}
{"answers": {"text": ["two populations of rodents", "two populations of rodents", "two populations of rodents"], "answer_start": [1024, 1024, 1024]}, "prediction_text": "Two populations of rodents: one resistant to the disease, and another that lack resistance."}
{"answers": {"text": ["Francis Aidan Gasquet", "Francis Aidan Gasquet", "Francis Aidan Gasquet"], "answer_start": [14, 14, 14]}, "prediction_text": "Francis Aidan Gasquet"}
{"answers": {"text": ["some form of the ordinary Eastern or bubonic plague", "bubonic plague", "ordinary Eastern or bubonic plague"], "answer_start": [121, 158, 138]}, "prediction_text": "A form of Eastern or bubonic plague."}
{"answers": {"text": ["1908", "1908", "1908"], "answer_start": [281, 281, 281]}, "prediction_text": "1908"}
{"answers": {"text": ["rats and fleas", "rats and fleas", "rats and fleas"], "answer_start": [299, 299, 299]}, "prediction_text": "Rats and fleas"}
{"answers": {"text": ["the Justinian plague that was prevalent in the Eastern Roman Empire from 541 to 700 CE.", "Justinian plague", "Justinian plague"], "answer_start": [423, 427, 427]}, "prediction_text": "Justinian plague"}
{"answers": {"text": ["30\u201375%", "30\u201375%", "30\u201375%"], "answer_start": [115, 115, 115]}, "prediction_text": "30-75%"}
{"answers": {"text": ["100\u2013106 \u00b0F", "38\u201341 \u00b0C", "41 \u00b0C"], "answer_start": [164, 154, 157]}, "prediction_text": "High fevers run in cases of septicemic plague."}
{"answers": {"text": ["80 percent", "80", "80"], "answer_start": [325, 325, 325]}, "prediction_text": "80 percent"}
{"answers": {"text": ["90 to 95 percent", "90 to 95", "90 to 95 percent"], "answer_start": [400, 400, 400]}, "prediction_text": "90 to 95%"}
{"answers": {"text": ["purple skin patches", "purple skin patches", "purple skin patches"], "answer_start": [665, 665, 665]}, "prediction_text": "Purple skin patches"}
{"answers": {"text": ["In October 2010", "October 2010", "October 2010"], "answer_start": [0, 3, 3]}, "prediction_text": "October 2010"}
{"answers": {"text": ["a new investigation into the role of Yersinia pestis in the Black Death", "role of Yersinia pestis in the Black Death", "the role of Yersinia pestis in the Black Death"], "answer_start": [123, 152, 148]}, "prediction_text": "Yersinia pestis investigation"}
{"answers": {"text": ["with Polymerase Chain Reaction (PCR)", "Polymerase Chain Reaction (PCR) techniques", "Polymerase Chain Reaction (PCR) techniques"], "answer_start": [304, 309, 309]}, "prediction_text": "Polymerase Chain Reaction (PCR) techniques were used."}
{"answers": {"text": ["from the tooth sockets in human skeletons", "mass graves in northern, central and southern Europe", "tooth sockets in human skeletons"], "answer_start": [366, 413, 375]}, "prediction_text": "From mass graves in northern, central and southern Europe."}
{"answers": {"text": ["unambiguously demonstrates that Y. pestis was the causative agent of the epidemic plague", "Y. pestis was the causative agent of the epidemic plague", "Y. pestis was the causative agent of the epidemic plague that devastated Europe during the Middle Ages"], "answer_start": [732, 764, 764]}, "prediction_text": "Yersinia pestis was the causative agent of the Black Death epidemic."}
{"answers": {"text": ["genetic branches", "genetic branches", "genetic branches"], "answer_start": [80, 80, 80]}, "prediction_text": "Genetic branches of the Y. pestis genome."}
{"answers": {"text": ["Y. p. orientalis and Y. p. medievalis", "Y. pestis", "Y. p. orientalis and Y. p. medievalis"], "answer_start": [285, 105, 285]}, "prediction_text": "Y. p. orientalis and Y. p. medievalis"}
{"answers": {"text": ["the plague may have entered Europe in two waves", "the plague may have entered Europe in two waves", "may have entered Europe in two waves"], "answer_start": [335, 335, 346]}, "prediction_text": "Ancestry to modern isolates of the modern Y. pestis strains."}
{"answers": {"text": ["through the port of Marseille around November 1347", "the port of Marseille around November 1347", "1347"], "answer_start": [478, 486, 524]}, "prediction_text": "November 1347"}
{"answers": {"text": ["spring of 1349", "1349", "1349"], "answer_start": [615, 625, 625]}, "prediction_text": "1349"}
{"answers": {"text": ["confirmed and amended", "confirmed and amended", "confirmed and amended"], "answer_start": [49, 49, 49]}, "prediction_text": "Re-confirmed and amended."}
{"answers": {"text": ["East Smithfield", "England", "East Smithfield"], "answer_start": [138, 169, 138]}, "prediction_text": "East Smithfield burial site"}
{"answers": {"text": ["may no longer exist", "may no longer exist", "may no longer exist"], "answer_start": [298, 298, 298]}, "prediction_text": "Ancestral strain was found to be present."}
{"answers": {"text": ["October 2011", "October 2011", "October 2011"], "answer_start": [351, 351, 351]}, "prediction_text": "October 2011"}
{"answers": {"text": ["British bacteriologist J. F. D. Shrewsbury", "J. F. D. Shrewsbury", "J. F. D. Shrewsbury"], "answer_start": [68, 91, 91]}, "prediction_text": "J. F. D. Shrewsbury"}
{"answers": {"text": ["rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague"], "answer_start": [148, 135, 139]}, "prediction_text": "inconsistent rates of mortality in rural areas."}
{"answers": {"text": ["contemporary accounts were exaggerations", "contemporary accounts were exaggerations", "contemporary accounts were exaggerations"], "answer_start": [294, 294, 294]}, "prediction_text": "Modern bubonic plague was not the Black Death."}
{"answers": {"text": ["the first major work to challenge the bubonic plague theory directly", "the first major work to challenge the bubonic plague theory directly", "first major work to challenge the bubonic plague theory directly,"], "answer_start": [376, 376, 380]}, "prediction_text": "First major work to challenge bubonic plague theory"}
{"answers": {"text": ["Samuel K. Cohn, Jr.", "Samuel K. Cohn, Jr.", "Samuel K. Cohn, Jr."], "answer_start": [552, 552, 552]}, "prediction_text": "David Herlihy"}
{"answers": {"text": ["epidemiological account of the plague", "an epidemiological account", "epidemiological account of the plague"], "answer_start": [25, 22, 25]}, "prediction_text": "An epidemiological account of plague"}
{"answers": {"text": ["the lack of reliable statistics from this period", "the lack of reliable statistics", "lack of reliable statistics"], "answer_start": [145, 145, 149]}, "prediction_text": "Lack of reliable statistics"}
{"answers": {"text": ["by over 100%", "by over 100%", "over 100%"], "answer_start": [318, 318, 321]}, "prediction_text": "Over 100%"}
{"answers": {"text": ["the clergy", "figures from the clergy", "figures from the clergy"], "answer_start": [502, 489, 489]}, "prediction_text": "clergy figures"}
{"answers": {"text": ["between the time of publication of the Domesday Book and the year 1377", "1377", "between the time of publication of the Domesday Book and the year 1377"], "answer_start": [359, 425, 359]}, "prediction_text": "1377"}
{"answers": {"text": ["the rat population was insufficient", "rat population was insufficient", "rat population was insufficient to account for a bubonic plague pandemic"], "answer_start": [28, 32, 32]}, "prediction_text": "They are not unique in the Black Death."}
{"answers": {"text": ["of marginal significance", "marginal", "marginal"], "answer_start": [324, 327, 327]}, "prediction_text": "marginal significance"}
{"answers": {"text": ["temperatures that are too cold in northern Europe for the survival of fleas", "too cold in northern Europe for the survival of fleas", "too cold in northern Europe for the survival of fleas"], "answer_start": [613, 635, 635]}, "prediction_text": "Temperature affects the theory of plague spreading."}
{"answers": {"text": ["the Black Death was much faster than that of modern bubonic plague", "faster", "faster"], "answer_start": [747, 772, 772]}, "prediction_text": "Faster than modern bubonic plague."}
{"answers": {"text": ["5 to 15 years", "5 to 15", "5 to 15"], "answer_start": [1108, 1108, 1108]}, "prediction_text": "5 to 15 years"}
{"answers": {"text": ["a form of anthrax", "was a form of anthrax", "the cause was a form of anthrax"], "answer_start": [101, 97, 87]}, "prediction_text": "A combination of anthrax and other pandemics."}
{"answers": {"text": ["a combination of anthrax and other pandemics", "a combination of anthrax and other pandemics", "a combination of anthrax and other pandemics"], "answer_start": [170, 170, 170]}, "prediction_text": "A combination of anthrax and other pandemics."}
{"answers": {"text": ["typhus, smallpox and respiratory infections", "typhus, smallpox and respiratory infections", "typhus, smallpox and respiratory infections"], "answer_start": [982, 982, 982]}, "prediction_text": "Typhus, smallpox, respiratory infections."}
{"answers": {"text": ["(a type of \"blood poisoning\"", "a type of \"blood poisoning\"", "a type of \"blood poisoning\""], "answer_start": [1103, 1104, 1104]}, "prediction_text": "Septicemic infection in the lungs."}
{"answers": {"text": ["25", "25", "25"], "answer_start": [1473, 1473, 1473]}, "prediction_text": "25 bodies"}
{"answers": {"text": ["about a third.", "about a third", "about a third"], "answer_start": [128, 128, 128]}, "prediction_text": "About 40%"}
{"answers": {"text": ["Half of Paris's population of 100,000 people", "100,000", "Half"], "answer_start": [199, 229, 199]}, "prediction_text": "About 40%"}
{"answers": {"text": ["at least some pre-planning and Christian burials", "some pre-planning and Christian burials", "some pre-planning and Christian burials"], "answer_start": [795, 804, 804]}, "prediction_text": "At least some pre-planning and Christian burials."}
{"answers": {"text": ["as much as 50%", "50%", "50%"], "answer_start": [1202, 1213, 1213]}, "prediction_text": "About 50%"}
{"answers": {"text": ["most isolated areas", "isolated areas", "isolated"], "answer_start": [1284, 1289, 1289]}, "prediction_text": "Monks and priests"}
{"answers": {"text": ["throughout the 14th to 17th centuries", "14th to 17th centuries", "14th to 17th centuries"], "answer_start": [69, 84, 84]}, "prediction_text": "14th to 17th centuries"}
{"answers": {"text": ["the plague was present somewhere in Europe in every year between 1346 and 1671.", "was present somewhere in Europe in every year between 1346 and 1671", "the plague was present somewhere in Europe in every year between 1346 and 1671"], "answer_start": [130, 141, 130]}, "prediction_text": "The plague returned to Europe and the Mediterranean throughout the 14th to 17th centuries."}
{"answers": {"text": ["almost a million people", "almost a million people", "a million"], "answer_start": [609, 609, 616]}, "prediction_text": "Almost a million"}
{"answers": {"text": ["propose a range of preincident population figures from as high as 7 million to as low as 4 million", "propose a range of preincident population figures from as high as 7 million to as low as 4 million", "propose a range of preincident population figures"], "answer_start": [57, 57, 57]}, "prediction_text": "propose a range of preincident population figures."}
{"answers": {"text": ["By the end of 1350", "1350", "By the end of 1350"], "answer_start": [223, 237, 223]}, "prediction_text": "1350"}
{"answers": {"text": ["10\u201315% of the population", "10\u201315% of the population", "10\u201315% of the population"], "answer_start": [493, 493, 493]}, "prediction_text": "10\u201315% of the population"}
{"answers": {"text": ["1665", "1665", "1665"], "answer_start": [771, 771, 771]}, "prediction_text": "1665"}
{"answers": {"text": ["40,000", "40,000", "40,000"], "answer_start": [17, 17, 17]}, "prediction_text": "40,000 people died."}
{"answers": {"text": ["Russia", "Russia", "Russia"], "answer_start": [235, 235, 235]}, "prediction_text": "Russia"}
{"answers": {"text": ["the Italian Plague of 1629\u20131631", "Italian Plague", "Italian Plague"], "answer_start": [732, 736, 736]}, "prediction_text": "Italian Plague"}
{"answers": {"text": ["The last plague outbreak ravaged Oslo in 1654.", "1654", "1654"], "answer_start": [925, 966, 966]}, "prediction_text": "1654"}
{"answers": {"text": ["22 times between 1361 and 1528", "22", "22"], "answer_start": [577, 577, 577]}, "prediction_text": "22 times"}
{"answers": {"text": ["some 1.7 million victims", "1.7 million", "1.7 million"], "answer_start": [56, 61, 61]}, "prediction_text": "About 14%"}
{"answers": {"text": ["about half of Naples' 300,000 inhabitants", "half of Naples' 300,000 inhabitants", "half of Naples' 300,000 inhabitants"], "answer_start": [150, 156, 156]}, "prediction_text": "About half of Naples' 300,000 inhabitants."}
{"answers": {"text": ["reduced the population of Seville by half", "half", "half"], "answer_start": [320, 357, 357]}, "prediction_text": "Two-thirds"}
{"answers": {"text": ["Sweden v. Russia and allies", "Sweden v. Russia and allies", "Sweden v. Russia and allies"], "answer_start": [440, 440, 440]}, "prediction_text": "Sweden v. Russia"}
{"answers": {"text": ["1720 in Marseille.", "1720", "1720"], "answer_start": [674, 674, 674]}, "prediction_text": "1720"}
{"answers": {"text": ["between 1500 and 1850", "1500 and 1850", "1500 and 1850"], "answer_start": [137, 145, 145]}, "prediction_text": "1500 to 1850"}
{"answers": {"text": ["30 to 50 thousand inhabitants", "30 to 50 thousand", "30 to 50 thousand"], "answer_start": [226, 226, 226]}, "prediction_text": "30 to 50 thousand inhabitants"}
{"answers": {"text": ["until the second quarter of the 19th century.", "until the second quarter of the 19th century", "until the second quarter of the 19th century"], "answer_start": [370, 370, 370]}, "prediction_text": "Between 1701 and 1750."}
{"answers": {"text": ["two-thirds of its population", "two-thirds of its population", "two-thirds of its population"], "answer_start": [642, 642, 642]}, "prediction_text": "Thirty-seven people"}
{"answers": {"text": ["melt (magma and/or lava)", "melt", "rock crystallizes from melt (magma and/or lava)", "melt (magma and/or lava)"], "answer_start": [238, 238, 215, 238]}, "prediction_text": "Melt or lava"}
{"answers": {"text": ["metamorphic rock", "metamorphic", "metamorphic rock", "metamorphic"], "answer_start": [592, 592, 592, 592]}, "prediction_text": "Metamorphic rock"}
{"answers": {"text": ["new magma", "igneous", "new magma", "magma"], "answer_start": [914, 949, 914, 918]}, "prediction_text": "New magma"}
{"answers": {"text": ["igneous, sedimentary, and metamorphic", "igneous, sedimentary, and metamorphic", "igneous, sedimentary, and metamorphic", "igneous, sedimentary, and metamorphic"], "answer_start": [37, 37, 37, 37]}, "prediction_text": "igneous, sedimentary, metamorphic."}
{"answers": {"text": ["heat and pressure", "heat and pressure", "heat and pressure", "heat and pressure"], "answer_start": [430, 430, 430, 430]}, "prediction_text": "Heat and pressure change the mineral content."}
{"answers": {"text": ["seafloor spreading", "seafloor spreading", "seafloor spreading", "seafloor spreading"], "answer_start": [71, 71, 71, 71]}, "prediction_text": "Seawater spreading"}
{"answers": {"text": ["the crust and rigid uppermost portion of the upper mantle", "crust and rigid uppermost portion of the upper mantle", "crust and rigid uppermost portion of the upper mantle", "crust and rigid uppermost portion of the upper mantle"], "answer_start": [143, 147, 147, 147]}, "prediction_text": "The crust and rigid uppermost portion."}
{"answers": {"text": ["asthenosphere", "asthenosphere", "asthenosphere", "asthenosphere"], "answer_start": [333, 333, 333, 333]}, "prediction_text": "asthenosphere"}
{"answers": {"text": ["the convecting mantle", "convection of the mantle", "convection of the mantle", "the convecting mantle"], "answer_start": [724, 436, 436, 724]}, "prediction_text": "The mantle convection currents"}
{"answers": {"text": ["the 1960s", "1960s", "1960s", "1960s"], "answer_start": [3, 7, 7, 7]}, "prediction_text": "1960s"}
{"answers": {"text": ["divergent boundaries", "divergent boundaries", "divergent boundaries", "divergent boundaries"], "answer_start": [295, 295, 295, 295]}, "prediction_text": "Mid-ocean ridges"}
{"answers": {"text": ["convergent boundaries", "convergent boundaries", "convergent boundaries", "convergent boundaries"], "answer_start": [398, 398, 398, 398]}, "prediction_text": "San Andreas fault system"}
{"answers": {"text": ["Transform boundaries", "Transform", "Transform boundaries", "Transform boundaries"], "answer_start": [461, 461, 461, 461]}, "prediction_text": "San Andreas fault system"}
{"answers": {"text": ["Alfred Wegener", "Alfred Wegener", "Alfred Wegener", "Alfred Wegener"], "answer_start": [612, 612, 612, 612]}, "prediction_text": "Alfred Wegener's theory"}
{"answers": {"text": ["the convecting mantle", "convecting mantle", "convecting", "convecting"], "answer_start": [1016, 1020, 1020, 1020]}, "prediction_text": "Geologic mantle"}
{"answers": {"text": ["seismic waves", "seismic", "seismic", "seismic"], "answer_start": [43, 43, 43, 43]}, "prediction_text": "Shear waves, dense solid inner core, layered model."}
{"answers": {"text": ["crust", "crust", "lithosphere", "crust and lithosphere"], "answer_start": [332, 332, 342, 332]}, "prediction_text": "A crust and lithosphere."}
{"answers": {"text": ["the mantle", "mantle", "mantle", "mantle"], "answer_start": [362, 366, 366, 366]}, "prediction_text": "The outer core and inner core"}
{"answers": {"text": ["wave speeds", "wave speeds", "wave speeds"], "answer_start": [578, 578, 578]}, "prediction_text": "Wave speeds inside the Earth."}
{"answers": {"text": ["the outer core and inner core", "outer core and inner core", "outer core and inner core", "outer core and inner core"], "answer_start": [463, 467, 467, 467]}, "prediction_text": "Largess and outer core."}
{"answers": {"text": ["second scale shows the most recent eon with an expanded scale", "compresses the most recent era", "compresses the most recent era"], "answer_start": [195, 275, 275]}, "prediction_text": "Compresses the most recent era."}
{"answers": {"text": ["Quaternary", "Quaternary", "Quaternary"], "answer_start": [372, 372, 372]}, "prediction_text": "The Pleistocene epoch"}
{"answers": {"text": ["The Holocene", "Holocene", "The Holocene", "Holocene"], "answer_start": [595, 599, 595, 599]}, "prediction_text": "Pleistocene epoch"}
{"answers": {"text": ["the Quaternary period", "Quaternary period", "Quaternary", "Quaternary"], "answer_start": [783, 787, 787, 787]}, "prediction_text": "The Quaternary period"}
{"answers": {"text": ["The principle of cross-cutting relationships", "cross-cutting relationships", "cross-cutting relationships"], "answer_start": [0, 17, 17]}, "prediction_text": "Cross-cutting relationships"}
{"answers": {"text": ["younger than the fault", "younger", "younger"], "answer_start": [369, 145, 369]}, "prediction_text": "Older or younger"}
{"answers": {"text": ["the key bed", "key bed", "key bed"], "answer_start": [401, 405, 405]}, "prediction_text": "Finding the key bed in these situations."}
{"answers": {"text": ["older than the fault", "older", "younger"], "answer_start": [309, 309, 145]}, "prediction_text": "Older than the fault itself."}
{"answers": {"text": ["xenoliths", "xenoliths", "inclusions", "xenoliths"], "answer_start": [530, 386, 141, 530]}, "prediction_text": "xenoliths"}
{"answers": {"text": ["magma or lava flows", "magma or lava flows", "magma or lava", "magma or lava flows"], "answer_start": [445, 445, 445, 445]}, "prediction_text": "Magma or lava flows"}
{"answers": {"text": ["clasts", "clasts", "clasts", "clasts"], "answer_start": [98, 98, 98, 98]}, "prediction_text": "Clasts"}
{"answers": {"text": ["The principle of inclusions and components", "principle of inclusions and components", "The principle of inclusions and components", "inclusions and components"], "answer_start": [0, 4, 0, 17]}, "prediction_text": "Principle of inclusions and components"}
{"answers": {"text": ["gravel", "gravel", "gravel", "gravel"], "answer_start": [257, 257, 257, 257]}, "prediction_text": "Geysers"}
{"answers": {"text": ["The principle of faunal succession", "principle of faunal succession", "The principle of faunal succession", "faunal succession"], "answer_start": [0, 4, 0, 17]}, "prediction_text": "Faunal succession"}
{"answers": {"text": ["William Smith", "William Smith", "William Smith", "William Smith"], "answer_start": [311, 311, 311, 311]}, "prediction_text": "William Smith's principles"}
{"answers": {"text": ["complex", "complex", "complex", "quite complex"], "answer_start": [523, 523, 523, 517]}, "prediction_text": "Complex"}
{"answers": {"text": ["organisms", "organisms", "organisms", "organisms"], "answer_start": [98, 98, 98, 98]}, "prediction_text": "Fossils in sedimentary rocks"}
{"answers": {"text": ["Charles Darwin", "Charles Darwin", "Charles Darwin", "Charles Darwin"], "answer_start": [374, 374, 374, 374]}, "prediction_text": "Charles Darwin's theory of evolution"}
{"answers": {"text": ["At the beginning of the 20th century", "20th century", "At the beginning of the 20th century", "beginning of the 20th century"], "answer_start": [0, 24, 0, 7]}, "prediction_text": "20th century"}
{"answers": {"text": ["stratigraphic correlation", "stratigraphic", "stratigraphic", "stratigraphic"], "answer_start": [311, 311, 311, 311]}, "prediction_text": "Fossil sequences"}
{"answers": {"text": ["absolute ages", "rock units", "new absolute"], "answer_start": [606, 453, 602]}, "prediction_text": "New absolute ages"}
{"answers": {"text": ["to one another", "one another", "one another"], "answer_start": [371, 374, 374]}, "prediction_text": "One another"}
{"answers": {"text": ["fossil sequences", "fossil sequences", "fossil sequences", "fossil sequences"], "answer_start": [510, 510, 510, 510]}, "prediction_text": "Fossils"}
{"answers": {"text": ["Thermochemical techniques", "Thermochemical", "Thermochemical", "Thermochemical"], "answer_start": [830, 830, 830, 830]}, "prediction_text": "Thermochemical techniques"}
{"answers": {"text": ["particular closure temperature", "closure temperature", "closure temperature"], "answer_start": [173, 184, 184]}, "prediction_text": "Point at which different radiometric isotopes stop diffusing into and out of the crystal lattice."}
{"answers": {"text": ["isotope ratios of radioactive elements", "isotope", "isotope", "isotope"], "answer_start": [32, 32, 32, 32]}, "prediction_text": "isotope ratios"}
{"answers": {"text": ["Dating of lava and volcanic ash layers found within a stratigraphic sequence", "Dating of lava and volcanic ash layers", "stratigraphic sequence", "Dating of lava and volcanic ash layers found within a stratigraphic sequence"], "answer_start": [540, 540, 594, 540]}, "prediction_text": "Using uranium-thorium dating"}
{"answers": {"text": ["horizontal compression", "horizontal", "horizontal"], "answer_start": [33, 33, 33]}, "prediction_text": "When rock units are placed under horizontal compression, they shorten and become thicker."}
{"answers": {"text": ["In the shallow crust", "shallow crust", "shallow crust"], "answer_start": [238, 245, 245]}, "prediction_text": "In shallow crust"}
{"answers": {"text": ["antiforms", "antiforms", "antiforms"], "answer_start": [877, 877, 877]}, "prediction_text": "Synclines."}
{"answers": {"text": ["synforms", "synforms", "synforms"], "answer_start": [930, 930, 930]}, "prediction_text": "Synclines."}
{"answers": {"text": ["anticlines and synclines", "overturned anticline", "anticlines and synclines"], "answer_start": [1029, 1150, 1029]}, "prediction_text": "anticlines or synclines."}
{"answers": {"text": ["Extension", "Extension", "Extension"], "answer_start": [0, 0, 0]}, "prediction_text": "Extension causes rock units to become longer and thinner."}
{"answers": {"text": ["boudins", "boudins", "boudins"], "answer_start": [683, 683, 683]}, "prediction_text": "Boudins"}
{"answers": {"text": ["within the Maria Fold and Thrust Belt", "Maria Fold and Thrust Belt", "Maria Fold and Thrust Belt"], "answer_start": [402, 413, 413]}, "prediction_text": "In the Maria Fold and Thrust Belt"}
{"answers": {"text": ["metamorphosed", "metamorphosed", "metamorphosed"], "answer_start": [609, 609, 609]}, "prediction_text": "Metamorphosed rocks"}
{"answers": {"text": ["normal faulting and through the ductile stretching and thinning", "normal faulting", "normal faulting and through the ductile stretching and thinning"], "answer_start": [112, 112, 112]}, "prediction_text": "Normal faults drop rock units."}
{"answers": {"text": ["Dikes", "Dikes", "Dikes"], "answer_start": [724, 724, 724]}, "prediction_text": "Dikes"}
{"answers": {"text": ["in areas that are being actively deformed", "areas that are being actively deformed", "in areas that are being actively deformed"], "answer_start": [826, 829, 826]}, "prediction_text": "In large numbers around volcanoes."}
{"answers": {"text": ["topographic gradients", "topographic", "topographic"], "answer_start": [171, 171, 171]}, "prediction_text": "Topographic gradients"}
{"answers": {"text": ["Continual motion along the fault", "Continual motion", "Continual motion along the fault"], "answer_start": [368, 368, 368]}, "prediction_text": "Deformation of rock units"}
{"answers": {"text": ["Deformational events", "Deformational", "Deformational"], "answer_start": [547, 547, 547]}, "prediction_text": "Dikes, long, planar igneous intrusions, enter along cracks, and therefore often form in large numbers."}
{"answers": {"text": ["layered basaltic lava flows", "layered basaltic lava flows", "layered basaltic lava flows"], "answer_start": [183, 183, 183]}, "prediction_text": "layered basaltic lava flows"}
{"answers": {"text": ["Acasta gneiss", "Acasta gneiss", "Acasta gneiss of the Slave craton in northwestern Canada"], "answer_start": [645, 645, 645]}, "prediction_text": "Acasta gneiss"}
{"answers": {"text": ["sedimentary rocks", "sedimentary", "sedimentary"], "answer_start": [366, 366, 366]}, "prediction_text": "Deformed rocks"}
{"answers": {"text": ["Cambrian time", "Cambrian time", "Cambrian time"], "answer_start": [418, 418, 418]}, "prediction_text": "Cambrian time"}
{"answers": {"text": ["Slave craton in northwestern Canada", "Canada", "northwestern Canada"], "answer_start": [666, 695, 682]}, "prediction_text": "Slave craton"}
{"answers": {"text": ["the study of rocks", "study of rocks", "the study of rocks"], "answer_start": [263, 267, 263]}, "prediction_text": "Study of rocks"}
{"answers": {"text": ["the study of sedimentary layers", "study of sedimentary layers", "the study of sedimentary layers"], "answer_start": [298, 302, 298]}, "prediction_text": "Study of sedimentary layers."}
{"answers": {"text": ["the study of positions of rock units and their deformation", "study of positions of rock units and their deformation", "the study of positions of rock units and their deformation"], "answer_start": [356, 360, 356]}, "prediction_text": "Study of positions of rock units."}
{"answers": {"text": ["modern soils", "soils, rivers, landscapes, and glaciers", "soils, rivers, landscapes, and glaciers"], "answer_start": [454, 461, 461]}, "prediction_text": "Southeastern soils, rivers, landscapes, and glaciers."}
{"answers": {"text": ["identifying rocks", "identifying rocks", "identifying rocks"], "answer_start": [15, 132, 132]}, "prediction_text": "Identifying rocks in the laboratory."}
{"answers": {"text": ["birefringence, pleochroism, twinning, and interference properties", "birefringence, pleochroism, twinning, and interference", "birefringence, pleochroism, twinning, and interference"], "answer_start": [483, 483, 483]}, "prediction_text": "Birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference properties, birefringence, pleochroism, twinning, interference, interference"}
{"answers": {"text": ["geochemical evolution of rock units", "geochemical evolution of rock units", "the geochemical evolution of rock units"], "answer_start": [794, 794, 790]}, "prediction_text": "Geochemical evolution of rock units."}
{"answers": {"text": ["the laboratory", "laboratory", "laboratory"], "answer_start": [85, 89, 89]}, "prediction_text": "In the laboratory"}
{"answers": {"text": ["petrographic microscope", "petrographic", "petrographic"], "answer_start": [324, 324, 324]}, "prediction_text": "Petrographic microscope"}
{"answers": {"text": ["pressure physical experiments", "fluid inclusion data", "fluid inclusion data"], "answer_start": [80, 26, 26]}, "prediction_text": "Through fluid inclusion data and high temperature and pressure physical experiments."}
{"answers": {"text": ["physical experiments", "high temperature and pressure physical experiments", "pressure physical experiments"], "answer_start": [89, 59, 80]}, "prediction_text": "Through fluid inclusion data and high temperature and pressure physical experiments."}
{"answers": {"text": ["metamorphic processes", "metamorphic", "metamorphic"], "answer_start": [321, 321, 321]}, "prediction_text": "Metamorphic processes"}
{"answers": {"text": ["Structural geologists", "Structural", "Structural"], "answer_start": [0, 0, 0]}, "prediction_text": "Structural geologists"}
{"answers": {"text": ["microscopic analysis of oriented thin sections", "microscopic analysis", "use microscopic analysis of oriented thin sections of geologic samples"], "answer_start": [26, 26, 22]}, "prediction_text": "Using microscopic analysis"}
{"answers": {"text": ["plot and combine", "plot and combine", "plot and combine"], "answer_start": [226, 226, 226]}, "prediction_text": "Plot and combine measurements"}
{"answers": {"text": ["analog and numerical experiments", "analog and numerical", "analog and numerical"], "answer_start": [443, 443, 443]}, "prediction_text": "Analog and numerical experiments"}
{"answers": {"text": ["orogenic wedges", "orogenic wedges", "orogenic wedges"], "answer_start": [80, 80, 80]}, "prediction_text": "orogenic wedges"}
{"answers": {"text": ["those involving orogenic wedges", "orogenic wedges", "involving orogenic wedges"], "answer_start": [64, 80, 70]}, "prediction_text": "Orogenic wedges experiments"}
{"answers": {"text": ["sand", "sand", "sand"], "answer_start": [252, 252, 252]}, "prediction_text": "Sand"}
{"answers": {"text": ["all angles remain the same", "all angles remain the same", "all angles remain the same"], "answer_start": [404, 404, 404]}, "prediction_text": "All angles remain the same."}
{"answers": {"text": ["Numerical models", "Numerical", "Numerical models"], "answer_start": [448, 448, 448]}, "prediction_text": "Analog models"}
{"answers": {"text": ["stratigraphers", "stratigraphers", "stratigraphers"], "answer_start": [19, 19, 19]}, "prediction_text": "Stratigraphers"}
{"answers": {"text": ["geophysical surveys", "geophysical", "geophysical"], "answer_start": [183, 183, 183]}, "prediction_text": "Geophysical surveys"}
{"answers": {"text": ["well logs", "well logs", "well logs"], "answer_start": [290, 290, 290]}, "prediction_text": "Computer programs"}
{"answers": {"text": ["computer programs", "computer programs", "computer programs"], "answer_start": [389, 389, 389]}, "prediction_text": "Computer programs"}
{"answers": {"text": ["water, coal, and hydrocarbon extraction", "hydrocarbon", "hydrocarbon"], "answer_start": [600, 617, 617]}, "prediction_text": "Water, coal, hydrocarbon extraction."}
{"answers": {"text": ["provide better absolute bounds on the timing and rates of deposition", "gain information about past climate", "provide better absolute bounds on the timing and rates of deposition"], "answer_start": [327, 568, 327]}, "prediction_text": "To provide better absolute bounds on deposition timing and rates."}
{"answers": {"text": ["biostratigraphers", "biostratigraphers", "biostratigraphers"], "answer_start": [19, 19, 19]}, "prediction_text": "Biostratigraphers"}
{"answers": {"text": ["Magnetic stratigraphers", "Magnetic stratigraphers", "Magnetic stratigraphers"], "answer_start": [397, 397, 397]}, "prediction_text": "Magnetic stratigraphers"}
{"answers": {"text": ["Geochronologists", "Geochronologists", "Geochronologists"], "answer_start": [244, 244, 244]}, "prediction_text": "Geochronologists"}
{"answers": {"text": ["Persia", "Persia", "Persia after the Muslim conquests had come to an end"], "answer_start": [130, 130, 130]}, "prediction_text": "Persia"}
{"answers": {"text": ["Abu al-Rayhan al-Biruni", "Abu al-Rayhan al-Biruni", "Abu al-Rayhan al-Biruni"], "answer_start": [184, 184, 184]}, "prediction_text": "Abu al-Rayhan al-Biruni"}
{"answers": {"text": ["Shen Kuo", "Shen Kuo", "Shen Kuo"], "answer_start": [782, 782, 782]}, "prediction_text": "Shen Kuo"}
{"answers": {"text": ["Ibn Sina", "Ibn Sina", "Ibn Sina"], "answer_start": [514, 514, 514]}, "prediction_text": "Ibn Sina"}
{"answers": {"text": ["his observation of fossil animal shells", "fossil animal shells", "based on his observation of fossil animal shells in a geological stratum in a mountain hundreds of miles from the ocean"], "answer_start": [871, 890, 862]}, "prediction_text": "Observations of fossil animal shells in a geological stratum."}
{"answers": {"text": ["James Hutton", "James Hutton", "James Hutton"], "answer_start": [0, 0, 0]}, "prediction_text": "James Hutton"}
{"answers": {"text": ["Theory of the Earth", "Theory of the Earth", "Theory of the Earth"], "answer_start": [98, 98, 98]}, "prediction_text": "Theory of the Earth"}
{"answers": {"text": ["1795", "1795", "1795"], "answer_start": [481, 481, 481]}, "prediction_text": "1795"}
{"answers": {"text": ["Earth must be much older than had previously been supposed", "Earth must be much older than had previously been supposed", "the Earth must be much older than had previously been supposed"], "answer_start": [200, 200, 196]}, "prediction_text": "Theory of the Earth"}
{"answers": {"text": ["William Maclure", "William Maclure", "William Maclure"], "answer_start": [61, 61, 61]}, "prediction_text": "William Maclure"}
{"answers": {"text": ["1809", "1809", "1809"], "answer_start": [53, 53, 53]}, "prediction_text": "1809"}
{"answers": {"text": ["1807", "1807", "1807"], "answer_start": [81, 81, 81]}, "prediction_text": "1809"}
{"answers": {"text": ["Observations on the Geology of the United States explanatory of a Geological Map", "Observations on the Geology of the United States explanatory of a Geological Map", "Observations on the Geology of the United States"], "answer_start": [420, 420, 420]}, "prediction_text": "Observations on the Geology of the United States"}
{"answers": {"text": ["the American Philosophical Society", "American Philosophical Society", "American Philosophical Society"], "answer_start": [364, 368, 368]}, "prediction_text": "American Philosophical Society"}
{"answers": {"text": ["Principles of Geology", "Principles of Geology", "Principles of Geology"], "answer_start": [51, 51, 51]}, "prediction_text": "Principles of Geology"}
{"answers": {"text": ["uniformitarianism", "uniformitarianism", "uniformitarianism"], "answer_start": [180, 180, 180]}, "prediction_text": "Uniformitarianism"}
{"answers": {"text": ["uniformitarianism", "uniformitarianism", "uniformitarianism"], "answer_start": [180, 180, 180]}, "prediction_text": "catastrophism"}
{"answers": {"text": ["catastrophism", "catastrophism", "catastrophism"], "answer_start": [338, 338, 338]}, "prediction_text": "catastrophism"}
{"answers": {"text": ["Charles Darwin", "Charles Darwin", "Charles Darwin"], "answer_start": [126, 126, 126]}, "prediction_text": "Charles Darwin"}
{"answers": {"text": ["103 miles", "103 miles", "103 miles"], "answer_start": [167, 167, 167]}, "prediction_text": "166 km (166 km from Edinburgh to Newcastle)"}
{"answers": {"text": ["8.5 mi", "8.5 mi", "8.5 mi"], "answer_start": [284, 284, 284]}, "prediction_text": "8.5 mi (13.7 km)"}
{"answers": {"text": ["Eurocities", "Eurocities", "the English Core Cities Group"], "answer_start": [526, 526, 473]}, "prediction_text": "Eurocities network"}
{"answers": {"text": ["Northumberland", "Northumberland", "county of Northumberland"], "answer_start": [601, 601, 591]}, "prediction_text": "Northumberland"}
{"answers": {"text": ["Geordie", "Geordie", "Geordie"], "answer_start": [838, 838, 838]}, "prediction_text": "Geordie"}
{"answers": {"text": ["Robert Curthose", "Robert Curthose", "Robert Curthose"], "answer_start": [107, 107, 107]}, "prediction_text": "Robert Curthose"}
{"answers": {"text": ["wool", "wool", "the wool trade"], "answer_start": [205, 205, 201]}, "prediction_text": "Wool trade"}
{"answers": {"text": ["coal", "coal", "coal"], "answer_start": [262, 262, 262]}, "prediction_text": "Coal"}
{"answers": {"text": ["16th century", "the 16th", "the 16th century"], "answer_start": [306, 302, 302]}, "prediction_text": "16th century"}
{"answers": {"text": ["the Great North Run", "the Great North Run", "the Great North Run"], "answer_start": [796, 796, 796]}, "prediction_text": "Great North Run"}
{"answers": {"text": ["Pons Aelius", "Pons Aelius", "Pons Aelius"], "answer_start": [59, 59, 59]}, "prediction_text": "Pons Aelius"}
{"answers": {"text": ["Tyne", "the River Tyne", "the River Tyne"], "answer_start": [113, 103, 103]}, "prediction_text": "River Tyne"}
{"answers": {"text": ["2,000", "2,000", "2,000"], "answer_start": [393, 393, 393]}, "prediction_text": "2,000"}
{"answers": {"text": ["Hadrian's", "Hadrian's", "Hadrian's Wall"], "answer_start": [413, 413, 677]}, "prediction_text": "Hadrian's Wall"}
{"answers": {"text": ["Pictish", "Pictish", "Pictish tribes"], "answer_start": [921, 921, 921]}, "prediction_text": "Pictish tribes"}
{"answers": {"text": ["England's", "England", "England"], "answer_start": [42, 42, 42]}, "prediction_text": "England"}
{"answers": {"text": ["Elizabeth", "Elizabeth", "Elizabeth"], "answer_start": [141, 141, 141]}, "prediction_text": "Elizabeth"}
{"answers": {"text": ["25-foot", "25-foot", "25-foot (7.6 m) high"], "answer_start": [162, 162, 162]}, "prediction_text": "25 feet (7.6 m)"}
{"answers": {"text": ["William the Lion", "William the Lion", "William the Lion"], "answer_start": [323, 323, 323]}, "prediction_text": "William the Lion"}
{"answers": {"text": ["three times", "three", "three times"], "answer_start": [515, 515, 515]}, "prediction_text": "Three times"}
{"answers": {"text": ["coal", "coal", "coal"], "answer_start": [50, 50, 50]}, "prediction_text": "Coal to Newcastle"}
{"answers": {"text": ["the Hostmen", "the Hostmen", "the Hostmen"], "answer_start": [172, 172, 172]}, "prediction_text": "Hostmen"}
{"answers": {"text": ["a pointless pursuit", "a pointless pursuit", "a pointless pursuit"], "answer_start": [396, 396, 396]}, "prediction_text": "A pointless pursuit."}
{"answers": {"text": ["an eccentric", "an eccentric", "an eccentric,"], "answer_start": [498, 498, 498]}, "prediction_text": "An eccentric"}
{"answers": {"text": ["ruin him", "ruin him", "to ruin him"], "answer_start": [613, 613, 610]}, "prediction_text": "Destroy him."}
{"answers": {"text": ["their families", "their families", "their families"], "answer_start": [116, 116, 116]}, "prediction_text": "Their families"}
{"answers": {"text": ["boats", "keels", "keels"], "answer_start": [186, 179, 179]}, "prediction_text": "From the keels to the colliers."}
{"answers": {"text": ["7,000", "7,000", "7,000"], "answer_start": [325, 325, 325]}, "prediction_text": "47%"}
{"answers": {"text": ["47%", "more than one-third", "47%"], "answer_start": [538, 386, 538]}, "prediction_text": "47%"}
{"answers": {"text": ["devastating loss", "devastating loss", "devastating loss"], "answer_start": [635, 635, 635]}, "prediction_text": "devastating loss"}
{"answers": {"text": ["the King", "the King", "for the King"], "answer_start": [53, 53, 49]}, "prediction_text": "King"}
{"answers": {"text": ["the Scots", "the Scots", "the Scots"], "answer_start": [123, 123, 123]}, "prediction_text": "The Scots"}
{"answers": {"text": ["drummes", "drummes", "drummes"], "answer_start": [366, 366, 366]}, "prediction_text": "roaring drummes"}
{"answers": {"text": ["Triumphing by a brave defence", "Triumphing by a brave defence", "Triumphing by a brave defence"], "answer_start": [479, 479, 479]}, "prediction_text": "Triumphant defence"}
{"answers": {"text": ["Charles I", "Charles I", "Charles I"], "answer_start": [526, 526, 526]}, "prediction_text": "Charles I"}
{"answers": {"text": ["urbanization", "urbanization", "the urbanization of the city"], "answer_start": [187, 187, 183]}, "prediction_text": "Urbanization and industrial structures"}
{"answers": {"text": ["the Maling company", "Maling", "Maling company"], "answer_start": [221, 225, 225]}, "prediction_text": "Maling company"}
{"answers": {"text": ["electric lighting", "the incandescent lightbulb", "the incandescent lightbulb"], "answer_start": [706, 611, 611]}, "prediction_text": "Electric lighting"}
{"answers": {"text": ["prosperity", "the city's prosperity", "the city's prosperity;"], "answer_start": [83, 72, 72]}, "prediction_text": "Economic prosperity"}
{"answers": {"text": ["the steam turbine", "the steam turbine", "the steam turbine"], "answer_start": [946, 946, 946]}, "prediction_text": "Steam turbine"}
{"answers": {"text": ["medieval", "medieval", "medieval street layout."], "answer_start": [42, 42, 42]}, "prediction_text": "Medieval street layout"}
{"answers": {"text": ["Narrow alleys", "Narrow alleys", "Narrow alleys"], "answer_start": [66, 66, 66]}, "prediction_text": "Stairs from the riverside to higher parts of the city centre."}
{"answers": {"text": ["Stairs", "Stairs", "chares'"], "answer_start": [199, 199, 84]}, "prediction_text": "Stairs from the riverside to higher parts of the city center."}
{"answers": {"text": ["modern", "modern buildings as well as structures dating from the 15th\u201318th centuries", "modern buildings"], "answer_start": [391, 391, 391]}, "prediction_text": "Modern buildings"}
{"answers": {"text": ["a restaurant", "a restaurant", "a restaurant situated at a Grade"], "answer_start": [580, 580, 580]}, "prediction_text": "A restaurant located at a Grade I-listed 16th century merchant's house."}
{"answers": {"text": ["Tyneside Classical", "Tyneside Classical", "Newcastle"], "answer_start": [61, 61, 231]}, "prediction_text": "Grey Street"}
{"answers": {"text": ["England's best-looking city", "England's best-looking city", "England's best-looking city"], "answer_start": [244, 244, 244]}, "prediction_text": "England's best-looking city"}
{"answers": {"text": ["Grey Street", "Grey Street", "Grey Street"], "answer_start": [358, 358, 358]}, "prediction_text": "Grey Street"}
{"answers": {"text": ["in the 1960s", "the 1960s", "the 1960s"], "answer_start": [771, 774, 774]}, "prediction_text": "1960s"}
{"answers": {"text": ["Shopping Centre", "Shopping Centre", "the Eldon Square Shopping Centre"], "answer_start": [817, 817, 800]}, "prediction_text": "The original Eldon Square"}
{"answers": {"text": ["Town Moor", "the Town Moor", "the Town Moor"], "answer_start": [40, 36, 36]}, "prediction_text": "Town Moor"}
{"answers": {"text": ["graze", "graze", "graze cattle on it."], "answer_start": [218, 218, 218]}, "prediction_text": "Collect rent for loss of privilege."}
{"answers": {"text": ["The Hoppings funfair", "The Hoppings funfair", "The Hoppings funfair"], "answer_start": [586, 586, 586]}, "prediction_text": "Hoppings funfair"}
{"answers": {"text": ["June", "June", "annually in June"], "answer_start": [686, 686, 674]}, "prediction_text": "June"}
{"answers": {"text": ["freemen", "freemen", "Honorary freemen"], "answer_start": [446, 446, 437]}, "prediction_text": "Honorary freeman"}
{"answers": {"text": ["Large-scale regeneration", "Large-scale regeneration", "new office developments"], "answer_start": [0, 0, 77]}, "prediction_text": "Existing office developments"}
{"answers": {"text": ["Gateshead Council", "Gateshead Council", "Gateshead Council"], "answer_start": [184, 184, 184]}, "prediction_text": "Gateshead Council"}
{"answers": {"text": ["Norman Foster", "Norman Foster", "Norman Foster"], "answer_start": [404, 404, 404]}, "prediction_text": "Norman Foster"}
{"answers": {"text": ["tourist promotion", "to spearhead the regeneration of the North-East", "to spearhead the regeneration of the North-East"], "answer_start": [583, 686, 686]}, "prediction_text": "Regeneration of the North-East."}
{"answers": {"text": ["ten", "ten", "for ten days"], "answer_start": [795, 795, 791]}, "prediction_text": "Ten days"}
{"answers": {"text": ["the Grainger Town area", "Grainger Town area", "the Grainger Town area"], "answer_start": [35, 39, 35]}, "prediction_text": "Grainger Town area"}
{"answers": {"text": ["between 1835 and 1842", "between 1835 and 1842", "between 1835 and 1842,"], "answer_start": [144, 144, 144]}, "prediction_text": "1835 to 1842"}
{"answers": {"text": ["four stories", "four stories", "four stories high"], "answer_start": [391, 391, 391]}, "prediction_text": "Vertical dormers"}
{"answers": {"text": ["244", "244", "244 are listed,"], "answer_start": [589, 589, 589]}, "prediction_text": "244 buildings are listed."}
{"answers": {"text": ["the Butcher Market", "the Butcher Market", "the Butcher Market"], "answer_start": [79, 79, 79]}, "prediction_text": "Butcher Market"}
{"answers": {"text": ["1835", "1835", "in 1835"], "answer_start": [141, 141, 138]}, "prediction_text": "1835"}
{"answers": {"text": ["2000", "2000", "2000 guests"], "answer_start": [356, 356, 356]}, "prediction_text": "2000 guests"}
{"answers": {"text": ["a painting", "a painting", "a painting"], "answer_start": [399, 399, 399]}, "prediction_text": "A painting of the opening was painted."}
{"answers": {"text": ["English Heritage", "English Heritage", "English Heritage."], "answer_start": [719, 719, 719]}, "prediction_text": "English Heritage"}
{"answers": {"text": ["oceanic", "oceanic", "significantly milder than some other locations"], "answer_start": [28, 28, 53]}, "prediction_text": "Oceanic (K\u00f6ppen Cfb)"}
{"answers": {"text": ["warming", "warming", "warming influence"], "answer_start": [147, 147, 147]}, "prediction_text": "Warmth influence"}
{"answers": {"text": ["rain", "rain", "the rain shadow"], "answer_start": [229, 229, 225]}, "prediction_text": "Rain shadow"}
{"answers": {"text": ["January 1982", "1982", "\u221212.6 \u00b0C (9.3 \u00b0F)"], "answer_start": [441, 449, 416]}, "prediction_text": "January 1982"}
{"answers": {"text": ["the British Isles", "the British Isles", "the remainder of the British Isles"], "answer_start": [618, 618, 601]}, "prediction_text": "British Isles"}
{"answers": {"text": ["2010", "2010", "In 2010"], "answer_start": [3, 3, 0]}, "prediction_text": "2010"}
{"answers": {"text": ["Eldon Square Shopping Centre,", "the Eldon Square Shopping Centre", "the Eldon Square Shopping Centre"], "answer_start": [184, 180, 180]}, "prediction_text": "Eldon Square Shopping Centre"}
{"answers": {"text": ["Bainbridge's", "Bainbridge's", "Bainbridges"], "answer_start": [456, 456, 427]}, "prediction_text": "Bainbridge's"}
{"answers": {"text": ["by department", "by department", "by department,"], "answer_start": [733, 733, 733]}, "prediction_text": "By department"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [943, 943, 943]}, "prediction_text": "2007"}
{"answers": {"text": ["shopping", "shopping", "shopping destinations"], "answer_start": [6, 6, 6]}, "prediction_text": "Modern Eldon Garden"}
{"answers": {"text": ["suburban", "suburban", "the largest suburban shopping areas"], "answer_start": [275, 275, 263]}, "prediction_text": "Newcastle"}
{"answers": {"text": ["Tesco", "Tesco", "Tesco store"], "answer_start": [335, 335, 335]}, "prediction_text": "MetroCentre"}
{"answers": {"text": ["the MetroCentre", "the MetroCentre", "the MetroCentre"], "answer_start": [489, 489, 489]}, "prediction_text": "MetroCentre"}
{"answers": {"text": ["Gateshead", "Gateshead", "in Gateshead"], "answer_start": [520, 520, 517]}, "prediction_text": "Gateshead"}
{"answers": {"text": ["The Tyneside flat", "The Tyneside flat", "The Tyneside flat"], "answer_start": [0, 0, 0]}, "prediction_text": "Tyneside flat"}
{"answers": {"text": ["terraces", "terraces", "terraces"], "answer_start": [297, 297, 297]}, "prediction_text": "Terraces"}
{"answers": {"text": ["the Ouseburn valley", "the Ouseburn valley", "the Ouseburn valley"], "answer_start": [454, 454, 454]}, "prediction_text": "Ouseburn valley"}
{"answers": {"text": ["Architects", "Architects", "Architects"], "answer_start": [494, 494, 494]}, "prediction_text": "Architects"}
{"answers": {"text": ["high density", "high density", "high density"], "answer_start": [571, 571, 571]}, "prediction_text": "High density without building high and getting rid of common areas."}
{"answers": {"text": ["7.8%", "to 7.8%", "(to 7.8%"], "answer_start": [135, 132, 131]}, "prediction_text": "7.8%"}
{"answers": {"text": ["5.9%", "highest", "5.9%"], "answer_start": [380, 335, 380]}, "prediction_text": "Above a handful of historic densely occupied markets."}
{"answers": {"text": ["overinflated", "converted or shared houses", "historic densely occupied, arguably overinflated markets"], "answer_start": [521, 262, 485]}, "prediction_text": "Overinflated markets"}
{"answers": {"text": ["authorities", "authorities", "authorities"], "answer_start": [555, 555, 555]}, "prediction_text": "Harrogate"}
{"answers": {"text": ["Tunbridge Wells.", "Tunbridge Wells", "Tunbridge Wells"], "answer_start": [634, 634, 634]}, "prediction_text": "Inner London"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [42, 42, 42]}, "prediction_text": "2001"}
{"answers": {"text": ["metropolitan", "the metropolitan", "the metropolitan borough"], "answer_start": [130, 126, 126]}, "prediction_text": "North Tyneside"}
{"answers": {"text": ["student", "student", "student"], "answer_start": [905, 905, 905]}, "prediction_text": "Students"}
{"answers": {"text": ["Universities", "Newcastle and Northumbria Universities", "Universities"], "answer_start": [955, 929, 955]}, "prediction_text": "University of Newcastle"}
{"answers": {"text": ["student populations", "student", "student populations"], "answer_start": [1010, 1010, 1010]}, "prediction_text": "Students"}
{"answers": {"text": ["37.8", "37.8", "37.8"], "answer_start": [83, 83, 83]}, "prediction_text": "37.8"}
{"answers": {"text": ["ancestors", "ancestors", "ancestors"], "answer_start": [170, 170, 170]}, "prediction_text": "Border Reiver surnames"}
{"answers": {"text": ["Border Reiver", "Border Reiver", "Border Reiver surnames"], "answer_start": [211, 211, 211]}, "prediction_text": "Border Reiver surnames"}
{"answers": {"text": ["500", "500", "500"], "answer_start": [468, 468, 468]}, "prediction_text": "1%"}
{"answers": {"text": ["1%", "up to 1%", "1% of the population"], "answer_start": [520, 514, 520]}, "prediction_text": "1%"}
{"answers": {"text": ["Geordie", "Geordie", "Geordie,"], "answer_start": [37, 37, 37]}, "prediction_text": "Geordie"}
{"answers": {"text": ["Anglo-Saxon populations", "Anglo-Saxon populations", "the Anglo-Saxon populations"], "answer_start": [245, 245, 241]}, "prediction_text": "Anglo-Saxon populations"}
{"answers": {"text": ["many elements", "many elements", "many elements of the old language."], "answer_start": [589, 589, 589]}, "prediction_text": "Many elements of the old language."}
{"answers": {"text": ["strong", "strang", "strong"], "answer_start": [710, 760, 710]}, "prediction_text": "\"go\""}
{"answers": {"text": ["stream", "stream", "stream"], "answer_start": [951, 951, 951]}, "prediction_text": "Yes, \"burn\" is pronounced \"burn\" in the Anglo-Saxon language."}
{"answers": {"text": ["Scandinavia", "Scandinavia", "Scandinavia"], "answer_start": [108, 108, 108]}, "prediction_text": "Scandinavia"}
{"answers": {"text": ["Northern United Kingdom", "elsewhere in the Northern United Kingdom", "the Northern United Kingdom"], "answer_start": [257, 240, 253]}, "prediction_text": "Northern United Kingdom"}
{"answers": {"text": ["Scots", "Scots", "Scots"], "answer_start": [431, 431, 431]}, "prediction_text": "Scots"}
{"answers": {"text": ["Many words", "Many words", "Canny"], "answer_start": [544, 544, 643]}, "prediction_text": "\"Canny\""}
{"answers": {"text": ["Dutch", "Dutch", "the Dutch gooien"], "answer_start": [767, 767, 763]}, "prediction_text": "Dutch"}
{"answers": {"text": ["a report", "a report", "a report"], "answer_start": [3, 3, 3]}, "prediction_text": "Ear Institute report"}
{"answers": {"text": ["noisiest", "noisiest", "the noisiest city in the whole of the UK"], "answer_start": [174, 174, 170]}, "prediction_text": "Noisiest city"}
{"answers": {"text": ["80.4", "80.4", "80.4 decibels"], "answer_start": [237, 237, 237]}, "prediction_text": "80.4 decibels"}
{"answers": {"text": ["negative", "negative long-term", "negative long-term impact on the health"], "answer_start": [308, 308, 308]}, "prediction_text": "Negative long-term impact"}
{"answers": {"text": ["a motorway underpass", "a motorway underpass", "a motorway underpass"], "answer_start": [521, 521, 521]}, "prediction_text": "Motorway underpass"}
{"answers": {"text": ["Collingwood Street", "Collingwood Street", "Collingwood Street,"], "answer_start": [201, 201, 201]}, "prediction_text": "The Diamond Strip is a concentration of high-end bars."}
{"answers": {"text": ["indoor complex", "a new indoor complex", "a new indoor complex"], "answer_start": [464, 458, 458]}, "prediction_text": "A new indoor complex consisting of bars, upmarket clubs, restaurants, and a 12-screen Empire multiplex cinema."}
{"answers": {"text": ["12", "12", "12-screen"], "answer_start": [533, 533, 533]}, "prediction_text": "12 screens"}
{"answers": {"text": ["'The Pink Triangle'", "The Pink Triangle", "The Pink Triangle"], "answer_start": [592, 593, 593]}, "prediction_text": "The Pink Triangle"}
{"answers": {"text": ["bars, caf\u00e9s and clubs", "Times Square", "bars, caf\u00e9s and clubs"], "answer_start": [694, 632, 694]}, "prediction_text": "Bars, caf\u00e9s, clubs."}
{"answers": {"text": ["theatre", "theatre", "theatre."], "answer_start": [32, 32, 32]}, "prediction_text": "Theatre"}
{"answers": {"text": ["Stephen Kemble", "Stephen Kemble"], "answer_start": [41, 41]}, "prediction_text": "Stephen Kemble"}
{"answers": {"text": ["many celebrated seasons", "many celebrated seasons", "many celebrated seasons."], "answer_start": [329, 329, 329]}, "prediction_text": "Many celebrated seasons"}
{"answers": {"text": ["1788", "21 January 1788", "21 January 1788"], "answer_start": [419, 408, 408]}, "prediction_text": "January 1788"}
{"answers": {"text": ["Grey Street", "Mosley Street", "Grey Street"], "answer_start": [492, 443, 492]}, "prediction_text": "Mosley Street"}
{"answers": {"text": ["theatres", "theatres", "theatres."], "answer_start": [29, 29, 29]}, "prediction_text": "Theatre theatres"}
{"answers": {"text": ["the Theatre Royal", "the Theatre Royal", "the Theatre Royal"], "answer_start": [52, 52, 52]}, "prediction_text": "Theatre Royal on Grey Street"}
{"answers": {"text": ["Royal Shakespeare", "the Royal Shakespeare Company", "the Royal Shakespeare Company"], "answer_start": [193, 189, 189]}, "prediction_text": "Royal Shakespeare Company"}
{"answers": {"text": ["local talent", "local talent", "local talent"], "answer_start": [382, 382, 382]}, "prediction_text": "Local talent"}
{"answers": {"text": ["arts capital of the UK", "arts capital of the UK", "the arts capital of the UK"], "answer_start": [741, 741, 737]}, "prediction_text": "Arts capital of the UK"}
{"answers": {"text": ["The Literary and Philosophical Society of Newcastle", "The Literary and Philosophical Society of Newcastle upon Tyne", "The Literary and Philosophical Society of Newcastle"], "answer_start": [0, 0, 0]}, "prediction_text": "Lit & Phil"}
{"answers": {"text": ["8000", "8000", "8000"], "answer_start": [211, 211, 211]}, "prediction_text": "8000 CDs"}
{"answers": {"text": ["Green", "Green", "John and Benjamin Green"], "answer_start": [340, 340, 322]}, "prediction_text": "John and Benjamin Green"}
{"answers": {"text": ["lecture theatre", "lecture theatre", "Lit and Phil premises"], "answer_start": [410, 410, 248]}, "prediction_text": "Joseph Swan's lecture on 20 October 1880."}
{"answers": {"text": ["Joseph Swan", "Joseph Swan", "Joseph Swan"], "answer_start": [505, 505, 505]}, "prediction_text": "Joseph Swan"}
{"answers": {"text": ["The Newcastle Beer Festival", "The Newcastle Beer Festival", "The Newcastle Beer Festival"], "answer_start": [0, 0, 0]}, "prediction_text": "Newcastle Beer Festival"}
{"answers": {"text": ["May", "Newcastle and Gateshead", "over the Spring bank holiday"], "answer_start": [74, 79, 195]}, "prediction_text": "May"}
{"answers": {"text": ["biennial", "biennial", "biennial"], "answer_start": [302, 302, 302]}, "prediction_text": "Late May"}
{"answers": {"text": ["EAT!", "EAT!", "EAT! NewcastleGateshead"], "answer_start": [554, 554, 554]}, "prediction_text": "EAT! NewcastleGateshead"}
{"answers": {"text": ["2", "2", "2 weeks each year"], "answer_start": [618, 618, 618]}, "prediction_text": "2 weeks"}
{"answers": {"text": ["The Hoppings", "The Hoppings", "The Hoppings"], "answer_start": [0, 0, 0]}, "prediction_text": "Hoppings (in the UK)"}
{"answers": {"text": ["every June", "every June", "every June"], "answer_start": [98, 98, 98]}, "prediction_text": "June"}
{"answers": {"text": ["Temperance", "the Temperance Movement", "the Temperance Movement"], "answer_start": [143, 139, 139]}, "prediction_text": "Temperance Movement"}
{"answers": {"text": ["a cycling festival", "a cycling festival", "cycling festival,"], "answer_start": [432, 432, 434]}, "prediction_text": "A cycling festival"}
{"answers": {"text": ["The Northern Pride Festival", "The Northern Pride Festival and Parade", "The Northern Pride Festival"], "answer_start": [509, 509, 509]}, "prediction_text": "Northern Pride Festival"}
{"answers": {"text": ["Newcastle Mela", "Newcastle Mela", "Newcastle Mela"], "answer_start": [0, 0, 0]}, "prediction_text": "Newcastle Mela"}
{"answers": {"text": ["Sage Gateshead Music and Arts Centre", "Sage Gateshead Music and Arts Centre", "Gateshead Music and Arts Centre"], "answer_start": [306, 306, 311]}, "prediction_text": "Norman Foster Music and Arts Centre"}
{"answers": {"text": ["Design Event festival", "Design Event festival", "Design Event festival"], "answer_start": [382, 382, 382]}, "prediction_text": "Design Event"}
{"answers": {"text": ["East Asian", "East Asian", "East Asian"], "answer_start": [549, 549, 549]}, "prediction_text": "Design Event"}
{"answers": {"text": ["NewcastleGateshead", "NewcastleGateshead", "NewcastleGateshead"], "answer_start": [188, 188, 188]}, "prediction_text": "Design Event"}
{"answers": {"text": ["folk-rock", "folk-rock", "folk-rock"], "answer_start": [18, 18, 18]}, "prediction_text": "Folk metal"}
{"answers": {"text": ["1971", "1971", "1971"], "answer_start": [112, 112, 112]}, "prediction_text": "1971"}
{"answers": {"text": ["Venom", "Venom", "Venom"], "answer_start": [180, 180, 180]}, "prediction_text": "Skyclad"}
{"answers": {"text": ["Skyclad", "Skyclad", "Skyclad"], "answer_start": [351, 351, 351]}, "prediction_text": "Skyclad"}
{"answers": {"text": ["Duran Duran", "Duran Duran", "Duran Duran"], "answer_start": [533, 533, 533]}, "prediction_text": "Duran Duran"}
{"answers": {"text": ["November 2006 and May 2008", "November 2006 and May 2008", "between November 2006 and May 2008"], "answer_start": [52, 52, 44]}, "prediction_text": "November 2006"}
{"answers": {"text": ["Old Town Hall", "the Old Town Hall", "the Old Town Hall,"], "answer_start": [140, 136, 136]}, "prediction_text": "Old Town Hall"}
{"answers": {"text": ["three", "three", "three cinemas"], "answer_start": [284, 284, 284]}, "prediction_text": "Three cinemas"}
{"answers": {"text": ["Classic", "Classic", "Classic"], "answer_start": [322, 322, 322]}, "prediction_text": "Classic"}
{"answers": {"text": ["roof", "a roof extension", "a roof"], "answer_start": [437, 435, 435]}, "prediction_text": "In the restored and refurbished original building."}
{"answers": {"text": ["Centre for Life", "the Centre for Life", "Tyneside"], "answer_start": [68, 64, 161]}, "prediction_text": "Centre for Life with its Science Village"}
{"answers": {"text": ["life on Tyneside", "life on Tyneside", "life on Tyneside,"], "answer_start": [153, 153, 153]}, "prediction_text": "Tyneside's shipbuilding heritage"}
{"answers": {"text": ["shipbuilding", "shipbuilding", "shipbuilding"], "answer_start": [192, 192, 192]}, "prediction_text": "Shipbuilding heritage"}
{"answers": {"text": ["2009", "2009", "2009"], "answer_start": [282, 282, 282]}, "prediction_text": "2009"}
{"answers": {"text": ["Seven Stories", "Seven Stories", "Seven Stories"], "answer_start": [384, 384, 384]}, "prediction_text": "Seven Stories"}
{"answers": {"text": ["On the Night of the Fire", "On the Night of the Fire", "On the Night of the Fire (1939),"], "answer_start": [78, 78, 78]}, "prediction_text": "On the Night of the Fire (1939)"}
{"answers": {"text": ["Get Carter", "Get Carter", "Get Carter"], "answer_start": [294, 294, 294]}, "prediction_text": "Get Carter"}
{"answers": {"text": ["gangster", "noir thriller", "gangster film,"], "answer_start": [478, 507, 478]}, "prediction_text": "Noir thriller"}
{"answers": {"text": ["Mike Figgis", "Mike Figgis", "Mike Figgis"], "answer_start": [548, 548, 548]}, "prediction_text": "Mike Figgis"}
{"answers": {"text": ["Sting", "Sting", "Sting"], "answer_start": [608, 608, 608]}, "prediction_text": "Tommy Lee Jones"}
{"answers": {"text": ["Gosforth Park", "Gosforth Park", "Gosforth Park"], "answer_start": [39, 39, 39]}, "prediction_text": "At Gosforth Park"}
{"answers": {"text": ["the Newcastle Eagles", "the Newcastle Eagles", "Newcastle Eagles"], "answer_start": [79, 79, 83]}, "prediction_text": "Newcastle Eagles"}
{"answers": {"text": ["Newcastle Diamonds", "Newcastle Diamonds", "Newcastle Diamonds"], "answer_start": [322, 322, 322]}, "prediction_text": "Newcastle Diamonds"}
{"answers": {"text": ["Brough Park", "Brough Park", "at Brough Park in Byker"], "answer_start": [354, 354, 351]}, "prediction_text": "South Shields"}
{"answers": {"text": ["Blaydon Race", "Blaydon Race", "Blaydon Race"], "answer_start": [727, 727, 727]}, "prediction_text": "Blaydon Race"}
{"answers": {"text": ["6 miles", "6", "6 miles"], "answer_start": [57, 57, 57]}, "prediction_text": "Approximately 6 miles (9.7 km)"}
{"answers": {"text": ["Metro Light Rail system", "Metro Light Rail", "via the Metro Light Rail system"], "answer_start": [251, 251, 243]}, "prediction_text": "By Metro Light Rail system"}
{"answers": {"text": ["20 minutes", "20 minutes", "20 minutes"], "answer_start": [336, 336, 336]}, "prediction_text": "20 minutes"}
{"answers": {"text": ["over five million", "over five million", "over five million passengers"], "answer_start": [368, 368, 368]}, "prediction_text": "Over five million"}
{"answers": {"text": ["over 90", "over 90", "over 90 destinations"], "answer_start": [579, 579, 579]}, "prediction_text": "Over 90 destinations"}
{"answers": {"text": ["Victorian architecture", "Victorian architecture", "the Victorian architecture"], "answer_start": [115, 115, 111]}, "prediction_text": "Victorian architecture was enhanced."}
{"answers": {"text": ["six", "six", "six"], "answer_start": [225, 225, 225]}, "prediction_text": "Six Grade One listed railway stations"}
{"answers": {"text": ["Victoria", "Victoria", "Queen Victoria"], "answer_start": [298, 298, 292]}, "prediction_text": "Queen Victoria"}
{"answers": {"text": ["Robert Stephenson.", "Robert Stephenson", "John Dobson"], "answer_start": [519, 519, 464]}, "prediction_text": "John Dobson"}
{"answers": {"text": ["Manors", "Manors", "Manors"], "answer_start": [754, 754, 754]}, "prediction_text": "Manors"}
{"answers": {"text": ["half-hourly", "half-hourly", "half-hourly"], "answer_start": [51, 51, 51]}, "prediction_text": "About three hours"}
{"answers": {"text": ["about three", "three", "about three hours"], "answer_start": [130, 136, 130]}, "prediction_text": "About three hours"}
{"answers": {"text": ["Edinburgh", "Edinburgh", "Edinburgh"], "answer_start": [293, 293, 293]}, "prediction_text": "Edinburgh"}
{"answers": {"text": ["CrossCountry", "CrossCountry", "CrossCountry"], "answer_start": [377, 377, 377]}, "prediction_text": "Northern Rail"}
{"answers": {"text": ["Northern Rail", "Northern Rail", "Northern Rail"], "answer_start": [537, 537, 537]}, "prediction_text": "Northern Rail"}
{"answers": {"text": ["Tyne and Wear Metro", "the Tyne and Wear Metro", "the Tyne and Wear Metro"], "answer_start": [26, 22, 22]}, "prediction_text": "Tyne and Wear Metro"}
{"answers": {"text": ["five", "five", "five phases"], "answer_start": [142, 142, 142]}, "prediction_text": "Five phases"}
{"answers": {"text": ["deep-level", "deep-level", "deep-level tunnels"], "answer_start": [369, 369, 369]}, "prediction_text": "Deep-level tunnels"}
{"answers": {"text": ["A bridge", "A bridge", "A bridge"], "answer_start": [431, 431, 431]}, "prediction_text": "A bridge"}
{"answers": {"text": ["over 37 million", "over 37 million", "over 37 million passengers"], "answer_start": [609, 609, 609]}, "prediction_text": "37 million"}
{"answers": {"text": ["Metro: All Change.'", "Metro: All Change", "Metro: All Change"], "answer_start": [90, 90, 90]}, "prediction_text": "Metro: All Change"}
{"answers": {"text": ["smart ticketing", "smart ticketing", "smart ticketing."], "answer_start": [237, 237, 237]}, "prediction_text": "Smart ticketing"}
{"answers": {"text": ["tracks, signalling and overhead wires", "tracks, signalling and overhead wires", "tracks, signalling and overhead wires"], "answer_start": [439, 439, 439]}, "prediction_text": "Tracks, signalling, and overhead wires."}
{"answers": {"text": ["an entirely new fleet of trains", "new fleet of trains", "an entirely new fleet of trains"], "answer_start": [549, 561, 549]}, "prediction_text": "Longer term plans include new trains."}
{"answers": {"text": ["trams", "trams", "trams"], "answer_start": [865, 865, 865]}, "prediction_text": "Trams"}
{"answers": {"text": ["the A1", "A1", "the A1 (Gateshead Newcastle Western Bypass)"], "answer_start": [32, 36, 32]}, "prediction_text": "A1 (Gateshead Newcastle Western Bypass)"}
{"answers": {"text": ["the A696", "A69", "A69"], "answer_start": [241, 211, 211]}, "prediction_text": "A69"}
{"answers": {"text": ["the old \"Great North Road\"", "Great North Road", "Great North Road"], "answer_start": [380, 389, 389]}, "prediction_text": "\"Great North Road\""}
{"answers": {"text": ["the roads", "the roads", "roads"], "answer_start": [707, 707, 711]}, "prediction_text": "Roads between Newcastle upon completion and its former alignment"}
{"answers": {"text": ["the capacity of the Tyne Tunnel", "capacity of the Tyne Tunnel", "the capacity of the Tyne Tunnel"], "answer_start": [906, 910, 906]}, "prediction_text": "The capacity of the Tyne Tunnel"}
{"answers": {"text": ["3", "3", "3"], "answer_start": [10, 10, 10]}, "prediction_text": "Three main bus companies"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [133, 133, 133]}, "prediction_text": "Two major bus stations"}
{"answers": {"text": ["Stagecoach", "Stagecoach", "Stagecoach"], "answer_start": [532, 532, 532]}, "prediction_text": "Arriva North East"}
{"answers": {"text": ["the Tyne and Wear Passenger Transport Executive.", "the Tyne and Wear Passenger Transport Executive", "Passenger Transport Executive"], "answer_start": [888, 888, 906]}, "prediction_text": "Passenger transport executive"}
{"answers": {"text": ["Go-Ahead", "Go-Ahead", "Go-Ahead"], "answer_start": [368, 368, 368]}, "prediction_text": "Arriva North East"}
{"answers": {"text": ["1998", "1998", "1998"], "answer_start": [109, 109, 109]}, "prediction_text": "1998"}
{"answers": {"text": ["highlighting the usage of cycling", "cycling", "highlighting the usage of cycling"], "answer_start": [193, 219, 193]}, "prediction_text": "Cycling strategies"}
{"answers": {"text": ["healthy", "healthy", "healthy living"], "answer_start": [283, 283, 283]}, "prediction_text": "Healthy living"}
{"answers": {"text": ["one way", "one way", "one way streets"], "answer_start": [508, 508, 508]}, "prediction_text": "One way streets"}
{"answers": {"text": ["national networks", "national networks", "to national networks"], "answer_start": [810, 810, 807]}, "prediction_text": "National networks"}
{"answers": {"text": ["Danish DFDS Seaways", "Danish DFDS Seaways", "DFDS Seaways"], "answer_start": [63, 63, 70]}, "prediction_text": "Danish DFDS Seaways"}
{"answers": {"text": ["end of October 2006", "the end of October 2006", "the end of October 2006"], "answer_start": [187, 183, 183]}, "prediction_text": "End of October 2006"}
{"answers": {"text": ["high fuel prices and new competition from low-cost air services", "high fuel prices and new competition", "high fuel prices and new competition"], "answer_start": [227, 227, 227]}, "prediction_text": "High fuel prices and new competition."}
{"answers": {"text": ["late 2008", "late 2008", "late 2008"], "answer_start": [371, 371, 371]}, "prediction_text": "Late 2008."}
{"answers": {"text": ["Thomson", "Thomson", "Thomson cruise lines"], "answer_start": [401, 401, 401]}, "prediction_text": "Thomson cruise lines"}
{"answers": {"text": ["eleven", "eleven", "eleven"], "answer_start": [10, 10, 10]}, "prediction_text": "Eleven schools"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [49, 49, 49]}, "prediction_text": "Seven schools"}
{"answers": {"text": ["the Royal Grammar School", "the Royal Grammar School", "the Royal Grammar School"], "answer_start": [423, 423, 423]}, "prediction_text": "Newcastle High School for Girls"}
{"answers": {"text": ["Newcastle College", "Newcastle College", "Newcastle College"], "answer_start": [688, 688, 688]}, "prediction_text": "Newcastle College"}
{"answers": {"text": ["Catholic", "Catholic", "Catholic"], "answer_start": [928, 928, 928]}, "prediction_text": "Catholic"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [13, 13, 13]}, "prediction_text": "Two universities"}
{"answers": {"text": ["Newcastle University", "Newcastle University", "Newcastle University"], "answer_start": [81, 81, 81]}, "prediction_text": "Newcastle University"}
{"answers": {"text": ["Sunday Times University of the Year award", "Sunday Times University of the Year", "Sunday Times University of the Year award"], "answer_start": [386, 386, 386]}, "prediction_text": "\"Best New University\" award"}
{"answers": {"text": ["polytechnics became new universities", "polytechnics became new universities", "polytechnics became new universities"], "answer_start": [628, 628, 628]}, "prediction_text": "Polytechnics became new universities."}
{"answers": {"text": ["Northumbria University", "Northumbria University", "Northumbria University"], "answer_start": [666, 666, 666]}, "prediction_text": "Northumbria University"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [14, 14, 14]}, "prediction_text": "Three cathedrals"}
{"answers": {"text": ["1474", "1474", "1474"], "answer_start": [93, 93, 93]}, "prediction_text": "1474"}
{"answers": {"text": ["Coptic", "Coptic", "Coptic Cathedral"], "answer_start": [170, 170, 170]}, "prediction_text": "Coptic Cathedral"}
{"answers": {"text": ["Thomas", "the Church of St Thomas", "the Church of St Thomas the Martyr"], "answer_start": [392, 375, 375]}, "prediction_text": "St. Thomas the Martyr"}
{"answers": {"text": ["parish churches", "parish churches", "as parish churches"], "answer_start": [248, 248, 245]}, "prediction_text": "Parish churches"}
{"answers": {"text": ["The Parish Church of St Andrew", "The Parish Church of St Andrew", "The Parish Church of St Andrew is"], "answer_start": [0, 0, 0]}, "prediction_text": "Parish Church of St Andrew"}
{"answers": {"text": ["1726", "1726", "1726"], "answer_start": [223, 223, 223]}, "prediction_text": "1726"}
{"answers": {"text": ["the main porch", "the main porch", "the main porch"], "answer_start": [205, 205, 205]}, "prediction_text": "Main porch"}
{"answers": {"text": ["ancient churchyards", "ancient churchyards", "ancient churchyards"], "answer_start": [568, 568, 568]}, "prediction_text": "Last of ancient churchyards"}
{"answers": {"text": ["The church tower", "The church tower", "The church tower"], "answer_start": [706, 706, 706]}, "prediction_text": "The church tower"}
{"answers": {"text": ["City Road", "City Road", "City Road"], "answer_start": [27, 27, 27]}, "prediction_text": "City Road, Gateshead"}
{"answers": {"text": ["a new facility", "The Watermark business park", "The Watermark business park"], "answer_start": [109, 127, 127]}, "prediction_text": "To a new facility on The Watermark business park"}
{"answers": {"text": ["The entrance to studio 5", "The entrance to studio 5", "Road complex"], "answer_start": [193, 193, 230]}, "prediction_text": "The entrance to studio 5 at the City Road complex gave its name to the 1980s music television program \"The Tube\"."}
{"answers": {"text": ["result of its colouring", "its colouring", "its colouring,"], "answer_start": [432, 442, 442]}, "prediction_text": "For its colouring"}
{"answers": {"text": ["BBC Radio Newcastle", "BBC Radio Newcastle", "BBC Radio Newcastle"], "answer_start": [599, 599, 599]}, "prediction_text": "BBC Radio Newcastle"}
{"answers": {"text": ["NE1fm", "NE1fm", "NE1fm"], "answer_start": [0, 0, 0]}, "prediction_text": "NE1fm"}
{"answers": {"text": ["Newcastle Student Radio", "Newcastle Student Radio", "Newcastle Student Radio"], "answer_start": [88, 88, 88]}, "prediction_text": "NE1fm"}
{"answers": {"text": ["since 1951", "1951", "since 1951"], "answer_start": [364, 370, 364]}, "prediction_text": "1951"}
{"answers": {"text": ["Radio Lollipop", "Radio Lollipop", "Radio Lollipop"], "answer_start": [434, 434, 434]}, "prediction_text": "Radio Lollipop"}
{"answers": {"text": ["Newcastle University's student's union building", "Newcastle University", "Newcastle University's student's union building"], "answer_start": [187, 187, 187]}, "prediction_text": "Student's union building"}
{"answers": {"text": ["1770", "1770", "1770"], "answer_start": [137, 137, 137]}, "prediction_text": "1770"}
{"answers": {"text": ["Archbishop of Westminster", "Archbishop of Westminster", "Archbishop of Westminster"], "answer_start": [155, 155, 155]}, "prediction_text": "Archbishop of Westminster"}
{"answers": {"text": ["George Stephenson", "George Stephenson", "George Stephenson,"], "answer_start": [552, 552, 552]}, "prediction_text": "George Stephenson"}
{"answers": {"text": ["the incandescent light bulb", "the steam turbine", "the steam turbine"], "answer_start": [693, 642, 642]}, "prediction_text": "Incandescent light bulb"}
{"answers": {"text": ["Thailand", "Thailand", "Thailand"], "answer_start": [960, 960, 960]}, "prediction_text": "Thailand"}
{"answers": {"text": ["Rutherford Grammar School", "Rutherford Grammar School", "Rutherford Grammar School,"], "answer_start": [160, 160, 160]}, "prediction_text": "Rutherford Grammar School"}
{"answers": {"text": ["international footballers", "international footballers", "international footballers"], "answer_start": [255, 255, 255]}, "prediction_text": "Footballer"}
{"answers": {"text": ["Nobel Prize", "Nobel Prize", "Nobel Prize"], "answer_start": [383, 383, 383]}, "prediction_text": "Nobel Prize"}
{"answers": {"text": ["keyed Northumbrian smallpipes", "keyed Northumbrian smallpipes", "inventor of keyed Northumbrian smallpipes"], "answer_start": [508, 508, 496]}, "prediction_text": "Keyed Northumbrian smallpipes"}
{"answers": {"text": ["Newcastle", "Newcastle", "Newcastle."], "answer_start": [94, 327, 327]}, "prediction_text": "Neville's hometown"}
{"answers": {"text": ["The V&A is located in the Brompton district of the Royal Borough of Kensington and Chelsea", "London", "London", "in the Brompton district of the Royal Borough of Kensington and Chelsea"], "answer_start": [265, 63, 63, 284]}, "prediction_text": "Brompton district of Kensington and Chelsea"}
{"answers": {"text": ["a permanent collection of over 4.5 million objects.", "over 4.5 million objects", "over 4.5 million", "4.5 million"], "answer_start": [140, 166, 166, 171]}, "prediction_text": "Over 4.5 million objects"}
{"answers": {"text": ["It was founded in 1852", "1852", "1852", "1852"], "answer_start": [192, 210, 210, 210]}, "prediction_text": "1852"}
{"answers": {"text": ["named after Queen Victoria and Prince Albert", "Queen Victoria and Prince Albert", "Queen Victoria and Prince Albert", "Queen Victoria and Prince Albert"], "answer_start": [219, 231, 231, 231]}, "prediction_text": "Queen Victoria and Prince Albert"}
{"answers": {"text": ["Royal Borough of Kensington and Chelsea", "Brompton district of the Royal Borough of Kensington and Chelsea", "Brompton district of the Royal Borough of Kensington and Chelsea,", "Royal"], "answer_start": [316, 291, 291, 316]}, "prediction_text": "Kensington and Chelsea"}
{"answers": {"text": ["1852", "1852", "1852", "1852"], "answer_start": [210, 210, 210, 210]}, "prediction_text": "1852"}
{"answers": {"text": ["Queen Victoria and Prince Albert", "Queen Victoria and Prince Albert", "Queen Victoria and Prince Albert", "Queen Victoria and Prince Albert"], "answer_start": [231, 231, 231, 231]}, "prediction_text": "Queen Victoria"}
{"answers": {"text": ["Department for Culture, Media and Sport", "Department for Culture, Media and Sport.", "the Department for Culture, Media and Sport.", "the Department for Culture, Media and Sport"], "answer_start": [691, 691, 687, 687]}, "prediction_text": "Department for Culture, Media and Sport"}
{"answers": {"text": ["2001", "2001", "2001", "2001"], "answer_start": [812, 812, 812, 812]}, "prediction_text": "2001"}
{"answers": {"text": ["12.5", "12.5 acres", "12.5 acres", "12.5"], "answer_start": [15, 15, 15, 15]}, "prediction_text": "51,000 m2"}
{"answers": {"text": ["145", "145", "145 galleries", "145"], "answer_start": [42, 42, 42, 42]}, "prediction_text": "145 galleries"}
{"answers": {"text": ["5,000", "5,000", "5,000 years", "5,000"], "answer_start": [78, 78, 78, 78]}, "prediction_text": "5,000 years"}
{"answers": {"text": ["Europe, North America, Asia and North Africa", "Europe, North America, Asia and North Africa", "Europe, North America, Asia and North Africa", "Europe, North America, Asia and North Africa"], "answer_start": [158, 158, 158, 158]}, "prediction_text": "Europe, North America, Asia, North Africa"}
{"answers": {"text": ["post-classical sculpture", "post-classical sculpture", "post-classical sculpture", "post-classical"], "answer_start": [484, 484, 484, 484]}, "prediction_text": "Renaissance period"}
{"answers": {"text": ["Great Exhibition of 1851", "Great Exhibition of 1851", "Great Exhibition"], "answer_start": [31, 31, 31]}, "prediction_text": "The Great Exhibition of 1851"}
{"answers": {"text": ["Henry Cole", "Henry Cole,", "Henry Cole"], "answer_start": [68, 68, 68]}, "prediction_text": "Henry Cole"}
{"answers": {"text": ["Museum of Manufactures", "Museum of Manufactures", "Museum of Manufactures"], "answer_start": [165, 165, 165]}, "prediction_text": "Museum of Manufactures"}
{"answers": {"text": ["Somerset House", "Somerset House", "Somerset House"], "answer_start": [278, 278, 278]}, "prediction_text": "Somerset House"}
{"answers": {"text": ["Gottfried Semper", "Gottfried Semper", "Gottfried Semper"], "answer_start": [619, 619, 619]}, "prediction_text": "Gottfried Semper"}
{"answers": {"text": ["Queen Victoria", "Queen Victoria", "Queen Victoria"], "answer_start": [24, 24, 24]}, "prediction_text": "Queen Victoria"}
{"answers": {"text": ["22 June 1857", "22 June 1857", "22 June 1857"], "answer_start": [46, 46, 46]}, "prediction_text": "22 June 1857"}
{"answers": {"text": ["George Wallis", "George Wallis", "George Wallis"], "answer_start": [599, 599, 599]}, "prediction_text": "George Wallis"}
{"answers": {"text": ["late night openings", "late night openings", "late night openings"], "answer_start": [83, 83, 83]}, "prediction_text": "In the year 1857, gas lighting was introduced."}
{"answers": {"text": ["1949", "1949", "1949"], "answer_start": [1029, 1029, 1029]}, "prediction_text": "1949"}
{"answers": {"text": ["between September and November 1946", "between September and November 1946,", "between September and November 1946"], "answer_start": [96, 96, 96]}, "prediction_text": "September to November 1946"}
{"answers": {"text": ["nearly a million and a half", "nearly a million and a half visitors", "nearly a million and a half"], "answer_start": [144, 144, 144]}, "prediction_text": "Nearly a million and a half"}
{"answers": {"text": ["Festival of Britain (1951)", "Council of Industrial Design", "the Council of Industrial Design"], "answer_start": [442, 208, 204]}, "prediction_text": "Council of Industrial Design"}
{"answers": {"text": ["Festival of Britain", "Festival of Britain", "the Festival of Britain"], "answer_start": [442, 442, 438]}, "prediction_text": "Festival of Britain"}
{"answers": {"text": ["1948", "1948", "1948"], "answer_start": [473, 473, 473]}, "prediction_text": "1948"}
{"answers": {"text": ["a rock concert", "present a rock concert", "a rock concert"], "answer_start": [119, 111, 119]}, "prediction_text": "A combined concert/lecture by British progressive folk-rock band Gryphon."}
{"answers": {"text": ["Gryphon", "Gryphon", "Gryphon"], "answer_start": [218, 218, 218]}, "prediction_text": "Gryphon"}
{"answers": {"text": ["Roy Strong", "Roy Strong", "Roy Strong"], "answer_start": [463, 463, 463]}, "prediction_text": "Roy Strong"}
{"answers": {"text": ["mediaeval music", "explored the lineage of mediaeval music and instrumentation and related how those contributed to contemporary music 500 years later", "mediaeval"], "answer_start": [255, 231, 255]}, "prediction_text": "Rock music"}
{"answers": {"text": ["Dundee", "Dundee", "Dundee"], "answer_start": [179, 179, 179]}, "prediction_text": "Dundee"}
{"answers": {"text": ["\u00a376 million", "\u00a376 million", "\u00a376 million"], "answer_start": [315, 315, 315]}, "prediction_text": "\u00a376 million"}
{"answers": {"text": ["on the city's waterfront", "on the city's waterfront", "on the city's waterfront"], "answer_start": [421, 421, 421]}, "prediction_text": "On the city's waterfront"}
{"answers": {"text": ["fashion, architecture, product design, graphic arts and photography", "fashion, architecture, product design, graphic arts and photography", "fashion, architecture, product design, graphic arts and photography"], "answer_start": [474, 474, 474]}, "prediction_text": "Fashion, architecture, product design, graphic arts, photography."}
{"answers": {"text": ["within five years", "within five years"], "answer_start": [576, 576]}, "prediction_text": "Within five years"}
{"answers": {"text": ["Brompton Park House", "Brompton Park House", "Brompton Park House"], "answer_start": [302, 302, 302]}, "prediction_text": "South Kensington"}
{"answers": {"text": ["Sheepshanks Gallery", "Sheepshanks Gallery", "1857"], "answer_start": [601, 601, 624]}, "prediction_text": "Sheepshanks Gallery"}
{"answers": {"text": ["Captain Francis Fowke", "Captain Francis Fowke", "Captain Francis Fowke"], "answer_start": [697, 697, 697]}, "prediction_text": "Captain Francis Fowke"}
{"answers": {"text": ["Secretariat Wing", "June 1862", "June 1862"], "answer_start": [1257, 1089, 1089]}, "prediction_text": "1862"}
{"answers": {"text": ["offices and board room", "houses the offices and board room etc. and is not open to the public", "the offices and board room etc."], "answer_start": [1310, 1299, 1306]}, "prediction_text": "Office and board room."}
{"answers": {"text": ["Oriental Courts", "Owen Jones", "Owen Jones"], "answer_start": [536, 509, 509]}, "prediction_text": "Owen Jones"}
{"answers": {"text": ["Italian Renaissance", "Italian Renaissance", "Italian Renaissance"], "answer_start": [1369, 1369, 1369]}, "prediction_text": "Italian Renaissance"}
{"answers": {"text": ["James Gamble & Reuben Townroe", "James Gamble & Reuben Townroe", "James Gamble & Reuben Townroe"], "answer_start": [1541, 1541, 1541]}, "prediction_text": "James Gamble & Reuben Townroe"}
{"answers": {"text": ["Isaac Newton", "Isaac Newton (astronomy", "Isaac Newton"], "answer_start": [1626, 1626, 1626]}, "prediction_text": "Humphry Davy"}
{"answers": {"text": ["Titian", "Michelangelo (sculpture)", "Michelangelo"], "answer_start": [1727, 1701, 1701]}, "prediction_text": "Humphry Davy"}
{"answers": {"text": ["Philip Webb and William Morris", "Philip Webb and William Morris", "Philip Webb and William Morris"], "answer_start": [129, 129, 129]}, "prediction_text": "Philip Webb and William Morris"}
{"answers": {"text": ["Edward Burne-Jones", "Edward Burne-Jones", "Edward Burne-Jones"], "answer_start": [452, 452, 452]}, "prediction_text": "Edward Burne-Jones"}
{"answers": {"text": ["James Gamble", "James Gamble,", "James Gamble"], "answer_start": [547, 547, 547]}, "prediction_text": "James Gamble"}
{"answers": {"text": ["Alfred Stevens", "Alfred Stevens", "Alfred Stevens"], "answer_start": [804, 804, 804]}, "prediction_text": "Alfred Stevens"}
{"answers": {"text": ["Sir Edward Poynter", "Sir Edward Poynter", "Sir Edward Poynter"], "answer_start": [941, 941, 941]}, "prediction_text": "Sir Edward Poynter"}
{"answers": {"text": ["Henry Young Darracott Scott", "Colonel (later Major General) Henry Young Darracott Scott,", "Colonel (later Major General) Henry Young Darracott Scott"], "answer_start": [132, 102, 102]}, "prediction_text": "Colonel (later Major General) Henry Young Darracott Scott"}
{"answers": {"text": ["School for Naval Architects", "the science schools", "School for Naval Architects"], "answer_start": [250, 293, 250]}, "prediction_text": "Henry Cole Wing"}
{"answers": {"text": ["Cadeby stone", "Cadeby stone", "Cadeby"], "answer_start": [467, 467, 467]}, "prediction_text": "Portland stone"}
{"answers": {"text": ["prints and architectural drawings", "(prints, drawings, paintings and photographs)", "prints and architectural drawings"], "answer_start": [604, 649, 604]}, "prediction_text": "Prints and drawings"}
{"answers": {"text": ["2008", "2008", "2008"], "answer_start": [838, 838, 838]}, "prediction_text": "2008"}
{"answers": {"text": ["sgraffito", "sgraffito", "sgraffito"], "answer_start": [179, 179, 179]}, "prediction_text": "Sgraffito was used."}
{"answers": {"text": ["Starkie Gardner", "Starkie Gardner", "Starkie Gardner"], "answer_start": [348, 348, 348]}, "prediction_text": "F. W. Moody"}
{"answers": {"text": ["southeast of the garden", "the southeast of the garden (the site of the \"Brompton Boilers\"),", "southeast of the garden"], "answer_start": [466, 462, 466]}, "prediction_text": "Southeast of the garden"}
{"answers": {"text": ["Art Library", "the south side of the garden", "south side of the garden"], "answer_start": [755, 808, 812]}, "prediction_text": "South side of the garden"}
{"answers": {"text": ["Reuben Townroe", "Reuben Townroe", "Reuben Townroe"], "answer_start": [912, 912, 912]}, "prediction_text": "Sir John Taylor"}
{"answers": {"text": ["Aston Webb", "Aston Webb", "Aston Webb"], "answer_start": [128, 128, 128]}, "prediction_text": "Aston Webb"}
{"answers": {"text": ["red brick and Portland stone", "red brick and Portland stone", "red brick and Portland stone"], "answer_start": [28, 28, 28]}, "prediction_text": "Red brick and Portland stone"}
{"answers": {"text": ["720 feet", "720 feet", "720 feet"], "answer_start": [68, 68, 68]}, "prediction_text": "720 feet (220 m)"}
{"answers": {"text": ["a statue of fame", "statue of fame", "an open work crown surmounted by a statue of fame"], "answer_start": [636, 638, 603]}, "prediction_text": "Open work crown surmounted by a statue of fame"}
{"answers": {"text": ["top row of windows", "top row of windows", "the top row of windows"], "answer_start": [851, 851, 847]}, "prediction_text": "The top row of windows"}
{"answers": {"text": ["Alfred Drury", "Alfred Drury.", "Alfred Drury"], "answer_start": [144, 144, 144]}, "prediction_text": "Alfred Drury"}
{"answers": {"text": ["four", "four levels", "four"], "answer_start": [181, 181, 181]}, "prediction_text": "Four levels"}
{"answers": {"text": ["Alfred Drury", "Webb", "Webb"], "answer_start": [144, 231, 231]}, "prediction_text": "Alfred Drury"}
{"answers": {"text": ["marble", "marble", "marble"], "answer_start": [414, 414, 414]}, "prediction_text": "marble"}
{"answers": {"text": ["Queen Victoria", "Prince Albert", "Queen Victoria"], "answer_start": [69, 0, 69]}, "prediction_text": "Queen Victoria"}
{"answers": {"text": ["Art Library", "new storage space for books in the Art Library", "new storage space for books in the Art Library"], "answer_start": [241, 206, 206]}, "prediction_text": "Art Library"}
{"answers": {"text": ["Henry Cole wing", "Henry Cole wing", "Henry Cole wing"], "answer_start": [706, 706, 706]}, "prediction_text": "Henry Cole wing"}
{"answers": {"text": ["a new entrance building", "new entrance building", "a new entrance building"], "answer_start": [931, 933, 931]}, "prediction_text": "A new entrance building"}
{"answers": {"text": ["Christopher Hay and Douglas Coyne", "Christopher Hay and Douglas Coyne", "Christopher Hay and Douglas Coyne"], "answer_start": [1164, 1164, 1164]}, "prediction_text": "Aston Webb"}
{"answers": {"text": ["the Spiral", "the Spiral,", "the Spiral"], "answer_start": [1032, 1032, 1032]}, "prediction_text": "Spiral between 1978 and 1982."}
{"answers": {"text": ["main silverware gallery", "the main glass galleries and the main silverware gallery", "silverware"], "answer_start": [130, 97, 135]}, "prediction_text": "Indian, Japanese, Chinese, iron work, the main glass galleries, the main silverware gallery."}
{"answers": {"text": ["mosaic floors", "the mosaic floors in the sculpture gallery", "mosaic floors"], "answer_start": [414, 410, 414]}, "prediction_text": "The mosaic floors were restored."}
{"answers": {"text": ["FuturePlan", "FuturePlan", "FuturePlan"], "answer_start": [708, 708, 708]}, "prediction_text": "FuturePlan"}
{"answers": {"text": ["South Kensington", "South Kensington", "South Kensington"], "answer_start": [1097, 1097, 1097]}, "prediction_text": "South Kensington tube station"}
{"answers": {"text": ["McInnes Usher McKnight Architects", "Gareth Hoskins was responsible for contemporary and architecture, Softroom, Islamic Middle East and the Members' Room, McInnes Usher McKnight Architects", "McInnes Usher McKnight Architects"], "answer_start": [1812, 1693, 1812]}, "prediction_text": "Gareth Hoskins"}
{"answers": {"text": ["Kim Wilkie", "Kim Wilkie", "Kim Wilkie"], "answer_start": [37, 37, 37]}, "prediction_text": "Kim Wilkie"}
{"answers": {"text": ["John Madejski Garden", "the John Madejski Garden", "John Madejski Garden"], "answer_start": [66, 62, 66]}, "prediction_text": "John Madejski Garden"}
{"answers": {"text": ["elliptical", "elliptical", "elliptical"], "answer_start": [198, 198, 198]}, "prediction_text": "elliptical"}
{"answers": {"text": ["receptions, gatherings or exhibition purposes", "receptions, gatherings or exhibition purposes", "receptions, gatherings or exhibition purposes"], "answer_start": [306, 306, 306]}, "prediction_text": "receptions, gatherings, or exhibition purposes."}
{"answers": {"text": ["American Sweetgum", "orange and lemon trees", "American Sweetgum"], "answer_start": [685, 796, 685]}, "prediction_text": "American Sweetgum tree"}
{"answers": {"text": ["2004", "2004", "2004"], "answer_start": [3, 3, 3]}, "prediction_text": "2004"}
{"answers": {"text": ["Royal Institute of British Architects", "Royal Institute of British Architects", "Royal Institute of British Architects"], "answer_start": [27, 27, 27]}, "prediction_text": "Royal Institute of British Architects"}
{"answers": {"text": ["over 600,000", "over 600,000", "600,000"], "answer_start": [413, 413, 418]}, "prediction_text": "Over 600,000 drawings"}
{"answers": {"text": ["RIBA Drawings and Archives Collection", "RIBA Drawings and Archives Collection", "RIBA Drawings and Archives Collection"], "answer_start": [276, 276, 276]}, "prediction_text": "RIBA Drawings and Archives Collection"}
{"answers": {"text": ["over 700,000", "over 700,000", "700,000"], "answer_start": [479, 479, 484]}, "prediction_text": "Over 700,000"}
{"answers": {"text": ["Andrea Palladio", "Andrea Palladio", "Andrea Palladio"], "answer_start": [235, 235, 235]}, "prediction_text": "Jacques Gentilhatre"}
{"answers": {"text": ["Zaha Hadid", "Andrea Palladio", "Zaha Hadid"], "answer_start": [990, 235, 990]}, "prediction_text": "Inigo Jones"}
{"answers": {"text": ["over 330", "over 330", "over 330"], "answer_start": [214, 214, 214]}, "prediction_text": "Over 330 drawings"}
{"answers": {"text": ["Sir Christopher Wren", "Sir Christopher Wren", "Sir Christopher Wren"], "answer_start": [482, 482, 482]}, "prediction_text": "Andrea Palladio"}
{"answers": {"text": ["Sir Edwin Lutyens", "Zaha Hadid", "Sir Edwin Lutyens"], "answer_start": [852, 990, 852]}, "prediction_text": "Andrea Palladio"}
{"answers": {"text": ["Bishopsgate", "Bishopsgate", "Bishopsgate"], "answer_start": [159, 159, 159]}, "prediction_text": "Bishopsgate"}
{"answers": {"text": ["Great Fire of London", "Great Fire of London", "Great Fire of London"], "answer_start": [248, 248, 248]}, "prediction_text": "Great Fire of London"}
{"answers": {"text": ["c1600", "c1600", "c1600"], "answer_start": [148, 148, 148]}, "prediction_text": "Bishopsgate (1516)"}
{"answers": {"text": ["Montal", "chateau of Montal", "Montal"], "answer_start": [482, 471, 482]}, "prediction_text": "Montal"}
{"answers": {"text": ["Alhambra", "Alhambra", "Alhambra"], "answer_start": [782, 782, 782]}, "prediction_text": "Alhambra"}
{"answers": {"text": ["over 19,000", "over 19,000", "over 19,000"], "answer_start": [14, 14, 14]}, "prediction_text": "Over 19,000 items"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [184, 184, 184]}, "prediction_text": "2006"}
{"answers": {"text": ["Ardabil Carpet", "the Ardabil Carpet", "Ardabil Carpet"], "answer_start": [266, 262, 266]}, "prediction_text": "Ardabil Carpet"}
{"answers": {"text": ["Spain", "Spain, North Africa, the Middle East, Central Asia and Afghanistan", "Spain"], "answer_start": [362, 362, 362]}, "prediction_text": "Spain"}
{"answers": {"text": ["1909", "1909", "1909"], "answer_start": [1016, 1016, 1016]}, "prediction_text": "1909"}
{"answers": {"text": ["nearly 60,000", "nearly 60,000", "nearly 60,000"], "answer_start": [123, 123, 123]}, "prediction_text": "Nearly 60,000 objects"}
{"answers": {"text": ["about 10,000", "10,000", "10,000"], "answer_start": [156, 162, 162]}, "prediction_text": "About 10,000"}
{"answers": {"text": ["6000", "6000", "6000"], "answer_start": [182, 182, 182]}, "prediction_text": "About 10,000"}
{"answers": {"text": ["1991", "1991", "1991"], "answer_start": [292, 292, 292]}, "prediction_text": "1991"}
{"answers": {"text": ["Jawaharlal Nehru", "Jawaharlal Nehru", "Jawaharlal Nehru"], "answer_start": [242, 242, 242]}, "prediction_text": "Jawaharlal Nehru"}
{"answers": {"text": ["more than 70,000", "more than 70,000", "70,000"], "answer_start": [36, 36, 46]}, "prediction_text": "Over 70,000 works of art"}
{"answers": {"text": ["China, Japan and Korea", "China, Japan and Korea", "East Asia: China, Japan and Korea"], "answer_start": [99, 99, 88]}, "prediction_text": "China, Japan, Korea"}
{"answers": {"text": ["The T. T. Tsui Gallery", "T. T. Tsui Gallery of Chinese art", "The T. T. Tsui Gallery of Chinese art"], "answer_start": [123, 127, 123]}, "prediction_text": "T. T. Tsui Gallery"}
{"answers": {"text": ["1991", "1991", "1991"], "answer_start": [171, 171, 171]}, "prediction_text": "1991"}
{"answers": {"text": ["Ming and Qing", "Ming and Qing", "Ming and Qing"], "answer_start": [381, 381, 381]}, "prediction_text": "Ming and Qing dynasties"}
{"answers": {"text": ["Toshiba", "Toshiba", "Toshiba"], "answer_start": [4, 4, 4]}, "prediction_text": "Ando Cloisonn\u00e9"}
{"answers": {"text": ["1986", "1986", "1986"], "answer_start": [55, 55, 55]}, "prediction_text": "December 1986"}
{"answers": {"text": ["13th", "13th-century", "13th"], "answer_start": [156, 156, 156]}, "prediction_text": "1550 to 1900"}
{"answers": {"text": ["from 1550 to 1900", "1550 to 1900", "1550 to 1900"], "answer_start": [91, 96, 96]}, "prediction_text": "1550 to 1900"}
{"answers": {"text": ["bronze", "bronze", "bronze"], "answer_start": [703, 703, 703]}, "prediction_text": "Bronze"}
{"answers": {"text": ["from the 14th to the 19th century", "14th to the 19th century", "14th to the 19th century"], "answer_start": [353, 362, 362]}, "prediction_text": "14th to 19th centuries"}
{"answers": {"text": ["Sri Lanka", "Thailand", "Thailand"], "answer_start": [560, 519, 519]}, "prediction_text": "South East Asia"}
{"answers": {"text": ["Hindu and Buddhist sculptures", "Refined Hindu and Buddhist sculptures", "betel-nut cutters, ivory combs and bronze palanquin hooks"], "answer_start": [720, 712, 804]}, "prediction_text": "Betel-nut cutters"}
{"answers": {"text": ["mother-of-pearl", "mother-of-pearl", "mother-of-pearl"], "answer_start": [197, 197, 197]}, "prediction_text": "Mother-of-pearl"}
{"answers": {"text": ["ivory", "ivory", "ivory"], "answer_start": [823, 823, 823]}, "prediction_text": "ivory"}
{"answers": {"text": ["Leonardo da Vinci", "Leonardo da Vinci", "Leonardo da Vinci"], "answer_start": [72, 72, 72]}, "prediction_text": "Leonardo da Vinci"}
{"answers": {"text": ["Forster I, Forster II, and Forster III", "Forster I, Forster II, and Forster III,", "Forster I, Forster II, and Forster III"], "answer_start": [161, 161, 161]}, "prediction_text": "Forster I, Forster II, and Forster III."}
{"answers": {"text": ["over 14,000", "over 14,000", "over 14,000"], "answer_start": [601, 601, 601]}, "prediction_text": "Over 18,000 books"}
{"answers": {"text": ["1869", "1869", "1869"], "answer_start": [636, 636, 636]}, "prediction_text": "1876"}
{"answers": {"text": ["1876", "1876", "1876"], "answer_start": [504, 504, 504]}, "prediction_text": "1876"}
{"answers": {"text": ["Charles Dickens", "Charles Dickens", "Charles Dickens"], "answer_start": [58, 58, 58]}, "prediction_text": "Charles Dickens and Beatrix Potter"}
{"answers": {"text": ["Beatrix Potter", "Beatrix Potter", "Beatrix Potter"], "answer_start": [78, 78, 78]}, "prediction_text": "Charles Dickens and Beatrix Potter"}
{"answers": {"text": ["from the 12th to 16th", "12th to 16th", "12th to 16th"], "answer_start": [140, 149, 149]}, "prediction_text": "12th to 16th centuries"}
{"answers": {"text": ["the trial and rehabilitation of Joan of Arc", "trial and rehabilitation of Joan of Arc", "the trial and rehabilitation of Joan of Arc"], "answer_start": [432, 436, 432]}, "prediction_text": "Joan of Arc's trial and rehabilitation."}
{"answers": {"text": ["Lucas Horenbout", "Lucas Horenbout", "Lucas Horenbout"], "answer_start": [380, 380, 380]}, "prediction_text": "Lucas Horenbout"}
{"answers": {"text": ["Word and Image Department", "Word and Image Department", "Word and Image Department"], "answer_start": [38, 38, 38]}, "prediction_text": "Word and Image Department"}
{"answers": {"text": ["MODES", "MODES", "MODES"], "answer_start": [235, 235, 235]}, "prediction_text": "MODES cataloging system"}
{"answers": {"text": ["Encoded Archival Description", "Encoded Archival Description (EAD", "Encoded Archival Description (EAD)"], "answer_start": [431, 431, 431]}, "prediction_text": "Encoded Archival Description (EAD)"}
{"answers": {"text": ["newly accessioned into the collection", "newly accessioned", "newly accessioned into the collection"], "answer_start": [579, 579, 579]}, "prediction_text": "Archival material"}
{"answers": {"text": ["Search the Collections", "Search the Collections,", "Search the Collections"], "answer_start": [736, 736, 736]}, "prediction_text": "\"Search the Collections\""}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [202, 202, 202]}, "prediction_text": "2007"}
{"answers": {"text": ["Factory Project", "Factory Project", "the Factory Project"], "answer_start": [883, 257, 253]}, "prediction_text": "Factory Project"}
{"answers": {"text": ["Andy Warhol", "Andy Warhol", "Andy Warhol"], "answer_start": [286, 286, 286]}, "prediction_text": "Andy Warhol"}
{"answers": {"text": ["15,000", "15,000", "15,000"], "answer_start": [696, 696, 696]}, "prediction_text": "15,000 images were digitized."}
{"answers": {"text": ["to catalog everything", "catalog everything", "to catalog everything"], "answer_start": [902, 905, 902]}, "prediction_text": "Audit the collection."}
{"answers": {"text": ["British patrons", "British patrons", "British patrons"], "answer_start": [150, 150, 150]}, "prediction_text": "British patrons"}
{"answers": {"text": ["Asia", "Asia", "Asia"], "answer_start": [191, 191, 191]}, "prediction_text": "Asia"}
{"answers": {"text": ["Gian Lorenzo Bernini", "Gian Lorenzo Bernini", "Gian Lorenzo Bernini"], "answer_start": [311, 311, 311]}, "prediction_text": "Gian Lorenzo Bernini"}
{"answers": {"text": ["Horace Walpole", "Horace Walpole", "Horace Walpole"], "answer_start": [640, 640, 640]}, "prediction_text": "Horace Walpole"}
{"answers": {"text": ["porcelain, cloth and wallpaper", "porcelain, cloth and wallpaper", "porcelain, cloth and wallpaper"], "answer_start": [207, 207, 207]}, "prediction_text": "Porcelain, cloth, wallpaper."}
{"answers": {"text": ["increase in tea drinking", "increase in tea drinking", "increase in tea drinking"], "answer_start": [470, 470, 470]}, "prediction_text": "Increasing trade and technology"}
{"answers": {"text": ["increasing emphasis on entertainment and leisure", "printed books and the work of European artists and craftsmen employed in Britain", "entertainment and leisure"], "answer_start": [403, 140, 426]}, "prediction_text": "Entertainment and leisure"}
{"answers": {"text": ["John Ruskin", "John Ruskin", "John Ruskin"], "answer_start": [1218, 1218, 1218]}, "prediction_text": "John Ruskin"}
{"answers": {"text": ["the growth of mass production", "the growth of mass production", "mass production"], "answer_start": [667, 667, 681]}, "prediction_text": "Mass production"}
{"answers": {"text": ["Arts and Crafts", "Gothic Revival", "Arts and Crafts"], "answer_start": [1250, 1009, 1250]}, "prediction_text": "Arts and Crafts movement"}
{"answers": {"text": ["Trajan's Column", "sculpture wing", "Trajan's Column"], "answer_start": [264, 71, 264]}, "prediction_text": "Michelangelo's David"}
{"answers": {"text": ["cut in half", "cut in half", "cut in half"], "answer_start": [281, 281, 281]}, "prediction_text": "Cut in half"}
{"answers": {"text": ["David", "David.", "David"], "answer_start": [477, 477, 477]}, "prediction_text": "David"}
{"answers": {"text": ["sculptures, friezes and tombs", "sculptures, friezes and tombs", "sculptures, friezes and tombs"], "answer_start": [180, 180, 180]}, "prediction_text": "sculptures"}
{"answers": {"text": ["in a glass case", "glass case", "in a glass case"], "answer_start": [649, 654, 649]}, "prediction_text": "In a glass case."}
{"answers": {"text": ["1731", "1731"], "answer_start": [197, 197]}, "prediction_text": "1731"}
{"answers": {"text": ["Frederick II the Great", "Frederick II the Great", "Frederick II the Great"], "answer_start": [258, 258, 258]}, "prediction_text": "Frederick II the Great"}
{"answers": {"text": ["1762", "1762", "1762"], "answer_start": [250, 250, 250]}, "prediction_text": "1762"}
{"answers": {"text": ["1909", "1909", "1909"], "answer_start": [742, 742, 742]}, "prediction_text": "1909"}
{"answers": {"text": ["Chinese and Japanese ceramics", "Chinese and Japanese ceramics.", "Chinese and Japanese ceramics"], "answer_start": [785, 785, 785]}, "prediction_text": "The collection of Chinese and Japanese ceramics"}
{"answers": {"text": ["Josiah Wedgwood, William De Morgan and Bernard Leach", "Josiah Wedgwood, William De Morgan and Bernard Leach", "Josiah Wedgwood, William De Morgan and Bernard Leach"], "answer_start": [29, 29, 29]}, "prediction_text": "Josiah Wedgwood, William De Morgan, Bernard Leach."}
{"answers": {"text": ["Britain and Holland", "Britain and Holland", "Britain and Holland"], "answer_start": [215, 215, 215]}, "prediction_text": "Britain and Holland"}
{"answers": {"text": ["ceramic stoves", "a series of elaborately ornamented ceramic stoves", "a series of elaborately ornamented ceramic stoves"], "answer_start": [488, 453, 453]}, "prediction_text": "A series of elaborately ornamented ceramic stoves"}
{"answers": {"text": ["from the 16th and 17th centuries", "16th and 17th centuries,", "16th and 17th centuries"], "answer_start": [503, 512, 512]}, "prediction_text": "1695-1695"}
{"answers": {"text": ["Germany and Switzerland", "Germany and Switzerland", "Germany and Switzerland"], "answer_start": [545, 545, 545]}, "prediction_text": "Germany and Switzerland"}
{"answers": {"text": ["4000", "4000 years", "4000"], "answer_start": [28, 28, 28]}, "prediction_text": "4000 years"}
{"answers": {"text": ["over 6000", "over 6000", "over 6000"], "answer_start": [64, 64, 64]}, "prediction_text": "4000 items"}
{"answers": {"text": ["Ancient Egypt", "Ancient Egypt", "Ancient Egypt"], "answer_start": [173, 173, 173]}, "prediction_text": "Ancient Egypt"}
{"answers": {"text": ["Ren\u00e9 Lalique", "Ren\u00e9 Lalique", "Ren\u00e9 Lalique"], "answer_start": [459, 459, 459]}, "prediction_text": "Ren\u00e9 Lalique"}
{"answers": {"text": ["Louis Comfort Tiffany and \u00c9mile Gall\u00e9", "Louis Comfort Tiffany and \u00c9mile Gall\u00e9", "Louis Comfort Tiffany and \u00c9mile Gall\u00e9"], "answer_start": [363, 363, 363]}, "prediction_text": "Louis Comfort Tiffany and \u00c9mile Gall\u00e9"}
{"answers": {"text": ["1994", "1994", "1994"], "answer_start": [35, 35, 35]}, "prediction_text": "1994"}
{"answers": {"text": ["Danny Lane", "Danny Lane,", "Danny Lane"], "answer_start": [109, 109, 109]}, "prediction_text": "Danny Lane"}
{"answers": {"text": ["2004", "2004", "2004"], "answer_start": [171, 171, 171]}, "prediction_text": "2004"}
{"answers": {"text": ["Dale Chihuly", "Dale Chihuly", "Dale Chihuly"], "answer_start": [793, 793, 793]}, "prediction_text": "Dale Chihuly"}
{"answers": {"text": ["13th", "13th-century", "13th"], "answer_start": [552, 552, 552]}, "prediction_text": "13th century"}
{"answers": {"text": ["over 10,000", "over 10,000", "10,000"], "answer_start": [36, 36, 41]}, "prediction_text": "Over 10,000 drawings"}
{"answers": {"text": ["2,000", "2,000", "2,000"], "answer_start": [60, 60, 60]}, "prediction_text": "Over 10,000 old masters works"}
{"answers": {"text": ["D\u00fcrer", "D\u00fcrer", "D\u00fcrer"], "answer_start": [104, 104, 104]}, "prediction_text": "D\u00fcrer"}
{"answers": {"text": ["Rembrandt", "Rembrandt", "Rembrandt"], "answer_start": [165, 165, 165]}, "prediction_text": "Paul Nash"}
{"answers": {"text": ["Jean Auguste Dominique Ingres", "Jean Auguste Dominique Ingres,", "Jean Auguste Dominique Ingres"], "answer_start": [326, 326, 326]}, "prediction_text": "Paul Nash"}
{"answers": {"text": ["over 14,000", "over 14,000 outfits", "over 14,000", "over 14,000"], "answer_start": [72, 72, 72, 72]}, "prediction_text": "1,442 items"}
{"answers": {"text": ["Word and Image department", "Word and Image department.", "Word and Image", "Word and Image"], "answer_start": [237, 237, 237, 237]}, "prediction_text": "Word and Image"}
{"answers": {"text": ["Because everyday clothing from previous eras has not generally survived", "Because everyday clothing from previous eras has not generally survived", "everyday clothing from previous eras has not generally survived", "everyday clothing from previous eras has not generally survived"], "answer_start": [264, 264, 272, 272]}, "prediction_text": "For special occasions, fashionable clothes are made."}
{"answers": {"text": ["1913", "1913", "1913", "1913"], "answer_start": [470, 470, 470, 470]}, "prediction_text": "1913"}
{"answers": {"text": ["Harrods", "Harrods", "Harrods", "Harrods"], "answer_start": [577, 577, 577, 577]}, "prediction_text": "Harrods"}
{"answers": {"text": ["2002", "2002", "2002"], "answer_start": [3, 3, 3]}, "prediction_text": "2002"}
{"answers": {"text": ["Vivienne Westwood", "Coco Chanel", "Vivienne Westwood"], "answer_start": [59, 146, 59]}, "prediction_text": "Vivienne Westwood"}
{"answers": {"text": ["178", "178", "178"], "answer_start": [55, 55, 55]}, "prediction_text": "178 costumes"}
{"answers": {"text": ["Costiff", "Vivienne Westwood", "Costiff"], "answer_start": [33, 59, 33]}, "prediction_text": "Costiff collection"}
{"answers": {"text": ["modern", "modern fashion", "modern"], "answer_start": [463, 463, 463]}, "prediction_text": "Modern fashion"}
{"answers": {"text": ["Italian and French Renaissance", "Italian and French Renaissance objects", "Renaissance"], "answer_start": [27, 27, 46]}, "prediction_text": "Italian and French Renaissance"}
{"answers": {"text": ["between 1859 and 1865", "1859 and 1865", "between 1859 and 1865"], "answer_start": [79, 87, 79]}, "prediction_text": "1859"}
{"answers": {"text": ["French 18th-century art and furnishings", "art and furnishings", "art and furnishings"], "answer_start": [161, 181, 181]}, "prediction_text": "French 18th-century art and furnishings"}
{"answers": {"text": ["1882", "1882", "1882"], "answer_start": [227, 227, 227]}, "prediction_text": "1882"}
{"answers": {"text": ["\u00a3250,000", "\u00a3250,000", "\u00a3250,000"], "answer_start": [248, 248, 248]}, "prediction_text": "\u00a3250,000"}
{"answers": {"text": ["1580", "1580", "1580"], "answer_start": [49, 49, 49]}, "prediction_text": "1580"}
{"answers": {"text": ["Hans Vredeman de Vries", "Hans Vredeman de Vries", "Hans Vredeman de Vries"], "answer_start": [92, 92, 92]}, "prediction_text": "Hans Vredeman de Vries"}
{"answers": {"text": ["c1750", "c1750", "c1750"], "answer_start": [232, 232, 232]}, "prediction_text": "1750"}
{"answers": {"text": ["Germany", "Germany", "Germany"], "answer_start": [243, 243, 243]}, "prediction_text": "Germany"}
{"answers": {"text": ["Charles and Ray Eames", "Charles and Ray Eames", "Charles and Ray Eames"], "answer_start": [815, 815, 815]}, "prediction_text": "Ernest Gimson, Edward William Godwin, Charles Voysey, Adolf Loos, Otto Wagner."}
{"answers": {"text": ["over 6000", "over 6000", "over 6000"], "answer_start": [37, 37, 37]}, "prediction_text": "Over 6000 items"}
{"answers": {"text": ["Ancient Egypt", "Ancient Egypt", "Ancient Egypt"], "answer_start": [166, 166, 166]}, "prediction_text": "Ancient Egypt"}
{"answers": {"text": ["1869", "1869"], "answer_start": [937, 937]}, "prediction_text": "1951"}
{"answers": {"text": ["154", "1869,", "154"], "answer_start": [914, 937, 914]}, "prediction_text": "154 gems"}
{"answers": {"text": ["William and Judith Bollinger", "William and Judith Bollinger", "William and Judith Bollinger"], "answer_start": [1189, 1189, 1189]}, "prediction_text": "William and Judith Bollinger"}
{"answers": {"text": ["secular and sacred", "secular and sacred covering both Christian (Roman Catholic, Anglican and Greek Orthodox) and Jewish liturgical vessels and items", "secular and sacred"], "answer_start": [132, 132, 132]}, "prediction_text": "secular and sacred"}
{"answers": {"text": ["1496\u201397", "1496\u201397", "1496\u201397"], "answer_start": [537, 537, 537]}, "prediction_text": "1496\u201397"}
{"answers": {"text": ["8", "8 tonnes", "nearly 8"], "answer_start": [1003, 1003, 996]}, "prediction_text": "8 tonnes"}
{"answers": {"text": ["Sir George Gilbert Scott", "Sir George Gilbert Scott", "Sir George Gilbert Scott"], "answer_start": [1062, 1062, 1062]}, "prediction_text": "Jean Tijou"}
{"answers": {"text": ["over 10,000", "over 10,000", "over 10,000"], "answer_start": [10, 10, 10]}, "prediction_text": "Over 10,000 objects"}
{"answers": {"text": ["c1110", "c1110", "c1110"], "answer_start": [93, 93, 93]}, "prediction_text": "c1110"}
{"answers": {"text": ["gilt bronze", "gilt bronze", "gilt bronze"], "answer_start": [110, 110, 110]}, "prediction_text": "Gilt bronze"}
{"answers": {"text": ["St Thomas Becket", "St Thomas Becket,", "St Thomas Becket"], "answer_start": [338, 338, 338]}, "prediction_text": "St Thomas Becket's relics"}
{"answers": {"text": ["c1180", "c1180", "c1180"], "answer_start": [311, 311, 311]}, "prediction_text": "1180"}
{"answers": {"text": ["gilt copper", "gilt copper", "gilt copper"], "answer_start": [366, 366, 366]}, "prediction_text": "Gilt copper"}
{"answers": {"text": ["over 5,100", "over 5,100", "over 5,100"], "answer_start": [122, 122, 122]}, "prediction_text": "Over 5,100 names"}
{"answers": {"text": ["Bryan Davies", "Bryan Davies", "Bryan Davies"], "answer_start": [258, 258, 258]}, "prediction_text": "Bryan Davies"}
{"answers": {"text": ["Horniman Museum", "The Horniman", "Horniman"], "answer_start": [551, 696, 551]}, "prediction_text": "Horniman Museum"}
{"answers": {"text": ["35", "35", "35"], "answer_start": [801, 801, 801]}, "prediction_text": "35 instruments"}
{"answers": {"text": ["2010", "2010,", "2010"], "answer_start": [51, 51, 51]}, "prediction_text": "2010"}
{"answers": {"text": ["1130", "1130"], "answer_start": [30, 30]}, "prediction_text": "About 1130 British oil paintings"}
{"answers": {"text": ["650", "650"], "answer_start": [47, 47]}, "prediction_text": "About 1130"}
{"answers": {"text": ["6800", "6800"], "answer_start": [75, 75]}, "prediction_text": "About 1130"}
{"answers": {"text": ["Queen Elizabeth II", "Queen Elizabeth II"], "answer_start": [232, 232]}, "prediction_text": "Her Majesty the Queen Elizabeth II"}
{"answers": {"text": ["Andr\u00e9s Marzal De Sax", "Andr\u00e9s Marzal De Sax"], "answer_start": [774, 774]}, "prediction_text": "Andr\u00e9s Marzal De Sax"}
{"answers": {"text": ["1857", "1857", "1857"], "answer_start": [3, 3, 3]}, "prediction_text": "1857"}
{"answers": {"text": ["233", "233", "233"], "answer_start": [33, 33, 33]}, "prediction_text": "233 paintings"}
{"answers": {"text": ["forming a 'A National Gallery of British Art'", "forming a 'A National Gallery of British Art',", "forming a 'A National Gallery of British Art'"], "answer_start": [157, 157, 157]}, "prediction_text": "Forming a National Gallery of British Art"}
{"answers": {"text": ["The Hay Wain", "The Hay Wain.", "The Hay Wain"], "answer_start": [698, 698, 698]}, "prediction_text": "The Hay Wain"}
{"answers": {"text": ["British", "British", "British"], "answer_start": [71, 71, 71]}, "prediction_text": "British"}
{"answers": {"text": ["continental art 1600\u20131800", "of continental art 1600\u20131800", "galleries of continental art"], "answer_start": [263, 260, 250]}, "prediction_text": "continental art 1600\u20131800"}
{"answers": {"text": ["Madame de Pompadour", "Madame de Pompadour", "Madame de Pompadour"], "answer_start": [431, 431, 431]}, "prediction_text": "Fran\u00e7ois Clouet's portrait"}
{"answers": {"text": ["Carlo Crivelli's Virgin and Child", "Carlo Crivelli's Virgin and Child)", "Carlo Crivelli's Virgin and Child"], "answer_start": [136, 136, 136]}, "prediction_text": "Carlo Crivelli's Virgin and Child"}
{"answers": {"text": ["Fran\u00e7ois, Duc d'Alen\u00e7on", "Duc d'Alen\u00e7on", "Duc d'Alen\u00e7on"], "answer_start": [316, 326, 326]}, "prediction_text": "Fran\u00e7ois Clouet's portrait"}
{"answers": {"text": ["Eadweard Muybridge", "Eadweard Muybridge's", "Eadweard Muybridge"], "answer_start": [47, 47, 47]}, "prediction_text": "Eadweard Muybridge"}
{"answers": {"text": ["1887", "1887", "1887"], "answer_start": [104, 104, 104]}, "prediction_text": "1887"}
{"answers": {"text": ["781", "781", "781"], "answer_start": [127, 127, 127]}, "prediction_text": "781 plates"}
{"answers": {"text": ["animals and humans performimg various actions", "images of different animals and humans performimg various actions", "different animals and humans performimg various actions"], "answer_start": [233, 213, 223]}, "prediction_text": "Images of different animals and humans performing actions."}
{"answers": {"text": ["James Lafayette", "James Lafayette's", "James Lafayette"], "answer_start": [396, 396, 396]}, "prediction_text": "James Lafayette's society portraits"}
{"answers": {"text": ["post-classical European", "post-classical European sculpture", "post-classical European"], "answer_start": [73, 73, 73]}, "prediction_text": "About 400 AD to 1914"}
{"answers": {"text": ["22,000", "22,000 objects", "22,000"], "answer_start": [145, 145, 145]}, "prediction_text": "22,000 objects"}
{"answers": {"text": ["from about 400 AD to 1914", "400 AD to 1914", "400 AD to 1914"], "answer_start": [200, 211, 211]}, "prediction_text": "About 400 AD to 1914"}
{"answers": {"text": ["All", "All uses", "All"], "answer_start": [438, 438, 438]}, "prediction_text": "Tomb and memorial, portrait, allegorical, religious, mythical, statues for gardens."}
{"answers": {"text": ["National Galleries of Scotland", "National Galleries of Scotland", "National Galleries of Scotland"], "answer_start": [224, 224, 224]}, "prediction_text": "National Galleries of Scotland"}
{"answers": {"text": ["Neptune and Triton", "Neptune and Triton", "Neptune and Triton"], "answer_start": [932, 932, 932]}, "prediction_text": "The Chancel Chapel"}
{"answers": {"text": ["Chancel Chapel", "Chancel Chapel", "Chancel Chapel"], "answer_start": [1469, 1469, 1469]}, "prediction_text": "The Chancel Chapel from Santa Chiara Florence"}
{"answers": {"text": ["Giuliano da Sangallo", "Giuliano da Sangallo", "Santa Chiara Florence"], "answer_start": [1540, 1540, 1489]}, "prediction_text": "Giuliano da Sangallo"}
{"answers": {"text": ["1493\u20131500", "1493\u20131500,", "1493\u20131500"], "answer_start": [1517, 1517, 1517]}, "prediction_text": "1493\u20131500"}
{"answers": {"text": ["more than 20", "20 works", "20"], "answer_start": [24, 34, 34]}, "prediction_text": "Over 20 works"}
{"answers": {"text": ["the sculptor", "by the sculptor", "Rodin"], "answer_start": [183, 180, 0]}, "prediction_text": "The sculptor in 1914"}
{"answers": {"text": ["1914", "1914", "1914"], "answer_start": [199, 199, 199]}, "prediction_text": "1914"}
{"answers": {"text": ["World War I", "World War I,", "World War I"], "answer_start": [258, 258, 258]}, "prediction_text": "World War I"}
{"answers": {"text": ["St John the Baptist", "St John the Baptist", "St John the Baptist"], "answer_start": [294, 294, 294]}, "prediction_text": "St John the Baptist"}
{"answers": {"text": ["George Frampton", "Agostino Carlini", "George Frampton"], "answer_start": [445, 249, 445]}, "prediction_text": "Nicholas Stone"}
{"answers": {"text": ["Thomas Brock", "Thomas Brock", "Thomas Brock"], "answer_start": [415, 415, 415]}, "prediction_text": "Nicholas Stone"}
{"answers": {"text": ["Sir Francis Chantrey", "Sir Francis Chantrey,", "Sir Francis Chantrey"], "answer_start": [328, 328, 328]}, "prediction_text": "Nicholas Stone"}
{"answers": {"text": ["Europeans who were based in Britain", "British and Europeans who were based in Britain", "both British and Europeans"], "answer_start": [27, 15, 10]}, "prediction_text": "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers, Sir Henry Cheere, Agostino Carlini, Thomas Banks, Joseph Nollekens, Joseph Wilton, John Flaxman, Sir Francis Chantrey, John Gibson, Edward Hodges Baily, Lord Leighton, Alfred Stevens, Thomas Brock, Alfred Gilbert, George Frampton, and Eric Gill."}
{"answers": {"text": ["Dorothy and Michael Hintze", "Dorothy and Michael Hintze", "Dorothy and Michael Hintze"], "answer_start": [24, 24, 24]}, "prediction_text": "Dorothy and Michael Hintze"}
{"answers": {"text": ["1950", "1600 to 1950", "1600 to 1950"], "answer_start": [149, 364, 364]}, "prediction_text": "1950"}
{"answers": {"text": ["by theme", "by theme, tomb sculpture, portraiture, garden sculpture and mythology", "by theme, tomb sculpture, portraiture, garden sculpture and mythology"], "answer_start": [614, 614, 614]}, "prediction_text": "By theme, tomb sculpture, portraiture, garden sculpture, mythology."}
{"answers": {"text": ["Henry Moore and Jacob Epstein", "Henry Moore and Jacob Epstein", "Henry Moore and Jacob Epstein"], "answer_start": [233, 233, 233]}, "prediction_text": "Henry Moore and Jacob Epstein"}
{"answers": {"text": ["Tate Britain", "Tate Britain", "Tate Britain"], "answer_start": [207, 207, 207]}, "prediction_text": "Tate Britain"}
{"answers": {"text": ["more than 53,000", "53,000", "53,000"], "answer_start": [39, 49, 49]}, "prediction_text": "53,000 items"}
{"answers": {"text": ["all populated continents", "western European", "all populated continents"], "answer_start": [97, 73, 97]}, "prediction_text": "Western Europe"}
{"answers": {"text": ["from the 1st century AD to the present", "1st century AD to the present,", "1st century AD to the present"], "answer_start": [146, 155, 155]}, "prediction_text": "1st century AD to present"}
{"answers": {"text": ["western Europe", "all populated continents", "western European"], "answer_start": [73, 97, 73]}, "prediction_text": "Near East"}
{"answers": {"text": ["by technique", "technique", "technique"], "answer_start": [356, 359, 359]}, "prediction_text": "By technique, countries of origin and date of production."}
{"answers": {"text": ["Cloth of St Gereon", "Cloth of St Gereon", "a fragment of the Cloth of St Gereon"], "answer_start": [51, 51, 33]}, "prediction_text": "Cloth of St Gereon"}
{"answers": {"text": ["15th", "15th-century", "15th"], "answer_start": [200, 200, 200]}, "prediction_text": "15th-century"}
{"answers": {"text": ["the Netherlands", "Netherlands", "the Netherlands"], "answer_start": [234, 238, 234]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["hunting of various animals", "hunting of various animals", "the hunting of various animals"], "answer_start": [265, 265, 261]}, "prediction_text": "Hunting of various animals."}
{"answers": {"text": ["John Vanderbank's workshop", "John Vanderbank's", "John Vanderbank"], "answer_start": [553, 553, 553]}, "prediction_text": "John Vanderbank's workshop"}
{"answers": {"text": ["late 14th-century", "late 14th-century", "late 14th-century"], "answer_start": [65, 65, 65]}, "prediction_text": "Late 14th-century"}
{"answers": {"text": ["William Morris", "William Morris", "William Morris"], "answer_start": [217, 217, 217]}, "prediction_text": "William Morris"}
{"answers": {"text": ["1887", "1887", "1887"], "answer_start": [318, 318, 318]}, "prediction_text": "1887"}
{"answers": {"text": ["Marion Dorn", "Marion Dorn", "Marion Dorn"], "answer_start": [450, 450, 450]}, "prediction_text": "Marion Dorn"}
{"answers": {"text": ["Serge Chermayeff", "Serge Chermayeff", "Serge Chermayeff"], "answer_start": [511, 511, 511]}, "prediction_text": "Serge Chermayeff"}
{"answers": {"text": ["Theatre Museum", "Theatre Museum", "the Theatre Museum"], "answer_start": [54, 54, 50]}, "prediction_text": "Theatre Museum"}
{"answers": {"text": ["2009", "2009", "2009"], "answer_start": [86, 86, 86]}, "prediction_text": "2009"}
{"answers": {"text": ["material about live performance", "UK's biggest national collection of material about live performance in the UK", "material about live performance in the UK since Shakespeare's day"], "answer_start": [242, 206, 242]}, "prediction_text": "UK's biggest national collection of material about live performance"}
{"answers": {"text": ["Shakespeare", "Shakespeare's", "Shakespeare"], "answer_start": [290, 290, 290]}, "prediction_text": "Shakespeare"}
{"answers": {"text": ["research, exhibitions and other shows", "research, exhibitions and other shows", "research, exhibitions and other shows"], "answer_start": [153, 153, 153]}, "prediction_text": "Research, exhibitions, and shows."}
{"answers": {"text": ["Conservation", "Conservation", "Conservation"], "answer_start": [0, 0, 0]}, "prediction_text": "Conservation of the collections"}
{"answers": {"text": ["temperature and light", "temperature and light", "temperature and light"], "answer_start": [572, 572, 572]}, "prediction_text": "Temperature and light"}
{"answers": {"text": ["interventive", "interventive", "interventive"], "answer_start": [690, 690, 690]}, "prediction_text": "Interventive conservation"}
{"answers": {"text": ["V&A Museum of Childhood", "V&A Museum of Childhood"], "answer_start": [134, 134]}, "prediction_text": "The V&A Museum of Childhood"}
{"answers": {"text": ["preventive", "preventive", "preventive"], "answer_start": [269, 269, 269]}, "prediction_text": "Correct packaging"}
{"answers": {"text": ["The Walt Disney Company", "Disney\u2013ABC Television Group", "Disney\u2013ABC Television Group"], "answer_start": [236, 157, 157]}, "prediction_text": "Disney\u2013ABC Television Group"}
{"answers": {"text": ["1957", "1957", "1957"], "answer_start": [75, 75, 75]}, "prediction_text": "1957"}
{"answers": {"text": ["Manhattan", "Manhattan", "Manhattan"], "answer_start": [391, 391, 391]}, "prediction_text": "Manhattan"}
{"answers": {"text": ["Columbus Avenue and West 66th Street", "Columbus Avenue and West 66th Street", "Columbus Avenue and West 66th Street"], "answer_start": [351, 351, 351]}, "prediction_text": "Columbus Avenue"}
{"answers": {"text": ["Disney Media Networks", "Disney Media Networks", "Disney Media Networks"], "answer_start": [202, 202, 202]}, "prediction_text": "The Walt Disney Company"}
{"answers": {"text": ["October 12, 1943", "October 12, 1943", "October 12, 1943"], "answer_start": [27, 27, 27]}, "prediction_text": "October 12, 1943"}
{"answers": {"text": ["radio network", "radio", "radio network"], "answer_start": [49, 49, 49]}, "prediction_text": "Radio network"}
{"answers": {"text": ["1948", "1948", "1948"], "answer_start": [222, 222, 222]}, "prediction_text": "1948"}
{"answers": {"text": ["ESPN", "ESPN", "ESPN"], "answer_start": [672, 672, 672]}, "prediction_text": "ESPN"}
{"answers": {"text": ["Capital Cities Communications", "Capital Cities Communications", "Capital Cities Communications"], "answer_start": [711, 711, 711]}, "prediction_text": "The Walt Disney Company"}
{"answers": {"text": ["232", "232", "over 232"], "answer_start": [61, 61, 56]}, "prediction_text": "Eight affiliated stations"}
{"answers": {"text": ["Citadel Broadcasting", "Citadel Broadcasting", "Citadel Broadcasting"], "answer_start": [768, 768, 768]}, "prediction_text": "Citadel Broadcasting"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [27, 27, 27]}, "prediction_text": "Eight owned-and-operated stations"}
{"answers": {"text": ["Canadian Radio-television and Telecommunications Commission", "Canadian Radio-television and Telecommunications Commission", "Canadian Radio-television and Telecommunications Commission"], "answer_start": [449, 449, 449]}, "prediction_text": "Canadian Radio-television and Telecommunications Commission"}
{"answers": {"text": ["Citadel Broadcasting", "Citadel Broadcasting", "Citadel Broadcasting"], "answer_start": [768, 768, 768]}, "prediction_text": "Citadel Broadcasting"}
{"answers": {"text": ["Radio Corporation of America", "Radio Corporation of America (RCA)", "Radio Corporation of America"], "answer_start": [238, 238, 238]}, "prediction_text": "Radio Corporation of America"}
{"answers": {"text": ["NBC Blue and NBC Red", "NBC Blue and NBC Red", "NBC Blue and NBC Red"], "answer_start": [355, 355, 355]}, "prediction_text": "NBC Blue and NBC Red"}
{"answers": {"text": ["major cities", "major cities", "major cities"], "answer_start": [545, 545, 545]}, "prediction_text": "Major cities"}
{"answers": {"text": ["drama series", "drama series", "drama series"], "answer_start": [571, 571, 571]}, "prediction_text": "Drama series"}
{"answers": {"text": ["NBC Blue", "NBC Blue Network", "NBC Blue Network"], "answer_start": [381, 381, 381]}, "prediction_text": "NBC Blue Network"}
{"answers": {"text": ["Mutual", "Mutual", "Mutual filed"], "answer_start": [9, 9, 9]}, "prediction_text": "Mutual"}
{"answers": {"text": ["1938", "1938", "1938"], "answer_start": [210, 210, 210]}, "prediction_text": "1938"}
{"answers": {"text": ["1940", "1940", "1940"], "answer_start": [368, 368, 368]}, "prediction_text": "1940"}
{"answers": {"text": ["NBC Red Network", "NBC Red Network", "NBC Red Network"], "answer_start": [471, 471, 471]}, "prediction_text": "NBC Red Network"}
{"answers": {"text": ["NBC Blue", "NBC Blue", "NBC Blue"], "answer_start": [581, 581, 581]}, "prediction_text": "NBC Blue"}
{"answers": {"text": ["Mark Woods", "Mark Woods", "Mark Woods"], "answer_start": [124, 124, 124]}, "prediction_text": "Mark Woods"}
{"answers": {"text": ["NBC Blue Network", "NBC Blue Network", "NBC Blue Network"], "answer_start": [154, 154, 154]}, "prediction_text": "NBC Blue"}
{"answers": {"text": ["Dillon, Read & Co.", "Dillon, Read & Co", "Dillon, Read & Co."], "answer_start": [867, 867, 867]}, "prediction_text": "Dillon, Read & Co."}
{"answers": {"text": ["David Sarnoff", "David Sarnoff", "David Sarnoff"], "answer_start": [1051, 1051, 1051]}, "prediction_text": "David Sarnoff"}
{"answers": {"text": ["$7.5 million", "$7.5 million", "$7.5 million"], "answer_start": [959, 959, 959]}, "prediction_text": "$7.5 million"}
{"answers": {"text": ["Life Savers candy", "Life Savers", "Life Savers"], "answer_start": [32, 32, 32]}, "prediction_text": "Life Savers"}
{"answers": {"text": ["October 12, 1943", "October 12, 1943", "October 12, 1943"], "answer_start": [371, 371, 371]}, "prediction_text": "October 12, 1943"}
{"answers": {"text": ["George B. Storer", "George B. Storer", "1944"], "answer_start": [592, 592, 612]}, "prediction_text": "George B. Storer"}
{"answers": {"text": ["president and CEO", "president and CEO", "president"], "answer_start": [733, 733, 733]}, "prediction_text": "Vice-chairman"}
{"answers": {"text": ["June 30, 1951", "1951", "June 30, 1951"], "answer_start": [872, 881, 872]}, "prediction_text": "June 30, 1951"}
{"answers": {"text": ["Magnetophon tape recorder", "Magnetophon", "Magnetophon tape recorder"], "answer_start": [693, 693, 693]}, "prediction_text": "Magnetophon tape recorder"}
{"answers": {"text": ["Paul Whiteman", "Paul Whiteman", "Paul Whiteman"], "answer_start": [153, 153, 153]}, "prediction_text": "Paul Whiteman"}
{"answers": {"text": ["ABC", "ABC", "NBC Blue"], "answer_start": [0, 0, 68]}, "prediction_text": "NBC"}
{"answers": {"text": ["Bing Crosby", "Bing Crosby", "Bing Crosby"], "answer_start": [960, 960, 960]}, "prediction_text": "Bing Crosby"}
{"answers": {"text": ["public service", "public service", "public service"], "answer_start": [93, 93, 93]}, "prediction_text": "Public service"}
{"answers": {"text": ["$155 million", "$155 million", "$155 million"], "answer_start": [402, 402, 402]}, "prediction_text": "$155 million"}
{"answers": {"text": ["ABC1", "ABC1", "ABC1"], "answer_start": [717, 717, 717]}, "prediction_text": "ABC1"}
{"answers": {"text": ["September 8, 2007", "September 8, 2007", "September 8, 2007"], "answer_start": [803, 803, 803]}, "prediction_text": "September 8, 2007"}
{"answers": {"text": ["ABC International", "ABC International", "ABC International"], "answer_start": [1006, 1006, 1006]}, "prediction_text": "ABC International"}
{"answers": {"text": ["United States", "United States", "United States"], "answer_start": [494, 494, 494]}, "prediction_text": "United Kingdom"}
{"answers": {"text": ["1959", "1959", "1959"], "answer_start": [130, 130, 130]}, "prediction_text": "1959"}
{"answers": {"text": ["satellite television", "The arrival of satellite television", "satellite television"], "answer_start": [273, 258, 273]}, "prediction_text": "Satellite television"}
{"answers": {"text": ["Japan and Latin America", "Japan and Latin America", "Japan and Latin America"], "answer_start": [591, 591, 591]}, "prediction_text": "Japan and Latin America"}
{"answers": {"text": ["legislation to limit foreign ownership of broadcasting properties", "legislation to limit foreign ownership of broadcasting properties", "governments also wanted to increase their independence and strengthen legislation"], "answer_start": [430, 430, 360]}, "prediction_text": "To strengthen legislation."}
{"answers": {"text": ["coronation of Queen Elizabeth II", "the coronation of Queen Elizabeth II", "the coronation of Queen Elizabeth II"], "answer_start": [364, 360, 360]}, "prediction_text": "Coronation of Queen Elizabeth II"}
{"answers": {"text": ["Beirut", "Beirut", "Beirut"], "answer_start": [1030, 1030, 1030]}, "prediction_text": "Lebanon"}
{"answers": {"text": ["Mainichi Broadcasting System", "Mainichi Broadcasting System", "Mainichi Broadcasting System"], "answer_start": [897, 897, 897]}, "prediction_text": "Mainichi Broadcasting System"}
{"answers": {"text": ["flight delays", "technical problems and flight delays", "technical problems and flight delays"], "answer_start": [517, 494, 494]}, "prediction_text": "Technical problems and flight delays."}
{"answers": {"text": ["technical problems", "technical problems and flight delays", "technical problems and flight delays"], "answer_start": [494, 494, 494]}, "prediction_text": "Technical problems and flight delays."}
{"answers": {"text": ["Peanuts", "Peanuts", "Peanuts"], "answer_start": [367, 367, 367]}, "prediction_text": "Peanuts television specials"}
{"answers": {"text": ["Emmy Awards", "Emmy Awards", "Emmy Awards"], "answer_start": [64, 64, 64]}, "prediction_text": "Academy Awards"}
{"answers": {"text": ["1965", "1965", "1965"], "answer_start": [476, 476, 476]}, "prediction_text": "1965"}
{"answers": {"text": ["the Academy Awards", "Academy Awards", "Academy Awards, Emmy Awards"], "answer_start": [44, 48, 48]}, "prediction_text": "Academy Awards"}
{"answers": {"text": ["It's the Great Pumpkin", "It's the Great Pumpkin, Charlie Brown", "It's the Great Pumpkin"], "answer_start": [621, 621, 621]}, "prediction_text": "A Charlie Brown Christmas"}
{"answers": {"text": ["1974", "1974"], "answer_start": [6, 6]}, "prediction_text": "1974"}
{"answers": {"text": ["Ryan Seacrest", "Ryan Seacrest", "Ryan Seacrest"], "answer_start": [158, 158, 158]}, "prediction_text": "Ryan Seacrest"}
{"answers": {"text": ["1954", "1954", "1954"], "answer_start": [452, 452, 452]}, "prediction_text": "1954"}
{"answers": {"text": ["Times Square", "Times Square", "New Year"], "answer_start": [350, 350, 75]}, "prediction_text": "New Year's Eve (in New York City)"}
{"answers": {"text": ["TLC", "TLC", "ABC"], "answer_start": [538, 538, 754]}, "prediction_text": "TLC"}
{"answers": {"text": ["General Hospital", "General Hospital", "General Hospital"], "answer_start": [95, 95, 95]}, "prediction_text": "General Hospital"}
{"answers": {"text": ["1975", "1975", "1975"], "answer_start": [337, 337, 337]}, "prediction_text": "1975"}
{"answers": {"text": ["The Edge of Night", "The Edge of Night", "The Edge of Night"], "answer_start": [707, 707, 707]}, "prediction_text": "The Edge of Night"}
{"answers": {"text": ["The View and The Chew", "The View and The Chew", "The View and The Chew"], "answer_start": [53, 53, 53]}, "prediction_text": "The View, The Chew, General Hospital, The City, Port Charles, Good Morning America, The Edge of Night, The Edge of Night, The Edge of Night, The New York Times, The New York Post, The Washington Post, The New York Times, The Washington Post, The New York Times, The New York Times, The New York Post, The New York Times, The New York Post, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New York Times, The New"}
{"answers": {"text": ["1963", "1963", "1963"], "answer_start": [243, 243, 243]}, "prediction_text": "Since 1963."}
{"answers": {"text": ["X Games", "X Games", "X Games"], "answer_start": [1302, 1302, 1302]}, "prediction_text": "NBA games"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [469, 469, 469]}, "prediction_text": "2006"}
{"answers": {"text": ["12:00 to 6:00 p.m. Eastern Time", "late afternoons", "Saturday Night Football"], "answer_start": [80, 530, 234]}, "prediction_text": "During college football season."}
{"answers": {"text": ["NBA", "NBA", "NBA"], "answer_start": [1357, 1412, 1412]}, "prediction_text": "NBA"}
{"answers": {"text": ["The Open Championship golf and The Wimbledon tennis tournaments", "The Open Championship golf and The Wimbledon", "The Wimbledon"], "answer_start": [1138, 1138, 1169]}, "prediction_text": "NBA games"}
{"answers": {"text": ["Frank Marx", "Frank Marx", "Frank Marx"], "answer_start": [442, 442, 442]}, "prediction_text": "Frank Marx"}
{"answers": {"text": ["channels 2 through 6", "2 through 6", "low-band VHF"], "answer_start": [556, 565, 513]}, "prediction_text": "VHF channel 7"}
{"answers": {"text": ["1947", "1947", "1947"], "answer_start": [157, 157, 157]}, "prediction_text": "1947"}
{"answers": {"text": ["VHF channel 7", "channel 7", "channel 7"], "answer_start": [424, 428, 428]}, "prediction_text": "VHF channel 7"}
{"answers": {"text": ["108", "108", "108"], "answer_start": [329, 329, 329]}, "prediction_text": "108"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [429, 429, 429]}, "prediction_text": "108"}
{"answers": {"text": ["DuMont Television Network", "DuMont Television Network", "DuMont Television Network"], "answer_start": [253, 253, 253]}, "prediction_text": "DuMont Television Network"}
{"answers": {"text": ["CBS and NBC", "CBS and NBC", "CBS and NBC"], "answer_start": [125, 125, 125]}, "prediction_text": "CBS and NBC"}
{"answers": {"text": ["U.S. Supreme Court", "U.S. Supreme Court", "United Paramount Theatres (UPT)"], "answer_start": [93, 93, 43]}, "prediction_text": "U.S. Supreme Court"}
{"answers": {"text": ["Paramount Pictures", "Paramount Pictures", "Paramount Pictures"], "answer_start": [168, 168, 168]}, "prediction_text": "Paramount Pictures"}
{"answers": {"text": ["nine", "nine", "nine"], "answer_start": [285, 285, 285]}, "prediction_text": "Nine affiliates"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [572, 572, 572]}, "prediction_text": "CBS"}
{"answers": {"text": ["Prudential Insurance Company of America", "Prudential Insurance Company of America", "Prudential Insurance Company of America."], "answer_start": [778, 778, 778]}, "prediction_text": "Prudential Insurance Company of America"}
{"answers": {"text": ["Leonard Goldenson", "Leonard Goldenson", "Leonard Goldenson"], "answer_start": [0, 0, 0]}, "prediction_text": "Leonard Goldenson"}
{"answers": {"text": ["William S. Paley", "William S. Paley", "William S. Paley"], "answer_start": [212, 212, 212]}, "prediction_text": "William S. Paley"}
{"answers": {"text": ["June 6, 1951", "June 6, 1951", "June 6, 1951"], "answer_start": [560, 560, 560]}, "prediction_text": "June 6, 1951"}
{"answers": {"text": ["1952", "1952", "1952"], "answer_start": [3, 3, 3]}, "prediction_text": "1952"}
{"answers": {"text": ["February 9, 1953", "February 9, 1953", "February 9, 1953"], "answer_start": [355, 355, 355]}, "prediction_text": "February 9, 1953"}
{"answers": {"text": ["American Broadcasting-Paramount Theatres, Inc", "American Broadcasting-Paramount Theatres, Inc.", "American Broadcasting-Paramount Theatres, Inc"], "answer_start": [479, 479, 479]}, "prediction_text": "American Broadcasting-Paramount Theatres Inc."}
{"answers": {"text": ["the Paramount Building", "Paramount Building at 1501 Broadway in Manhattan", "Paramount Building"], "answer_start": [547, 551, 551]}, "prediction_text": "1501 Broadway"}
{"answers": {"text": ["August 10, 1948", "August 10, 1948", "August 10, 1948"], "answer_start": [123, 123, 123]}, "prediction_text": "August 10, 1948"}
{"answers": {"text": ["October 1948", "October 1948", "October 1948"], "answer_start": [407, 407, 407]}, "prediction_text": "October 1948"}
{"answers": {"text": ["Mount Wilson", "Mount Wilson", "August 1"], "answer_start": [1028, 1028, 1127]}, "prediction_text": "Mount Wilson"}
{"answers": {"text": ["The Prospect Studios", "The Prospect Studios", "The Prospect Studios"], "answer_start": [975, 975, 975]}, "prediction_text": "The Prospect Studios"}
{"answers": {"text": ["September 30, 1960", "September 30, 1960", "September 30, 1960"], "answer_start": [212, 212, 212]}, "prediction_text": "September 30, 1960"}
{"answers": {"text": ["1960s", "1960s", "1960s"], "answer_start": [4, 4, 4]}, "prediction_text": "1960s"}
{"answers": {"text": ["William Hanna and Joseph Barbera", "William Hanna and Joseph Barbera", "William Hanna and Joseph Barbera"], "answer_start": [336, 336, 336]}, "prediction_text": "William Hanna and Joseph Barbera"}
{"answers": {"text": ["1960s", "1960s"], "answer_start": [4, 4]}, "prediction_text": "1960s"}
{"answers": {"text": ["1959", "1959", "1959"], "answer_start": [3, 3, 3]}, "prediction_text": "1959"}
{"answers": {"text": ["NBC", "NBC", "NBC"], "answer_start": [298, 298, 298]}, "prediction_text": "NBC"}
{"answers": {"text": ["1961", "1961", "1961"], "answer_start": [644, 644, 262]}, "prediction_text": "1961"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [707, 707, 707]}, "prediction_text": "1985"}
{"answers": {"text": ["circle logo", "circle logo", "circle logo"], "answer_start": [74, 74, 74]}, "prediction_text": "The dot"}
{"answers": {"text": ["Troika Design Group", "Troika Design Group", "Troika Design Group"], "answer_start": [319, 319, 319]}, "prediction_text": "Troika Design Group"}
{"answers": {"text": ["black-and-yellow", "black-and-yellow", "black-and-yellow"], "answer_start": [409, 409, 409]}, "prediction_text": "Black-and-yellow"}
{"answers": {"text": ["the dot", "\"the dot\"", "the dot"], "answer_start": [100, 99, 100]}, "prediction_text": "\"The dot\""}
{"answers": {"text": ["Pittard Sullivan", "Pittard Sullivan", "Pittard Sullivan"], "answer_start": [78, 78, 78]}, "prediction_text": "Pittard Sullivan"}
{"answers": {"text": ["2015", "2015", "2015"], "answer_start": [935, 935, 935]}, "prediction_text": "1998\u20132002"}
{"answers": {"text": ["\"We Love TV\" image campaign", "We Love TV", "We Love TV"], "answer_start": [464, 465, 465]}, "prediction_text": "\"We Love TV\" image campaign"}
{"answers": {"text": ["ABC on Demand to the beginning of the ABC show", "ABC on Demand", "ABC on Demand"], "answer_start": [1284, 1284, 1284]}, "prediction_text": "ABC's website"}
{"answers": {"text": ["1993\u201394 season", "1993\u201394", "1993\u201394"], "answer_start": [462, 462, 462]}, "prediction_text": "1993\u201394"}
{"answers": {"text": ["1995\u201396 season", "1995\u201396", "2011\u201312"], "answer_start": [645, 645, 774]}, "prediction_text": "2011\u201312 season"}
{"answers": {"text": ["1983", "1983", "1983"], "answer_start": [3, 3, 3]}, "prediction_text": "1983"}
{"answers": {"text": ["That Special Feeling", "That Special Feeling", "That Special Feeling"], "answer_start": [164, 164, 164]}, "prediction_text": "\"That Special Feeling\""}
{"answers": {"text": ["1977", "1977", "1977"], "answer_start": [302, 302, 302]}, "prediction_text": "1977"}
{"answers": {"text": ["black background", "black", "black"], "answer_start": [347, 347, 347]}, "prediction_text": "Black"}
{"answers": {"text": ["glossy gold", "gold", "white, blue, pink, rainbow neon and glittering"], "answer_start": [393, 400, 191]}, "prediction_text": "White"}
{"answers": {"text": ["Paul Rand", "Paul Rand", "Paul Rand"], "answer_start": [26, 26, 26]}, "prediction_text": "Paul Rand"}
{"answers": {"text": ["Bauhaus typeface", "Bauhaus typeface", "Bauhaus"], "answer_start": [293, 293, 293]}, "prediction_text": "Bauhaus typeface"}
{"answers": {"text": ["Herbert Bayer", "Herbert Bayer", "Herbert Bayer"], "answer_start": [322, 322, 322]}, "prediction_text": "Herbert Bayer"}
{"answers": {"text": ["1963\u201364 season", "1963\u201364 season", "1962"], "answer_start": [233, 233, 3]}, "prediction_text": "1962"}
{"answers": {"text": ["ABC Radio", "ABC Radio", "ABC Radio"], "answer_start": [92, 92, 92]}, "prediction_text": "ABC Radio"}
{"answers": {"text": ["October 19, 2005", "October 19, 2005", "October 19, 2005"], "answer_start": [327, 327, 327]}, "prediction_text": "October 19, 2005"}
{"answers": {"text": ["six divisions", "six", "six"], "answer_start": [395, 395, 395]}, "prediction_text": "Six divisions"}
{"answers": {"text": ["2004", "2004", "2004"], "answer_start": [3, 3, 3]}, "prediction_text": "2004"}
{"answers": {"text": ["Grey's Anatomy", "Grey's Anatomy", "Grey's Anatomy"], "answer_start": [397, 397, 397]}, "prediction_text": "Desperate Housewives"}
{"answers": {"text": ["Anne Sweeney", "Anne Sweeney", "Anne Sweeney"], "answer_start": [644, 644, 644]}, "prediction_text": "Anne Sweeney"}
{"answers": {"text": ["NASCAR", "NASCAR", "ESPN"], "answer_start": [936, 936, 878]}, "prediction_text": "NASCAR"}
{"answers": {"text": ["2002", "2002", "2002"], "answer_start": [63, 63, 63]}, "prediction_text": "September 2002"}
{"answers": {"text": ["Michael Eisner", "Michael Eisner", "Michael Eisner"], "answer_start": [103, 103, 103]}, "prediction_text": "Michael Eisner"}
{"answers": {"text": ["The Bachelor", "The Bachelor", "The Bachelor"], "answer_start": [420, 420, 420]}, "prediction_text": "The Bachelor"}
{"answers": {"text": ["The Bachelorette", "The Bachelorette", "The Bachelorette"], "answer_start": [496, 496, 496]}, "prediction_text": "The Bachelorette"}
{"answers": {"text": ["Time Warner Cable", "Time Warner Cable", "Time Warner Cable"], "answer_start": [63, 63, 63]}, "prediction_text": "Time Warner Cable"}
{"answers": {"text": ["ABC", "ABC", "ABC"], "answer_start": [548, 548, 548]}, "prediction_text": "ABC"}
{"answers": {"text": ["ABC", "ABC", "ABC"], "answer_start": [641, 641, 641]}, "prediction_text": "ABC"}
{"answers": {"text": ["afternoon of May 2.", "afternoon of May 2", "December 31, 1999"], "answer_start": [621, 621, 374]}, "prediction_text": "May 2"}
{"answers": {"text": ["2000", "2000", "2000"], "answer_start": [375, 375, 375]}, "prediction_text": "1997\u201398"}
{"answers": {"text": ["The WB", "The WB", "WB"], "answer_start": [524, 524, 528]}, "prediction_text": "The WB"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [648, 648, 648]}, "prediction_text": "ABC"}
{"answers": {"text": ["August 1999", "August 1999", "August 1999"], "answer_start": [3, 3, 3]}, "prediction_text": "August 1999"}
{"answers": {"text": ["Regis Philbin", "Regis Philbin", "Regis Philbin"], "answer_start": [181, 181, 181]}, "prediction_text": "Meredith Vieira"}
{"answers": {"text": ["Buena Vista Television", "Buena Vista Television", "Buena Vista Television"], "answer_start": [679, 679, 679]}, "prediction_text": "Buena Vista Television"}
{"answers": {"text": ["Meredith Vieira", "Meredith Vieira", "Meredith Vieira"], "answer_start": [787, 787, 787]}, "prediction_text": "Meredith Vieira"}
{"answers": {"text": ["July 31, 1995", "July 31, 1995", "On July 31, 1995"], "answer_start": [3, 3, 0]}, "prediction_text": "July 31, 1995"}
{"answers": {"text": ["ABC Inc.", "ABC Inc.", "ABC Inc"], "answer_start": [344, 344, 344]}, "prediction_text": "ABC Inc."}
{"answers": {"text": ["Knight Ridder", "Knight Ridder", "Knight Ridder"], "answer_start": [943, 943, 943]}, "prediction_text": "Knight Ridder"}
{"answers": {"text": ["Robert Iger", "Robert Iger", "Robert Iger"], "answer_start": [1029, 1029, 1029]}, "prediction_text": "Robert Iger"}
{"answers": {"text": ["Sports Night", "Sports Night", "Sports Night"], "answer_start": [1407, 1407, 1407]}, "prediction_text": "Sports Night"}
{"answers": {"text": ["1965\u201366 season", "1965\u201366", "1965\u201366"], "answer_start": [21, 21, 21]}, "prediction_text": "1965\u201366"}
{"answers": {"text": ["third place", "third", "third"], "answer_start": [147, 147, 147]}, "prediction_text": "Third place"}
{"answers": {"text": ["Beating the Odds: The Untold Story Behind the Rise of ABC", "\"Beating the Odds: The Untold Story Behind the Rise of ABC\"", "Beating the Odds: The Untold Story Behind the Rise of ABC"], "answer_start": [414, 413, 414]}, "prediction_text": "\"Beating the Odds: The Untold Story Behind the Rise of ABC\""}
{"answers": {"text": ["May 1, 1953", "May 1, 1953", "May 1, 1953"], "answer_start": [3, 3, 3]}, "prediction_text": "May 1, 1953"}
{"answers": {"text": ["7 West 66th Street", "7 West 66th Street", "7 West 66th Street"], "answer_start": [190, 190, 190]}, "prediction_text": "7 West 66th Street"}
{"answers": {"text": ["Baltimore", "Baltimore", "Baltimore"], "answer_start": [421, 421, 421]}, "prediction_text": "Baltimore"}
{"answers": {"text": ["Robert Kintner", "Robert Kintner", "Robert Kintner"], "answer_start": [99, 99, 99]}, "prediction_text": "Robert Kintner"}
{"answers": {"text": ["DuMont Television Network", "DuMont Television Network", "DuMont Television Network"], "answer_start": [497, 497, 497]}, "prediction_text": "ABC-DuMont"}
{"answers": {"text": ["ABC-DuMont", "ABC-DuMont", "ABC-DuMont"], "answer_start": [628, 628, 628]}, "prediction_text": "ABC-DuMont"}
{"answers": {"text": ["$5 million in cash", "$5 million in cash", "$5 million"], "answer_start": [687, 687, 687]}, "prediction_text": "$5 million"}
{"answers": {"text": ["Paramount Pictures", "Paramount Pictures", "Paramount Pictures"], "answer_start": [231, 231, 231]}, "prediction_text": "Paramount Pictures"}
{"answers": {"text": ["The Lone Ranger", "The Lone Ranger", "The Lone Ranger"], "answer_start": [542, 542, 542]}, "prediction_text": "The Lone Ranger"}
{"answers": {"text": ["The Adventures of Ozzie and Harriet", "The Adventures of Ozzie and Harriet", "The Adventures of Ozzie and Harriet"], "answer_start": [609, 609, 609]}, "prediction_text": "The Lone Ranger"}
{"answers": {"text": ["Cheyenne", "Cheyenne", "Cheyenne"], "answer_start": [297, 297, 297]}, "prediction_text": "Sugarfoot"}
{"answers": {"text": ["Sugarfoot", "Sugarfoot", "Sugarfoot"], "answer_start": [348, 348, 348]}, "prediction_text": "Maverick"}
{"answers": {"text": ["Walt Disney", "Walt Disney", "Walt Disney"], "answer_start": [519, 519, 519]}, "prediction_text": "Walt Disney's agreement with ABC"}
{"answers": {"text": ["Warner Bros. Presents", "wheel series Warner Bros. Presents", "wheel series"], "answer_start": [160, 147, 147]}, "prediction_text": "ABC Presents"}
{"answers": {"text": ["Roy", "Roy", "Roy"], "answer_start": [28, 28, 28]}, "prediction_text": "Roy Disney"}
{"answers": {"text": ["$500,000", "$500,000", "$500,000"], "answer_start": [220, 220, 220]}, "prediction_text": "$500,000"}
{"answers": {"text": ["1954", "1954", "1954"], "answer_start": [342, 342, 342]}, "prediction_text": "1953"}
{"answers": {"text": ["Disneyland", "Disneyland", "Disneyland"], "answer_start": [448, 448, 448]}, "prediction_text": "Disneyland"}
{"answers": {"text": ["Allen Shaw", "Allen Shaw", "Allen Shaw"], "answer_start": [109, 109, 109]}, "prediction_text": "Allen Shaw"}
{"answers": {"text": ["Harold L. Neal", "Harold L. Neal", "Harold L. Neal"], "answer_start": [207, 207, 207]}, "prediction_text": "Harold L. Neal"}
{"answers": {"text": ["LOVE Radio", "LOVE Radio", "LOVE Radio"], "answer_start": [331, 331, 331]}, "prediction_text": "\"LOVE Radio\""}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [418, 418, 418]}, "prediction_text": "Seven stations"}
{"answers": {"text": ["1969", "1969", "September 1969"], "answer_start": [37, 37, 27]}, "prediction_text": "September 1969"}
{"answers": {"text": ["Duel", "Duel", "Duel"], "answer_start": [419, 419, 419]}, "prediction_text": "Duel"}
{"answers": {"text": ["1971", "1971", "1971"], "answer_start": [409, 409, 409]}, "prediction_text": "1971"}
{"answers": {"text": ["$400,000\u2013$450,000", "$400,000\u2013$450,000", "$400,000\u2013$450,000"], "answer_start": [468, 468, 468]}, "prediction_text": "$400,000\u2013$450,000"}
{"answers": {"text": ["early 1970s", "1970s", "1970s"], "answer_start": [7, 13, 13]}, "prediction_text": "1970s"}
{"answers": {"text": ["ABC", "ABC", "ABC"], "answer_start": [112, 112, 112]}, "prediction_text": "ABC"}
{"answers": {"text": ["behavioral and demographic data", "behavioral and demographic", "behavioral and demographic"], "answer_start": [220, 220, 220]}, "prediction_text": "Behavioral and demographic data"}
{"answers": {"text": ["Monday Night Football", "Monday Night Football", "Monday Night Football"], "answer_start": [21, 21, 21]}, "prediction_text": "Monday Night Football"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [209, 209, 209]}, "prediction_text": "2006"}
{"answers": {"text": ["ESPN", "ESPN", "NBC"], "answer_start": [329, 329, 258]}, "prediction_text": "NBC"}
{"answers": {"text": ["15%\u201316%", "15%\u201316%", "15%\u201316%"], "answer_start": [474, 474, 474]}, "prediction_text": "15%\u201316%"}
{"answers": {"text": ["1970", "1970", "1970"], "answer_start": [3, 3, 3]}, "prediction_text": "1970"}
{"answers": {"text": ["1972", "1972", "1972"], "answer_start": [265, 265, 265]}, "prediction_text": "1972"}
{"answers": {"text": ["Worldvision Enterprises", "Worldvision Enterprises", "Worldvision Enterprises"], "answer_start": [381, 381, 381]}, "prediction_text": "ABC Circle Films"}
{"answers": {"text": ["cigarette advertising from all television and radio networks", "cigarette advertising", "1970"], "answer_start": [84, 84, 9]}, "prediction_text": "cigarette advertising"}
{"answers": {"text": ["January 2, 1971", "January 2, 1971", "January 2, 1971"], "answer_start": [184, 184, 184]}, "prediction_text": "January 2, 1971"}
{"answers": {"text": ["Henry Plitt", "Henry Plitt", "Henry Plitt"], "answer_start": [319, 319, 319]}, "prediction_text": "Henry Plitt"}
{"answers": {"text": ["Elton Rule", "Elton Rule", "Elton Rule"], "answer_start": [361, 361, 361]}, "prediction_text": "Elton Rule"}
{"answers": {"text": ["1966", "1966", "1966"], "answer_start": [54, 54, 54]}, "prediction_text": "1966"}
{"answers": {"text": ["Happy Days", "Happy Days", "Happy Days"], "answer_start": [164, 164, 164]}, "prediction_text": "Happy Days"}
{"answers": {"text": ["youth-oriented programming", "developing youth-oriented programming", "developing youth-oriented programming"], "answer_start": [341, 330, 330]}, "prediction_text": "Development of youth-oriented programming"}
{"answers": {"text": ["Paramount Pictures", "Paramount Pictures", "Paramount Pictures"], "answer_start": [750, 750, 750]}, "prediction_text": "Paramount Pictures"}
{"answers": {"text": ["Fred Pierce", "Fred Pierce"], "answer_start": [23, 23]}, "prediction_text": "Fred Pierce"}
{"answers": {"text": ["Fred Silverman", "Fred Silverman", "Fred Silverman"], "answer_start": [95, 95, 95]}, "prediction_text": "Fred Pierce"}
{"answers": {"text": ["S.W.A.T", "S.W.A.T.", "S.W.A.T"], "answer_start": [341, 341, 341]}, "prediction_text": "S.W.A.T."}
{"answers": {"text": ["November 3, 1975", "November 3, 1975", "1973"], "answer_start": [1407, 1407, 644]}, "prediction_text": "November 3, 1975."}
{"answers": {"text": ["president of NBC's entertainment division", "president of NBC's entertainment division", "president of NBC"], "answer_start": [352, 352, 352]}, "prediction_text": "President of NBC's entertainment division"}
{"answers": {"text": ["Laverne & Shirley", "Laverne & Shirley", "Laverne & Shirley"], "answer_start": [471, 471, 471]}, "prediction_text": "Laverne & Shirley"}
{"answers": {"text": ["jiggle TV", "\"jiggle TV\"", "\"jiggle TV\""], "answer_start": [661, 660, 660]}, "prediction_text": "Jiggle TV"}
{"answers": {"text": ["Alex Haley", "Alex Haley", "Alex Haley"], "answer_start": [134, 134, 134]}, "prediction_text": "Alex Haley"}
{"answers": {"text": ["Aaron Spelling", "Aaron Spelling", "Aaron Spelling"], "answer_start": [262, 262, 262]}, "prediction_text": "Aaron Spelling"}
{"answers": {"text": ["nine seasons", "nine", "nine"], "answer_start": [491, 491, 491]}, "prediction_text": "Nine seasons"}
{"answers": {"text": ["1976\u201377 season", "1976\u201377", "1976\u201377"], "answer_start": [770, 770, 770]}, "prediction_text": "1977\u201378"}
{"answers": {"text": ["Soap", "Soap", "Soap"], "answer_start": [829, 829, 829]}, "prediction_text": "Soap"}
{"answers": {"text": ["Roone Arledge", "Roone Arledge", "Roone Arledge"], "answer_start": [126, 126, 126]}, "prediction_text": "Roone Arledge"}
{"answers": {"text": ["ABC Sports", "ABC Sports", "ABC Sports"], "answer_start": [214, 214, 214]}, "prediction_text": "ABC Sports"}
{"answers": {"text": ["7 Lincoln Square", "7 Lincoln Square", "7 Lincoln Square"], "answer_start": [534, 534, 534]}, "prediction_text": "\"7 Lincoln Square\""}
{"answers": {"text": ["June 1979", "June 1979", "1979"], "answer_start": [762, 762, 767]}, "prediction_text": "July 1979"}
{"answers": {"text": ["June 1978", "June 1978", "June 1978"], "answer_start": [3, 3, 3]}, "prediction_text": "June 1978"}
{"answers": {"text": ["Hugh Downs", "Hugh Downs", "Hugh Downs"], "answer_start": [291, 291, 291]}, "prediction_text": "Hugh Downs"}
{"answers": {"text": ["Barbara Walters", "Barbara Walters", "Barbara Walters"], "answer_start": [377, 377, 377]}, "prediction_text": "Barbara Walters"}
{"answers": {"text": ["MCA Inc.", "MCA Inc.", "MCA Inc"], "answer_start": [448, 448, 448]}, "prediction_text": "MCA Inc."}
{"answers": {"text": ["ABC Cable News", "ABC Cable News", "ABC Cable News"], "answer_start": [73, 73, 73]}, "prediction_text": "ABC Cable News"}
{"answers": {"text": ["ABC News Now", "ABC News Now", "ABC News Now"], "answer_start": [267, 267, 267]}, "prediction_text": "ABC News Now"}
{"answers": {"text": ["WJRT-TV", "WJRT-TV", "WJRT-TV"], "answer_start": [423, 423, 423]}, "prediction_text": "WJRT-TV"}
{"answers": {"text": ["WTVG", "WTVG", "WTVG"], "answer_start": [435, 435, 435]}, "prediction_text": "WJRT-TV"}
{"answers": {"text": ["Writers Guild of America", "The Writers Guild of America", "Writers Guild of America"], "answer_start": [4, 0, 4]}, "prediction_text": "Writers Guild of America"}
{"answers": {"text": ["Duel", "Duel", "Duel"], "answer_start": [607, 607, 607]}, "prediction_text": "Duel"}
{"answers": {"text": ["Caris & Co.", "Caris & Co.", "Caris & Co."], "answer_start": [996, 996, 996]}, "prediction_text": "Caris & Co."}
{"answers": {"text": ["ABC Entertainment", "ABC Entertainment", "ABC Studios"], "answer_start": [50, 50, 72]}, "prediction_text": "ABC Entertainment Group"}
{"answers": {"text": ["ABC Entertainment Group", "ABC Entertainment Group", "Entertainment Group"], "answer_start": [105, 105, 109]}, "prediction_text": "ABC Entertainment Group"}
{"answers": {"text": ["Citadel Media", "Citadel Media", "Citadel Media"], "answer_start": [387, 387, 387]}, "prediction_text": "Citadel Media"}
{"answers": {"text": ["iTunes", "iTunes", "iTunes"], "answer_start": [640, 640, 640]}, "prediction_text": "iTunes"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [62, 62, 62]}, "prediction_text": "2010"}
{"answers": {"text": ["2004", "2004", "2004"], "answer_start": [172, 172, 172]}, "prediction_text": "2004"}
{"answers": {"text": ["Fridays", "Fridays", "Fridays"], "answer_start": [267, 267, 267]}, "prediction_text": "Wednesdays"}
{"answers": {"text": ["Wednesdays", "Wednesdays", "Wednesdays"], "answer_start": [383, 383, 383]}, "prediction_text": "Fall of 2009"}
{"answers": {"text": ["1970", "1970", "1970"], "answer_start": [42, 42, 42]}, "prediction_text": "1970"}
{"answers": {"text": ["Worldvision Enterprises", "Worldvision Enterprises", "Worldvision Enterprises"], "answer_start": [87, 87, 87]}, "prediction_text": "Worldvision Enterprises"}
{"answers": {"text": ["ABC Circle Films", "ABC Circle Films", "ABC Circle Films"], "answer_start": [145, 145, 145]}, "prediction_text": "ABC Circle Films"}
{"answers": {"text": ["Turner Broadcasting System", "Turner Broadcasting System", "Turner Broadcasting System"], "answer_start": [738, 738, 738]}, "prediction_text": "Turner Broadcasting System"}
{"answers": {"text": ["Disney\u2013ABC Domestic Television", "Disney\u2013ABC Domestic Television", "Disney\u2013ABC Domestic Television"], "answer_start": [343, 343, 343]}, "prediction_text": "Buena Vista Television"}
{"answers": {"text": ["Buena Vista Television", "Buena Vista Television", "Buena Vista Television"], "answer_start": [393, 393, 393]}, "prediction_text": "Buena Vista Television"}
{"answers": {"text": ["Buena Vista International Television", "Buena Vista International Television", "Buena Vista International Television"], "answer_start": [520, 520, 520]}, "prediction_text": "Buena Vista International Television"}
{"answers": {"text": ["Selznick library", "Selznick", "Selznick library"], "answer_start": [47, 47, 47]}, "prediction_text": "Cinerama Productions"}
{"answers": {"text": ["WABC-TV and WPVI-TV", "WABC-TV and WPVI-TV", "WABC-TV and WPVI-TV"], "answer_start": [73, 73, 73]}, "prediction_text": "WABC-TV and WPVI-TV"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [187, 187, 187]}, "prediction_text": "Eight owned-and-operated stations"}
{"answers": {"text": ["235 additional television stations", "235", "235"], "answer_start": [274, 274, 274]}, "prediction_text": "235 additional television stations"}
{"answers": {"text": ["96.26%", "96.26%", "96.26%"], "answer_start": [539, 539, 539]}, "prediction_text": "96.26%"}
{"answers": {"text": ["1946", "1946", "1943"], "answer_start": [114, 114, 68]}, "prediction_text": "1946"}
{"answers": {"text": ["the seal of the Federal Communications Commission", "1953", "\"ABC\" enclosed in a circular shield surmounted by the bald eagle"], "answer_start": [367, 318, 435]}, "prediction_text": "Federal Communications Commission seal"}
{"answers": {"text": ["1957", "1957", "1957"], "answer_start": [504, 504, 504]}, "prediction_text": "1957"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [9, 9, 9]}, "prediction_text": "2011"}
{"answers": {"text": ["Extreme Makeover: Home Edition", "Extreme Makeover: Home Edition", "Extreme Makeover: Home Edition"], "answer_start": [42, 42, 42]}, "prediction_text": "Extreme Makeover: Home Edition"}
{"answers": {"text": ["HD", "HD", "HD"], "answer_start": [235, 235, 235]}, "prediction_text": "4:3 SD"}
{"answers": {"text": ["Litton's Weekend Aventure", "Litton's Weekend Aventure", "Litton's Weekend Aventure"], "answer_start": [666, 666, 666]}, "prediction_text": "Weekend Aventure"}
{"answers": {"text": ["720p high definition", "720p high definition", "720p"], "answer_start": [36, 36, 36]}, "prediction_text": "720p high definition"}
{"answers": {"text": ["1080i HD", "1080i HD", "1080i HD"], "answer_start": [247, 247, 247]}, "prediction_text": "1080i HD"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [263, 263, 263]}, "prediction_text": "11 affiliates"}
{"answers": {"text": ["720p high definition", "720p high definition", "480i"], "answer_start": [36, 36, 336]}, "prediction_text": "720p high definition"}
{"answers": {"text": ["Body of Proof", "Body of Proof", "Body of Proof"], "answer_start": [215, 215, 215]}, "prediction_text": "Body of Proof"}
{"answers": {"text": ["Happy Endings", "Happy Endings", "Happy Endings"], "answer_start": [409, 409, 409]}, "prediction_text": "Happy Endings"}
{"answers": {"text": ["NBC", "NBC", "NBC"], "answer_start": [719, 719, 719]}, "prediction_text": "NBC"}
{"answers": {"text": ["V", "V", "Brothers & Sisters"], "answer_start": [567, 567, 479]}, "prediction_text": "Brothers & Sisters"}
{"answers": {"text": ["All My Children and One Life to Live", "All My Children and One Life to Live", "All My Children and One Life to Live"], "answer_start": [61, 61, 61]}, "prediction_text": "All My Children and One Life to Live"}
{"answers": {"text": ["Prospect Park", "Prospect Park", "Prospect Park"], "answer_start": [213, 213, 213]}, "prediction_text": "Prospect Park"}
{"answers": {"text": ["Hulu", "Hulu", "Hulu"], "answer_start": [266, 266, 266]}, "prediction_text": "Hulu"}
{"answers": {"text": ["The Revolution", "The Revolution", "The Revolution"], "answer_start": [619, 619, 619]}, "prediction_text": "The Revolution"}
{"answers": {"text": ["18\u201349 demographic", "18\u201349", "18\u201349"], "answer_start": [780, 780, 780]}, "prediction_text": "18-49"}
{"answers": {"text": ["2004", "eight years", "2004"], "answer_start": [487, 389, 487]}, "prediction_text": "2004"}
{"answers": {"text": ["CBS", "CBS", "CBS"], "answer_start": [554, 554, 554]}, "prediction_text": "ABC"}
{"answers": {"text": ["Agents of S.H.I.E.L.D.", "Agents of S.H.I.E.L.D"], "answer_start": [90, 90]}, "prediction_text": "The Goldbergs"}
{"answers": {"text": ["The Neighbors", "The Neighbors", "Agents of S.H.I.E.L.D"], "answer_start": [214, 214, 90]}, "prediction_text": "Suburgatory"}
{"answers": {"text": ["The Middle and Modern Family", "The Middle and Modern Family", "The Middle and Modern Family"], "answer_start": [193, 193, 193]}, "prediction_text": "The Middle and Modern Family"}
{"answers": {"text": ["Dragon's Den", "Dragon's Den", "Dragon's Den"], "answer_start": [312, 312, 312]}, "prediction_text": "Dragon's Den"}
{"answers": {"text": ["Sundays", "Sundays", "Sundays"], "answer_start": [380, 380, 380]}, "prediction_text": "Sundays"}
{"answers": {"text": ["Tim Allen", "Tim Allen", "Tim Allen"], "answer_start": [617, 617, 617]}, "prediction_text": "Tim Allen"}
{"answers": {"text": ["Daniel Burke", "Daniel Burke", "Daniel Burke"], "answer_start": [0, 0, 0]}, "prediction_text": "Thomas Murphy"}
{"answers": {"text": ["Thomas Murphy", "Thomas Murphy", "Thomas Murphy"], "answer_start": [69, 69, 69]}, "prediction_text": "Thomas Murphy"}
{"answers": {"text": ["NYPD Blue", "NYPD Blue", "NYPD Blue"], "answer_start": [178, 178, 178]}, "prediction_text": "NYPD Blue"}
{"answers": {"text": ["Steven Bochco", "Steven Bochco", "Steven Bochco"], "answer_start": [221, 221, 221]}, "prediction_text": "Steven Bochco"}
{"answers": {"text": ["ten seasons", "ten", "ten"], "answer_start": [346, 346, 346]}, "prediction_text": "Ten seasons"}
{"answers": {"text": ["1993", "1993", "1993"], "answer_start": [3, 3, 3]}, "prediction_text": "1993"}
{"answers": {"text": ["DIC Entertainment", "DIC Entertainment", "DIC Entertainment"], "answer_start": [226, 226, 226]}, "prediction_text": "DIC Entertainment"}
{"answers": {"text": ["Time Warner Cable", "Time Warner Cable", "Time Warner Cable"], "answer_start": [278, 278, 278]}, "prediction_text": "Time Warner Cable"}
{"answers": {"text": ["23.63% of American households", "23.63% of American households", "23.63%"], "answer_start": [444, 444, 444]}, "prediction_text": "23.63%"}
{"answers": {"text": ["WLS", "WLS", "WLS"], "answer_start": [316, 316, 316]}, "prediction_text": "WLS"}
{"answers": {"text": ["May 9, 1960", "May 9, 1960", "May 9, 1960"], "answer_start": [448, 448, 448]}, "prediction_text": "May 9, 1960"}
{"answers": {"text": ["John Bassett", "John Bassett", "John Bassett"], "answer_start": [555, 555, 555]}, "prediction_text": "John Bassett"}
{"answers": {"text": ["CFTO-TV", "CFTO-TV", "CFTO-TV"], "answer_start": [730, 730, 730]}, "prediction_text": "CFTO-TV"}
{"answers": {"text": ["Wide World of Sports", "Wide World of Sports", "Wide World of Sports"], "answer_start": [214, 214, 214]}, "prediction_text": "Wide World of Sports"}
{"answers": {"text": ["Edgar Scherick", "Edgar Scherick", "Edgar Scherick"], "answer_start": [267, 267, 267]}, "prediction_text": "Edgar Scherick"}
{"answers": {"text": ["Roone Arledge", "Roone Arledge", "Roone Arledge"], "answer_start": [348, 348, 348]}, "prediction_text": "Roone Arledge"}
{"answers": {"text": ["Sports Programs, Inc.", "Sports Programs, Inc.", "Sports Programs, Inc"], "answer_start": [434, 434, 434]}, "prediction_text": "Sports Programs, Inc."}
{"answers": {"text": ["American Broadcasting Companies", "American Broadcasting Companies", "American Broadcasting Companies"], "answer_start": [92, 92, 92]}, "prediction_text": "American Broadcasting Companies"}
{"answers": {"text": ["The Dating Game", "The Dating Game", "The Dating Game"], "answer_start": [309, 309, 309]}, "prediction_text": "The Newlywed Game"}
{"answers": {"text": ["The Newlywed Game", "The Newlywed Game", "The Newlywed Game"], "answer_start": [551, 551, 551]}, "prediction_text": "The Newlywed Game"}
{"answers": {"text": ["1330 Avenue of the Americas in Manhattan", "1330 Avenue of the Americas in Manhattan", "1330 Avenue of the Americas in Manhattan"], "answer_start": [841, 841, 841]}, "prediction_text": "1330 Avenue of the Americas"}
{"answers": {"text": ["90%", "90%", "90%"], "answer_start": [128, 128, 128]}, "prediction_text": "90%"}
{"answers": {"text": ["Dynasty", "Dynasty", "Dynasty"], "answer_start": [260, 260, 260]}, "prediction_text": "Dynasty"}
{"answers": {"text": ["Mork & Mindy", "Mork & Mindy", "Mork & Mindy"], "answer_start": [689, 689, 689]}, "prediction_text": "Mork & Mindy"}
{"answers": {"text": ["Alpha Repertory Television Service (ARTS)", "Alpha Repertory Television Service (ARTS)", "Alpha Repertory Television Service (ARTS)"], "answer_start": [771, 771, 771]}, "prediction_text": "Alpha Repertory Television Service"}
{"answers": {"text": ["Infinity Broadcasting Corporation", "Infinity Broadcasting Corporation", "Infinity Broadcasting Corporation"], "answer_start": [30, 30, 30]}, "prediction_text": "Infinity Broadcasting Corporation"}
{"answers": {"text": ["Getty Oil", "Getty Oil", "Getty Oil's"], "answer_start": [260, 260, 260]}, "prediction_text": "Getty Oil"}
{"answers": {"text": ["The Entertainment Channel", "The Entertainment Channel", "The Entertainment Channel"], "answer_start": [653, 653, 653]}, "prediction_text": "The Entertainment Channel"}
{"answers": {"text": ["Arts & Entertainment Television (A&E)", "Arts & Entertainment Television (A&E)", "Arts & Entertainment Television (A&E)"], "answer_start": [715, 715, 715]}, "prediction_text": "Arts & Entertainment Television (A&E)"}
{"answers": {"text": ["Daniel B. Burke", "Daniel B. Burke", "Daniel B. Burke"], "answer_start": [65, 65, 65]}, "prediction_text": "Daniel B. Burke"}
{"answers": {"text": ["chairman and CEO", "chairman and CEO", "chairman"], "answer_start": [103, 103, 103]}, "prediction_text": "ABC's chairman and CEO"}
{"answers": {"text": ["$465 million", "$465 million", "$465 million"], "answer_start": [161, 161, 161]}, "prediction_text": "$465 million"}
{"answers": {"text": ["America's Funniest Home Videos", "America's Funniest Home Videos", "America's Funniest Home Videos"], "answer_start": [282, 282, 282]}, "prediction_text": "Family Matters"}
{"answers": {"text": ["Home Improvement", "Home Improvement", "Home Improvement"], "answer_start": [667, 667, 667]}, "prediction_text": "Home Improvement"}
{"answers": {"text": ["General Hospital", "General Hospital", "General Hospital"], "answer_start": [314, 314, 314]}, "prediction_text": "General Hospital"}
{"answers": {"text": ["The View and The Chew", "The View and The Chew", "The View and The Chew"], "answer_start": [273, 273, 273]}, "prediction_text": "Good Morning America, Jimmy Kimmel Live!."}
{"answers": {"text": ["7:00 to 9:00 a.m. weekdays", "7:00 to 9:00 a.m", "7:00 to 9:00 a.m."], "answer_start": [388, 388, 388]}, "prediction_text": "7:00 to 9:00 a.m. weekdays"}
{"answers": {"text": ["Jimmy Kimmel", "Jimmy Kimmel", "Jimmy Kimmel"], "answer_start": [840, 840, 840]}, "prediction_text": "Jimmy Kimmel"}
{"answers": {"text": ["New Jersey, Rhode Island and Delaware", "New Jersey, Rhode Island and Delaware", "New Jersey, Rhode Island and Delaware"], "answer_start": [11, 11, 11]}, "prediction_text": "New Jersey, Rhode Island, Delaware"}
{"answers": {"text": ["WBMA-LD", "WBMA-LD", "(WBMA-LD"], "answer_start": [489, 489, 488]}, "prediction_text": "WBMA-LD"}
{"answers": {"text": ["WBND-LD", "WBND-LD", "WBND-LD"], "answer_start": [545, 545, 545]}, "prediction_text": "WBND-LD"}
{"answers": {"text": ["WLQP-LP", "WLQP-LP", "WLQP-LP"], "answer_start": [511, 511, 511]}, "prediction_text": "WLQP-LP"}
{"answers": {"text": ["ABC Circle Films", "ABC Circle Films", "ABC Circle Films"], "answer_start": [222, 222, 222]}, "prediction_text": "ABC Circle Films"}
{"answers": {"text": ["ABC Studios", "ABC Studios", "ABC Studios"], "answer_start": [342, 342, 342]}, "prediction_text": "ABC Studios"}
{"answers": {"text": ["ABC Television Center", "ABC Television Center", "The Prospect Studios"], "answer_start": [437, 437, 464]}, "prediction_text": "ABC Television Center"}
{"answers": {"text": ["ABC Television Center, East", "ABC Television Center, East", "ABC Television Center"], "answer_start": [589, 589, 589]}, "prediction_text": "ABC Television Center"}
{"answers": {"text": ["Times Square Studios", "Times Square Studios", "Times Square Studios"], "answer_start": [18, 18, 18]}, "prediction_text": "ABC Studios"}
{"answers": {"text": ["Good Morning America and Nightline", "Good Morning America and Nightline", "Good Morning America and Nightline"], "answer_start": [153, 153, 153]}, "prediction_text": "Good Morning America and Nightline"}
{"answers": {"text": ["Peter Jennings", "Peter Jennings", "Peter Jennings"], "answer_start": [468, 468, 468]}, "prediction_text": "Peter Jennings Way"}
{"answers": {"text": ["World News Tonight", "World News Tonight", "World News Tonight"], "answer_start": [574, 574, 574]}, "prediction_text": "World News Tonight"}
{"answers": {"text": ["ABC on Demand", "ABC on Demand", "ABC on Demand"], "answer_start": [140, 140, 140]}, "prediction_text": "ABC on Demand"}
{"answers": {"text": ["Hulu", "Hulu", "Hulu"], "answer_start": [266, 266, 266]}, "prediction_text": "Hulu"}
{"answers": {"text": ["July 6, 2009", "July 6, 2009", "July 6, 2009"], "answer_start": [518, 518, 518]}, "prediction_text": "July 6, 2009"}
{"answers": {"text": ["27% ownership stake", "27%", "27%"], "answer_start": [688, 688, 688]}, "prediction_text": "27%"}
{"answers": {"text": ["the day after their original broadcast", "the day after their original broadcast", "day after"], "answer_start": [112, 112, 116]}, "prediction_text": "After their original broadcast."}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [487, 487, 487]}, "prediction_text": "Eight days"}
{"answers": {"text": ["fast forwarding of accessed content", "fast forwarding", "fast forwarding"], "answer_start": [282, 282, 282]}, "prediction_text": "Fast forwarding access to accessed content."}
{"answers": {"text": ["January 7, 2014", "January 7, 2014", "January 7, 2014"], "answer_start": [378, 378, 378]}, "prediction_text": "January 7, 2014"}
{"answers": {"text": ["LoyalKaspar", "LoyalKaspar", "LoyalKaspar"], "answer_start": [317, 317, 317]}, "prediction_text": "LoyalKaspar"}
{"answers": {"text": ["four variants", "four", "four"], "answer_start": [566, 566, 566]}, "prediction_text": "Four variants"}
{"answers": {"text": ["ABC Modern", "ABC Modern", "ABC Modern"], "answer_start": [1009, 1009, 1009]}, "prediction_text": "ABC Modern"}
{"answers": {"text": ["ESPN", "ESPN on ABC", "ESPN"], "answer_start": [893, 893, 893]}, "prediction_text": "ESPN"}
{"answers": {"text": ["14", "14", "14"], "answer_start": [264, 264, 264]}, "prediction_text": "14 primary affiliates"}
{"answers": {"text": ["74", "74", "71"], "answer_start": [302, 302, 355]}, "prediction_text": "74"}
{"answers": {"text": ["All-Channel Receiver Act", "All-Channel Receiver Act", "All-Channel Receiver Act"], "answer_start": [665, 665, 665]}, "prediction_text": "All-Channel Receiver Act"}
{"answers": {"text": ["UHF tuning", "UHF", "UHF"], "answer_start": [745, 745, 745]}, "prediction_text": "UHF tuning"}
{"answers": {"text": ["Youngstown", "WKST-TV in Youngstown", "Youngstown"], "answer_start": [221, 210, 221]}, "prediction_text": "Youngstown"}
{"answers": {"text": ["five times lower viewership", "five times", "five times"], "answer_start": [477, 477, 477]}, "prediction_text": "Five times lower"}
{"answers": {"text": ["WTRF-TV", "WTRF-TV", "WTRF-TV"], "answer_start": [966, 966, 966]}, "prediction_text": "WTRF-TV"}
{"answers": {"text": ["1980s", "1980s or even the advent of digital television in the 2000s", "1980s or even the advent of digital television in the 2000s"], "answer_start": [877, 877, 877]}, "prediction_text": "2000s"}
{"answers": {"text": ["Walt Disney Presents", "Walt Disney Presents", "Walt Disney Presents"], "answer_start": [67, 67, 67]}, "prediction_text": "Walt Disney Presents"}
{"answers": {"text": ["Desilu Productions", "Desilu Productions", "Desilu Productions"], "answer_start": [446, 446, 446]}, "prediction_text": "Desilu Productions"}
{"answers": {"text": ["its use of violence", "its use of violence", "violence"], "answer_start": [567, 567, 578]}, "prediction_text": "Violence and violence-based shows were not popular."}
{"answers": {"text": ["April 1959", "April 1959", "April 1959"], "answer_start": [687, 687, 687]}, "prediction_text": "April 1959"}
{"answers": {"text": ["ABC Sunday Night Movie", "ABC Sunday Night Movie", "ABC Sunday Night Movie"], "answer_start": [230, 230, 230]}, "prediction_text": "ABC Sunday Night Movie"}
{"answers": {"text": ["$15.5 million", "$15.5", "$15.5 million"], "answer_start": [540, 540, 540]}, "prediction_text": "$15.5 million"}
{"answers": {"text": ["Hanna-Barbera", "Hanna-Barbera", "Hanna-Barbera"], "answer_start": [694, 694, 694]}, "prediction_text": "Hanna-Barbera"}
{"answers": {"text": ["The Jetsons", "The Jetsons", "The Jetsons"], "answer_start": [709, 709, 709]}, "prediction_text": "The Flintstones"}
{"answers": {"text": ["April 1, 1963", "April 1, 1963", "April 1, 1963"], "answer_start": [833, 833, 833]}, "prediction_text": "September 17, 1962"}
{"answers": {"text": ["ITT", "ITT", "ITT"], "answer_start": [64, 64, 64]}, "prediction_text": "ITT"}
{"answers": {"text": ["Donald F. Turner", "Donald F. Turner", "Donald F. Turner"], "answer_start": [234, 234, 234]}, "prediction_text": "Turner"}
{"answers": {"text": ["Department of Justice", "Department of Justice", "Department of Justice"], "answer_start": [683, 683, 683]}, "prediction_text": "Department of Justice"}
{"answers": {"text": ["January 1, 1968", "January 1, 1968", "January 1, 1968"], "answer_start": [827, 827, 827]}, "prediction_text": "January 1, 1968."}
{"answers": {"text": ["Capital Cities Communications", "Capital Cities Communications", "Capital Cities Communications"], "answer_start": [63, 63, 63]}, "prediction_text": "Capital Cities Communications"}
{"answers": {"text": ["$3.5 billion", "$3.5 billion and $118 for each of ABC's shares as well as a guarantee of 10% (or $3) for a total of $121 per share", "$3.5 billion"], "answer_start": [362, 362, 362]}, "prediction_text": "$3.5 billion and $118 per share."}
{"answers": {"text": ["Warren Buffett", "Warren Buffett", "Warren Buffett"], "answer_start": [868, 868, 868]}, "prediction_text": "Warren Buffett"}
{"answers": {"text": ["E. W. Scripps Company", "E. W. Scripps Company", "E. W. Scripps Company"], "answer_start": [1375, 1375, 1375]}, "prediction_text": "E. W. Scripps Company"}
{"answers": {"text": ["12 television stations", "12", "12"], "answer_start": [1245, 1245, 1245]}, "prediction_text": "12 television stations"}
{"answers": {"text": ["September 5, 1985", "September 5, 1985", "September 5, 1985"], "answer_start": [71, 71, 71]}, "prediction_text": "September 5, 1985"}
{"answers": {"text": ["Capital Cities/ABC, Inc.", "Capital Cities/ABC, Inc.", "Capital Cities/ABC, Inc."], "answer_start": [205, 205, 205]}, "prediction_text": "ABC/Capital Cities"}
{"answers": {"text": ["president of ABC's broadcasting division", "president of ABC's broadcasting division", "president"], "answer_start": [603, 603, 603]}, "prediction_text": "President of ABC Broadcasting"}
{"answers": {"text": ["Michael P. Millardi", "Michael P. Millardi", "Michael P. Millardi"], "answer_start": [645, 645, 645]}, "prediction_text": "Michael P. Millardi"}
{"answers": {"text": ["Roone Arledge", "Roone Arledge", "Roone Arledge"], "answer_start": [960, 960, 960]}, "prediction_text": "Brandon Stoddard"}
{"answers": {"text": ["Laverne & Shirley", "Laverne & Shirley", "Laverne & Shirley"], "answer_start": [116, 116, 116]}, "prediction_text": "Laverne & Shirley"}
{"answers": {"text": ["Three's Company", "Three's Company", "Three's Company"], "answer_start": [172, 172, 172]}, "prediction_text": "The Love Boat"}
{"answers": {"text": ["NBC", "NBC", "NBC"], "answer_start": [348, 348, 348]}, "prediction_text": "NBC"}
{"answers": {"text": ["The Love Boat", "The Love Boat", "The Love Boat"], "answer_start": [269, 269, 269]}, "prediction_text": "The Love Boat"}
{"answers": {"text": ["comedies and family-oriented series", "comedies and family-oriented", "comedies and family-oriented"], "answer_start": [543, 543, 543]}, "prediction_text": "Family-oriented series"}
{"answers": {"text": ["the \"TGIF\" block", "TGIF", "TGIF"], "answer_start": [170, 175, 175]}, "prediction_text": "\"TGIF\" block"}
{"answers": {"text": ["Thank Goodness It's Funny", "Thank Goodness It's Funny", "Thank Goodness It's Funny"], "answer_start": [227, 227, 227]}, "prediction_text": "\"Thank Goodness It's Funny\""}
{"answers": {"text": ["Miller-Boyett Productions", "Miller-Boyett Productions", "Miller-Boyett Productions"], "answer_start": [329, 329, 329]}, "prediction_text": "Miller-Boyett Productions"}
{"answers": {"text": ["Warner Bros.", "Warner Bros.", "Warner Bros"], "answer_start": [358, 358, 358]}, "prediction_text": "Warner Bros."}
{"answers": {"text": ["seven radio stations", "seven", "seven"], "answer_start": [117, 117, 117]}, "prediction_text": "Seven radio stations"}
{"answers": {"text": ["Charly", "Charly", "Charly"], "answer_start": [457, 457, 457]}, "prediction_text": "Charly"}
{"answers": {"text": ["Ralph Nelson", "Ralph Nelson", "ABC Pictures"], "answer_start": [435, 435, 347]}, "prediction_text": "Ralph Nelson"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [535, 535, 535]}, "prediction_text": "1985"}
{"answers": {"text": ["Redwood City, California", "Redwood City, California", "July 1968"], "answer_start": [751, 751, 639]}, "prediction_text": "Redwood City, California"}
{"answers": {"text": ["westerns and detective series", "westerns and detective series", "westerns and detective series"], "answer_start": [212, 212, 212]}, "prediction_text": "Westerns and detective series"}
{"answers": {"text": ["500%", "almost 500%", "500%"], "answer_start": [261, 254, 261]}, "prediction_text": "Over 500% increase"}
{"answers": {"text": ["between 10% and 18%", "between 10% and 18%", "10% and 18%"], "answer_start": [363, 363, 371]}, "prediction_text": "18%"}
{"answers": {"text": ["Ollie Treiz", "Ollie Treiz", "Ollie Treiz"], "answer_start": [512, 512, 512]}, "prediction_text": "Ollie Treiz"}
{"answers": {"text": ["Dick Clark", "Dick Clark", "Dick Clark"], "answer_start": [907, 907, 907]}, "prediction_text": "Dick Clark"}
{"answers": {"text": ["counterprogramming", "counterprogramming against its competitors", "\"philosophy of counterprogramming against its competitors\""], "answer_start": [74, 74, 59]}, "prediction_text": "Counterprogramming against its competitors."}
{"answers": {"text": ["Zorro", "Zorro", "Zorro"], "answer_start": [353, 353, 353]}, "prediction_text": "Zorro"}
{"answers": {"text": ["Life", "Life", "Life"], "answer_start": [644, 644, 644]}, "prediction_text": "Life"}
{"answers": {"text": ["detective shows", "detective", "detective"], "answer_start": [457, 457, 457]}, "prediction_text": "Detective shows"}
{"answers": {"text": ["WATCH ABC", "WATCH ABC", "WATCH ABC"], "answer_start": [27, 27, 27]}, "prediction_text": "\"WATCH ABC\""}
{"answers": {"text": ["New York City O&O WABC-TV and Philadelphia O&O WPVI-TV", "New York City O&O WABC-TV and Philadelphia O&O WPVI-TV", "WABC-TV and Philadelphia O&O WPVI-TV"], "answer_start": [715, 715, 733]}, "prediction_text": "New York City O&O WABC-TV and Philadelphia O&O WPVI-TV."}
{"answers": {"text": ["Hearst Television", "Hearst Television", "Hearst Television"], "answer_start": [993, 993, 993]}, "prediction_text": "Hearst Television"}
{"answers": {"text": ["WatchESPN", "WatchESPN", "WatchESPN"], "answer_start": [457, 457, 457]}, "prediction_text": "WatchESPN"}
{"answers": {"text": ["Sinclair Broadcast Group", "Sinclair Broadcast Group", "Sinclair Broadcast Group"], "answer_start": [4, 4, 4]}, "prediction_text": "Sinclair Broadcast Group"}
{"answers": {"text": ["WABM-DT2/WDBB-DT2 in the Birmingham market", "WABM-DT2/WDBB-DT2", "Sinclair"], "answer_start": [253, 253, 186]}, "prediction_text": "WABM-DT2/WDBB-DT2"}
{"answers": {"text": ["E. W. Scripps Company", "The E. W. Scripps Company", "E. W. Scripps Company"], "answer_start": [533, 529, 533]}, "prediction_text": "Sinclair Broadcast Group"}
{"answers": {"text": ["28 ABC affiliates and two additional subchannel-only affiliates", "28 ABC affiliates and two additional subchannel-only affiliates", "28 ABC affiliates and two additional subchannel-only"], "answer_start": [121, 121, 121]}, "prediction_text": "28 affiliates"}
{"answers": {"text": ["15", "15"], "answer_start": [636, 636]}, "prediction_text": "15 ABC-affiliated stations"}
{"answers": {"text": ["Start Here", "\"Start Here\"", "Start Here"], "answer_start": [97, 96, 97]}, "prediction_text": "\"Start Here\""}
{"answers": {"text": ["Troika", "Troika", "Troika"], "answer_start": [128, 128, 128]}, "prediction_text": "Troika"}
{"answers": {"text": ["the entertainment division", "entertainment", "entertainment"], "answer_start": [708, 712, 712]}, "prediction_text": "Entertainment"}
{"answers": {"text": ["ABC News", "ABC News", "ABC News"], "answer_start": [769, 769, 769]}, "prediction_text": "Entertainment"}
{"answers": {"text": ["WFTS-TV and WWSB", "WFTS-TV and WWSB", "WFTS-TV and WWSB"], "answer_start": [138, 138, 138]}, "prediction_text": "WFTS-TV and WWSB"}
{"answers": {"text": ["KMBC-TV and KQTV", "KMBC-TV and KQTV", "KMBC-TV and KQTV"], "answer_start": [262, 262, 262]}, "prediction_text": "KMBC-TV and KQTV"}
{"answers": {"text": ["WZZM and WOTV", "WZZM and WOTV", "WZZM and WOTV"], "answer_start": [184, 184, 184]}, "prediction_text": "WZZM and WOTV"}
{"answers": {"text": ["WTSP", "WTSP", "WTSP"], "answer_start": [613, 613, 613]}, "prediction_text": "WTSP"}
{"answers": {"text": ["the Mongol Empire", "Mongol Empire", "Mongol Empire"], "answer_start": [89, 93, 93]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["many of the nomadic tribes of Northeast Asia", "nomadic tribes of Northeast Asia", "many of the nomadic tribes of Northeast Asia."], "answer_start": [28, 40, 28]}, "prediction_text": "Nomadic tribes of Northeast Asia"}
{"answers": {"text": ["Khwarezmian and Xia controlled lands", "Khwarezmian and Xia controlled lands", "Qara Khitai, Caucasus, Khwarezmid Empire, Western Xia and Jin dynasties"], "answer_start": [450, 450, 267]}, "prediction_text": "Khwarezmian and Xia controlled lands"}
{"answers": {"text": ["a substantial portion of Central Asia and China", "substantial portion of Central Asia and China", "a substantial portion of Central Asia and China"], "answer_start": [539, 541, 539]}, "prediction_text": "Central Asia and China"}
{"answers": {"text": ["the Qara Khitai, Caucasus, Khwarezmid Empire, Western Xia and Jin dynasties", "Qara Khitai, Caucasus, Khwarezmid Empire, Western Xia and Jin", "Khwarezmian and Xia controlled lands"], "answer_start": [263, 267, 450]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["\u00d6gedei Khan", "\u00d6gedei Khan", "\u00d6gedei Khan"], "answer_start": [38, 38, 38]}, "prediction_text": "\u00d6gedei Khan"}
{"answers": {"text": ["1227", "1227", "1227"], "answer_start": [143, 143, 143]}, "prediction_text": "1227"}
{"answers": {"text": ["Western Xia", "Western Xia", "Western Xia"], "answer_start": [168, 168, 168]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["his sons and grandsons", "sons and grandsons", "his sons and grandsons."], "answer_start": [108, 112, 108]}, "prediction_text": "His sons and grandsons"}
{"answers": {"text": ["somewhere in Mongolia at an unknown location", "Mongolia", "unmarked grave somewhere in Mongolia"], "answer_start": [216, 229, 201]}, "prediction_text": "In Mongolia"}
{"answers": {"text": ["Del\u00fc\u00fcn Boldog", "Del\u00fc\u00fcn Boldog", "Del\u00fc\u00fcn Boldog,"], "answer_start": [37, 37, 37]}, "prediction_text": "Northern Mongolia"}
{"answers": {"text": ["Yes\u00fcgei, a Khamag Mongol's major chief of the Kiyad", "Yes\u00fcgei", "Yes\u00fcgei"], "answer_start": [405, 405, 405]}, "prediction_text": "Toghrul Khan"}
{"answers": {"text": ["1162", "1162", "1162"], "answer_start": [29, 29, 29]}, "prediction_text": "1162"}
{"answers": {"text": ["a Tatar chieftain, Tem\u00fcjin-\u00fcge, whom his father had just captured", "Tem\u00fcjin-\u00fcge", "Tatar chieftain, Tem\u00fcjin-\u00fcge"], "answer_start": [605, 624, 607]}, "prediction_text": "Tatar chieftain"}
{"answers": {"text": ["Tem\u00fclen", "Tem\u00fclen", "Tem\u00fclen"], "answer_start": [82, 82, 82]}, "prediction_text": "Tem\u00fclen"}
{"answers": {"text": ["Hasar, Hachiun, and Tem\u00fcge", "Hasar, Hachiun, and Tem\u00fcge", "Hasar, Hachiun, and Tem\u00fcge"], "answer_start": [33, 33, 33]}, "prediction_text": "Hasar, Hachiun, and Tem\u00fclen."}
{"answers": {"text": ["B\u00f6rte", "B\u00f6rte", "B\u00f6rte"], "answer_start": [349, 349, 349]}, "prediction_text": "B\u00f6rte"}
{"answers": {"text": ["Khongirad", "Khongirad", "Khongirad"], "answer_start": [386, 386, 386]}, "prediction_text": "Khongirad"}
{"answers": {"text": ["Dai Setsen", "Dai Setsen", "Dai Setsen"], "answer_start": [437, 437, 437]}, "prediction_text": "Dai Setsen"}
{"answers": {"text": ["Begter", "Begter", "Begter"], "answer_start": [189, 189, 189]}, "prediction_text": "Temujin's brother Khasar"}
{"answers": {"text": ["Hoelun", "Hoelun", "Temujin's mother"], "answer_start": [320, 320, 303]}, "prediction_text": "Temujin's mother"}
{"answers": {"text": ["Tem\u00fcjin and his brother Khasar", "Tem\u00fcjin and his brother Khasar", "Tem\u00fcjin and his brother Khasar"], "answer_start": [484, 484, 484]}, "prediction_text": "Khasar and Temujin's brothers"}
{"answers": {"text": ["during one hunting excursion", "one hunting excursion", "during one hunting excursion"], "answer_start": [450, 457, 450]}, "prediction_text": "One hunting excursion"}
{"answers": {"text": ["the Tayichi'ud", "Tayichi'ud", "his father's former allies, the Tayichi'ud"], "answer_start": [109, 113, 81]}, "prediction_text": "The Tayichi'ud"}
{"answers": {"text": ["with a cangue, a sort of portable stocks", "cangue", "cangue, a sort of portable stocks"], "answer_start": [169, 176, 176]}, "prediction_text": "By his father's former allies"}
{"answers": {"text": ["Chilaun", "Chilaun", "the father of Chilaun"], "answer_start": [268, 268, 254]}, "prediction_text": "Jelme and Bo'orchu"}
{"answers": {"text": ["Jelme and Bo'orchu", "Jelme and Bo'orchu", "Jelme and Bo'orchu"], "answer_start": [467, 467, 467]}, "prediction_text": "Jelme and Bo'orchu"}
{"answers": {"text": ["a river crevice", "a river crevice", "a river crevice."], "answer_start": [404, 404, 404]}, "prediction_text": "In a river crevice"}
{"answers": {"text": ["arranged marriages", "arranged marriages", "arranged marriages"], "answer_start": [89, 89, 89]}, "prediction_text": "Tem\u00fcjin's mother taught him lessons about political instability."}
{"answers": {"text": ["Tem\u00fcjin's mother Hoelun", "Hoelun", "Tem\u00fcjin's mother Hoelun"], "answer_start": [457, 474, 457]}, "prediction_text": "Hoelun"}
{"answers": {"text": ["the Chinese dynasties to the south", "Chinese dynasties", "Chinese dynasties to the south"], "answer_start": [421, 425, 425]}, "prediction_text": "Chinese dynasties"}
{"answers": {"text": ["the need for alliances", "need for alliances", "need for alliances."], "answer_start": [566, 570, 570]}, "prediction_text": "Need for alliances"}
{"answers": {"text": ["the Onggirat", "Onggirat", "Onggirat tribe"], "answer_start": [63, 67, 67]}, "prediction_text": "Onggirat tribe"}
{"answers": {"text": ["the Merkits", "Merkits", "the Merkits"], "answer_start": [227, 231, 227]}, "prediction_text": "Merkits"}
{"answers": {"text": ["Jamukha, and his protector, Toghrul Khan of the Keraite tribe", "Jamukha, and his protector, Toghrul Khan", "Jamukha, and his protector, Toghrul Khan"], "answer_start": [342, 342, 342]}, "prediction_text": "Toghrul Khan"}
{"answers": {"text": ["Jochi", "Jochi", "Jochi"], "answer_start": [430, 430, 430]}, "prediction_text": "Jochi (1185\u20131226)"}
{"answers": {"text": ["1185", "1185", "(1185"], "answer_start": [437, 437, 436]}, "prediction_text": "1185-1226"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [10, 10, 10]}, "prediction_text": "Three sons"}
{"answers": {"text": ["Chagatai", "Chagatai", "\u00d6gedei"], "answer_start": [27, 27, 49]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["1241", "1241", "1241"], "answer_start": [42, 42, 42]}, "prediction_text": "1187\u20141241"}
{"answers": {"text": ["Tolui", "Tolui", "Tolui"], "answer_start": [73, 73, 73]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [283, 283, 283]}, "prediction_text": "Six names"}
{"answers": {"text": ["sworn brother or blood brother", "sworn brother", "sworn brother or blood brother)"], "answer_start": [130, 130, 130]}, "prediction_text": "Sworn brother or blood brother."}
{"answers": {"text": ["Toghrul", "Toghrul", "Toghrul"], "answer_start": [162, 162, 162]}, "prediction_text": "Toghrul's father"}
{"answers": {"text": ["the Keraites", "Keraites", "Keraites"], "answer_start": [187, 191, 191]}, "prediction_text": "Jadaran"}
{"answers": {"text": ["20,000", "20,000", "20,000"], "answer_start": [468, 468, 468]}, "prediction_text": "20,000 warriors"}
{"answers": {"text": ["Jamukha", "Jamukha", "Jamukha"], "answer_start": [555, 555, 555]}, "prediction_text": "Jamukha"}
{"answers": {"text": ["the traditional Mongolian aristocracy", "traditional Mongolian aristocracy", "the traditional Mongolian aristocracy"], "answer_start": [132, 136, 132]}, "prediction_text": "The Merkits"}
{"answers": {"text": ["Kokochu", "Kokochu", "Kokochu"], "answer_start": [357, 357, 357]}, "prediction_text": "Kokochu's proclamation"}
{"answers": {"text": ["1186", "1186", "1186"], "answer_start": [462, 462, 462]}, "prediction_text": "1186"}
{"answers": {"text": ["Battle of Dalan Balzhut", "Battle of Dalan Balzhut", "1187"], "answer_start": [819, 819, 611]}, "prediction_text": "Battle of Dalan Balzhut"}
{"answers": {"text": ["Qara Khitai", "Qara Khitai", "Qara Khitai."], "answer_start": [1084, 1084, 1084]}, "prediction_text": "The Qara Khitai"}
{"answers": {"text": ["the Yassa code", "Yassa code", "Yassa code"], "answer_start": [70, 74, 74]}, "prediction_text": "Yassa code"}
{"answers": {"text": ["wealth from future possible war spoils", "wealth", "wealth"], "answer_start": [126, 126, 126]}, "prediction_text": "Wealth from future war spoils"}
{"answers": {"text": ["orphans from the conquered tribe", "orphans", "orphans from the conquered tribe"], "answer_start": [395, 395, 395]}, "prediction_text": "His mother adopted orphans from the conquered tribe."}
{"answers": {"text": ["his protection", "political innovations", "protection and integrated its members into his own tribe."], "answer_start": [297, 466, 301]}, "prediction_text": "Wealth from future war spoils"}
{"answers": {"text": ["Jochi", "Jochi", "Jochi,"], "answer_start": [112, 112, 112]}, "prediction_text": "Jochi (Tem\u00fcjin's eldest son)"}
{"answers": {"text": ["Jamukha", "Jamukha", "Jamukha,"], "answer_start": [295, 295, 295]}, "prediction_text": "Jamukha"}
{"answers": {"text": ["Jamukha", "Jamukha", "Jamukha"], "answer_start": [485, 485, 485]}, "prediction_text": "Jamukha"}
{"answers": {"text": ["the Keraite", "Keraite", "Keraite tribe"], "answer_start": [590, 594, 594]}, "prediction_text": "Keraite tribe"}
{"answers": {"text": ["the Naimans", "Naimans", "the Naimans"], "answer_start": [38, 42, 38]}, "prediction_text": "Naimans (Naiman Mongols)"}
{"answers": {"text": ["1201", "1201", "1201"], "answer_start": [213, 213, 213]}, "prediction_text": "1201"}
{"answers": {"text": ["universal ruler", "universal ruler", "universal ruler"], "answer_start": [261, 261, 261]}, "prediction_text": "Universal ruler"}
{"answers": {"text": ["Subutai", "Subutai", "Subutai"], "answer_start": [528, 528, 528]}, "prediction_text": "Subutai"}
{"answers": {"text": ["1206", "1206", "1206"], "answer_start": [657, 657, 657]}, "prediction_text": "1201"}
{"answers": {"text": ["his friendship", "friendship", "friendship"], "answer_start": [55, 59, 59]}, "prediction_text": "A friendship"}
{"answers": {"text": ["he did not want disloyal men in his army", "did not want disloyal men in his army", "he did not want disloyal men in his army"], "answer_start": [178, 181, 178]}, "prediction_text": "He did not want disloyal men in his army."}
{"answers": {"text": ["a noble death", "a noble death", "a noble death."], "answer_start": [340, 340, 340]}, "prediction_text": "A noble death"}
{"answers": {"text": ["breaking the back", "breaking the back", "breaking the back"], "answer_start": [420, 420, 420]}, "prediction_text": "Noble death"}
{"answers": {"text": ["the Chinese", "Chinese", "the Chinese"], "answer_start": [698, 702, 698]}, "prediction_text": "Chinese"}
{"answers": {"text": ["Jamukha", "Jamukha", "tribes led by Jamukha"], "answer_start": [826, 826, 812]}, "prediction_text": "Jamukha's tribes"}
{"answers": {"text": ["Khasar", "Khasar", "Khasar"], "answer_start": [382, 382, 382]}, "prediction_text": "Khasar"}
{"answers": {"text": ["Yam route systems", "understanding the motivations of his rivals"], "answer_start": [562, 472]}, "prediction_text": "The economy of Genghis Khan"}
{"answers": {"text": ["Wang Khan", "Wang Khan", "Wang Khan"], "answer_start": [207, 207, 207]}, "prediction_text": "Wang Khan"}
{"answers": {"text": ["1206", "1206", "1206"], "answer_start": [16, 16, 16]}, "prediction_text": "1206"}
{"answers": {"text": ["Khuruldai", "Khuruldai", "Khuruldai"], "answer_start": [254, 254, 254]}, "prediction_text": "Khuruldai"}
{"answers": {"text": ["Khagan", "Khagan", "Khagan"], "answer_start": [404, 404, 404]}, "prediction_text": "Khagan"}
{"answers": {"text": ["\u00d6gedei", "\u00d6gedei", "\u00d6gedei"], "answer_start": [491, 491, 491]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["a council of Mongol chiefs", "a council of Mongol chiefs", "a council of Mongol chiefs"], "answer_start": [265, 265, 265]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["the Jin dynasty", "Jin dynasty.", "Jin dynasty"], "answer_start": [82, 86, 86]}, "prediction_text": "Jin dynasty"}
{"answers": {"text": ["Ming-Tan", "Ming-Tan", "Ming-Tan"], "answer_start": [261, 261, 261]}, "prediction_text": "Ming-Tan"}
{"answers": {"text": ["1215", "1215", "1215"], "answer_start": [489, 489, 489]}, "prediction_text": "1211"}
{"answers": {"text": ["Kaifeng", "Kaifeng", "Kaifeng,"], "answer_start": [644, 644, 644]}, "prediction_text": "Kaifeng"}
{"answers": {"text": ["\u00d6gedei Khan", "\u00d6gedei Khan", "\u00d6gedei Khan"], "answer_start": [803, 803, 803]}, "prediction_text": "\u00d6gedei Khan"}
{"answers": {"text": ["Kuchlug", "Kuchlug", "Kuchlug"], "answer_start": [0, 0, 0]}, "prediction_text": "Kuchlug"}
{"answers": {"text": ["the Liao dynasty", "Liao", "Liao dynasty"], "answer_start": [241, 245, 245]}, "prediction_text": "Liao dynasty"}
{"answers": {"text": ["20,000", "20,000", "20,000"], "answer_start": [537, 537, 537]}, "prediction_text": "20,000 soldiers"}
{"answers": {"text": ["Jebe", "Jebe", "Jebe"], "answer_start": [598, 598, 598]}, "prediction_text": "Jebe"}
{"answers": {"text": ["The Arrow", "The Arrow", "The Arrow"], "answer_start": [614, 614, 614]}, "prediction_text": "\"The Arrow\""}
{"answers": {"text": ["inciting internal revolt", "inciting internal revolt", "inciting internal revolt among Kuchlug's supporters"], "answer_start": [93, 93, 93]}, "prediction_text": "Invaded Kuchlug's supporters."}
{"answers": {"text": ["west of Kashgar", "west of Kashgar", "west of Kashgar"], "answer_start": [247, 247, 247]}, "prediction_text": "West of Kashgar"}
{"answers": {"text": ["Lake Balkhash", "Lake Balkhash", "Lake Balkhash,"], "answer_start": [443, 443, 443]}, "prediction_text": "West of Kashgar"}
{"answers": {"text": ["Khwarezmid Empire", "Khwarezmid", "Khwarezmid Empire"], "answer_start": [489, 489, 489]}, "prediction_text": "Khwarezmid Empire"}
{"answers": {"text": ["a Muslim state", "Muslim", "Muslim"], "answer_start": [509, 511, 511]}, "prediction_text": "Muslim state"}
{"answers": {"text": ["Shah Ala ad-Din Muhammad", "Shah Ala ad-Din Muhammad", "Shah Ala ad-Din Muhammad"], "answer_start": [67, 67, 67]}, "prediction_text": "Shah Ala ad-Din Muhammad"}
{"answers": {"text": ["Inalchuq", "Inalchuq", "Inalchuq"], "answer_start": [300, 300, 300]}, "prediction_text": "Inalchuq"}
{"answers": {"text": ["the Muslim", "Muslim", "the Muslim"], "answer_start": [845, 742, 845]}, "prediction_text": "The Muslim beheaded the ambassador."}
{"answers": {"text": ["100,000", "100,000", "100,000 soldiers"], "answer_start": [1079, 1079, 1079]}, "prediction_text": "100,000 soldiers"}
{"answers": {"text": ["the Silk Road", "Silk Road", "Silk Road"], "answer_start": [186, 190, 190]}, "prediction_text": "Silk Road"}
{"answers": {"text": ["Tien Shan", "Tien Shan", "Tien Shan"], "answer_start": [70, 70, 70]}, "prediction_text": "Tien Shan mountains"}
{"answers": {"text": ["three", "three", "three groups"], "answer_start": [261, 261, 261]}, "prediction_text": "Three divisions"}
{"answers": {"text": ["the southeast", "southeast", "the southeast part of Khwarzemia"], "answer_start": [397, 401, 397]}, "prediction_text": "From the northeast part of Khwarzemia"}
{"answers": {"text": ["Tolui", "Tolui", "Genghis Khan and Tolui"], "answer_start": [536, 536, 519]}, "prediction_text": "Tolui"}
{"answers": {"text": ["Samarkand", "Samarkand", "Samarkand"], "answer_start": [483, 483, 483]}, "prediction_text": "Samarkand"}
{"answers": {"text": ["fragmentation", "fragmentation", "fragmentation"], "answer_start": [156, 156, 156]}, "prediction_text": "Small fractions of Khwarzemi forces"}
{"answers": {"text": ["Otrar", "Otrar", "Otrar"], "answer_start": [432, 432, 432]}, "prediction_text": "Near the end of the battle, the Shah fled."}
{"answers": {"text": ["silver", "silver", "molten silver"], "answer_start": [627, 627, 620]}, "prediction_text": "Silver"}
{"answers": {"text": ["fled", "fled", "fled"], "answer_start": [726, 726, 726]}, "prediction_text": "He fled."}
{"answers": {"text": ["Subutai and Jebe", "Subutai and Jebe", "Subutai and Jebe"], "answer_start": [775, 775, 775]}, "prediction_text": "Subutai and Jebe"}
{"answers": {"text": ["Samarkand", "Samarkand", "Samarkand"], "answer_start": [82, 82, 82]}, "prediction_text": "Samarkand"}
{"answers": {"text": ["Bukhara", "Bukhara", "Bukhara"], "answer_start": [123, 123, 123]}, "prediction_text": "Bukhara"}
{"answers": {"text": ["a river", "a river", "a river"], "answer_start": [443, 443, 443]}, "prediction_text": "diverted a river"}
{"answers": {"text": ["captured enemies", "captured enemies", "captured enemies"], "answer_start": [37, 37, 37]}, "prediction_text": "Covered enemies as body shields."}
{"answers": {"text": ["reneged", "reneged", "executed every soldier"], "answer_start": [220, 220, 255]}, "prediction_text": "Reneged on surrender terms"}
{"answers": {"text": ["pyramids of severed heads", "pyramids of severed heads", "pyramids of severed heads"], "answer_start": [442, 442, 442]}, "prediction_text": "Pyramids of severed heads"}
{"answers": {"text": ["opened the gates", "opened the gates to the Mongols", "opened the gates to the Mongols"], "answer_start": [140, 140, 140]}, "prediction_text": "opened the gates to the Mongols."}
{"answers": {"text": ["a unit of Turkish defenders", "a unit of Turkish defenders", "Turkish defenders"], "answer_start": [180, 180, 190]}, "prediction_text": "Turkish defenders"}
{"answers": {"text": ["artisans and craftsmen", "artisans and craftsmen", "artisans and craftsmen"], "answer_start": [299, 299, 299]}, "prediction_text": "Young men who had not fought"}
{"answers": {"text": ["the flail of God", "the flail of God", "the flail of God,"], "answer_start": [687, 687, 687]}, "prediction_text": "The flail of God"}
{"answers": {"text": ["young men who had not fought", "young men who had not fought", "young men who had not fought"], "answer_start": [350, 350, 350]}, "prediction_text": "Young men who had not fought"}
{"answers": {"text": ["1220", "1220", "1220,"], "answer_start": [46, 46, 46]}, "prediction_text": "1220"}
{"answers": {"text": ["Subutai", "Subutai", "Subutai"], "answer_start": [167, 167, 167]}, "prediction_text": "Subutai's plan"}
{"answers": {"text": ["near the Black Sea", "Black Sea", "Russia"], "answer_start": [601, 610, 399]}, "prediction_text": "In Persia and Armenia."}
{"answers": {"text": ["Kalka River", "Kalka River", "Kalka River"], "answer_start": [996, 996, 996]}, "prediction_text": "Near the Black Sea"}
{"answers": {"text": ["Mstislav the Bold of Halych and Mstislav III of Kiev", "Mstislav the Bold of Halych and Mstislav III of Kiev", "Mstislav the Bold of Halych and Mstislav III of Kiev"], "answer_start": [761, 761, 761]}, "prediction_text": "Mstislav III of Kiev"}
{"answers": {"text": ["Batu", "Batu", "Genghis Khan's grandson Batu"], "answer_start": [883, 883, 859]}, "prediction_text": "Genghis Khan"}
{"answers": {"text": ["the Golden Horde", "Golden Horde", "the Golden Horde"], "answer_start": [892, 896, 892]}, "prediction_text": "Mongol army"}
{"answers": {"text": ["Subutai and Jebe", "Subutai and Jebe", "Subutai and Jebe"], "answer_start": [302, 302, 302]}, "prediction_text": "Genghis Khan and Batu"}
{"answers": {"text": ["1225", "1225", "1225"], "answer_start": [681, 681, 681]}, "prediction_text": "1225"}
{"answers": {"text": ["on the road back to Samarkand", "on the road back to Samarkand", "the road back to Samarkand"], "answer_start": [234, 234, 237]}, "prediction_text": "On the road back to Samarkand."}
{"answers": {"text": ["1226", "1226", "1226"], "answer_start": [3, 3, 3]}, "prediction_text": "1226"}
{"answers": {"text": ["autumn", "autumn", "autumn"], "answer_start": [209, 209, 209]}, "prediction_text": "Autumn"}
{"answers": {"text": ["the Mongols", "Mongols", "the Mongols"], "answer_start": [297, 301, 297]}, "prediction_text": "The Tangut relief army"}
{"answers": {"text": ["the Yellow River", "Yellow River", "Yellow River"], "answer_start": [432, 436, 436]}, "prediction_text": "Yellow River"}
{"answers": {"text": ["a line of five stars arranged in the sky", "a line of five stars", "a line of five stars arranged in the sky"], "answer_start": [550, 550, 550]}, "prediction_text": "Five stars"}
{"answers": {"text": ["Ning Hia", "Ning Hia", "Ning Hia"], "answer_start": [74, 74, 74]}, "prediction_text": "Ning Hia"}
{"answers": {"text": ["Ma Jianlong", "Ma Jianlong", "Ma Jianlong"], "answer_start": [241, 241, 241]}, "prediction_text": "Ma Jianlong"}
{"answers": {"text": ["arrows", "arrows", "arrows"], "answer_start": [417, 417, 417]}, "prediction_text": "Arrows"}
{"answers": {"text": ["Liupanshan", "Liupanshan", "Liupanshan"], "answer_start": [482, 482, 482]}, "prediction_text": "Liupanshan (Qingshui County, Gansu Province)"}
{"answers": {"text": ["executed", "executed", "executed"], "answer_start": [778, 778, 778]}, "prediction_text": "He ordered the entire imperial family to be executed."}
{"answers": {"text": ["Jochi", "Jochi", "Jochi"], "answer_start": [250, 250, 187]}, "prediction_text": "Jochi's sons"}
{"answers": {"text": ["Chagatai", "Chagatai", "Chagatai"], "answer_start": [498, 383, 383]}, "prediction_text": "Chagatai"}
{"answers": {"text": ["invasion of the Khwarezmid Empire", "invasion of the Khwarezmid Empire", "invasion of the Khwarezmid Empire"], "answer_start": [447, 447, 447]}, "prediction_text": "The invasion of the Khwarezmid Empire"}
{"answers": {"text": ["\u00d6gedei", "\u00d6gedei", "\u00d6gedei"], "answer_start": [670, 670, 670]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["Chagatai and Jochi", "Chagatai and Jochi", "Chagatai and Jochi)"], "answer_start": [78, 78, 78]}, "prediction_text": "Chagatai and Jochi"}
{"answers": {"text": ["Chagatai", "Chagatai", "Chagatai"], "answer_start": [310, 78, 310]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["Tolui", "Tolui", "Tolui,"], "answer_start": [486, 486, 486]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["\u00d6gedei", "\u00d6gedei", "\u00d6gedei"], "answer_start": [855, 855, 855]}, "prediction_text": "\u00d6gedei"}
{"answers": {"text": ["1226", "1226", "1226"], "answer_start": [14, 14, 14]}, "prediction_text": "1226"}
{"answers": {"text": ["Khorasan", "Khorasan", "Khorasan"], "answer_start": [326, 326, 326]}, "prediction_text": "Khorasan"}
{"answers": {"text": ["Urgench", "Urgench", "Urgench"], "answer_start": [443, 443, 483]}, "prediction_text": "Urgench"}
{"answers": {"text": ["Sultan Muhammad", "Sultan Muhammad", "Sultan Muhammad"], "answer_start": [811, 811, 811]}, "prediction_text": "Sultan Muhammad"}
{"answers": {"text": ["Sultan Muhammad was already dead in 1223", "Sultan Muhammad was already dead in 1223", "Sultan Muhammad was already dead in 1223,"], "answer_start": [1033, 1033, 1033]}, "prediction_text": "The story is based on the fact that Jochi was secretly poisoned by Genghis Khan."}
{"answers": {"text": ["Yinchuan", "Yinchuan", "Yinchuan"], "answer_start": [35, 35, 35]}, "prediction_text": "Western Xia"}
{"answers": {"text": ["hunting", "hunting", "hunting"], "answer_start": [380, 380, 380]}, "prediction_text": "Hunting and fighting."}
{"answers": {"text": ["arrow", "arrow", "arrow wound"], "answer_start": [615, 615, 615]}, "prediction_text": "An arrow wound"}
{"answers": {"text": ["Western Xia", "Western Xia", "Western Xia"], "answer_start": [720, 720, 720]}, "prediction_text": "Western Xia"}
{"answers": {"text": ["Oirads", "Oirads", "Oirads"], "answer_start": [983, 983, 983]}, "prediction_text": "The Oirads"}
{"answers": {"text": ["without markings", "buried without markings", "buried without markings"], "answer_start": [56, 49, 49]}, "prediction_text": "No markings, no burial."}
{"answers": {"text": ["Khentii Aimag", "Khentii Aimag", "Khentii Aimag"], "answer_start": [198, 198, 198]}, "prediction_text": "Khentii Aimag"}
{"answers": {"text": ["Onon River", "Onon", "Onon River"], "answer_start": [267, 267, 267]}, "prediction_text": "Onon River"}
{"answers": {"text": ["The Genghis Khan Mausoleum", "Genghis Khan Mausoleum", "The Genghis Khan Mausoleum"], "answer_start": [473, 477, 473]}, "prediction_text": "The Genghis Khan Mausoleum"}
{"answers": {"text": ["Edsen Khoroo", "Edsen Khoroo", "Edsen Khoroo"], "answer_start": [112, 112, 112]}, "prediction_text": "Dongshan Dafo Dian"}
{"answers": {"text": ["Dongshan Dafo Dian", "Dongshan Dafo Dian", "the Dongshan Dafo Dian"], "answer_start": [290, 290, 286]}, "prediction_text": "Kumbum Monastery"}
{"answers": {"text": ["Kumbum Monastery or Ta'er Shi near Xining", "Kumbum Monastery", "Tibetan monastery of Kumbum Monastery"], "answer_start": [479, 479, 458]}, "prediction_text": "Mongolian Buddhist monastery"}
{"answers": {"text": ["1954", "1954", "1954,"], "answer_start": [572, 572, 572]}, "prediction_text": "1956"}
{"answers": {"text": ["Red Guards", "Red Guards", "1968"], "answer_start": [754, 754, 717]}, "prediction_text": "Red Guards"}
{"answers": {"text": ["October 6, 2004", "October 6, 2004", "October 6, 2004"], "answer_start": [3, 3, 3]}, "prediction_text": "October 6, 2004"}
{"answers": {"text": ["a river", "river", "river"], "answer_start": [244, 246, 246]}, "prediction_text": "River"}
{"answers": {"text": ["Sumerian King Gilgamesh of Uruk and Atilla the Hun", "King Gilgamesh of Uruk and Atilla the Hun", "Gilgamesh of Uruk and Atilla the Hun"], "answer_start": [344, 353, 358]}, "prediction_text": "Atilla the Hun and Gilgamesh"}
{"answers": {"text": ["horses", "horses", "horses"], "answer_start": [457, 457, 457]}, "prediction_text": "Horses"}
{"answers": {"text": ["Genghis Khan", "Genghis Khan", "Genghis Khan"], "answer_start": [93, 93, 93]}, "prediction_text": "Genghis Khan"}
{"answers": {"text": ["Yassa", "Yassa", "Yassa"], "answer_start": [75, 75, 75]}, "prediction_text": "Yassa"}
{"answers": {"text": ["meritocracy", "meritocracy", "meritocracy"], "answer_start": [250, 250, 250]}, "prediction_text": "Appreciation of ethnicity and race"}
{"answers": {"text": ["Genghis Khan and his family", "Genghis Khan and his family", "Genghis Khan and his family"], "answer_start": [293, 293, 293]}, "prediction_text": "Genghis Khan and his family"}
{"answers": {"text": ["Muhammad Khan", "Muhammad Khan", "Muhammad Khan"], "answer_start": [666, 666, 666]}, "prediction_text": "Genghis Khan"}
{"answers": {"text": ["tax exemptions", "tax exemptions", "tax exemptions"], "answer_start": [11, 11, 11]}, "prediction_text": "Tax exemptions"}
{"answers": {"text": ["Ong Khan", "Ong Khan", "Ong Khan"], "answer_start": [315, 315, 315]}, "prediction_text": "Ong Khan"}
{"answers": {"text": ["a personal concept", "tolerance", "a personal concept, and not subject to law or interference"], "answer_start": [196, 468, 196]}, "prediction_text": "Religion was a personal concept."}
{"answers": {"text": ["Shamanist, Buddhist or Christian", "Shamanist, Buddhist or Christian", "Shamanist, Buddhist or Christian"], "answer_start": [424, 424, 424]}, "prediction_text": "Shamanist, Buddhist, Christian."}
{"answers": {"text": ["T\u00f6regene Khatun", "T\u00f6regene Khatun", "T\u00f6regene Khatun"], "answer_start": [435, 435, 435]}, "prediction_text": "T\u00f6regene Khatun"}
{"answers": {"text": ["the Pax Mongolica (Mongol Peace)", "Pax Mongolica", "Pax Mongolica (Mongol Peace)"], "answer_start": [620, 624, 624]}, "prediction_text": "Pax Mongolica"}
{"answers": {"text": ["the Chinese", "Chinese", "Chinese"], "answer_start": [337, 341, 341]}, "prediction_text": "Chinese"}
{"answers": {"text": ["legal equality of all individuals, including women", "legal equality of all individuals", "Great Yassa"], "answer_start": [167, 167, 123]}, "prediction_text": "Legal equality of all individuals."}
{"answers": {"text": ["Chu'Tsai", "Chu'Tsai", "Chu'Tsai,"], "answer_start": [307, 307, 307]}, "prediction_text": "Chu'Tsai"}
{"answers": {"text": ["they were nomads", "nomads", "nomads and thus had no experience governing cities"], "answer_start": [190, 200, 200]}, "prediction_text": "Nomads had no experience governing cities."}
{"answers": {"text": ["Jin", "Jin", "Jin dynasty"], "answer_start": [417, 417, 391]}, "prediction_text": "Mongol army"}
{"answers": {"text": ["Khitan rulers", "Khitan rulers", "Khitan rulers,"], "answer_start": [516, 516, 516]}, "prediction_text": "Khitan rulers"}
{"answers": {"text": ["his generals", "Muqali, Jebe and Subutai", "his generals"], "answer_start": [35, 57, 35]}, "prediction_text": "Muqali, Jebe, Subutai"}
{"answers": {"text": ["Karakorum", "Karakorum", "Karakorum"], "answer_start": [329, 329, 329]}, "prediction_text": "Karakorum"}
{"answers": {"text": ["Muqali", "Muqali", "Muqali,"], "answer_start": [340, 340, 340]}, "prediction_text": "Muqali"}
{"answers": {"text": ["Subutai and Jebe", "Subutai and Jebe", "Subutai and Jebe"], "answer_start": [486, 486, 486]}, "prediction_text": "Muqali and Subutai"}
{"answers": {"text": ["unwavering loyalty", "unwavering loyalty", "unwavering loyalty"], "answer_start": [751, 751, 751]}, "prediction_text": "Unwavering loyalty"}
{"answers": {"text": ["rivers", "rivers", "rivers"], "answer_start": [122, 122, 122]}, "prediction_text": "River streams"}
{"answers": {"text": ["Muslim and Chinese", "Muslim and Chinese", "Muslim and Chinese"], "answer_start": [295, 295, 295]}, "prediction_text": "Muslim and Chinese siege engines and engineers"}
{"answers": {"text": ["feigned retreat", "feigned retreat", "feigned retreat"], "answer_start": [463, 463, 463]}, "prediction_text": "Fleeing from larger group and attacking with siege engines and engineers."}
{"answers": {"text": ["driving them in front of the army", "driving them in front of the army", "driving them in front of the army"], "answer_start": [157, 157, 157]}, "prediction_text": "Used as bait for ambush and counterattack."}
{"answers": {"text": ["Sea of Japan", "Sea of Japan", "Caspian Sea to the Sea of Japan"], "answer_start": [191, 191, 172]}, "prediction_text": "Sea of Japan"}
{"answers": {"text": ["Caspian Sea", "Caspian Sea", "Caspian Sea to the Sea of Japan"], "answer_start": [172, 172, 172]}, "prediction_text": "Sea of Japan"}
{"answers": {"text": ["\u00d6gedei Khan", "\u00d6gedei Khan", "\u00d6gedei Khan"], "answer_start": [320, 320, 320]}, "prediction_text": "Genghis Khan"}
{"answers": {"text": ["1279", "1279", "1279"], "answer_start": [570, 570, 570]}, "prediction_text": "1279"}
{"answers": {"text": ["the Silk Road", "Silk Road", "Silk Road"], "answer_start": [39, 43, 43]}, "prediction_text": "Silk Road"}
{"answers": {"text": ["Turkey", "Turkey", "Turkey,"], "answer_start": [423, 423, 423]}, "prediction_text": "Turkey"}
{"answers": {"text": ["tolerant", "tolerant", "tolerant of religions"], "answer_start": [342, 342, 342]}, "prediction_text": "He instituted certain levels of meritocracy."}
{"answers": {"text": ["increased", "expanding the horizons", "increased communication and trade"], "answer_start": [108, 187, 108]}, "prediction_text": "Increased communication and trade."}
{"answers": {"text": ["1990s", "1990s", "1990s"], "answer_start": [13, 13, 13]}, "prediction_text": "1990s"}
{"answers": {"text": ["uniting warring tribes", "uniting warring tribes", "uniting warring tribes"], "answer_start": [322, 322, 322]}, "prediction_text": "Uniting warring tribes."}
{"answers": {"text": ["Genghis Khan's children", "Genghis Khan's children", "father of the Mongols"], "answer_start": [467, 467, 521]}, "prediction_text": "They refer to him as \"Genghis Khan's Mongolia\" and \"father of the Mongols.\""}
{"answers": {"text": ["his brutality", "butchery", "his butchery"], "answer_start": [632, 775, 771]}, "prediction_text": "His brutality"}
{"answers": {"text": ["unfairly biased", "unfairly biased", "his positive role is underrated"], "answer_start": [725, 725, 806]}, "prediction_text": "Unfairly biased against Genghis Khan."}
{"answers": {"text": ["t\u00f6gr\u00f6g", "t\u00f6gr\u00f6g", "t\u00f6gr\u00f6g"], "answer_start": [286, 286, 286]}, "prediction_text": "500, 1,000, 5,000, 10,000, 20,000 Mongolian t\u00f6gr\u00f6g (\u20ae)"}
{"answers": {"text": ["Genghis Khan", "Genghis Khan's"], "answer_start": [19, 19]}, "prediction_text": "500, 1,000, 5,000, 10,000, 20,000."}
{"answers": {"text": ["Chinggis Khaan International Airport", "Chinggis Khaan International Airport", "Chinggis Khaan International Airport"], "answer_start": [360, 360, 360]}, "prediction_text": "Chinggis Khaan International Airport"}
{"answers": {"text": ["to avoid trivialization", "avoid trivialization", "avoid trivialization."], "answer_start": [571, 574, 574]}, "prediction_text": "To avoid trivialization."}
{"answers": {"text": ["Ulaanbaatar", "Ulaanbaatar", "Ulaanbaatar"], "answer_start": [474, 474, 474]}, "prediction_text": "Ulaanbaatar"}
{"answers": {"text": ["Ikh Zasag", "Ikh Zasag (", "Ikh Zasag"], "answer_start": [484, 484, 484]}, "prediction_text": "Ikh Zasag law"}
{"answers": {"text": ["corruption and bribery", "corruption and bribery", "corruption and bribery"], "answer_start": [661, 661, 661]}, "prediction_text": "Illegal matters related to corruption and bribery."}
{"answers": {"text": ["Tsakhiagiin Elbegdorj", "Tsakhiagiin Elbegdorj", "Elbegdorj"], "answer_start": [719, 719, 1203]}, "prediction_text": "Tsakhiagiin Elbegdorj"}
{"answers": {"text": ["traditional Mongolian script", "traditional Mongolian script", "traditional Mongolian script"], "answer_start": [431, 431, 431]}, "prediction_text": "Traditional Mongolian script"}
{"answers": {"text": ["Inner Mongolia region", "Inner Mongolia region", "Inner Mongolia region"], "answer_start": [118, 118, 118]}, "prediction_text": "Inner Mongolia region"}
{"answers": {"text": ["5 million", "around 5 million", "around 5 million"], "answer_start": [283, 276, 276]}, "prediction_text": "Around 5 million"}
{"answers": {"text": ["Kublai Khan", "Kublai Khan", "Kublai Khan"], "answer_start": [397, 397, 397]}, "prediction_text": "Kublai Khan"}
{"answers": {"text": ["Yuan", "Yuan", "Yuan dynasty"], "answer_start": [453, 453, 657]}, "prediction_text": "Yuan dynasty"}
{"answers": {"text": ["grandson", "grandson", "grandson"], "answer_start": [388, 388, 388]}, "prediction_text": "Kublai Khan was Kublai Khan's grandson."}
{"answers": {"text": ["Iran", "Iran", "Iran"], "answer_start": [40, 40, 40]}, "prediction_text": "Iran"}
{"answers": {"text": ["three-fourths", "three-fourths", "up to three-fourths of the population"], "answer_start": [293, 293, 287]}, "prediction_text": "Up to three-fourths"}
{"answers": {"text": ["10 to 15 million", "10 to 15 million people", "10 to 15 million people"], "answer_start": [358, 358, 358]}, "prediction_text": "10 to 15 million"}
{"answers": {"text": ["Hulagu Khan", "Hulagu Khan", "Hulagu Khan"], "answer_start": [181, 181, 181]}, "prediction_text": "Hulagu Khan"}
{"answers": {"text": ["the Mamluks of Egypt", "Mamluks", "the Mamluks of Egypt"], "answer_start": [286, 290, 286]}, "prediction_text": "The Mamluks of Egypt"}
{"answers": {"text": ["Ghazan Khan", "Ghazan Khan", "Ghazan Khan"], "answer_start": [332, 332, 332]}, "prediction_text": "Ghazan Khan"}
{"answers": {"text": ["1237", "1237", "1237"], "answer_start": [593, 593, 593]}, "prediction_text": "1237"}
{"answers": {"text": ["Novgorod and Pskov", "Novgorod and Pskov", "Novgorod and Pskov"], "answer_start": [811, 811, 811]}, "prediction_text": "Novgorod and Pskov"}
{"answers": {"text": ["Mughal emperors", "Mughal emperors", "Mughal emperors"], "answer_start": [20, 20, 20]}, "prediction_text": "Mughal emperors"}
{"answers": {"text": ["Timur", "Timur", "Timur"], "answer_start": [431, 92, 92]}, "prediction_text": "Timur (Mongol Empire)"}
{"answers": {"text": ["Nishapur", "Nishapur", "Nishapur"], "answer_start": [312, 312, 312]}, "prediction_text": "South Asia"}
{"answers": {"text": ["tenggis", "tenggis", "tenggis"], "answer_start": [95, 95, 95]}, "prediction_text": "Tenggis Khan"}
{"answers": {"text": ["Lake Baikal", "Lake Baikal", "Lake Baikal"], "answer_start": [153, 153, 153]}, "prediction_text": "Lake Baikal"}
{"answers": {"text": ["\"right\", \"just\", or \"true\"", "right", "right\", \"just\", or \"true\","], "answer_start": [375, 376, 376]}, "prediction_text": "Right, just, true."}
{"answers": {"text": ["Zh\u00e8ng", "Zh\u00e8ng", "Zh\u00e8ng"], "answer_start": [348, 348, 348]}, "prediction_text": "Tenggis Khan"}
{"answers": {"text": ["Chinggis", "Chinggis", "\"Jenggis"], "answer_start": [627, 627, 470]}, "prediction_text": "\"Chinggis\""}
{"answers": {"text": ["Chinggis Khaan", "Chinggis Khaan", "Chinggis Khaan", "Chinggis Khaan"], "answer_start": [95, 95, 95, 95]}, "prediction_text": "Chinggis Khan"}
{"answers": {"text": ["Cengiz Han", "Cengiz Han", "Cengiz Han", "Cengiz Han, \u00c7ingiz Xan, \u00c7ingiz Han, Chingizxon, \u00c7\u0131\u00f1\u011f\u0131z Xan, Chengez Khan, Chinggis Khan, Chinggis Xaan, Chingis Khan, Jenghis Khan, Chinggis Qan, Djingis Kahn"], "answer_start": [198, 198, 198, 198]}, "prediction_text": "Ch\u00e9ngj\u00eds\u012b H\u00e1n"}
{"answers": {"text": ["Ti\u011bm\u00f9zh\u0113n", "Ti\u011bm\u00f9zh\u0113n", "Ti\u011bm\u00f9zh\u0113n", "Ti\u011bm\u00f9zh\u0113n"], "answer_start": [516, 516, 516, 516]}, "prediction_text": "simplified Chinese: \u9435\u6728\u771e"}
{"answers": {"text": ["Chinghiz, Chinghis, and Chingiz", "Chinghiz, Chinghis, and Chingiz", "Chinghiz, Chinghis, and Chingiz", "Chinghiz, Chinghis, and Chingiz"], "answer_start": [119, 119, 119, 119]}, "prediction_text": "Chinghiz"}
{"answers": {"text": ["Ch\u00e9ngj\u00eds\u012b H\u00e1n", "Ch\u00e9ngj\u00eds\u012b H\u00e1n", "Ch\u00e9ngj\u00eds\u012b H\u00e1n", "Ch\u00e9ngj\u00eds\u012b H\u00e1n,"], "answer_start": [175, 175, 175, 175]}, "prediction_text": "Chingj\u00eds\u012b H\u00e1n"}
{"answers": {"text": ["its root word pharma", "pharma", "pharma", "pharma"], "answer_start": [34, 48, 48, 48]}, "prediction_text": "Greek word pharma"}
{"answers": {"text": ["ingredients for medicines, sold tobacco and patent medicines", "ingredients for medicines, sold tobacco and patent medicines", "ingredients for medicines, sold tobacco and patent medicines", "medicines"], "answer_start": [483, 483, 483, 499]}, "prediction_text": "Tobacco and patent medicines."}
{"answers": {"text": ["sorcery or even poison", "sorcery or even poison", "sorcery", "sorcery"], "answer_start": [163, 163, 163, 163]}, "prediction_text": "sorcery or poison."}
{"answers": {"text": ["outdated or only approproriate if herbal remedies were on offer to a large extent", "outdated", "outdated", "outdated"], "answer_start": [767, 767, 767, 767]}, "prediction_text": "outdated or only approproriate if herbal remedies were on offer."}
{"answers": {"text": ["many other herbs not listed", "many other herbs", "other herbs not listed", "other herbs"], "answer_start": [872, 872, 877, 877]}, "prediction_text": "Other herbs not listed."}
{"answers": {"text": ["healthcare professionals", "healthcare", "healthcare professionals with specialised education"], "answer_start": [16, 16, 16]}, "prediction_text": "Healthcare professionals"}
{"answers": {"text": ["optimal health outcomes", "optimal", "optimal health outcomes"], "answer_start": [117, 117, 117]}, "prediction_text": "Quality use of medicines"}
{"answers": {"text": ["optimisation of a drug treatment for an individual", "optimisation of a drug treatment", "optimisation of a drug treatment for an individual"], "answer_start": [475, 475, 475]}, "prediction_text": "Optimisation of a drug treatment"}
{"answers": {"text": ["small-business proprietors", "small-business proprietors", "small-business proprietors"], "answer_start": [222, 222, 222]}, "prediction_text": "In optimisation of drugs"}
{"answers": {"text": ["specialised education and training", "specialised education and training", "specialised education and training"], "answer_start": [46, 46, 46]}, "prediction_text": "Preparation for drugs"}
{"answers": {"text": ["other senior pharmacy technicians", "senior pharmacy technicians", "other senior pharmacy technicians"], "answer_start": [220, 226, 220]}, "prediction_text": "A Pharmacy Technician in the UK is considered a health care professional."}
{"answers": {"text": ["the General Pharmaceutical Council (GPhC) register", "General Pharmaceutical Council (GPhC)", "General Pharmaceutical Council (GPhC) register"], "answer_start": [640, 644, 644]}, "prediction_text": "GPhC"}
{"answers": {"text": ["regulates the practice of pharmacists and pharmacy technicians", "governing body for pharmacy health care professionals", "regulates the practice of pharmacists and pharmacy technicians"], "answer_start": [778, 708, 778]}, "prediction_text": "Regulating pharmacy practice"}
{"answers": {"text": ["health care professional", "pharmacy health care", "health care professional"], "answer_start": [48, 727, 48]}, "prediction_text": "Health care professional"}
{"answers": {"text": ["manage the pharmacy department and specialised areas in pharmacy practice", "manage the pharmacy department and specialised areas", "manage the pharmacy department"], "answer_start": [342, 342, 342]}, "prediction_text": "Manage pharmacy department, specialised areas."}
{"answers": {"text": ["writing a five volume book in his native Greek", "writing a five volume book", "five volume book in his native Greek"], "answer_start": [220, 220, 230]}, "prediction_text": "Writing a five volume book in his native Greek."}
{"answers": {"text": ["De Materia Medica", "De Materia Medica", "De Materia Medica"], "answer_start": [331, 331, 331]}, "prediction_text": "De Materia Medica"}
{"answers": {"text": ["materia medica", "materia medica", "materia medica"], "answer_start": [533, 533, 533]}, "prediction_text": "materia medica"}
{"answers": {"text": ["Diocles of Carystus", "Diocles of Carystus", "Diocles of Carystus"], "answer_start": [19, 19, 19]}, "prediction_text": "Diocles of Carystus"}
{"answers": {"text": ["many middle eastern scientists", "middle eastern scientists", "many middle eastern scientists"], "answer_start": [445, 450, 445]}, "prediction_text": "Latin translation De Materia Medica"}
{"answers": {"text": ["highly respected", "highly respected", "highly respected"], "answer_start": [160, 160, 160]}, "prediction_text": "Highly respected"}
{"answers": {"text": ["the Taih\u014d Code (701) and re-stated in the Y\u014dr\u014d Code (718)", "Taih\u014d Code (701) and re-stated in the Y\u014dr\u014d Code", "Taih\u014d Code (701) and re-stated in the Y\u014dr\u014d Code"], "answer_start": [239, 243, 243]}, "prediction_text": "Taih\u014d Code (701) and Y\u014dr\u014d Code (718)"}
{"answers": {"text": ["the pre-Heian Imperial court", "Taih\u014d Code", "pre-Heian Imperial court"], "answer_start": [318, 243, 322]}, "prediction_text": "The Taih\u014d Code (701) and the Y\u014dr\u014d Code (718)"}
{"answers": {"text": ["status superior to all others in health-related fields such as physicians and acupuncturists", "Ranked positions", "status superior to all others in health-related fields"], "answer_start": [553, 298, 553]}, "prediction_text": "Ranked above personal physicians."}
{"answers": {"text": ["ranked above", "ranked above", "ranked above the two personal physicians of the Emperor"], "answer_start": [698, 698, 698]}, "prediction_text": "Above the two personal physicians."}
{"answers": {"text": ["botany and chemistry", "botany and chemistry", "advances made in the Middle East in botany and chemistry"], "answer_start": [40, 40, 4]}, "prediction_text": "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes) and Al-Biruni (973\u20131050)"}
{"answers": {"text": ["Muhammad ibn Zakar\u012bya R\u0101zi", "Muhammad ibn Zakar\u012bya R\u0101zi", "Muhammad ibn Zakar\u012bya R\u0101zi"], "answer_start": [131, 131, 131]}, "prediction_text": "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes)"}
{"answers": {"text": ["Abu al-Qasim al-Zahrawi", "Abu al-Qasim al-Zahrawi", "Abu al-Qasim al-Zahrawi"], "answer_start": [249, 249, 249]}, "prediction_text": "Abu al-Qasim al-Zahrawi (Abulcasis)"}
{"answers": {"text": ["Al-Muwaffaq", "Al-Muwaffaq", "Al-Muwaffaq"], "answer_start": [1570, 1570, 1570]}, "prediction_text": "Peter of Abano"}
{"answers": {"text": ["sodium carbonate and potassium carbonate", "sodium carbonate and potassium carbonate", "sodium carbonate and potassium carbonate"], "answer_start": [1838, 1838, 1838]}, "prediction_text": "Sodium carbonate and potassium carbonate."}
{"answers": {"text": ["1317", "1317", "1317"], "answer_start": [125, 125, 125]}, "prediction_text": "At least 1422"}
{"answers": {"text": ["Church of Santa Maria Novella in Florence, Italy", "Church of Santa Maria Novella in Florence, Italy", "Florence, Italy"], "answer_start": [264, 264, 297]}, "prediction_text": "In Florence, Italy"}
{"answers": {"text": ["museum", "a museum", "museum"], "answer_start": [447, 445, 447]}, "prediction_text": "A museum"}
{"answers": {"text": ["albarellos from the 16th and 17th centuries, old prescription books and antique drugs", "albarellos from the 16th and 17th centuries, old prescription books and antique drugs", "old prescription books and antique drugs"], "answer_start": [495, 495, 540]}, "prediction_text": "Old prescription books, antique drugs."}
{"answers": {"text": ["1221", "1221", "1221"], "answer_start": [252, 252, 252]}, "prediction_text": "1221"}
{"answers": {"text": ["pharmacy legislation", "pharmacy legislation", "pharmacy legislation"], "answer_start": [48, 48, 48]}, "prediction_text": "Pharmacy legislation"}
{"answers": {"text": ["within the dispensary compounding/dispensing medications", "communicating with patients", "compounding/dispensing medications"], "answer_start": [224, 403, 246]}, "prediction_text": "Communication with patients"}
{"answers": {"text": ["automation", "automation", "automation"], "answer_start": [481, 481, 481]}, "prediction_text": "Automation"}
{"answers": {"text": ["patients' prescriptions and patient safety issues", "patients' prescriptions and patient safety issues", "dealing with patients' prescriptions and patient safety issues"], "answer_start": [538, 538, 525]}, "prediction_text": "Patient safety issues"}
{"answers": {"text": ["storage conditions, compulsory texts, equipment, etc.", "storage conditions, compulsory texts, equipment, etc.", "storage conditions, compulsory texts, equipment"], "answer_start": [92, 92, 92]}, "prediction_text": "Storage conditions, compulsory texts, equipment, etc."}
{"answers": {"text": ["a pharmacy practice residency", "pharmacy practice residency", "pharmacy practice residency"], "answer_start": [322, 324, 324]}, "prediction_text": "At hospitals and at home."}
{"answers": {"text": ["various disciplines of pharmacy", "various disciplines of pharmacy", "various disciplines of pharmacy"], "answer_start": [509, 509, 509]}, "prediction_text": "Different disciplines of pharmacy."}
{"answers": {"text": ["effectiveness of treatment regimens", "effectiveness of treatment regimens", "effectiveness of treatment regimens"], "answer_start": [73, 73, 73]}, "prediction_text": "Drug interactions"}
{"answers": {"text": ["pharmacists practicing in hospitals", "pharmacists practicing in hospitals", "clinical pharmacists"], "answer_start": [223, 223, 459]}, "prediction_text": "Clinical pharmacists"}
{"answers": {"text": ["within the premises of the hospital", "premises of the hospital", "within the premises of the hospital"], "answer_start": [39, 50, 39]}, "prediction_text": "Within the hospital premises"}
{"answers": {"text": ["unit-dose, or a single dose of medicine", "unit-dose", "unit-dose, or a single dose of medicine"], "answer_start": [260, 260, 260]}, "prediction_text": "Single dose"}
{"answers": {"text": ["high risk preparations and some other compounding functions", "high risk preparations and some other compounding functions", "high risk preparations and some other compounding functions"], "answer_start": [663, 663, 663]}, "prediction_text": "High risk preparations and compounding functions."}
{"answers": {"text": ["The high cost of medications and drug-related technology", "high cost of medications", "high cost of medications and drug-related technology"], "answer_start": [767, 771, 771]}, "prediction_text": "Training and facilities"}
{"answers": {"text": ["Hospital pharmacies usually stock a larger range of medications, including more specialized medications", "more specialized medications", "stock a larger range of medications, including more specialized medications"], "answer_start": [76, 151, 104]}, "prediction_text": "Large range of medications, superior training, and facilities."}
{"answers": {"text": ["optimizes the use of medication and promotes health, wellness, and disease prevention", "optimizes the use of medication and promotes health, wellness, and disease prevention", "direct patient care services that optimizes the use of medication and promotes health, wellness, and disease prevention"], "answer_start": [54, 54, 20]}, "prediction_text": "Optimizes use of medication, promotes health, and disease prevention."}
{"answers": {"text": ["inside hospitals and clinics", "inside hospitals and clinics", "the clinical pharmacy movement initially began inside hospitals and clinics"], "answer_start": [260, 260, 213]}, "prediction_text": "Inside hospitals and clinics"}
{"answers": {"text": ["physicians and other healthcare professionals", "physicians", "physicians and other healthcare professionals"], "answer_start": [334, 334, 334]}, "prediction_text": "Physicians"}
{"answers": {"text": ["patient care rounds drug product selection", "interdisciplinary approach", "patient care rounds drug product selection"], "answer_start": [535, 465, 535]}, "prediction_text": "Patient care rounds drug product selection."}
{"answers": {"text": ["all health care settings", "drug product selection", "all health care settings"], "answer_start": [183, 555, 183]}, "prediction_text": "In hospitals and clinics"}
{"answers": {"text": ["creating a comprehensive drug therapy plan for patient-specific problems", "identifying goals of therapy", "creating a comprehensive drug therapy plan for patient-specific problems"], "answer_start": [40, 114, 40]}, "prediction_text": "Creating a comprehensive drug therapy plan"}
{"answers": {"text": ["an evaluation of the appropriateness of the drug therapy", "an evaluation of the appropriateness of the drug therapy", "evaluation of the appropriateness of the drug therapy"], "answer_start": [274, 274, 277]}, "prediction_text": "Review process"}
{"answers": {"text": ["drug choice, dose, route, frequency, and duration of therapy", "drug choice, dose, route, frequency, and duration of therapy", "drug choice, dose, route, frequency, and duration of therapy"], "answer_start": [338, 338, 338]}, "prediction_text": "Drug therapy plan, review process, monitoring, and patient drug allergies."}
{"answers": {"text": ["potential drug interactions, adverse drug reactions", "potential drug interactions", "potential drug interactions, adverse drug reactions, and assess patient drug allergies"], "answer_start": [455, 455, 455]}, "prediction_text": "Drug interactions, adverse drug reactions, and patient drug allergies."}
{"answers": {"text": ["full independent prescribing authority", "full independent prescribing authority", "full independent prescribing authority"], "answer_start": [132, 132, 132]}, "prediction_text": "Independent prescribing authority"}
{"answers": {"text": ["North Carolina and New Mexico", "North Carolina and New Mexico", "North Carolina and New Mexico"], "answer_start": [192, 192, 192]}, "prediction_text": "North Carolina and New Mexico"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [316, 316, 316]}, "prediction_text": "2011"}
{"answers": {"text": ["Board Certified Ambulatory Care Pharmacist", "Board Certified Ambulatory Care Pharmacist", "Board Certified Ambulatory Care Pharmacist"], "answer_start": [555, 555, 555]}, "prediction_text": "BCACP"}
{"answers": {"text": ["the VA, the Indian Health Service, and NIH", "the VA, the Indian Health Service, and NIH", "VA, the Indian Health Service, and NIH"], "answer_start": [50, 50, 54]}, "prediction_text": "VA, Indian Health Service, NIH"}
{"answers": {"text": ["medication regimen review", "medication regimen review", "medication regimen review"], "answer_start": [45, 45, 45]}, "prediction_text": "Medication regimen review"}
{"answers": {"text": ["nursing homes", "nursing homes", "nursing homes"], "answer_start": [181, 181, 181]}, "prediction_text": "Nursing homes"}
{"answers": {"text": ["Omnicare, Kindred Healthcare and PharMerica", "Omnicare, Kindred Healthcare and PharMerica", "Omnicare, Kindred Healthcare and PharMerica"], "answer_start": [463, 463, 463]}, "prediction_text": "Omnicare, Kindred Healthcare, PharMerica"}
{"answers": {"text": ["because many elderly people are now taking numerous medications but continue to live outside of institutional settings", "many elderly people are now taking numerous medications but continue to live outside of institutional settings", "many elderly people are now taking numerous medications but continue to live outside of institutional settings"], "answer_start": [621, 629, 629]}, "prediction_text": "Aging population, including elderly people."}
{"answers": {"text": ["employ consultant pharmacists and/or provide consulting services", "employ consultant pharmacists", "employ consultant pharmacists and/or provide consulting services"], "answer_start": [767, 767, 767]}, "prediction_text": "Employ consultant pharmacists and provide consulting services."}
{"answers": {"text": ["about the year 2000", "2000", "2000"], "answer_start": [6, 21, 21]}, "prediction_text": "About 2000"}
{"answers": {"text": ["brick-and-mortar community pharmacies that serve consumers online and those that walk in their door", "brick-and-mortar community pharmacies", "brick-and-mortar community pharmacies"], "answer_start": [213, 213, 213]}, "prediction_text": "Community pharmacies"}
{"answers": {"text": ["online pharmacies", "online pharmacies", "online pharmacies"], "answer_start": [626, 626, 626]}, "prediction_text": "Online pharmacies"}
{"answers": {"text": ["another customer might overhear about the drugs that they take", "homebound", "more convenient and private method"], "answer_start": [527, 715, 439]}, "prediction_text": "More convenient method"}
{"answers": {"text": ["the method by which the medications are requested and received", "method by which the medications are requested and received", "the method by which the medications are requested and received"], "answer_start": [340, 344, 340]}, "prediction_text": "Method by which medications are requested and received."}
{"answers": {"text": ["to avoid the \"inconvenience\" of visiting a doctor or to obtain medications which their doctors were unwilling to prescribe", "avoid the \"inconvenience\" of visiting a doctor", "avoid the \"inconvenience\" of visiting a doctor or to obtain medications which their doctors were unwilling to prescribe"], "answer_start": [220, 223, 223]}, "prediction_text": "Avoidance of doctor visits."}
{"answers": {"text": ["those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability for use of a medication.", "by those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability for use of a medication", "those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability for use of a medication"], "answer_start": [427, 424, 427]}, "prediction_text": "Those who feel that only doctors can reliably assess contraindications, risk/benefit ratios, and an individual's overall suitability."}
{"answers": {"text": ["dispensing substandard products", "potentially dangerous", "reports of such pharmacies dispensing substandard products"], "answer_start": [633, 390, 606]}, "prediction_text": "Dangerous practice"}
{"answers": {"text": ["sell prescription drugs without requiring a prescription", "sell prescription drugs without requiring a prescription", "some Internet pharmacies sell prescription drugs without requiring a prescription"], "answer_start": [114, 114, 89]}, "prediction_text": "Selling prescription drugs without a prescription."}
{"answers": {"text": ["sell prescription drugs and require a valid prescription", "sell prescription drugs", "sell prescription drugs and require a valid prescription"], "answer_start": [31, 31, 31]}, "prediction_text": "Sell prescription drugs without a prescription."}
{"answers": {"text": ["the ease with which people, youth in particular, can obtain controlled substances", "ease with which people, youth in particular, can obtain controlled substances", "the ease with which people, youth in particular, can obtain controlled substances"], "answer_start": [50, 54, 50]}, "prediction_text": "Easy access to controlled substances."}
{"answers": {"text": ["it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship"], "answer_start": [576, 576, 576]}, "prediction_text": "A legitimate medical purpose by a licensed practitioner."}
{"answers": {"text": ["the ease with which people, youth in particular, can obtain controlled substances", "ease with which people, youth in particular, can obtain controlled substances", "the ease with which people, youth in particular, can obtain controlled substances"], "answer_start": [50, 54, 50]}, "prediction_text": "Easy access to controlled substances."}
{"answers": {"text": ["it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "it must be issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship"], "answer_start": [576, 576, 576]}, "prediction_text": "A legitimate medical purpose by a licensed practitioner."}
{"answers": {"text": ["to ensure that the prescription is valid", "ensure that the prescription is valid", "The filling pharmacy has a corresponding responsibility to ensure that the prescription is valid"], "answer_start": [774, 777, 718]}, "prediction_text": "Ensure valid prescription is issued."}
{"answers": {"text": ["individual state laws", "individual state laws", "Often, individual state laws outline what defines a valid patient-doctor relationship"], "answer_start": [823, 823, 816]}, "prediction_text": "State laws"}
{"answers": {"text": ["Vicodin, generically known as hydrocodone", "Vicodin", "Vicodin"], "answer_start": [139, 139, 139]}, "prediction_text": "Vicodin"}
{"answers": {"text": ["to reduce consumer costs", "reduce consumer costs", "in order to reduce consumer costs"], "answer_start": [125, 128, 116]}, "prediction_text": "Reduce consumer costs."}
{"answers": {"text": ["Canada", "Canada", "Canada"], "answer_start": [88, 88, 88]}, "prediction_text": "Canada"}
{"answers": {"text": ["international drug suppliers, rather than consumers", "international drug suppliers", "international drug suppliers"], "answer_start": [322, 322, 322]}, "prediction_text": "International drug suppliers"}
{"answers": {"text": ["There is no known case", "no known case", "no"], "answer_start": [375, 384, 384]}, "prediction_text": "No known case"}
{"answers": {"text": ["to legalize importation of medications from Canada and other countries", "legalize importation of medications", "legalize importation of medications from Canada and other countries"], "answer_start": [44, 47, 47]}, "prediction_text": "Importation of medications"}
{"answers": {"text": ["pharmacy practice science and applied information science", "pharmacy practice science and applied information science", "pharmacy practice science and applied information science"], "answer_start": [43, 43, 43]}, "prediction_text": "Pharmacy practice science and applied information science."}
{"answers": {"text": ["information technology departments or for healthcare information technology vendor companies", "information technology departments or for healthcare information technology vendor companies", "information technology departments or for healthcare information technology vendor companies"], "answer_start": [198, 198, 198]}, "prediction_text": "Information technology departments or healthcare information technology vendor companies."}
{"answers": {"text": ["major national and international patient information projects and health system interoperability goals", "major national and international patient information projects", "major national and international patient information projects"], "answer_start": [395, 395, 395]}, "prediction_text": "National and international patient information projects and health system interoperability goals."}
{"answers": {"text": ["medication management system development, deployment and optimization", "medication management system development, deployment and optimization", "medication management system development, deployment and optimization"], "answer_start": [554, 554, 554]}, "prediction_text": "Practice areas and specialist domains."}
{"answers": {"text": ["quickly", "growing quickly", "quickly"], "answer_start": [366, 358, 366]}, "prediction_text": "Rapidly"}
{"answers": {"text": ["specialty pharmacies", "specialty pharmacies", "specialty pharmacies"], "answer_start": [485, 485, 485]}, "prediction_text": "Specialty pharmacies"}
{"answers": {"text": ["19", "19", "19 of 28 newly FDA approved medications"], "answer_start": [739, 739, 739]}, "prediction_text": "19 of 28"}
{"answers": {"text": ["cancer, hepatitis, and rheumatoid arthritis", "chronic and complex disease states", "chronic and complex disease states such as cancer, hepatitis, and rheumatoid arthritis"], "answer_start": [149, 106, 106]}, "prediction_text": "Chronic and complex disease states"}
{"answers": {"text": ["novel medications that need to be properly stored, administered, carefully monitored, and clinically managed", "novel medications", "novel medications that need to be properly stored, administered, carefully monitored, and clinically managed"], "answer_start": [337, 337, 337]}, "prediction_text": "High-cost injectable medications"}
{"answers": {"text": ["lab monitoring, adherence counseling, and assist patients with cost-containment strategies needed to obtain their expensive specialty drugs", "lab monitoring, adherence counseling, and assist patients with cost-containment strategies", "lab monitoring, adherence counseling, and assist patients with cost-containment strategies needed to obtain their expensive specialty drugs"], "answer_start": [519, 519, 519]}, "prediction_text": "Lab monitoring, adherence counseling, and assistance."}
{"answers": {"text": ["separately from physicians", "separately from physicians", "separately from physicians"], "answer_start": [77, 77, 77]}, "prediction_text": "In most jurisdictions, pharmacists are regulated separately from physicians."}
{"answers": {"text": ["only pharmacists", "only pharmacists", "only pharmacists may supply scheduled pharmaceuticals to the public"], "answer_start": [151, 151, 151]}, "prediction_text": "Only pharmacists"}
{"answers": {"text": ["the American Medical Association (AMA)", "American Medical Association", "American Medical Association (AMA)"], "answer_start": [334, 338, 338]}, "prediction_text": "American Medical Association (AMA) Code of Ethics"}
{"answers": {"text": ["7 to 10 percent", "7 to 10 percent", "7 to 10 percent of American physicians"], "answer_start": [590, 590, 590]}, "prediction_text": "10 to 20 percent"}
{"answers": {"text": ["form business partnerships with physicians or give them \"kickback\" payments", "form business partnerships with physicians", "pharmacists cannot form business partnerships with physicians or give them \"kickback\" payments"], "answer_start": [248, 248, 229]}, "prediction_text": "Provide pharmaceuticals to the public."}
{"answers": {"text": ["Austria", "Austria", "Austria"], "answer_start": [435, 435, 435]}, "prediction_text": "Austria"}
{"answers": {"text": ["In some rural areas in the United Kingdom", "rural areas in the United Kingdom", "prescribe and dispense prescription-only medicines to their patients from within their practices"], "answer_start": [0, 8, 99]}, "prediction_text": "Rural areas in the United Kingdom"}
{"answers": {"text": ["1.6 kilometres", "1.6 kilometres", "1.6 kilometres"], "answer_start": [337, 337, 337]}, "prediction_text": "1.6 kilometres"}
{"answers": {"text": ["more than 4 kilometers", "4 kilometers", "more than 4 kilometers"], "answer_start": [493, 503, 493]}, "prediction_text": "1.6 kilometres"}
{"answers": {"text": ["the high risk of a conflict of interest and/or the avoidance of absolute powers", "high risk of a conflict of interest", "high risk of a conflict of interest and/or the avoidance of absolute powers"], "answer_start": [36, 40, 40]}, "prediction_text": "High risk of conflict of interest and avoidance of absolute powers."}
{"answers": {"text": ["because he or she can then sell more medications to the patient", "sell more medications to the patient", "sell more medications to the patient"], "answer_start": [259, 286, 286]}, "prediction_text": "To sell more medications."}
{"answers": {"text": ["the checks and balances system of the U.S. and many other governments.", "checks and balances system of the U.S. and many other governments", "similarity to the checks and balances system of the U.S. and many other governments"], "answer_start": [544, 548, 530]}, "prediction_text": "Checks and balances system"}
{"answers": {"text": ["exaggerating their seriousness", "avoiding the unnecessary use of medication that may have side-effects", "because he or she can then sell more medications to the patient"], "answer_start": [227, 433, 259]}, "prediction_text": "Exaggerate severity, sell medications."}
{"answers": {"text": ["in obtaining cost-effective medication and avoiding the unnecessary use of medication that may have side-effects", "obtaining cost-effective medication", "the physician has a financial self-interest in \"diagnosing\" as many conditions as possible"], "answer_start": [390, 393, 128]}, "prediction_text": "In diagnosing as many conditions as possible."}
{"answers": {"text": ["expected to become more integral within the health care system", "patient care skills", "pharmacists are expected to become more integral within the health care system"], "answer_start": [39, 211, 23]}, "prediction_text": "More integral within health care system"}
{"answers": {"text": ["increasingly expected to be compensated for their patient care skills", "patient care skills", "pharmacists are increasingly expected to be compensated for their patient care skills"], "answer_start": [161, 211, 145]}, "prediction_text": "More patient care and education."}
{"answers": {"text": ["clinical services that pharmacists can provide for their patients", "clinical services that pharmacists can provide for their patients", "the clinical services that pharmacists can provide for their patients"], "answer_start": [296, 296, 292]}, "prediction_text": "Clinical services"}
{"answers": {"text": ["thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual", "thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual.", "the thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual"], "answer_start": [389, 389, 385]}, "prediction_text": "Medication Therapy Management (MTM)"}
{"answers": {"text": ["a reconciliation of medication and patient education resulting in increased patient health outcomes and decreased costs to the health care system", "increased patient health outcomes and decreased costs", "a reconciliation of medication and patient education resulting in increased patient health outcomes and decreased costs to the health care system"], "answer_start": [525, 591, 525]}, "prediction_text": "Increased patient health outcomes and decreased costs."}
{"answers": {"text": ["Alberta and British Columbia", "Alberta and British Columbia", "Alberta and British Columbia"], "answer_start": [279, 279, 279]}, "prediction_text": "Alberta and British Columbia"}
{"answers": {"text": ["the Australian Government", "Australian Government", "the Australian Government"], "answer_start": [117, 121, 117]}, "prediction_text": "Australian Government"}
{"answers": {"text": ["medicine use reviews", "medicine use reviews", "medicine use reviews"], "answer_start": [630, 630, 630]}, "prediction_text": "Medicine use reviews"}
{"answers": {"text": ["pharmaceutical care or clinical pharmacy", "pharmaceutical care or clinical pharmacy", "pharmaceutical care or clinical pharmacy"], "answer_start": [965, 965, 965]}, "prediction_text": "Consultant pharmacists"}
{"answers": {"text": ["Doctor of Pharmacy (Pharm. D.)", "Doctor of Pharmacy", "the Doctor of Pharmacy (Pharm. D.) degree"], "answer_start": [1079, 1079, 1075]}, "prediction_text": "Doctor of Pharmacy (Pharm. D.)"}
{"answers": {"text": ["the mortar and pestle and the \u211e (recipere) character", "mortar and pestle and the \u211e (recipere) character", "the mortar and pestle and the \u211e (recipere) character"], "answer_start": [89, 93, 89]}, "prediction_text": "The mortar and pestle and the \u211e character."}
{"answers": {"text": ["The show globe", "show globe", "show globe"], "answer_start": [189, 193, 193]}, "prediction_text": "Show globe"}
{"answers": {"text": ["the Netherlands", "the Netherlands", "the Netherlands"], "answer_start": [347, 347, 347]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["Germany and Austria", "Germany and Austria", "Germany and Austria"], "answer_start": [648, 648, 648]}, "prediction_text": "Germany and Austria"}
{"answers": {"text": ["France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India", "France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India", "France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India"], "answer_start": [487, 487, 487]}, "prediction_text": "France, Argentina, United Kingdom, Belgium, Ireland, Italy, Spain, and India."}
{"answers": {"text": ["a system of many biological structures and processes within an organism that protects against disease", "system of many biological structures and processes", "a system of many biological structures and processes within an organism", "a system of many biological structures and processes within an organism"], "answer_start": [21, 23, 21, 21]}, "prediction_text": "A system of biological structures and processes within an organism."}
{"answers": {"text": ["a wide variety of agents, known as pathogens, from viruses to parasitic worms", "disease", "disease", "against disease"], "answer_start": [175, 115, 115, 107]}, "prediction_text": "Pathogens and parasitic worms."}
{"answers": {"text": ["the innate immune system versus the adaptive immune system", "innate immune system versus the adaptive immune system", "humoral immunity versus cell-mediated immunity", "innate immune system versus the adaptive immune system"], "answer_start": [393, 397, 456, 397]}, "prediction_text": "innate immune system versus adaptive immune system."}
{"answers": {"text": ["the neuroimmune system", "neuroimmune system", "neuroimmune system", "neuroimmune system"], "answer_start": [651, 655, 655, 655]}, "prediction_text": "Blood\u2013brain barrier"}
{"answers": {"text": ["biological structures and processes within an organism", "system of many biological structures and processes", "a system of many biological structures and processes within an organism", "a system of many biological structures and processes within an organism"], "answer_start": [38, 23, 21, 21]}, "prediction_text": "A system of biological structures and processes within an organism."}
{"answers": {"text": ["pathogens, from viruses to parasitic worms", "disease", "disease", "against disease"], "answer_start": [210, 115, 115, 107]}, "prediction_text": "Pathogens and parasitic worms."}
{"answers": {"text": ["innate immune system versus the adaptive immune system", "innate immune system versus the adaptive immune system", "humoral immunity versus cell-mediated immunity", "innate immune system versus the adaptive immune system"], "answer_start": [397, 397, 456, 397]}, "prediction_text": "innate immune system versus adaptive immune system."}
{"answers": {"text": ["disease", "disease", "disease", "disease"], "answer_start": [115, 115, 115, 115]}, "prediction_text": "Pathogens"}
{"answers": {"text": ["pathogens", "pathogens", "pathogens", "pathogens"], "answer_start": [210, 210, 210, 210]}, "prediction_text": "Pathogens"}
{"answers": {"text": ["neuroimmune system", "neuroimmune", "neuroimmune", "neuroimmune system"], "answer_start": [655, 655, 655, 655]}, "prediction_text": "Blood\u2013brain barrier"}
{"answers": {"text": ["blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier", "blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier, and similar fluid\u2013brain barriers", "blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier, and similar fluid\u2013brain barriers", "fluid\u2013brain barriers"], "answer_start": [519, 519, 519, 587]}, "prediction_text": "Blood\u2013brain barrier"}
{"answers": {"text": ["pathogens", "pathogens", "pathogens", "pathogens"], "answer_start": [210, 210, 210, 210]}, "prediction_text": "Pathogens"}
{"answers": {"text": ["innate immune system versus the adaptive immune system", "innate immune system versus the adaptive immune system", "innate immune system versus the adaptive immune system", "innate immune system versus the adaptive immune system"], "answer_start": [397, 397, 397, 397]}, "prediction_text": "innate immune system versus adaptive immune system."}
{"answers": {"text": ["humoral immunity versus cell-mediated immunity", "humoral immunity versus cell-mediated immunity", "humoral immunity versus cell-mediated immunity", "humoral immunity versus cell-mediated immunity"], "answer_start": [456, 456, 456, 456]}, "prediction_text": "innate immune system versus adaptive immune system."}
{"answers": {"text": ["neuroimmune system", "neuroimmune", "neuroimmune system", "neuroimmune system"], "answer_start": [655, 655, 655, 655]}, "prediction_text": "The immune system of the brained"}
{"answers": {"text": ["Pathogens can rapidly evolve and adapt", "rapidly evolve and adapt", "rapidly evolve and adapt"], "answer_start": [0, 14, 14]}, "prediction_text": "Antigen neutralization by immune system."}
{"answers": {"text": ["enzymes that protect against bacteriophage infections", "rudimentary", "rudimentary"], "answer_start": [306, 264, 264]}, "prediction_text": "Antibiotic enzymes protect against bacteriophage infections."}
{"answers": {"text": ["eukaryotes", "eukaryotes", "bacteria"], "answer_start": [410, 410, 245]}, "prediction_text": "Plants and invertebrates"}
{"answers": {"text": ["creates immunological memory", "immunological memory", "creates immunological memory"], "answer_start": [811, 819, 811]}, "prediction_text": "Increases immunity to specific pathogens."}
{"answers": {"text": ["bacteriophage", "bacteriophage", "bacteriophage infections"], "answer_start": [335, 335, 335]}, "prediction_text": "Bacteriophage infections"}
{"answers": {"text": ["defensins", "defensins", "defensins"], "answer_start": [564, 564, 564]}, "prediction_text": "Defensins"}
{"answers": {"text": ["vaccination", "vaccination", "vaccination"], "answer_start": [1022, 1022, 1022]}, "prediction_text": "Vaccination"}
{"answers": {"text": ["Adaptive (or acquired) immunity", "Adaptive (or acquired) immunity", "Adaptive (or acquired) immunity"], "answer_start": [779, 779, 779]}, "prediction_text": "Antigen memory"}
{"answers": {"text": ["autoimmune diseases, inflammatory diseases and cancer", "autoimmune diseases", "autoimmune diseases"], "answer_start": [45, 45, 45]}, "prediction_text": "Arthritis, diabetes mellitus type 1, and systemic lupus erythematosus."}
{"answers": {"text": ["when the immune system is less active than normal", "when the immune system is less active than normal", "when the immune system is less active than normal"], "answer_start": [124, 124, 124]}, "prediction_text": "In humans"}
{"answers": {"text": ["recurring and life-threatening infections", "recurring and life-threatening infections.", "genetic disease"], "answer_start": [188, 188, 289]}, "prediction_text": "recurring and life-threatening infections."}
{"answers": {"text": ["genetic disease", "genetic disease", "HIV/AIDS"], "answer_start": [289, 289, 375]}, "prediction_text": "Genetic disease"}
{"answers": {"text": ["rheumatoid arthritis", "Hashimoto's thyroiditis", "Hashimoto's thyroiditis"], "answer_start": [616, 591, 591]}, "prediction_text": "Hashimoto's thyroiditis"}
{"answers": {"text": ["Immunodeficiency", "Immunodeficiency", "Immunodeficiency occurs"], "answer_start": [100, 100, 100]}, "prediction_text": "Recurring and life-threatening infections."}
{"answers": {"text": ["autoimmunity", "autoimmunity", "autoimmunity"], "answer_start": [442, 442, 442]}, "prediction_text": "Autoimmunity"}
{"answers": {"text": ["Immunology", "Immunology", "Immunology"], "answer_start": [698, 698, 698]}, "prediction_text": "Immunology"}
{"answers": {"text": ["HIV/AIDS", "HIV/AIDS", "HIV/AIDS"], "answer_start": [375, 375, 375]}, "prediction_text": "HIV/AIDS"}
{"answers": {"text": ["plague of Athens in 430 BC", "plague of Athens in 430 BC", "during the plague of Athens in 430 BC"], "answer_start": [227, 227, 216]}, "prediction_text": "Thucydides' observations"}
{"answers": {"text": ["scorpion", "scorpion", "scorpion venom"], "answer_start": [483, 483, 483]}, "prediction_text": "scorpion venom"}
{"answers": {"text": ["Louis Pasteur", "Louis Pasteur", "Louis Pasteur"], "answer_start": [638, 638, 638]}, "prediction_text": "Louis Pasteur"}
{"answers": {"text": ["Walter Reed", "Walter Reed", "Walter Reed."], "answer_start": [1095, 1095, 1095]}, "prediction_text": "Walter Reed"}
{"answers": {"text": ["Robert Koch", "Robert Koch", "Robert Koch"], "answer_start": [850, 850, 850]}, "prediction_text": "Walter Reed"}
{"answers": {"text": ["microorganisms", "microorganisms", "microorganisms"], "answer_start": [930, 930, 930]}, "prediction_text": "Yellow fever virus"}
{"answers": {"text": ["yellow fever virus", "yellow fever", "yellow fever virus"], "answer_start": [1073, 1073, 1073]}, "prediction_text": "Yellow fever virus"}
{"answers": {"text": ["Athens in 430 BC", "430 BC", "430 BC."], "answer_start": [237, 247, 247]}, "prediction_text": "430 BC"}
{"answers": {"text": ["immunological memory", "immunological memory", "immunological memory"], "answer_start": [764, 764, 764]}, "prediction_text": "Adaptive immune system"}
{"answers": {"text": ["the innate immune system", "innate immune system", "the innate immune system"], "answer_start": [250, 254, 250]}, "prediction_text": "Innate immune system"}
{"answers": {"text": ["the adaptive immune system", "adaptive immune system", "the adaptive immune system"], "answer_start": [487, 491, 487]}, "prediction_text": "Adaptive immune system"}
{"answers": {"text": ["Innate immune systems", "Innate", "Innate immune systems"], "answer_start": [325, 325, 325]}, "prediction_text": "Innate immune systems"}
{"answers": {"text": ["adaptive immune system", "adaptive", "the adaptive immune system"], "answer_start": [491, 491, 487]}, "prediction_text": "Innate immune system"}
{"answers": {"text": ["immunological memory", "immunological memory", "immunological memory"], "answer_start": [764, 764, 764]}, "prediction_text": "Innate immune system"}
{"answers": {"text": ["physical barriers", "physical barriers", "physical barriers"], "answer_start": [118, 118, 118]}, "prediction_text": "Physical barriers"}
{"answers": {"text": ["self and non-self", "self and non-self", "self and non-self molecules"], "answer_start": [100, 100, 100]}, "prediction_text": "Self and non-self molecules"}
{"answers": {"text": ["self molecules", "self", "self molecules"], "answer_start": [144, 144, 144]}, "prediction_text": "Self molecules"}
{"answers": {"text": ["non-self molecules", "non-self", "non-self molecules"], "answer_start": [286, 286, 286]}, "prediction_text": "Antigens (short for antibody generators)"}
{"answers": {"text": ["antigens", "antigens", "antigens"], "answer_start": [391, 391, 391]}, "prediction_text": "Antigens"}
{"answers": {"text": ["specific immune receptors", "receptors", "specific immune receptors"], "answer_start": [475, 491, 475]}, "prediction_text": "Specific immune receptors"}
{"answers": {"text": ["pattern recognition receptors", "receptors", "cells"], "answer_start": [198, 218, 75]}, "prediction_text": "Pattern recognition receptors"}
{"answers": {"text": ["innate immune system", "innate immune system", "The innate immune"], "answer_start": [656, 656, 652]}, "prediction_text": "Innate immune system"}
{"answers": {"text": ["microorganisms", "microorganisms", "microorganisms"], "answer_start": [297, 297, 297]}, "prediction_text": "Microorganisms"}
{"answers": {"text": ["non-specific", "non-specific", "non-specific"], "answer_start": [507, 507, 507]}, "prediction_text": "Non-specific"}
{"answers": {"text": ["exoskeleton", "exoskeleton", "exoskeleton"], "answer_start": [145, 145, 145]}, "prediction_text": "Exoskeleton of insects"}
{"answers": {"text": ["The waxy cuticle", "waxy cuticle", "waxy cuticle"], "answer_start": [108, 112, 112]}, "prediction_text": "Exoskeleton of insects"}
{"answers": {"text": ["coughing and sneezing", "coughing and sneezing", "coughing and sneezing"], "answer_start": [515, 515, 515]}, "prediction_text": "Mucus secreted by the respiratory and gastrointestinal tract"}
{"answers": {"text": ["mucus", "mucus", "mucus"], "answer_start": [695, 695, 695]}, "prediction_text": "Microorganisms secreted by the respiratory tract."}
{"answers": {"text": ["tears", "tears", "tears"], "answer_start": [637, 637, 637]}, "prediction_text": "tears and urine"}
{"answers": {"text": ["\u03b2-defensins", "\u03b2-defensins", "\u03b2-defensins"], "answer_start": [124, 124, 124]}, "prediction_text": "\u03b2-defensins"}
{"answers": {"text": ["lysozyme and phospholipase A2", "lysozyme and phospholipase A2", "lysozyme"], "answer_start": [153, 153, 153]}, "prediction_text": "Lysozyme and phospholipase A2"}
{"answers": {"text": ["defensins and zinc", "defensins and zinc", "defensins"], "answer_start": [364, 364, 364]}, "prediction_text": "Defensins and zinc"}
{"answers": {"text": ["gastric acid and proteases", "gastric acid and proteases", "gastric acid"], "answer_start": [418, 418, 418]}, "prediction_text": "Gastric acid and proteases"}
{"answers": {"text": ["menarche", "menarche", "menarche"], "answer_start": [299, 299, 299]}, "prediction_text": "Menarche"}
{"answers": {"text": ["commensal flora", "commensal flora", "commensal flora"], "answer_start": [54, 54, 54]}, "prediction_text": "Pathogenic bacteria"}
{"answers": {"text": ["fungi", "fungi", "fungi"], "answer_start": [430, 430, 430]}, "prediction_text": "fungi"}
{"answers": {"text": ["lactobacilli", "lactobacilli", "lactobacilli"], "answer_start": [656, 656, 656]}, "prediction_text": "lactobacilli"}
{"answers": {"text": ["pH or available iron", "pH or available iron", "balance of microbial populations"], "answer_start": [233, 233, 733]}, "prediction_text": "pH or available iron"}
{"answers": {"text": ["Inflammation", "Inflammation", "Inflammation"], "answer_start": [0, 0, 0]}, "prediction_text": "Redness, swelling, heat, and pain."}
{"answers": {"text": ["increased blood flow into tissue", "increased blood flow into tissue", "increased blood flow into tissue"], "answer_start": [166, 166, 166]}, "prediction_text": "Increased blood flow into tissue."}
{"answers": {"text": ["eicosanoids and cytokines", "eicosanoids and cytokines", "eicosanoids"], "answer_start": [228, 228, 228]}, "prediction_text": "Eicosanoids and cytokines"}
{"answers": {"text": ["prostaglandins", "prostaglandins", "prostaglandins"], "answer_start": [324, 324, 324]}, "prediction_text": "prostaglandins"}
{"answers": {"text": ["interleukins", "interleukins", "interleukins"], "answer_start": [517, 517, 517]}, "prediction_text": "Interleukins"}
{"answers": {"text": ["phagocytes", "phagocytes", "phagocytes"], "answer_start": [92, 92, 92]}, "prediction_text": "Phagocytes"}
{"answers": {"text": ["cytokines", "cytokines", "cytokines"], "answer_start": [254, 254, 254]}, "prediction_text": "cytokines"}
{"answers": {"text": ["phagosome", "phagosome", "phagosome"], "answer_start": [371, 371, 371]}, "prediction_text": "A phagosome"}
{"answers": {"text": ["phagolysosome", "phagolysosome", "phagolysosome"], "answer_start": [601, 456, 456]}, "prediction_text": "A phagosome is formed."}
{"answers": {"text": ["acquiring nutrients", "acquiring nutrients", "acquiring nutrients"], "answer_start": [651, 651, 651]}, "prediction_text": "Acquiring nutrients"}
{"answers": {"text": ["Neutrophils and macrophages", "Neutrophils and macrophages", "Neutrophils and macrophages"], "answer_start": [0, 0, 0]}, "prediction_text": "Neutrophils and macrophages"}
{"answers": {"text": ["Neutrophils", "Neutrophils", "Neutrophils"], "answer_start": [109, 109, 109]}, "prediction_text": "Neutrophils"}
{"answers": {"text": ["50% to 60%", "50% to 60%", "50% to 60%"], "answer_start": [226, 226, 226]}, "prediction_text": "50% to 60%"}
{"answers": {"text": ["chemotaxis", "chemotaxis", "chemotaxis"], "answer_start": [435, 435, 435]}, "prediction_text": "Chemotaxis"}
{"answers": {"text": ["interleukin 1", "interleukin 1", "interleukin 1"], "answer_start": [684, 684, 684]}, "prediction_text": "Interleukin 1"}
{"answers": {"text": ["Leukocytes", "Leukocytes", "Leukocytes"], "answer_start": [0, 0, 0]}, "prediction_text": "White blood cells"}
{"answers": {"text": ["Leukocytes (white blood cells)", "white blood cells", "white blood cells"], "answer_start": [0, 12, 12]}, "prediction_text": "Leukocytes"}
{"answers": {"text": ["adaptive immune system", "adaptive", "adaptive immune system."], "answer_start": [500, 500, 500]}, "prediction_text": "adaptive immune system"}
{"answers": {"text": ["macrophages, neutrophils, and dendritic cells", "macrophages, neutrophils, and dendritic cells", "macrophages, neutrophils, and dendritic cells"], "answer_start": [175, 175, 175]}, "prediction_text": "Phagocytes (white blood cells)"}
{"answers": {"text": ["Dendritic cells", "Dendritic cells", "Dendritic cells"], "answer_start": [0, 0, 0]}, "prediction_text": "Dendritic cells"}
{"answers": {"text": ["neuronal dendrites", "neuronal dendrites", "neuronal dendrites"], "answer_start": [224, 224, 224]}, "prediction_text": "Dendritic cells"}
{"answers": {"text": ["T cells", "T cells", "T cells"], "answer_start": [484, 484, 484]}, "prediction_text": "Dendritic cells"}
{"answers": {"text": ["T cells", "T cells", "T cells"], "answer_start": [484, 484, 484]}, "prediction_text": "T cells"}
{"answers": {"text": ["missing self", "missing self", "missing self"], "answer_start": [271, 271, 271]}, "prediction_text": "\"missing self\""}
{"answers": {"text": ["Natural killer cells", "Natural killer cells", "Natural killer cells"], "answer_start": [0, 0, 0]}, "prediction_text": "NK cells"}
{"answers": {"text": ["MHC I (major histocompatibility complex)", "MHC I", "MHC I (major histocompatibility complex)"], "answer_start": [360, 360, 360]}, "prediction_text": "MHC I"}
{"answers": {"text": ["killer cell immunoglobulin receptors (KIR", "killer cell immunoglobulin", "killer cell immunoglobulin receptors (KIR)"], "answer_start": [993, 993, 993]}, "prediction_text": "Killer cell immunoglobulin receptors (KIR)"}
{"answers": {"text": ["vertebrates", "vertebrates", "early vertebrates"], "answer_start": [44, 44, 38]}, "prediction_text": "Early vertebrates"}
{"answers": {"text": ["antigen presentation", "antigen presentation", "antigen presentation"], "answer_start": [325, 325, 325]}, "prediction_text": "antigen presentation"}
{"answers": {"text": ["pathogens or pathogen-infected cells", "pathogens", "pathogen-infected cells"], "answer_start": [436, 436, 449]}, "prediction_text": "Pathogen-infected cells"}
{"answers": {"text": ["killer T cell and the helper T cell", "killer T cell and the helper T cell", "the killer T cell and the helper T cell"], "answer_start": [371, 371, 367]}, "prediction_text": "Killer T cells and helper T cells."}
{"answers": {"text": ["regulatory T cells", "regulatory", "regulatory T cells"], "answer_start": [430, 430, 430]}, "prediction_text": "Killer T cells"}
{"answers": {"text": ["Class I MHC molecules", "Class I MHC", "Class I MHC molecules"], "answer_start": [548, 548, 548]}, "prediction_text": "Class I MHC molecules"}
{"answers": {"text": ["Class II MHC molecules", "Class II MHC", "Class II MHC molecules"], "answer_start": [650, 650, 650]}, "prediction_text": "Class II MHC molecules"}
{"answers": {"text": ["\u03b3\u03b4 T cells", "\u03b3\u03b4", "\u03b3\u03b4 T cells"], "answer_start": [806, 806, 806]}, "prediction_text": "\u03b3\u03b4 T cells"}
{"answers": {"text": ["Killer T cells", "Killer T", "Killer T cells"], "answer_start": [0, 0, 0]}, "prediction_text": "Killer T cells"}
{"answers": {"text": ["CD8", "CD8", "CD8"], "answer_start": [465, 465, 465]}, "prediction_text": "CD8"}
{"answers": {"text": ["T cell receptor (TCR)", "T cell receptor", "T cell receptor (TCR)"], "answer_start": [264, 264, 264]}, "prediction_text": "MHC Class I receptor"}
{"answers": {"text": ["granulysin", "granulysin", "granulysin (a protease)"], "answer_start": [797, 797, 797]}, "prediction_text": "granulysin"}
{"answers": {"text": ["perforin", "perforin", "perforin"], "answer_start": [656, 656, 656]}, "prediction_text": "Perforin"}
{"answers": {"text": ["CD4 co-receptor", "CD4", "CD4 co-receptor"], "answer_start": [166, 166, 166]}, "prediction_text": "CD4 co-receptor"}
{"answers": {"text": ["around 200\u2013300", "around 200\u2013300", "around 200\u2013300"], "answer_start": [416, 416, 416]}, "prediction_text": "Around 200\u2013300 receptors"}
{"answers": {"text": ["a single MHC:antigen molecule", "single", "a single MHC:antigen molecule"], "answer_start": [578, 580, 578]}, "prediction_text": "Around 200\u2013300"}
{"answers": {"text": ["cytokines", "cytokines", "cytokines"], "answer_start": [774, 774, 774]}, "prediction_text": "Cytokine signals"}
{"answers": {"text": ["CD40 ligand", "CD40", "CD40 ligand"], "answer_start": [1078, 1078, 1078]}, "prediction_text": "CD40 ligand"}
{"answers": {"text": ["helper T cells, cytotoxic T cells and NK cells", "helper T cells, cytotoxic T cells", "helper T cells"], "answer_start": [152, 152, 152]}, "prediction_text": "helper T cells, cytotoxic T cells, NK cells."}
{"answers": {"text": ["alternative T cell receptor (TCR)", "T cell", "T cell receptor (TCR)"], "answer_start": [44, 56, 56]}, "prediction_text": "CD4+ or CD8+"}
{"answers": {"text": ["\u03b3\u03b4 T cells", "\u03b3\u03b4", "\u03b3\u03b4 T cells"], "answer_start": [395, 395, 395]}, "prediction_text": "\u03b3\u03b4 T cells"}
{"answers": {"text": ["receptor diversity", "receptor diversity", "receptor diversity"], "answer_start": [564, 564, 564]}, "prediction_text": "receptor diversity"}
{"answers": {"text": ["V\u03b39/V\u03b42 T cells", "V\u03b39/V\u03b42", "V\u03b39/V\u03b42 T cells"], "answer_start": [822, 822, 822]}, "prediction_text": "Large numbers of human T cells respond."}
{"answers": {"text": ["B cell", "B", "A B cell"], "answer_start": [2, 2, 0]}, "prediction_text": "B cell"}
{"answers": {"text": ["proteolysis", "proteolysis", "proteolysis"], "answer_start": [170, 170, 170]}, "prediction_text": "MHC class II proteolysis"}
{"answers": {"text": ["lymphokines", "lymphokines", "lymphokines"], "answer_start": [372, 372, 372]}, "prediction_text": "Lymphokines"}
{"answers": {"text": ["long-lived memory cells", "long-lived memory cells", "long-lived memory cells"], "answer_start": [94, 94, 94]}, "prediction_text": "Long-lived memory cells"}
{"answers": {"text": ["adaptive", "adaptive", "strong response"], "answer_start": [296, 296, 236]}, "prediction_text": "Adaptive response"}
{"answers": {"text": ["passive short-term memory or active long-term memory", "passive short-term memory or active long-term memory", "passive short-term memory or active long-term memory"], "answer_start": [514, 514, 514]}, "prediction_text": "Passive short-term memory and active long-term memory."}
{"answers": {"text": ["specific pathogen", "pathogen", "each specific pathogen"], "answer_start": [190, 199, 185]}, "prediction_text": "Pathogen"}
{"answers": {"text": ["microbes", "microbes", "microbes"], "answer_start": [42, 42, 42]}, "prediction_text": "Microbes"}
{"answers": {"text": ["IgG", "IgG", "IgG"], "answer_start": [218, 218, 218]}, "prediction_text": "IgG"}
{"answers": {"text": ["Breast milk or colostrum", "Breast milk", "Breast milk or colostrum"], "answer_start": [412, 412, 412]}, "prediction_text": "Passive immunity"}
{"answers": {"text": ["passive immunity", "passive", "passive immunity"], "answer_start": [726, 726, 726]}, "prediction_text": "Passive immunity"}
{"answers": {"text": ["immunomodulators", "immunomodulators", "immunomodulators"], "answer_start": [20, 20, 20]}, "prediction_text": "Immunostimulators"}
{"answers": {"text": ["adaptive and innate immune responses", "both adaptive and innate", "adaptive and innate immune responses"], "answer_start": [154, 149, 154]}, "prediction_text": "adaptive and innate immune responses."}
{"answers": {"text": ["lupus erythematosus", "lupus erythematosus", "lupus erythematosus"], "answer_start": [225, 225, 225]}, "prediction_text": "Lupus erythematosus"}
{"answers": {"text": ["immunosuppressive", "immunosuppressive", "immunosuppressive"], "answer_start": [383, 383, 383]}, "prediction_text": "Helps regulate immune system."}
{"answers": {"text": ["NFIL3", "NFIL3", "NFIL3"], "answer_start": [243, 243, 243]}, "prediction_text": "NFIL3"}
{"answers": {"text": ["heart disease, chronic pain, and asthma", "heart disease, chronic pain, and asthma", "chronic pain"], "answer_start": [573, 573, 588]}, "prediction_text": "Heart disease, chronic pain, asthma."}
{"answers": {"text": ["sleep deprivation", "sleep", "sleep deprivation"], "answer_start": [20, 20, 20]}, "prediction_text": "Sleep deprivation"}
{"answers": {"text": ["decline in hormone levels with age", "decline in hormone levels", "decline in hormone levels"], "answer_start": [37, 37, 37]}, "prediction_text": "Increased hormone levels"}
{"answers": {"text": ["vitamin D", "vitamin D", "vitamin D."], "answer_start": [657, 657, 657]}, "prediction_text": "Vitamin D"}
{"answers": {"text": ["hormones", "hormones", "hormones"], "answer_start": [166, 166, 166]}, "prediction_text": "Thyroid hormone"}
{"answers": {"text": ["cholecalciferol", "cholecalciferol", "cholecalciferol"], "answer_start": [556, 556, 556]}, "prediction_text": "Cholecalciferol"}
{"answers": {"text": ["killer T cells", "killer T cells", "killer T cells"], "answer_start": [88, 88, 88]}, "prediction_text": "Killer T cells"}
{"answers": {"text": ["MHC class I molecules", "MHC class I", "MHC class I molecules"], "answer_start": [404, 404, 404]}, "prediction_text": "MHC class I molecules"}
{"answers": {"text": ["viral antigens", "viral", "viral antigens"], "answer_start": [227, 227, 227]}, "prediction_text": "viral antigens"}
{"answers": {"text": ["antibodies", "antibodies", "antibodies"], "answer_start": [507, 507, 507]}, "prediction_text": "NK cells"}
{"answers": {"text": ["phagocytic cells", "phagocytic", "phagocytic cells"], "answer_start": [28, 28, 28]}, "prediction_text": "Phagocytic cells"}
{"answers": {"text": ["Pathogen-associated molecular patterns", "Pathogen-associated molecular patterns", "Pathogen-associated molecular patterns or PAMPs"], "answer_start": [222, 222, 222]}, "prediction_text": "Pathogen-associated molecular patterns or PAMPs"}
{"answers": {"text": ["apoptosis", "apoptosis", "rapid apoptosis"], "answer_start": [421, 421, 415]}, "prediction_text": "Rapid hypersensitive response"}
{"answers": {"text": ["Systemic acquired resistance (SAR)", "Systemic acquired resistance", "Systemic acquired resistance (SAR)"], "answer_start": [497, 497, 497]}, "prediction_text": "SARS defense"}
{"answers": {"text": ["RNA silencing mechanisms", "RNA silencing mechanisms", "RNA silencing mechanisms"], "answer_start": [653, 653, 653]}, "prediction_text": "RNA silencing mechanisms"}
{"answers": {"text": ["autoimmune disorders", "autoimmune", "autoimmune disorders"], "answer_start": [91, 91, 91]}, "prediction_text": "autoimmune disorders"}
{"answers": {"text": ["self and non-self", "self and non-self", "self and non-self"], "answer_start": [175, 175, 175]}, "prediction_text": "Self and non-self"}
{"answers": {"text": ["thymus and bone marrow", "thymus and bone marrow", "thymus and bone marrow"], "answer_start": [366, 366, 366]}, "prediction_text": "In the thymus and bone marrow"}
{"answers": {"text": ["\"self\" peptides", "self", "self\" peptides"], "answer_start": [291, 292, 292]}, "prediction_text": "Self peptides"}
{"answers": {"text": ["Immunodeficiencies", "Immunodeficiencies", "Immunodeficiencies"], "answer_start": [0, 0, 0]}, "prediction_text": "Immunodeficiency disorders"}
{"answers": {"text": ["the young and the elderly", "the young and the elderly", "young and the elderly"], "answer_start": [174, 174, 178]}, "prediction_text": "Young and elderly"}
{"answers": {"text": ["around 50 years of age", "50", "around 50 years of age"], "answer_start": [247, 254, 247]}, "prediction_text": "Around 50 years of age."}
{"answers": {"text": ["obesity, alcoholism, and drug use", "obesity, alcoholism, and drug use", "obesity, alcoholism, and drug use"], "answer_start": [319, 319, 319]}, "prediction_text": "Diets lacking sufficient protein, malnutrition, and drug use."}
{"answers": {"text": ["malnutrition", "malnutrition", "malnutrition"], "answer_start": [405, 405, 405]}, "prediction_text": "Diets lacking sufficient protein"}
{"answers": {"text": ["vaccination", "vaccination", "vaccination"], "answer_start": [148, 148, 148]}, "prediction_text": "Vaccination"}
{"answers": {"text": ["immunization", "immunization", "immunization"], "answer_start": [207, 207, 207]}, "prediction_text": "Immunization"}
{"answers": {"text": ["an antigen from a pathogen", "antigen", "antigen from a pathogen"], "answer_start": [237, 240, 240]}, "prediction_text": "Antigen from a pathogen"}
{"answers": {"text": ["natural specificity of the immune system", "natural specificity", "the natural specificity"], "answer_start": [508, 508, 504]}, "prediction_text": "Natural specificity"}
{"answers": {"text": ["enzymes", "enzymes", "enzymes"], "answer_start": [291, 291, 291]}, "prediction_text": "Bacteria secrete enzymes to digest a physical barrier."}
{"answers": {"text": ["type III secretion system", "type III secretion system", "type III secretion system"], "answer_start": [397, 397, 397]}, "prediction_text": "Bacteria infection"}
{"answers": {"text": ["shut down host defenses", "shut down host defenses", "shut down host defenses."], "answer_start": [584, 584, 584]}, "prediction_text": "Shut down defenses"}
{"answers": {"text": ["elude host immune responses", "elude host immune responses", "ability to elude host immune responses"], "answer_start": [54, 54, 43]}, "prediction_text": "Elude host immune responses"}
{"answers": {"text": ["Frank Burnet", "Frank Burnet", "Frank Burnet"], "answer_start": [18, 18, 18]}, "prediction_text": "Frank Burnet"}
{"answers": {"text": ["pathogens, an allograft", "pathogens, an allograft", "pathogens, an allograft"], "answer_start": [383, 383, 383]}, "prediction_text": "Pathogens and allografts."}
{"answers": {"text": ["histocompatibility", "histocompatibility", "histocompatibility"], "answer_start": [514, 514, 514]}, "prediction_text": "\"Two-signal\" activation of T cells."}
{"answers": {"text": ["Niels Jerne", "Niels Jerne", "Niels Jerne"], "answer_start": [65, 65, 65]}, "prediction_text": "Niels Jerne"}
{"answers": {"text": ["Glucocorticoids", "Glucocorticoids", "Glucocorticoids"], "answer_start": [79, 79, 79]}, "prediction_text": "Glucocorticoids"}
{"answers": {"text": ["cytotoxic or immunosuppressive drugs", "cytotoxic or immunosuppressive", "Cytotoxic drugs"], "answer_start": [364, 364, 439]}, "prediction_text": "cytotoxic drugs"}
{"answers": {"text": ["methotrexate or azathioprine", "methotrexate or azathioprine", "methotrexate or azathioprine"], "answer_start": [409, 409, 409]}, "prediction_text": "Methotrexate and azathioprine"}
{"answers": {"text": ["cyclosporin", "cyclosporin", "cyclosporin"], "answer_start": [707, 707, 707]}, "prediction_text": "Cyclosporin"}
{"answers": {"text": ["cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes)", "cytotoxic natural killer cells and CTLs", "cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes)"], "answer_start": [72, 72, 72]}, "prediction_text": "cytotoxic natural killer cells"}
{"answers": {"text": ["cortisol and catecholamines", "cortisol and catecholamines", "cortisol and catecholamines"], "answer_start": [290, 290, 290]}, "prediction_text": "Cortisol and catecholamines"}
{"answers": {"text": ["melatonin", "melatonin", "melatonin"], "answer_start": [600, 600, 600]}, "prediction_text": "Melatonin"}
{"answers": {"text": ["free radical production", "free radical", "free radical production"], "answer_start": [739, 739, 739]}, "prediction_text": "Free radical production"}
{"answers": {"text": ["a vitamin D receptor", "extends a vitamin D receptor", "vitamin D receptor"], "answer_start": [56, 48, 58]}, "prediction_text": "Vitamin D receptor"}
{"answers": {"text": ["calcitriol", "calcitriol", "steroid hormone calcitriol"], "answer_start": [201, 201, 185]}, "prediction_text": "calcitriol"}
{"answers": {"text": ["symbiotic relationship", "symbiotic", "symbiotic relationship"], "answer_start": [228, 228, 228]}, "prediction_text": "T-cells extend vitamin D receptor"}
{"answers": {"text": ["gene CYP27B1", "CYP27B1", "gene CYP27B1"], "answer_start": [433, 438, 433]}, "prediction_text": "CYP27B1"}
{"answers": {"text": ["dendritic cells, keratinocytes and macrophages", "dendritic cells, keratinocytes and macrophages", "dendritic cells"], "answer_start": [767, 767, 767]}, "prediction_text": "Dendritic cells, keratinocytes, macrophages."}
{"answers": {"text": ["Pattern recognition receptors", "Pattern recognition receptors", "Pattern recognition receptors"], "answer_start": [0, 0, 0]}, "prediction_text": "Pattern recognition receptors"}
{"answers": {"text": ["defensins", "defensins", "defensins"], "answer_start": [151, 151, 151]}, "prediction_text": "Defensins"}
{"answers": {"text": ["phagocytic cells", "phagocytic", "phagocytic cells"], "answer_start": [355, 355, 355]}, "prediction_text": "Phagocytic cells"}
{"answers": {"text": ["RNA interference pathway", "RNA interference", "RNA interference pathway"], "answer_start": [444, 444, 444]}, "prediction_text": "RNA interference pathway"}
{"answers": {"text": ["immunoglobulins and T cell receptors", "immunoglobulins and T cell receptors", "immunoglobulins"], "answer_start": [159, 159, 159]}, "prediction_text": "Immunoglobulins and T cell receptors"}
{"answers": {"text": ["the lamprey and hagfish", "lamprey and hagfish", "the lamprey and hagfish"], "answer_start": [340, 344, 340]}, "prediction_text": "Lamprey and hagfish"}
{"answers": {"text": ["Variable lymphocyte receptors (VLRs)", "Variable lymphocyte receptors", "Variable lymphocyte receptors (VLRs)"], "answer_start": [421, 421, 421]}, "prediction_text": "Variable lymphocyte receptors"}
{"answers": {"text": ["adaptive immune system", "adaptive", "the adaptive immune system"], "answer_start": [17, 17, 125]}, "prediction_text": "Evolution of adaptive immune system"}
{"answers": {"text": ["lymphocytes", "lymphocytes", "lymphocytes"], "answer_start": [126, 126, 126]}, "prediction_text": "Lymphocytes"}
{"answers": {"text": ["the restriction modification system", "restriction modification system", "restriction modification system"], "answer_start": [418, 422, 422]}, "prediction_text": "Restriction modification system"}
{"answers": {"text": ["bacteriophages", "viral", "bacteriophages"], "answer_start": [505, 481, 505]}, "prediction_text": "Viral pathogens"}
{"answers": {"text": ["CRISPR", "CRISPR sequences", "CRISPR"], "answer_start": [592, 592, 592]}, "prediction_text": "RNA interference"}
{"answers": {"text": ["\"cellular\" and \"humoral\" theories of immunity", "\"cellular\" and \"humoral\"", "\"cellular\" and \"humoral\" theories"], "answer_start": [317, 317, 317]}, "prediction_text": "Cellular theory and humoral theory."}
{"answers": {"text": ["Elie Metchnikoff", "Elie Metchnikoff", "Elie Metchnikoff"], "answer_start": [439, 439, 439]}, "prediction_text": "Elie Metchnikoff"}
{"answers": {"text": ["phagocytes", "phagocytes", "phagocytes"], "answer_start": [488, 488, 488]}, "prediction_text": "Phagocytes"}
{"answers": {"text": ["Robert Koch and Emil von Behring", "Robert Koch and Emil von Behring", "Robert Koch and Emil von Behring,"], "answer_start": [613, 613, 613]}, "prediction_text": "Robert Koch and Emil von Behring"}
{"answers": {"text": ["soluble components (molecules)", "soluble components", "soluble components (molecules)"], "answer_start": [689, 689, 689]}, "prediction_text": "Soluble components (molecules)"}
{"answers": {"text": ["cancers", "cancers", "cancers"], "answer_start": [65, 65, 65]}, "prediction_text": "Cancerous tumors"}
{"answers": {"text": ["MHC class I molecules", "MHC class I", "MHC class I molecules"], "answer_start": [117, 117, 117]}, "prediction_text": "MHC class I molecules"}
{"answers": {"text": ["cytokine TGF-\u03b2", "cytokine TGF-\u03b2", "cytokine TGF-\u03b2"], "answer_start": [302, 302, 302]}, "prediction_text": "TGF-\u03b2"}
{"answers": {"text": ["macrophages and lymphocytes", "macrophages and lymphocytes", "macrophages and lymphocytes"], "answer_start": [351, 351, 351]}, "prediction_text": "macrophages and lymphocytes"}
{"answers": {"text": ["Hypersensitivity", "Hypersensitivity", "Hypersensitivity"], "answer_start": [0, 0, 0]}, "prediction_text": "Hypersensitivity"}
{"answers": {"text": ["four classes (Type I \u2013 IV)", "four", "four classes"], "answer_start": [98, 98, 98]}, "prediction_text": "Four classes"}
{"answers": {"text": ["Type I", "Type I", "Type I hypersensitivity"], "answer_start": [210, 210, 210]}, "prediction_text": "Type I hypersensitivity"}
{"answers": {"text": ["IgE", "IgE", "IgE"], "answer_start": [396, 396, 396]}, "prediction_text": "IgE"}
{"answers": {"text": ["Type II hypersensitivity", "Type II", "Type II hypersensitivity"], "answer_start": [488, 488, 488]}, "prediction_text": "Immunological reactions"}
{"answers": {"text": ["intracellular pathogenesis", "intracellular pathogenesis", "intracellular pathogenesis"], "answer_start": [135, 135, 135]}, "prediction_text": "Evading the innate immune system by hiding within the cells."}
{"answers": {"text": ["Salmonella", "Salmonella", "Salmonella"], "answer_start": [404, 404, 404]}, "prediction_text": "Salmonella"}
{"answers": {"text": ["Plasmodium falciparum", "Plasmodium falciparum", "Plasmodium falciparum"], "answer_start": [464, 464, 464]}, "prediction_text": "Leishmania spp."}
{"answers": {"text": ["Mycobacterium tuberculosis", "Mycobacterium tuberculosis", "Mycobacterium tuberculosis"], "answer_start": [548, 548, 548]}, "prediction_text": "Mycobacterium tuberculosis"}
{"answers": {"text": ["protein A", "G", "Streptococcus (protein G)"], "answer_start": [1166, 1139, 1116]}, "prediction_text": "Streptococcus aureus"}
{"answers": {"text": ["antigenic variation", "antigenic variation", "antigenic variation"], "answer_start": [263, 263, 263]}, "prediction_text": "antigenic variation"}
{"answers": {"text": ["HIV", "HIV", "HIV"], "answer_start": [298, 298, 298]}, "prediction_text": "HIV"}
{"answers": {"text": ["Trypanosoma brucei", "Trypanosoma brucei", "Trypanosoma brucei"], "answer_start": [553, 553, 553]}, "prediction_text": "Trypanosoma brucei"}
{"answers": {"text": ["antigens", "antigens", "antigens"], "answer_start": [728, 728, 728]}, "prediction_text": "Antibody molecules"}
{"answers": {"text": ["immune surveillance", "immune surveillance", "immune surveillance"], "answer_start": [96, 96, 96]}, "prediction_text": "Immune surveillance"}
{"answers": {"text": ["human papillomavirus", "human papillomavirus", "human papillomavirus"], "answer_start": [433, 433, 433]}, "prediction_text": "Human papillomavirus"}
{"answers": {"text": ["tyrosinase", "tyrosinase", "tyrosinase"], "answer_start": [641, 641, 641]}, "prediction_text": "tyrosinase"}
{"answers": {"text": ["melanomas", "melanomas", "melanomas"], "answer_start": [757, 757, 757]}, "prediction_text": "Melanomas"}
{"answers": {"text": ["melanocytes", "melanocytes", "melanocytes"], "answer_start": [725, 725, 725]}, "prediction_text": "Melanocytes"}
{"answers": {"text": [">500 Da", ">500 Da", ">500 Da"], "answer_start": [14, 14, 14]}, "prediction_text": "Large drugs (>500 Da)"}
{"answers": {"text": ["hydrophilic amino acids", "hydrophilic", "hydrophilic amino acids"], "answer_start": [749, 749, 749]}, "prediction_text": "Hydrophilic amino acids"}
{"answers": {"text": ["Immunoproteomics", "Immunoproteomics", "Immunoproteomics"], "answer_start": [1257, 1257, 1257]}, "prediction_text": "Immunoproteomics"}
{"answers": {"text": ["B cells", "B", "B cells"], "answer_start": [1142, 1142, 1142]}, "prediction_text": "B cells"}
{"answers": {"text": ["immunoinformatics", "immunoinformatics", "immunoinformatics"], "answer_start": [1238, 1238, 1238]}, "prediction_text": "Immunoinformatics"}
{"answers": {"text": ["leptin, pituitary growth hormone, and prolactin", "leptin, pituitary growth hormone, and prolactin", "leptin"], "answer_start": [404, 404, 404]}, "prediction_text": "leptin, pituitary growth hormone, and prolactin."}
{"answers": {"text": ["APCs", "APCs", "APCs"], "answer_start": [1069, 1069, 1069]}, "prediction_text": "APCs"}
{"answers": {"text": ["Th1", "one that supports Th1"], "answer_start": [1153, 1135]}, "prediction_text": "Th1/Th2"}
{"answers": {"text": ["Th1 immune responses", "Th1", "Th1 immune responses"], "answer_start": [1356, 1356, 1356]}, "prediction_text": "Th1 immune responses"}
{"answers": {"text": ["carbohydrates", "carbohydrates", "carbohydrates"], "answer_start": [152, 152, 152]}, "prediction_text": "Antibodies"}
{"answers": {"text": ["disrupting their plasma membrane", "disrupting their plasma membrane", "disrupting their plasma membrane."], "answer_start": [929, 929, 929]}, "prediction_text": "By disrupting their plasma membrane."}
{"answers": {"text": ["signal amplification", "signal amplification", "signal amplification"], "answer_start": [295, 295, 295]}, "prediction_text": "Signal amplification"}
{"answers": {"text": ["catalytic cascade", "catalytic", "catalytic"], "answer_start": [598, 598, 598]}, "prediction_text": "Production of peptides and opsonization of pathogen surface."}
{"answers": {"text": ["Civil disobedience", "Civil disobedience", "Civil disobedience", "Civil disobedience", "Civil disobedience"], "answer_start": [130, 130, 130, 130, 130]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["apartheid", "fight against apartheid", "the fight against apartheid", "the fight against apartheid", "Singing Revolution to bring independence to the Baltic countries"], "answer_start": [497, 483, 479, 479, 554]}, "prediction_text": "Velvet Revolution"}
{"answers": {"text": ["Singing Revolution", "Singing Revolution", "the Singing Revolution", "Singing Revolution", "Singing Revolution"], "answer_start": [554, 554, 550, 554, 554]}, "prediction_text": "Rose Revolution"}
{"answers": {"text": ["Ukraine", "Ukraine", "Ukraine", "Ukraine", "Ukraine"], "answer_start": [726, 726, 726, 726, 726]}, "prediction_text": "Ukraine"}
{"answers": {"text": ["Georgia", "Georgia", "Georgia", "Georgia", "Georgia"], "answer_start": [684, 684, 684, 684, 684]}, "prediction_text": "Georgia"}
{"answers": {"text": ["Egyptians", "Egyptians", "Egyptians", "Egyptians", "India"], "answer_start": [65, 65, 65, 65, 296]}, "prediction_text": "Egyptians"}
{"answers": {"text": ["the British", "British", "Egyptians against the British occupation in the 1919 Revolution.", "British occupation", "communist governments"], "answer_start": [83, 87, 65, 87, 437]}, "prediction_text": "British occupation"}
{"answers": {"text": ["nonviolent resistance", "unfair laws", "nonviolent resistance movements", "rebelled against what they deem to be unfair"], "answer_start": [261, 223, 261, 185]}, "prediction_text": "To oust their communist governments."}
{"answers": {"text": ["unfair laws", "unfair laws", "unfair laws.", "unfair laws", "what they deem to be unfair"], "answer_start": [223, 223, 223, 223, 202]}, "prediction_text": "Fairness laws"}
{"answers": {"text": ["American Civil Rights Movement", "American Civil Rights Movement", "American Civil Rights Movement", "Civil Rights Movement", "American Civil Rights Movement"], "answer_start": [515, 515, 515, 524, 515]}, "prediction_text": "Rose Revolution"}
{"answers": {"text": ["Antigone", "Antigone", "Antigone", "Antigone", "Antigone"], "answer_start": [73, 73, 73, 73, 73]}, "prediction_text": "Antigone"}
{"answers": {"text": ["former King of Thebes", "Oedipus", "Oedipus", "Oedipus", "King of Thebes"], "answer_start": [126, 149, 149, 149, 133]}, "prediction_text": "Oedipus (King of Thebes)"}
{"answers": {"text": ["Creon", "Creon", "Creon", "Creon", "Creon"], "answer_start": [165, 165, 165, 165, 165]}, "prediction_text": "Polynices"}
{"answers": {"text": ["Oedipus", "Antigone", "Antigone", "Antigone", "Antigone"], "answer_start": [149, 92, 73, 73, 92]}, "prediction_text": "Antigone"}
{"answers": {"text": ["giving her brother Polynices a proper burial", "trying to stop her from giving her brother Polynices a proper burial", "giving her brother Polynices a proper burial", "giving her brother Polynices a proper burial.", "from giving her brother Polynices a proper burial"], "answer_start": [231, 207, 231, 231, 226]}, "prediction_text": "Giving Polynices a proper burial."}
{"answers": {"text": ["Antigone", "Antigone", "Antigone", "Antigone", "Antigone"], "answer_start": [73, 73, 73, 73, 73]}, "prediction_text": "Sophocles' Antigone"}
{"answers": {"text": ["Sophocles", "Sophocles", "Sophocles", "Sophocles", "Sophocles"], "answer_start": [57, 57, 57, 57, 57]}, "prediction_text": "Sophocles"}
{"answers": {"text": ["Creon, the current King of Thebes", "Creon", "Creon, the current King of Thebes", "Creon", "Creon"], "answer_start": [165, 165, 165, 165, 165]}, "prediction_text": "Oedipus (King of Thebes)"}
{"answers": {"text": ["giving her brother Polynices a proper burial", "giving her brother Polynices a proper burial", "the current King of Thebes, who is trying to stop her from giving her brother Polynices a proper burial", "Creon, the current King of Thebes, who is trying to stop her from giving her brother Polynices a proper burial", "giving her brother Polynices a proper burial"], "answer_start": [231, 231, 172, 165, 231]}, "prediction_text": "Disobeying conscience"}
{"answers": {"text": ["obey her conscience rather than human law", "She gives a stirring speech", "She gives a stirring speech in which she tells him that she must obey her conscience rather than human law", "a stirring speech", "She gives a stirring speech in which she tells him that she must obey her conscience rather than human law"], "answer_start": [342, 277, 277, 287, 277]}, "prediction_text": "In Sophocles' play Antigone."}
{"answers": {"text": ["Percy Shelley", "Percy Shelley", "Percy Shelley", "Percy Shelley", "Percy Shelley"], "answer_start": [46, 46, 46, 46, 46]}, "prediction_text": "Percy Shelley"}
{"answers": {"text": ["nonviolent", "political poem", "nonviolent", "nonviolent", "nonviolent"], "answer_start": [349, 70, 349, 349, 349]}, "prediction_text": "nonviolent protest"}
{"answers": {"text": ["Satyagraha", "Satyagraha", "Satyagraha", "Satyagraha", "Satyagraha"], "answer_start": [519, 498, 498, 519, 498]}, "prediction_text": "Satyagraha"}
{"answers": {"text": ["free India", "free India", "campaign for a free India", "protest and political action", "during the campaign for a free India"], "answer_start": [755, 755, 740, 596, 729]}, "prediction_text": "Free India"}
{"answers": {"text": ["Henry David Thoreau", "Gandhi", "Henry David Thoreau", "Henry David Thoreau", "Gandhi"], "answer_start": [406, 472, 406, 406, 472]}, "prediction_text": "Henry David Thoreau"}
{"answers": {"text": ["Percy Shelley", "Percy Shelley", "Percy Shelley", "Percy Shelley", "Percy Shelley"], "answer_start": [46, 46, 46, 46, 46]}, "prediction_text": "Percy Shelley"}
{"answers": {"text": ["unjust forms of authority", "Peterloo massacre", "unjust forms of authority", "the unjust forms of authority", "Peterloo massacre"], "answer_start": [179, 14, 179, 175, 14]}, "prediction_text": "The unjust forms of authority of his time."}
{"answers": {"text": ["principle of nonviolent protest", "nonviolent protest", "nonviolent protest", "nonviolent protest", "nonviolent protest"], "answer_start": [336, 349, 349, 349, 349]}, "prediction_text": "nonviolent protest"}
{"answers": {"text": ["doctrine of Satyagraha", "Satyagraha", "Satyagraha", "Satyagraha", "Satyagraha"], "answer_start": [486, 519, 519, 519, 498]}, "prediction_text": "Satyagraha"}
{"answers": {"text": ["Gandhi", "Gandhi", "Gandhi", "Gandhi", "Gandhi"], "answer_start": [472, 658, 472, 472, 472]}, "prediction_text": "Gandhi"}
{"answers": {"text": ["muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins", "civil disobedience", "muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins", "muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins", "activities of muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins"], "answer_start": [370, 34, 370, 370, 356]}, "prediction_text": "Mugs, arsonists, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents, political assassins."}
{"answers": {"text": ["Marshall Cohen", "Marshall Cohen", "Marshall Cohen", "Marshall Cohen", "Marshall Cohen"], "answer_start": [134, 134, 134, 134, 134]}, "prediction_text": "Marshall Cohen"}
{"answers": {"text": ["ambiguity", "debased", "ambiguity", "ambiguity", "ambiguity"], "answer_start": [79, 125, 79, 79, 79]}, "prediction_text": "ambiguity and debasing."}
{"answers": {"text": ["utterly debased", "debased", "everything from bringing a test-case in the federal courts to taking aim at a federal official", "utterly debased"], "answer_start": [117, 125, 186, 117]}, "prediction_text": "Deceitful"}
{"answers": {"text": ["become utterly debased", "utterly debased", "in modern times, become utterly debased", "become utterly debased", "become utterly debased"], "answer_start": [110, 117, 93, 110, 110]}, "prediction_text": "It has become completely debased."}
{"answers": {"text": ["Marshall Cohen", "Marshall Cohen", "Marshall Cohen", "Marshall Cohen", "President Agnew"], "answer_start": [134, 134, 134, 134, 299]}, "prediction_text": "Marshall Cohen"}
{"answers": {"text": ["code-word describing the activities of muggers, arsonists, draft evaders", "utterly debased", "become utterly debased", "become utterly debased", "become utterly debased"], "answer_start": [331, 117, 110, 110, 110]}, "prediction_text": "Deemed as a code-word for activities."}
{"answers": {"text": ["Vice President Agnew", "Vice President Agnew", "Vice President Agnew", "Vice President Agnew", "Marshall Cohen"], "answer_start": [294, 294, 294, 294, 134]}, "prediction_text": "Vice President Agnew"}
{"answers": {"text": ["ambiguity", "ambiguity", "ambiguity", "ambiguity"], "answer_start": [79, 79, 79, 79]}, "prediction_text": "Federal courts"}
{"answers": {"text": ["LeGrande", "LeGrande", "LeGrande", "LeGrande", "LeGrande"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "LeGrande"}
{"answers": {"text": ["impossible", "a maze of semantical problems and grammatical niceties", "impossible", "impossible"], "answer_start": [121, 258, 121, 121]}, "prediction_text": "A maze of semantical problems and grammatical niceties."}
{"answers": {"text": ["lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience"], "answer_start": [498, 498, 498, 498, 498]}, "prediction_text": "lawful protest demonstration, nonviolent civil disobedience, violent civil disobedience."}
{"answers": {"text": ["semantical", "semantical", "a maze of semantical problems", "semantical", "semantical problems"], "answer_start": [268, 268, 258, 268, 268]}, "prediction_text": "Specific terminology"}
{"answers": {"text": ["specific", "civil disobedience", "specific", "specific"], "answer_start": [360, 571, 360, 360]}, "prediction_text": "No more meaning than individual orator intended."}
{"answers": {"text": ["LeGrande", "LeGrande", "LeGrande", "LeGrande", "LeGrande"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "LeGrande"}
{"answers": {"text": ["voluminous literature", "voluminous", "voluminous", "voluminous"], "answer_start": [150, 150, 150, 150]}, "prediction_text": "A maze of semantical problems and grammatical niceties."}
{"answers": {"text": ["semantical problems and grammatical niceties", "maze of semantical problems and grammatical niceties", "semantical problems and grammatical niceties", "semantical problems and grammatical niceties"], "answer_start": [268, 260, 268, 268]}, "prediction_text": "Semantical problems and grammatical niceties."}
{"answers": {"text": ["nonviolent civil disobedience", "nonviolent civil disobedience", "nonviolent", "nonviolent", "nonviolent"], "answer_start": [528, 528, 528, 528, 528]}, "prediction_text": "Violent civil disobedience"}
{"answers": {"text": ["violent civil disobedience", "violent civil disobedience", "violent", "violent", "violent"], "answer_start": [563, 563, 563, 563, 563]}, "prediction_text": "Violent civil disobedience"}
{"answers": {"text": ["constitutional impasse", "her or his capacity as public official", "capacity as public official", "constitutional impasse"], "answer_start": [127, 454, 465, 127]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["citizen's", "head of government", "private citizen", "private citizen", "private"], "answer_start": [57, 268, 505, 505, 505]}, "prediction_text": "Public official"}
{"answers": {"text": ["to the state and its laws", "relation to the state and its laws", "a citizen's relation to the state and its laws,", "pertaining to a citizen's relation to the state and its laws", "as pertaining to a citizen's relation to the state and its laws"], "answer_start": [76, 67, 55, 41, 38]}, "prediction_text": "relation to the state and its laws."}
{"answers": {"text": ["the head of government would be acting in her or his capacity as public official", "two public agencies, especially two equally sovereign branches of government, conflict", "two public agencies, especially two equally sovereign branches of government, conflict", "if the head of government of a country were to refuse to enforce a decision of that country's highest court", "two public agencies, especially two equally sovereign branches of government, conflict"], "answer_start": [412, 159, 159, 261, 159]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["Civil disobedience", "Civil disobedience", "Civil disobedience", "Civil disobedience", "Civil disobedience"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["the state and its laws", "a citizen's relation to the state and its laws", "a citizen's relation to the state and its laws", "a citizen's relation to the state and its laws", "a citizen's relation to the state and its laws"], "answer_start": [79, 55, 55, 55, 55]}, "prediction_text": "Relationships with the state and its laws."}
{"answers": {"text": ["refuse to enforce a decision", "constitutional impasse", "two public agencies, especially two equally sovereign branches of government, conflict.", "a constitutional impasse in which two public agencies", "constitutional impasse"], "answer_start": [308, 127, 159, 125, 127]}, "prediction_text": "Defending a decision of a country's highest court."}
{"answers": {"text": ["head of government", "public official", "public official", "public"], "answer_start": [416, 477, 477, 477]}, "prediction_text": "Public official"}
{"answers": {"text": ["private citizen", "private citizen", "private citizen", "private"], "answer_start": [505, 505, 505, 505]}, "prediction_text": "Civilians"}
{"answers": {"text": ["sovereign branches of government", "public official", "public agencies", "public"], "answer_start": [203, 477, 163, 477]}, "prediction_text": "Citizens (in the context of the question)"}
{"answers": {"text": ["Thoreau", "Thoreau", "Thoreau", "Thoreau", "Thoreau's"], "answer_start": [40, 489, 40, 40, 40]}, "prediction_text": "Thoreau"}
{"answers": {"text": ["imprisonment", "imprisonment", "imprisonment", "imprisonment", "imprisonment"], "answer_start": [393, 393, 393, 393, 393]}, "prediction_text": "Thoreau was imprisoned."}
{"answers": {"text": ["not necessarily right", "not necessarily right", "the will of elite politicians", "the will of elite politicians", "not necessarily right"], "answer_start": [1201, 1201, 861, 861, 1201]}, "prediction_text": "Powerful."}
{"answers": {"text": ["Resign", "refusal to pay", "Resign", "Resign", "Resign"], "answer_start": [511, 473, 511, 511, 511]}, "prediction_text": "Resign."}
{"answers": {"text": ["elite politicians", "elite politicians", "individuals", "elite politicians", "individuals"], "answer_start": [873, 873, 218, 873, 218]}, "prediction_text": "Elite politicians"}
{"answers": {"text": ["The individual", "individuals", "The individual", "The individual", "individual"], "answer_start": [115, 1112, 115, 115, 119]}, "prediction_text": "The individual"}
{"answers": {"text": ["individuals", "individuals", "an individual", "individuals", "individuals"], "answer_start": [218, 1112, 294, 218, 218]}, "prediction_text": "The government"}
{"answers": {"text": ["Thoreau", "Thoreau", "Thoreau", "Thoreau", "Thoreau"], "answer_start": [489, 489, 40, 489, 569]}, "prediction_text": "Thoreau"}
{"answers": {"text": ["Resign", "Resign", "Resign", "Resign", "Resign"], "answer_start": [511, 511, 511, 511, 511]}, "prediction_text": "Resign."}
{"answers": {"text": ["not necessarily right", "may be powerful but it is not necessarily right", "The majority may be powerful but it is not necessarily right", "The majority may be powerful but it is not necessarily right", "may be powerful but it is not necessarily right"], "answer_start": [1201, 1175, 1162, 1162, 1175]}, "prediction_text": "Powerful but not necessarily right."}
{"answers": {"text": ["governmental entities", "against governmental entities", "governmental entities", "governmental entities", "governmental entities"], "answer_start": [91, 83, 91, 91, 91]}, "prediction_text": "Government entities"}
{"answers": {"text": ["trade unions, banks, and private universities", "non-governmental agencies", "decisions of non-governmental agencies", "non-governmental agencies", "non-governmental agencies"], "answer_start": [216, 182, 169, 182, 182]}, "prediction_text": "Non-governmental agencies"}
{"answers": {"text": ["legal system", "foreign", "legal system", "international organizations and foreign governments"], "answer_start": [321, 487, 321, 455]}, "prediction_text": "Non-governmental agencies"}
{"answers": {"text": ["international organizations and foreign governments", "a larger challenge to the legal system that permits those decisions to be taken", "international organizations and foreign governments", "breaches of law in protest against international organizations and foreign governments", "opposition to the decisions of non-governmental agencies such as trade unions, banks, and private universities"], "answer_start": [455, 295, 455, 420, 151]}, "prediction_text": "International organizations and foreign governments"}
{"answers": {"text": ["Brownlee", "Brownlee", "Brownlee", "Brownlee", "Brownlee"], "answer_start": [114, 114, 114, 114, 114]}, "prediction_text": "Brownlee"}
{"answers": {"text": ["a larger challenge to the legal system", "challenge to the legal system that permits those decisions to be taken", "it reflects \"a larger challenge to the legal system that permits those decisions to be taken", "a larger challenge to the legal system"], "answer_start": [295, 304, 282, 295]}, "prediction_text": "Legal system permits violations."}
{"answers": {"text": ["only justified against governmental entities", "civil disobedience is only justified against governmental entities", "civil disobedience is only justified against governmental entities.", "civil disobedience is only justified against governmental entities", "that civil disobedience is only justified against governmental entities"], "answer_start": [68, 46, 46, 46, 41]}, "prediction_text": "Only justified against governmental entities."}
{"answers": {"text": ["universities", "private universities", "private universities", "private universities", "private universities"], "answer_start": [249, 241, 241, 241, 241]}, "prediction_text": "Trade unions, banks, and private universities."}
{"answers": {"text": ["civil disobedience", "lawbreaking", "civil disobedience", "civil disobedience", "civil disobedience"], "answer_start": [130, 30, 130, 130, 130]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["covert lawbreaking", "lawbreaking", "covert lawbreaking", "covert lawbreaking", "covert lawbreaking"], "answer_start": [346, 353, 346, 346, 346]}, "prediction_text": "Open disobedience"}
{"answers": {"text": ["hiding a Jew in their house", "hiding a Jew", "hiding a Jew in their house", "hiding a Jew in their house", "hiding a Jew"], "answer_start": [886, 886, 886, 886, 886]}, "prediction_text": "Defecting from morality"}
{"answers": {"text": ["(Exodus 1: 15-19)", "Book of Exodus", "the Book of Exodus", "Shiphrah and Puah refused a direct order of Pharaoh but misrepresented how they did it", "Book of Exodus,"], "answer_start": [1093, 983, 979, 1005, 983]}, "prediction_text": "The Book of Exodus"}
{"answers": {"text": ["Shiphrah and Puah", "Shiphrah and Puah", "Shiphrah and Puah", "Shiphrah and Puah", "Shiphrah and Puah"], "answer_start": [1005, 1005, 1005, 1005, 1005]}, "prediction_text": "Shiphrah and Puah"}
{"answers": {"text": ["must be publicly announced", "publicly announced", "must be publicly announced", "publicly announced", "civil disobedience"], "answer_start": [80, 88, 80, 88, 130]}, "prediction_text": "At least publicly announced."}
{"answers": {"text": ["rules that conflict with morality", "rules that conflict with morality", "rules that conflict with morality", "rules that conflict with morality"], "answer_start": [212, 212, 212, 212]}, "prediction_text": "Rules that conflict with morality."}
{"answers": {"text": ["fabricating evidence or committing perjury", "fabricating evidence or committing perjury", "covert lawbreaking", "assisting in fabricating evidence or committing perjury", "covert lawbreaking"], "answer_start": [513, 513, 346, 500, 346]}, "prediction_text": "Open disobedience"}
{"answers": {"text": ["the dilemma faced by German citizens", "German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house", "the dilemma faced by German citizens", "the dilemma faced by German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house"], "answer_start": [791, 812, 791, 791]}, "prediction_text": "German citizens faced dilemma when Hitler's secret police demanded to know if they were hiding a Jew in their house."}
{"answers": {"text": ["Book of Exodus", "Exodus", "Exodus", "Exodus", "Exodus"], "answer_start": [983, 991, 991, 991, 991]}, "prediction_text": "The Book of Exodus"}
{"answers": {"text": ["non-violence", "non-violent", "non-violent", "non-violent", "non-violent"], "answer_start": [122, 77, 332, 332, 332]}, "prediction_text": "Carefully chosen and legitimate means"}
{"answers": {"text": ["Black's Law", "Black's Law Dictionary", "Black's Law Dictionary", "Black's Law Dictionary", "Black's Law Dictionary"], "answer_start": [90, 90, 90, 90, 90]}, "prediction_text": "Black's Law Dictionary"}
{"answers": {"text": ["civil rebellion", "rebellion", "civil rebellion are justified by appeal to constitutional defects, rebellion is much more", "rebellion", "rebellion"], "answer_start": [404, 471, 404, 471, 471]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["tolerance", "tolerance of civil disobedience", "tolerance of civil disobedience", "tolerance of civil disobedience", "tolerance"], "answer_start": [846, 846, 846, 846, 846]}, "prediction_text": "More tolerance"}
{"answers": {"text": ["violence", "non-violent", "appeal to constitutional defects", "violence", "civil disobedience"], "answer_start": [126, 77, 437, 126, 38]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["non-violent", "non-violent", "non-violent", "non-violent", "non-violence"], "answer_start": [77, 77, 332, 77, 122]}, "prediction_text": "Civil disobedience is commonly accepted."}
{"answers": {"text": ["civil rebellion", "civil rebellion", "civil rebellion", "rebellion", "rebellion"], "answer_start": [404, 639, 639, 471, 471]}, "prediction_text": "Civil disobedience"}
{"answers": {"text": ["destructive", "use of force and violence and refusal to submit to arrest", "rebellion is much more destructive", "rebellion is much more destructive", "force and violence and refusal to submit to arrest"], "answer_start": [494, 702, 471, 471, 709]}, "prediction_text": "More destructive"}
{"answers": {"text": ["help preserve society's tolerance of civil disobedience", "preserve society's tolerance of civil disobedience", "rebellion is much more destructive", "Civil disobedients' refraining from violence is also said to help preserve society's tolerance of civil disobedience", "help preserve society's tolerance"], "answer_start": [822, 827, 471, 761, 822]}, "prediction_text": "To preserve society's tolerance."}
{"answers": {"text": ["Revolutionary civil disobedience", "Revolutionary civil disobedience", "Revolutionary civil disobedience", "Revolutionary civil disobedience", "Revolutionary civil disobedience"], "answer_start": [298, 298, 298, 298, 298]}, "prediction_text": "Revolutionary civil disobedience"}
{"answers": {"text": ["Hungarians", "Hungarians", "the Hungarians under Ferenc De\u00e1k", "Hungarians", "Hungarians"], "answer_start": [716, 716, 712, 716, 716]}, "prediction_text": "Hungarians"}
{"answers": {"text": ["Ferenc De\u00e1k", "Ferenc De\u00e1k", "Ferenc De\u00e1k", "Ferenc De\u00e1k", "Ferenc De\u00e1k"], "answer_start": [733, 733, 733, 733, 733]}, "prediction_text": "Ferenc De\u00e1k"}
{"answers": {"text": ["Gandhi's", "Gandhi", "Gandhi", "Gandhi's"], "answer_start": [616, 616, 616, 616]}, "prediction_text": "Hungarians under Ferenc De\u00e1k"}
{"answers": {"text": ["cultural traditions, social customs, religious beliefs", "revolutionary civil disobedience", "change cultural traditions, social customs, religious beliefs, etc", "cultural traditions, social customs, religious beliefs", "peaceable revolution"], "answer_start": [400, 653, 393, 400, 876]}, "prediction_text": "Political, cultural, religious, etc..."}
{"answers": {"text": ["disobedience of laws", "Non-revolutionary civil disobedience", "Non-revolutionary civil disobedience", "Non-revolutionary", "cultural revolution"], "answer_start": [49, 0, 0, 0, 509]}, "prediction_text": "Non-revolutionary civil disobedience"}
{"answers": {"text": ["judged \"wrong\" by an individual conscience", "they are judged \"wrong\" by an individual conscience", "they are judged \"wrong\" by an individual conscience", "to cause their repeal", "they are judged \"wrong\" by an individual conscience"], "answer_start": [99, 90, 90, 203, 90]}, "prediction_text": "To alter or abolish a government."}
{"answers": {"text": ["render certain laws ineffective", "to render certain laws ineffective, to cause their repeal, or to exert pressure to get one's political wishes on some other issue", "render certain laws ineffective, to cause their repeal", "t to render certain laws ineffective, to cause their repeal, or to exert pressure to get one's political wishes on some other issue", "to render certain laws ineffective,"], "answer_start": [170, 167, 170, 165, 167]}, "prediction_text": "To render certain laws ineffective, cause repeal, or exert pressure."}
{"answers": {"text": ["Revolutionary civil disobedience", "Revolutionary civil disobedience", "Revolutionary civil disobedience", "Revolutionary", "Revolutionary"], "answer_start": [298, 298, 298, 298, 298]}, "prediction_text": "Revolutionary civil disobedience"}
{"answers": {"text": ["Gandhi", "Gandhi's", "Gandhi's", "Gandhi", "Gandhi's"], "answer_start": [616, 616, 616, 616, 616]}, "prediction_text": "Gandhi's actions"}
{"answers": {"text": ["during the Roman Empire", "Roman Empire", "during the Roman Empire", "the Roman Empire", "during the Roman Empire"], "answer_start": [76, 87, 76, 83, 76]}, "prediction_text": "Roman Empire"}
{"answers": {"text": ["gathered in the streets", "gathered in the streets", "gathered in the streets", "gathered in the streets", "gathered in the streets"], "answer_start": [131, 131, 131, 131, 131]}, "prediction_text": "Organized civil disobedience."}
{"answers": {"text": ["was not covered in any newspapers", "was not covered in any newspapers in the days, weeks and months after it happened.", "his arrest was not covered in any newspapers", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "his arrest was not covered in any newspapers"], "answer_start": [742, 742, 731, 731, 731]}, "prediction_text": "Thoreau rose to higher political office, and his essay was not published until after the end of the Mexican War."}
{"answers": {"text": ["rose to higher political office", "higher political office", "higher political office", "rose to higher political office", "higher political office"], "answer_start": [860, 868, 868, 860, 868]}, "prediction_text": "Higher political office"}
{"answers": {"text": ["after the end of the Mexican War", "end of the Mexican War", "after the end of the Mexican War.", "after the end of the Mexican War", "after the end of the Mexican War"], "answer_start": [937, 947, 937, 937, 937]}, "prediction_text": "After the end of the Mexican War."}
{"answers": {"text": ["during the Roman Empire", "during the Roman Empire", "during the Roman Empire", "during the Roman Empire", "during the Roman Empire"], "answer_start": [76, 76, 76, 76, 76]}, "prediction_text": "During the Roman Empire"}
{"answers": {"text": ["prevent the installation of pagan images", "prevent the installation of pagan images in the Temple in Jerusalem", "prevent the installation of pagan images in the Temple in Jerusalem", "to prevent the installation of pagan images in the Temple in Jerusalem", "prevent the installation of pagan images"], "answer_start": [158, 158, 158, 155, 158]}, "prediction_text": "Prevent installation of pagan images in the Temple in Jerusalem."}
{"answers": {"text": ["refuse to sign bail", "collectively refuse to sign bail until certain demands are met", "some activists who commit civil disobedience as a group collectively refuse to sign bail until certain demands are met", "jail solidarity"], "answer_start": [350, 337, 281, 491]}, "prediction_text": "Unarmed Jews gather in the streets to prevent installation of pagan images."}
{"answers": {"text": ["jail solidarity", "solitary civil disobedience", "jail solidarity", "jail solidarity", "jail solidarity"], "answer_start": [491, 560, 491, 491, 491]}, "prediction_text": "Jail solidarity"}
{"answers": {"text": ["until after the end of the Mexican War", "months", "months after it happened", "Thoreau's essay was not published until after the end of the Mexican War", "after the end of the Mexican War"], "answer_start": [931, 799, 799, 897, 937]}, "prediction_text": "After Mexican War"}
{"answers": {"text": ["illegal", "illegal acts", "illegal acts", "illegal acts", "illegal acts"], "answer_start": [54, 54, 54, 54, 54]}, "prediction_text": "Illegal acts"}
{"answers": {"text": ["propaganda", "propaganda", "propaganda", "propaganda", "just a harassment"], "answer_start": [696, 696, 696, 696, 338]}, "prediction_text": "Propaganda"}
{"answers": {"text": ["Voice in the Wilderness", "Voice in the Wilderness", "Voice in the Wilderness", "Voice in the Wilderness", "Voice in the Wilderness"], "answer_start": [810, 810, 810, 810, 810]}, "prediction_text": "The proprietors of illegal medical cannabis dispensaries"}
{"answers": {"text": ["738 days", "738 days", "738 days", "738 days", "738 days"], "answer_start": [1134, 1134, 1134, 1134, 1134]}, "prediction_text": "738 days"}
{"answers": {"text": ["successfully preventing it from being cut down", "successfully preventing it from being cut down", "successfully preventing it from being cut down", "successfully preventing it from being cut down", "preventing it from being cut down"], "answer_start": [1144, 1144, 1144, 1144, 1157]}, "prediction_text": "Prevented cut down."}
{"answers": {"text": ["illegal acts", "symbolic illegal protests", "symbolic illegal protests", "a variety of different illegal acts", "illegal"], "answer_start": [54, 631, 631, 31, 54]}, "prediction_text": "Trespassing at a nuclear-missile installation."}
{"answers": {"text": ["trespassing at a nuclear-missile installation", "symbolic illegal protests", "trespassing at a nuclear-missile installation", "the proprietors of illegal medical cannabis dispensaries", "trespassing at a nuclear-missile installation"], "answer_start": [269, 631, 269, 749, 269]}, "prediction_text": "Bedau writes, \"There is a whole class of acts, undertaken in the name of civil disobedience, which, even if they were widely practiced, would constitute hardly more than a nuisance (e.g. trespassing at a nuclear-missile installation).\""}
{"answers": {"text": ["entirely symbolic", "symbolic illegal protests", "harassment", "symbolic", "inane"], "answer_start": [622, 631, 345, 631, 397]}, "prediction_text": "Ineffectiveness and absurdity"}
{"answers": {"text": ["social goal", "social goal", "protests toward public policy", "propaganda", "social"], "answer_start": [940, 940, 648, 696, 940]}, "prediction_text": "Preventing public policy goals"}
{"answers": {"text": ["Julia Butterfly Hill", "Julia Butterfly Hill", "Julia Butterfly Hill", "Julia Butterfly Hill", "Julia Butterfly Hill"], "answer_start": [1033, 1033, 1033, 1033, 1033]}, "prediction_text": "Julia Butterfly Hill"}
{"answers": {"text": ["sending an email to the Lebanon, New Hampshire city councilors", "sending an email", "sending an email to the Lebanon, New Hampshire city councilors", "sending an email", "sending an email to the Lebanon"], "answer_start": [513, 513, 513, 513, 513]}, "prediction_text": "Sent an email to Lebanon, New Hampshire city councilors."}
{"answers": {"text": ["\"Wise up or die.\"", "Wise up or die", "\"Wise up or die.\"", "Wise up or die", "Wise up or die"], "answer_start": [585, 586, 585, 586, 586]}, "prediction_text": "Wise up or die."}
{"answers": {"text": ["criminalized behavior", "forbidden speech", "criminalized behavior", "forbidden", "forbidden"], "answer_start": [19, 114, 19, 114, 114]}, "prediction_text": "Pure speech"}
{"answers": {"text": ["Supreme Court case of FCC v. Pacifica Foundation", "1978 Supreme Court case of FCC v. Pacifica Foundation", "Supreme Court case of FCC v. Pacifica Foundation", "FCC v. Pacifica Foundation", "the 1978 Supreme Court case of FCC v. Pacifica Foundation"], "answer_start": [265, 260, 265, 287, 256]}, "prediction_text": "1978 Supreme Court case of FCC v. Pacifica Foundation"}
{"answers": {"text": ["1978", "1978", "1978", "1978", "1978"], "answer_start": [260, 260, 260, 260, 260]}, "prediction_text": "1978"}
{"answers": {"text": ["pure speech", "forbidden speech", "pure speech", "engaging in the forbidden speech"], "answer_start": [44, 114, 44, 98]}, "prediction_text": "Speech or threats"}
{"answers": {"text": ["broadcasting", "engaging in the forbidden speech", "broadcasting", "broadcasting"], "answer_start": [159, 98, 159, 159]}, "prediction_text": "Engage in the forbidden speech."}
{"answers": {"text": ["Threatening government officials", "forbidden speech", "engaging in the forbidden speech", "speech", "Threatening government officials"], "answer_start": [315, 114, 98, 49, 315]}, "prediction_text": "Engage in the forbidden speech."}
{"answers": {"text": ["sending an email", "email", "Supreme Court case", "broadcasting"], "answer_start": [513, 524, 265, 159]}, "prediction_text": "Engaging in the forbidden speech"}
{"answers": {"text": ["system to function", "system to function", "for a system to function", "for a system to function", "for a system to function"], "answer_start": [179, 179, 173, 173, 173]}, "prediction_text": "System's ability to function"}
{"answers": {"text": ["by padlocking the gates", "padlocking the gates", "padlocking the gates", "padlocking the gates", "padlocking the gates"], "answer_start": [566, 569, 569, 569, 569]}, "prediction_text": "By padlocking the gates and using sickles."}
{"answers": {"text": ["using sickles to deflate one of the large domes covering two satellite dishes", "using sickles to deflate one of the large domes covering two satellite dishes", "using sickles to deflate one of the large domes covering two satellite dishes", "using sickles to deflate one of the large domes covering two satellite dishes", "using sickles to deflate one of the large domes"], "answer_start": [594, 594, 594, 594, 594]}, "prediction_text": "GCSB Waihopai"}
{"answers": {"text": ["limited coercion", "civil disobedience", "employ limited coercion", "limited coercion", "employ limited coercion"], "answer_start": [443, 14, 436, 443, 436]}, "prediction_text": "Limited coercion"}
{"answers": {"text": ["coercive", "civil disobedience", "coercive", "coercive", "civil disobedience"], "answer_start": [237, 14, 237, 237, 14]}, "prediction_text": "Cursory aim"}
{"answers": {"text": ["refusals to pay taxes", "civil disobedience", "refusals to pay taxes", "refusals to pay taxes", "refusals to pay taxes"], "answer_start": [60, 14, 60, 60, 60]}, "prediction_text": "Illegal boycotts"}
{"answers": {"text": ["coercion", "make it more difficult for a system to function", "make it more difficult for a system to function", "make it more difficult for a system to function"], "answer_start": [328, 150, 150, 150]}, "prediction_text": "System failure"}
{"answers": {"text": ["engage in moral dialogue", "get their issue onto the table", "get their issue onto the table", ", make it more difficult for a system to function"], "answer_start": [367, 472, 472, 148]}, "prediction_text": "Engage in moral dialogue."}
{"answers": {"text": ["padlocking the gates", "illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins", "boycotts", "illegal boycotts", "sit-ins"], "answer_start": [569, 42, 50, 42, 141]}, "prediction_text": "Block GCSB Waihopai"}
{"answers": {"text": ["criminal investigations", "grant a consent search", "grant a consent search", "criminal investigations", "Many of the same decisions and principles that apply in other criminal investigations", "criminal"], "answer_start": [62, 200, 200, 62, 0, 62]}, "prediction_text": "Criminal investigations"}
{"answers": {"text": ["not to grant a consent search", "not to talk to police officers", "not to talk to police officers", "not to talk", "resist responding to investigators' questions", "grant a consent search"], "answer_start": [193, 255, 255, 255, 558, 200]}, "prediction_text": "Talking to criminal investigators."}
{"answers": {"text": ["suspect's talking to criminal investigators", "responding to investigators' questions", "responding to investigators' questions", "grant a consent search of his property,", "talking to criminal investigators", "responding to investigators' questions"], "answer_start": [398, 565, 565, 200, 408, 565]}, "prediction_text": "Fear of seeming rude."}
{"answers": {"text": ["lack of understanding of the legal ramifications,", "a suspect's talking to criminal investigators", "lack of understanding", "lack of understanding of the legal ramifications, or due to a fear of seeming rude."], "answer_start": [624, 396, 624, 624]}, "prediction_text": "Lack of understanding of legal ramifications, fear of seeming rude, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of understanding of the legal ramifications, lack of"}
{"answers": {"text": ["use the arrest as an opportunity", "civil disobedience", "civil disobedience", "civil disobedience", "civil disobedience", "to make an impression"], "answer_start": [746, 112, 112, 112, 112, 779]}, "prediction_text": "Fear of seeming rude."}
{"answers": {"text": ["accept punishment", "accept punishment", "punishment", "punishment", "punishment"], "answer_start": [58, 58, 65, 65, 65]}, "prediction_text": "The legitimacy of a government."}
{"answers": {"text": ["validity of the social contract", "their belief in the validity of the social contract", "because of their belief in the validity of the social contract", "belief in the validity of the social contract", "their belief in the validity of the social contract"], "answer_start": [107, 87, 76, 93, 87]}, "prediction_text": "For a violation of criminal law."}
{"answers": {"text": ["legitimacy of a particular law", "law", "laws", "the legitimacy of any government"], "answer_start": [464, 491, 178, 582]}, "prediction_text": "Government (or criminal law)"}
{"answers": {"text": ["anarchists", "anarchists", "anarchists", "anarchists", "anarchists"], "answer_start": [553, 553, 553, 553, 553]}, "prediction_text": "Anarchists"}
{"answers": {"text": ["does not infringe the rights of others", "don't believe in the legitimacy of any government", "a violation of criminal law that does not infringe the rights of others", "see no need to accept punishment for a violation of criminal law that does not infringe the rights of others", "a violation of criminal law that does not infringe the rights of others."], "answer_start": [700, 565, 667, 630, 667]}, "prediction_text": "Violation of criminal law"}
{"answers": {"text": ["whether or not to plead guilty", "whether or not to plead guilty", "whether or not to plead guilty", "whether or not to plead guilty", "whether or not to plead guilty.", "whether or not to plead guilty."], "answer_start": [48, 48, 48, 48, 48, 48]}, "prediction_text": "Whether or not to plead guilty."}
{"answers": {"text": ["submit to the punishment prescribed by law", "to submit to the punishment prescribed by law", "submit to the punishment", "to submit to the punishment prescribed by law", "to submit to the punishment prescribed by law", "to submit to the punishment prescribed by law"], "answer_start": [173, 170, 173, 170, 170, 170]}, "prediction_text": "Defending themselves in court."}
{"answers": {"text": ["I feel I did the right thing by violating this particular law", "I feel I did the right thing by violating this particular law", "proud of it", "proud of it", "have violated some specific laws, but I am guilty of doing no w", "have violated some specific laws, but I am guilty of doing no w"], "answer_start": [638, 638, 625, 625, 838, 838]}, "prediction_text": "To protect the rights of others."}
{"answers": {"text": ["Guilt implies wrong-doing", "Guilt implies wrong-doing", "guilty of doing no wrong", "Guilt implies wrong-doing", "I may have violated some specific laws, but I am guilty of doing no wrong", "I may have violated some specific laws, but I am guilty of doing no wrong"], "answer_start": [776, 776, 881, 776, 832, 832]}, "prediction_text": "Communication with the community."}
{"answers": {"text": ["creative plea", "no contest", "creative plea", "creative plea", "creative plea", "creative plea"], "answer_start": [1177, 948, 1177, 1177, 1177, 1177]}, "prediction_text": "Plea of not guilty"}
{"answers": {"text": ["Camp Mercury nuclear test site", "Camp Mercury nuclear test site", "Camp Mercury nuclear test site", "Camp Mercury nuclear test site", "Camp Mercury nuclear test site"], "answer_start": [85, 85, 85, 85, 85]}, "prediction_text": "Camp Mercury"}
{"answers": {"text": ["tempted to enter the test site", "protesters attempted to enter the test site", "attempted to enter the test site", "13 of the protesters attempted to enter the test site", "protest"], "answer_start": [163, 150, 161, 140, 54]}, "prediction_text": "Protesting against nuclear tests."}
{"answers": {"text": ["arrested", "arrest", "were immediately arrested", "one at a time they stepped across the \"line\" and were immediately arrested", "put on a bus and taken to the Nye County seat of Tonopah, Nevada, and arraigned for trial before the local Justice of the Peace"], "answer_start": [326, 218, 309, 260, 346]}, "prediction_text": "Arrested persons were found guilty."}
{"answers": {"text": ["nolo contendere", "nolo contendere", "nolo contendere", "nolo contendere", "nolo contendere"], "answer_start": [616, 616, 616, 616, 616]}, "prediction_text": "\"nolo contendere\""}
{"answers": {"text": ["suspended sentences", "suspended sentences", "suspended", "suspended", "suspended"], "answer_start": [759, 759, 759, 759, 759]}, "prediction_text": "Suspended sentences"}
{"answers": {"text": ["a way of continuing their protest", "continuing their protest", "a way of continuing their protest", "a way of continuing their protest", "a way of continuing their protest"], "answer_start": [86, 95, 86, 86, 86]}, "prediction_text": "To remind their countrymen of injustice."}
{"answers": {"text": ["reminding their countrymen of injustice", "reminding their countrymen of injustice", "reminding their countrymen of injustice", "reminding their countrymen of injustice", "reminding their countrymen of injustice"], "answer_start": [133, 133, 133, 133, 133]}, "prediction_text": "Led to civil disobedience"}
{"answers": {"text": ["protest should be maintained all the way", "spirit of protest", "the spirit of protest should be maintained all the way", "the spirit of protest should be maintained all the way", "spirit of protest"], "answer_start": [327, 317, 313, 313, 317]}, "prediction_text": "Stay in jail"}
{"answers": {"text": ["accept jail penitently", "is to switch suddenly to a spirit of subservience", "To accept jail penitently as an accession to 'the rules' is to switch suddenly to a spirit of subservience", "To accept jail penitently as an accession to 'the rules' is to switch suddenly to a spirit of subservience"], "answer_start": [431, 485, 428, 428]}, "prediction_text": "For protest, not for civil disobedience."}
{"answers": {"text": ["plea bargain", "plead guilty to one misdemeanor count and receive no jail time", "plea bargain", "plea bargain", "plea bargain"], "answer_start": [37, 161, 37, 37, 37]}, "prediction_text": "A plea bargain"}
{"answers": {"text": ["no jail time", "plead guilty to one misdemeanor count and receive no jail time", "receive no jail time", "no jail time", "receive no jail time"], "answer_start": [211, 161, 203, 211, 203]}, "prediction_text": "Secure plea agreement for everyone."}
{"answers": {"text": ["solidarity tactics", "solidarity tactics", "solidarity", "solidarity", "solidarity"], "answer_start": [285, 285, 285, 285, 285]}, "prediction_text": "Signing a blind plea"}
{"answers": {"text": ["blind plea", "blind plea", "blind plea", "blind plea", "blind plea"], "answer_start": [391, 391, 391, 391, 391]}, "prediction_text": "A plea bargain is taken as an act of disobedience."}
{"answers": {"text": ["Mohandas Gandhi", "Mohandas Gandhi", "Mohandas Gandhi", "Mohandas Gandhi", "Gan"], "answer_start": [456, 456, 456, 456, 465]}, "prediction_text": "Mohandas Gandhi"}
{"answers": {"text": ["defiant speech", "defiant speech", "allocution", "defiant speech", "defiant speech", "defiant speech"], "answer_start": [52, 52, 109, 52, 52, 52]}, "prediction_text": "Defiant speech, explaining actions."}
{"answers": {"text": ["explaining their actions", "explaining their actions", "make a defiant speech, or a speech explaining their actions,", "explaining their actions", "explaining their actions", "explaining their actions"], "answer_start": [80, 80, 45, 80, 80, 80]}, "prediction_text": "Defiant speech"}
{"answers": {"text": ["lack of remorse", "lack of remorse", "the judge increased her sentence", "statement suggested a lack of remorse"], "answer_start": [554, 554, 381, 532]}, "prediction_text": "Defiant speech can be more harmful for the individual."}
{"answers": {"text": ["likelihood of repeating", "likelihood of repeating her illegal actions", "a lack of remorse", "lack of remorse", "lack of remorse"], "answer_start": [634, 634, 552, 554, 554]}, "prediction_text": "To avoid repeat crimes."}
{"answers": {"text": ["mistreatment from government officials", "mistreatment", "mistreatment from government officials", "sentence", "mistreatment", "mistreatment"], "answer_start": [758, 758, 758, 405, 758, 758]}, "prediction_text": "Mistreatment from government officials."}
{"answers": {"text": ["acquittal and avoid imprisonment", "win an acquittal and avoid imprisonment or a fine", "to use the proceedings as a forum", "win an acquittal", "to win an acquittal and avoid imprisonment or a fine"], "answer_start": [121, 114, 168, 114, 111]}, "prediction_text": "Win an acquittal and avoid imprisonment or a fine."}
{"answers": {"text": ["use the proceedings as a forum", "use the proceedings as a forum to inform the jury and the public of the political circumstances", "win an acquittal and avoid imprisonment", "use the proceedings as a forum to inform the jury and the public of the political circumstances", "use the proceedings as a forum to inform the jury and the public of the political circumstances surrounding the case"], "answer_start": [171, 171, 114, 171, 171]}, "prediction_text": "Avoid imprisonment or fine."}
{"answers": {"text": ["inform the jury and the public of the political circumstances", "plead not guilty", "plead not guilty", "inform the jury and the public", "plead not guilty"], "answer_start": [205, 40, 40, 205, 40]}, "prediction_text": "Seek jury nullification."}
{"answers": {"text": ["Vietnam War", "Vietnam War", "Vietnam War", "Vietnam War", "Vietnam War"], "answer_start": [486, 486, 486, 486, 486]}, "prediction_text": "Vietnam War"}
{"answers": {"text": ["jury nullification", "jury nullification", "jury nullification", "nullification", "nullification"], "answer_start": [1068, 763, 1068, 768, 768]}, "prediction_text": "Seek jury nullification."}
{"answers": {"text": ["general disobedience", "undermine the law by encouraging general disobedience which is neither conscientious nor of social benefit", "great amount of it", "general disobedience", "conscientious lawbreakers"], "answer_start": [117, 84, 59, 117, 203]}, "prediction_text": "Accident or escape."}
{"answers": {"text": ["neither conscientious nor of social benefit", "neither conscientious nor of social benefit", "any great amount of it would undermine the law", "conscientious lawbreakers"], "answer_start": [147, 147, 55, 203]}, "prediction_text": "For civil disobedience."}
{"answers": {"text": ["breaking the law for self-gratification", "breaking the law for self-gratification", "it would undermine the law by encouraging general disobedience", "breaking the law for self-gratification"], "answer_start": [476, 476, 75, 476]}, "prediction_text": "Lack of direct action and attribution."}
{"answers": {"text": ["not being a civil disobedient", "viewed as not being a civil disobedient", "conscientious lawbreakers must be punished", "it would undermine the law by encouraging general disobedience", "constitute civil disobedience"], "answer_start": [880, 870, 203, 75, 416]}, "prediction_text": "Not being a civil disobedient."}
{"answers": {"text": ["avoiding attribution", "viewed as not being a civil disobedient", "it would undermine the law by encouraging general disobedience", "constitute civil disobedience"], "answer_start": [761, 870, 75, 416]}, "prediction_text": "For self-gratification."}
{"answers": {"text": ["Indirect civil disobedience", "Indirect civil disobedience", "Indirect civil disobedience", "Indirect civil disobedience", "Indirect civil disobedience"], "answer_start": [68, 68, 68, 68, 68]}, "prediction_text": "Indirect civil disobedience"}
{"answers": {"text": ["direct civil disobedience", "direct civil disobedience", "direct civil disobedience", "direct civil disobedience", "direct civil disobedience"], "answer_start": [174, 174, 174, 174, 174]}, "prediction_text": "Indirect civil disobedience"}
{"answers": {"text": ["Vietnam War", "Vietnam War", "Vietnam War", "Vietnam War", "Vietnam"], "answer_start": [443, 288, 443, 443, 288]}, "prediction_text": "Vietnam War"}
{"answers": {"text": ["competing harms defense", "necessity defense", "necessity defense", "necessity"], "answer_start": [1035, 506, 506, 506]}, "prediction_text": "Shadow defense"}
{"answers": {"text": ["the leaflets will have to be given to the leafleter's own jury as evidence", "if they arrest fully informed jury leafleters, the leaflets will have to be given to the leafleter's own jury as evidence", "the leaflets will have to be given to the leafleter's own jury as evidence", "the leaflets will have to be given to the leafleter's own jury as evidence", "the leaflets will have to be given to the leafleter's own jury as evidence"], "answer_start": [1377, 1330, 1377, 1377, 1377]}, "prediction_text": "They have escaped prosecution."}
{"answers": {"text": ["incapacitation", "achieving crime control via incapacitation and deterrence", "achieving crime control via incapacitation and deterrence", "achieving crime control", "achieving crime control"], "answer_start": [79, 51, 51, 51, 51]}, "prediction_text": "Crime control via incapacitation and deterrence."}
{"answers": {"text": ["would do more harm than good", "whether it would do more harm than good", "it focuses attention on the threat of punishment and not the moral reasons to follow this law", "whether it would do more harm than good", "whether it would do more harm than good."], "answer_start": [553, 542, 322, 542, 542]}, "prediction_text": "Engaging in moral dialogue with the offender."}
{"answers": {"text": ["the state", "judges", "the state (including the judges)", "the judges", "judges"], "answer_start": [664, 689, 664, 685, 689]}, "prediction_text": "The state (including judges)"}
{"answers": {"text": ["moral reasons to follow this law", "whether it would do more harm than good", "whether it would do more harm than good", "whether it would do more harm than good", "whether it would do more harm than good"], "answer_start": [383, 542, 542, 542, 542]}, "prediction_text": "Moral dialogue with the offender"}
{"answers": {"text": ["Construction", "Construction", "Construction"], "answer_start": [0, 0, 0]}, "prediction_text": "Construction"}
{"answers": {"text": ["manufacturing", "manufacturing", "manufacturing"], "answer_start": [122, 100, 122]}, "prediction_text": "Construction"}
{"answers": {"text": ["six to nine percent", "six to nine percent", "six to nine percent"], "answer_start": [331, 331, 331]}, "prediction_text": "Six to nine percent"}
{"answers": {"text": ["planning,[citation needed] design, and financing", "planning,[citation needed] design, and financing", "planning,[citation needed] design, and financing and continues until the project is built"], "answer_start": [430, 430, 430]}, "prediction_text": "Plans, financing, and construction."}
{"answers": {"text": ["a known client", "client", "known client"], "answer_start": [277, 285, 279]}, "prediction_text": "Known client"}
{"answers": {"text": ["An architect", "architect", "architect"], "answer_start": [77, 80, 80]}, "prediction_text": "Architect"}
{"answers": {"text": ["a construction manager, design engineer, construction engineer or project manager", "construction engineer or project manager", "construction manager, design engineer, construction engineer or project manager"], "answer_start": [120, 161, 122]}, "prediction_text": "Architect"}
{"answers": {"text": ["effective planning", "effective planning", "effective planning"], "answer_start": [260, 260, 260]}, "prediction_text": "Effective planning"}
{"answers": {"text": ["megaprojects", "megaprojects", "megaprojects"], "answer_start": [703, 703, 703]}, "prediction_text": "megaprojects"}
{"answers": {"text": ["Those involved with the design and execution of the infrastructure", "Those involved with the design and execution of the infrastructure", "Those involved with the design and execution of the infrastructure in question"], "answer_start": [293, 293, 293]}, "prediction_text": "Construction-site safety, availability, transportation of building materials, logistics, inconvenience to the public."}
{"answers": {"text": ["buildings, infrastructure and industrial", "buildings, infrastructure and industrial", "buildings, infrastructure and industrial"], "answer_start": [53, 53, 53]}, "prediction_text": "Buildings, infrastructure, industrial."}
{"answers": {"text": ["residential and non-residential", "residential and non-residential (commercial/institutional)", "residential and non-residential (commercial/institutional)"], "answer_start": [149, 149, 149]}, "prediction_text": "Residential and non-residential"}
{"answers": {"text": ["heavy/highway, heavy civil or heavy engineering", "heavy/highway, heavy civil or heavy engineering", "heavy/highway, heavy civil or heavy engineering"], "answer_start": [240, 240, 240]}, "prediction_text": "Heavy/highway, heavy civil, heavy engineering"}
{"answers": {"text": ["Infrastructure", "Infrastructure", "Infrastructure"], "answer_start": [209, 209, 209]}, "prediction_text": "Heavy/highway"}
{"answers": {"text": ["Industrial", "heavy civil or heavy engineering", "Industrial"], "answer_start": [389, 255, 389]}, "prediction_text": "Heavy/highway"}
{"answers": {"text": ["a trade magazine for the construction industry", "a trade magazine for the construction industry", "trade magazine for the construction industry"], "answer_start": [33, 33, 35]}, "prediction_text": "A trade magazine for the construction industry."}
{"answers": {"text": ["ENR", "Engineering News-Record (ENR)", "Engineering News-Record (ENR)"], "answer_start": [92, 0, 0]}, "prediction_text": "Engineering News-Record (ENR)"}
{"answers": {"text": ["2014", "2014", "2014"], "answer_start": [369, 369, 369]}, "prediction_text": "2014"}
{"answers": {"text": ["transportation, sewer, hazardous waste and water", "data on transportation, sewer, hazardous waste and water", "transportation, sewer, hazardous waste and water"], "answer_start": [652, 644, 652]}, "prediction_text": "Transportation, sewer, hazardous waste, water."}
{"answers": {"text": ["building construction, heavy and civil engineering construction, and specialty trade contractors", "building construction, heavy and civil engineering construction, and specialty trade contractors", "building construction, heavy and civil engineering construction, and specialty trade contractors"], "answer_start": [287, 287, 287]}, "prediction_text": "Building construction, heavy and civil engineering construction, specialty trade contractors."}
{"answers": {"text": ["construction service firms (e.g., engineering, architecture) and construction managers", "service firms", "construction service firms (e.g., engineering, architecture) and construction managers"], "answer_start": [415, 428, 415]}, "prediction_text": "Construction service firms, construction managers, construction service firms."}
{"answers": {"text": ["The Standard Industrial Classification and the newer North American Industry Classification System", "Standard Industrial Classification", "The Standard Industrial Classification and the newer North American Industry Classification System"], "answer_start": [0, 4, 0]}, "prediction_text": "Standard Industrial Classification and North American Industry Classification System"}
{"answers": {"text": ["firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project", "firms engaged in managing construction projects", "(firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project)"], "answer_start": [503, 503, 502]}, "prediction_text": "Construction firms engaged in managing construction projects without assuming direct financial responsibility."}
{"answers": {"text": ["Building construction", "Building construction", "Building construction"], "answer_start": [0, 0, 0]}, "prediction_text": "Building construction"}
{"answers": {"text": ["small renovations", "small renovations", "small renovations"], "answer_start": [151, 151, 151]}, "prediction_text": "Small renovations"}
{"answers": {"text": ["the owner of the property", "the owner", "owner of the property"], "answer_start": [234, 234, 238]}, "prediction_text": "Owner of the property"}
{"answers": {"text": ["structural collapse, cost overruns, and/or litigation", "structural collapse, cost overruns, and/or litigation", "structural collapse, cost overruns, and/or litigation"], "answer_start": [545, 545, 545]}, "prediction_text": "Structural collapse, cost overruns, litigation."}
{"answers": {"text": ["make detailed plans and maintain careful oversight", "make detailed plans and maintain careful oversight", "make detailed plans and maintain careful oversight during the project"], "answer_start": [652, 652, 652]}, "prediction_text": "Make detailed plans, maintain careful oversight, and maintain detailed plans during project."}
{"answers": {"text": ["local building authority regulations and codes of practice", "local building authority regulations and codes of practice", "local building authority regulations and codes of practice"], "answer_start": [80, 80, 80]}, "prediction_text": "Local building authority regulations and codes of practice."}
{"answers": {"text": ["Materials readily available in the area", "Materials readily available in the area", "Materials readily available in the area"], "answer_start": [140, 140, 140]}, "prediction_text": "Brick versus stone"}
{"answers": {"text": ["a lot of waste", "waste", "waste"], "answer_start": [629, 638, 638]}, "prediction_text": "Waste"}
{"answers": {"text": ["Cost of construction", "Cost of construction", "Cost of construction"], "answer_start": [272, 272, 272]}, "prediction_text": "Cost of construction"}
{"answers": {"text": ["3D printing technology", "3D printing technology", "advances in 3D printing technology"], "answer_start": [91, 91, 79]}, "prediction_text": "3D printing technology"}
{"answers": {"text": ["around 20 hours", "around 20 hours", "20 hours"], "answer_start": [349, 349, 356]}, "prediction_text": "Around 20 hours"}
{"answers": {"text": ["Working versions of 3D-printing building technology are already printing", "2014", "2014"], "answer_start": [466, 850, 850]}, "prediction_text": "2014"}
{"answers": {"text": ["2 metres (6 ft 7 in)", "2 metres (6 ft 7 in)", "2 metres (6 ft 7 in)"], "answer_start": [539, 539, 539]}, "prediction_text": "2 metres (6 ft 7 in) per hour"}
{"answers": {"text": ["plan the physical proceedings, and to integrate those proceedings with the other parts", "plan the physical proceedings, and to integrate those proceedings with the other parts", "plan the physical proceedings, and to integrate those proceedings with the other parts"], "answer_start": [148, 148, 148]}, "prediction_text": "Plan physical proceedings"}
{"answers": {"text": ["designs into reality", "designs into reality", "designs into reality"], "answer_start": [85, 85, 85]}, "prediction_text": "Design designs into reality"}
{"answers": {"text": ["the property owner", "the property owner", "property owner"], "answer_start": [611, 611, 615]}, "prediction_text": "Property owner"}
{"answers": {"text": ["a quantity surveyor", "quantity surveyor", "quantity surveyor"], "answer_start": [919, 921, 921]}, "prediction_text": "A quantity surveyor"}
{"answers": {"text": ["the most cost efficient bidder", "the most cost efficient bidder", "most cost efficient bidder"], "answer_start": [1011, 1011, 1015]}, "prediction_text": "Most cost efficient bidder"}
{"answers": {"text": ["previously separated specialties", "previously separated specialties", "previously separated specialties, especially among large firms"], "answer_start": [52, 52, 52]}, "prediction_text": "Specialties"}
{"answers": {"text": ["entirely separate companies", "entirely separate companies", "entirely separate companies"], "answer_start": [254, 254, 254]}, "prediction_text": "All separate companies"}
{"answers": {"text": ["\"one-stop shopping\"", "one-stop shopping", "\"one-stop shopping\""], "answer_start": [562, 563, 562]}, "prediction_text": "One-stop shopping"}
{"answers": {"text": ["\"design build\" contract", "design build", "\"design build\" contract"], "answer_start": [657, 658, 657]}, "prediction_text": "Design build contract"}
{"answers": {"text": ["design-build, partnering and construction management", "design-build, partnering and construction management", "design-build, partnering and construction management"], "answer_start": [79, 79, 79]}, "prediction_text": "Design-build, partnering and construction management."}
{"answers": {"text": ["architects, interior designers, engineers and constructors", "architects, interior designers, engineers and constructors", "architects, interior designers, engineers and constructors"], "answer_start": [224, 224, 224]}, "prediction_text": "Architects, interior designers, engineers, and constructors."}
{"answers": {"text": ["establishing relationships with other necessary participants through the design-build process", "establishing relationships with other necessary participants", "establishing relationships with other necessary participants"], "answer_start": [462, 462, 462]}, "prediction_text": "Building relationships with other participants"}
{"answers": {"text": ["preventable financial problems", "preventable financial problems", "preventable financial problems"], "answer_start": [38, 38, 38]}, "prediction_text": "Financial problems"}
{"answers": {"text": ["when builders ask for too little money to complete the project", "when builders ask for too little money to complete the project", "builders ask for too little money to complete the project"], "answer_start": [87, 87, 92]}, "prediction_text": "A project that cannot be completed."}
{"answers": {"text": ["when the present amount of funding cannot cover the current costs for labour and materials", "when the present amount of funding cannot cover the current costs for labour and materials", "present amount of funding cannot cover the current costs for labour and materials"], "answer_start": [176, 176, 185]}, "prediction_text": "When the present amount cannot cover current costs."}
{"answers": {"text": ["Fraud", "Fraud", "Fraud"], "answer_start": [394, 394, 394]}, "prediction_text": "Fraud"}
{"answers": {"text": ["Mortgage bankers, accountants, and cost engineers", "Mortgage bankers, accountants, and cost engineers", "Mortgage bankers, accountants, and cost engineers"], "answer_start": [0, 0, 0]}, "prediction_text": "Mortgage bankers, accountants, and cost engineers."}
{"answers": {"text": ["the mortgage banker", "mortgage banker", "mortgage banker"], "answer_start": [185, 189, 189]}, "prediction_text": "Mortgage bankers"}
{"answers": {"text": ["Accountants", "Accountants", "Accountants"], "answer_start": [360, 360, 360]}, "prediction_text": "Mortgage bankers"}
{"answers": {"text": ["identified change orders or project changes that increased costs", "identified change orders or project changes that increased costs", "contractor identified change orders or project changes that increased costs"], "answer_start": [676, 676, 665]}, "prediction_text": "identified change orders or project changes"}
{"answers": {"text": ["Cost engineers and estimators", "Cost engineers and estimators", "Cost engineers and estimators"], "answer_start": [492, 492, 492]}, "prediction_text": "Cost engineers and estimators"}
{"answers": {"text": ["zoning and building code requirements", "zoning and building code requirements", "zoning and building code requirements"], "answer_start": [27, 27, 27]}, "prediction_text": "Zoning and building code requirements."}
{"answers": {"text": ["the owner", "owner", "the owner"], "answer_start": [136, 140, 136]}, "prediction_text": "The owner"}
{"answers": {"text": ["the desire to prevent things that are indisputably bad", "desire to prevent things that are indisputably bad", "the desire to prevent things that are indisputably bad"], "answer_start": [212, 216, 212]}, "prediction_text": "Malum in se considerations refers to the desire to prevent things that are indisputably bad."}
{"answers": {"text": ["things that are a matter of custom or expectation", "things that are a matter of custom or expectation", "things that are a matter of custom or expectation"], "answer_start": [372, 372, 372]}, "prediction_text": "Malum prohibitum considerations prevent certain things from occurring."}
{"answers": {"text": ["An attorney", "attorney", "An attorney"], "answer_start": [517, 520, 517]}, "prediction_text": "An attorney"}
{"answers": {"text": ["A construction project", "A construction project", "A construction project"], "answer_start": [0, 0, 0]}, "prediction_text": "A construction project"}
{"answers": {"text": ["A contract", "A contract", "A contract"], "answer_start": [133, 133, 133]}, "prediction_text": "Construction contract"}
{"answers": {"text": ["that a delay costs money, and in cases of bottlenecks, the delay can be extremely expensive", "a delay costs money", "that a delay costs money, and in cases of bottlenecks, the delay can be extremely expensive"], "answer_start": [388, 393, 388]}, "prediction_text": "A delay costs money."}
{"answers": {"text": ["that each side is capable of performing the obligations set out", "that each side is capable of performing the obligations set out", "each side is capable of performing the obligations set out"], "answer_start": [528, 528, 533]}, "prediction_text": "Each side is capable of performing obligations"}
{"answers": {"text": ["poorly drafted contracts", "poorly drafted contracts", "poorly drafted contracts"], "answer_start": [758, 758, 758]}, "prediction_text": "Contract design and construction"}
{"answers": {"text": ["relationship contracting where the emphasis is on a co-operative relationship", "relationship contracting", "relationship contracting"], "answer_start": [72, 72, 72]}, "prediction_text": "Relationship contracting"}
{"answers": {"text": ["Public-Private Partnering", "Public-Private Partnering", "Public-Private Partnering"], "answer_start": [278, 278, 278]}, "prediction_text": "Private finance initiative"}
{"answers": {"text": ["private finance initiatives (PFIs)", "private finance initiatives (PFIs)", "private finance initiatives (PFIs)"], "answer_start": [315, 315, 315]}, "prediction_text": "Private finance initiatives"}
{"answers": {"text": ["co-operation", "co-operation", "co-operation"], "answer_start": [454, 454, 454]}, "prediction_text": "Co-operation"}
{"answers": {"text": ["the architect or engineer", "the architect or engineer", "the architect or engineer"], "answer_start": [120, 120, 120]}, "prediction_text": "Architect or engineer"}
{"answers": {"text": ["the project coordinator", "project coordinator", "the architect or engineer"], "answer_start": [154, 158, 120]}, "prediction_text": "Architect or engineer"}
{"answers": {"text": ["the architect's client and the main contractor", "the architect's client and the main contractor", "architect's client and the main contractor"], "answer_start": [418, 418, 422]}, "prediction_text": "The architect's client"}
{"answers": {"text": ["the main contractor", "the main contractor", "main contractor"], "answer_start": [445, 527, 531]}, "prediction_text": "The main contractor"}
{"answers": {"text": ["the building is ready to occupy.", "the building is ready to occupy", "building is ready to occupy"], "answer_start": [578, 578, 582]}, "prediction_text": "The building is ready to occupy."}
{"answers": {"text": ["The owner", "The owner", "The owner"], "answer_start": [0, 0, 0]}, "prediction_text": "The owner"}
{"answers": {"text": ["D&B contractors", "D&B contractors", "Several D&B contractors"], "answer_start": [112, 112, 104]}, "prediction_text": "D&B contractors"}
{"answers": {"text": ["The owner", "The owner", "The owner"], "answer_start": [189, 189, 189]}, "prediction_text": "The owner selects and hires the best ideas."}
{"answers": {"text": ["a consortium of several contractors", "a consortium of several contractors", "a consortium of several contractors"], "answer_start": [318, 318, 318]}, "prediction_text": "A consortium of contractors"}
{"answers": {"text": ["they design phase 2", "they design phase 2", "they design phase 2"], "answer_start": [475, 475, 475]}, "prediction_text": "Design-bid-build contract"}
{"answers": {"text": ["contractors", "contractors", "contractors"], "answer_start": [34, 34, 34]}, "prediction_text": "Utilities themselves"}
{"answers": {"text": ["damage", "the likelihood of damage", "the likelihood of damage to the existing electrical, water, sewage, phone, and cable facilities"], "answer_start": [237, 219, 219]}, "prediction_text": "Damage to existing facilities"}
{"answers": {"text": ["electrical, water, sewage, phone, and cable facilities", "electrical, water, sewage, phone, and cable", "electrical, water, sewage, phone, and cable facilities"], "answer_start": [260, 260, 260]}, "prediction_text": "Electrical, water, sewage, phone, cable."}
{"answers": {"text": ["the municipal building inspector", "municipal building inspector", "the municipal building inspector"], "answer_start": [419, 423, 419]}, "prediction_text": "Municipal building inspector"}
{"answers": {"text": ["an occupancy permit", "occupancy permit", "an occupancy permit"], "answer_start": [648, 651, 648]}, "prediction_text": "Occupancy permit"}
{"answers": {"text": ["$960 billion", "$960 billion", "$960 billion"], "answer_start": [54, 54, 54]}, "prediction_text": "Around $960 billion"}
{"answers": {"text": ["$680 billion", "$680 billion", "$680 billion"], "answer_start": [148, 148, 148]}, "prediction_text": "$680 billion"}
{"answers": {"text": ["667,000 firms", "667,000 firms", "667,000 firms"], "answer_start": [288, 288, 288]}, "prediction_text": "667,000"}
{"answers": {"text": ["fewer than 10 employees", "fewer than 10", "fewer than 10"], "answer_start": [434, 434, 434]}, "prediction_text": "Less than 10 employees"}
{"answers": {"text": ["828,000", "828,000 women", "828,000"], "answer_start": [604, 604, 604]}, "prediction_text": "828,000"}
{"answers": {"text": ["\u00a342,090", "\u00a342,090", "\u00a342,090"], "answer_start": [484, 484, 484]}, "prediction_text": "\u00a342,090"}
{"answers": {"text": ["\u00a326,719", "\u00a326,719", "\u00a326,719"], "answer_start": [505, 505, 505]}, "prediction_text": "\u00a326,719"}
{"answers": {"text": ["US/Canada", "US/Canada", "US/Canada"], "answer_start": [792, 792, 792]}, "prediction_text": "US/Canada"}
{"answers": {"text": ["Construction", "Construction", "Construction"], "answer_start": [0, 0, 0]}, "prediction_text": "Construction"}
{"answers": {"text": ["Falls", "Falls", "Falls"], "answer_start": [319, 319, 319]}, "prediction_text": "Falling or electrocution"}
{"answers": {"text": ["electrocution, transportation accidents, and trench cave-ins", "electrocution, transportation accidents, and trench cave-ins", "electrocution, transportation accidents, and trench cave-ins"], "answer_start": [689, 689, 689]}, "prediction_text": "Electrocution, transportation accidents, trench cave-ins."}
{"answers": {"text": ["Proper safety equipment such as harnesses and guardrails and procedures such as securing ladders and inspecting scaffolding", "Proper safety equipment", "Proper safety equipment"], "answer_start": [419, 419, 419]}, "prediction_text": "Proper safety equipment and procedures."}
{"answers": {"text": ["independent", "independent schools", "independent schools"], "answer_start": [31, 31, 31]}, "prediction_text": "Private schools are not administered by local, state, or national governments."}
{"answers": {"text": ["academic", "academic", "academic"], "answer_start": [538, 538, 538]}, "prediction_text": "Academic scholarship"}
{"answers": {"text": ["tuition", "charging their students tuition", "tuition"], "answer_start": [268, 244, 268]}, "prediction_text": "Fees"}
{"answers": {"text": ["to select their students", "select their students", "select their students"], "answer_start": [181, 184, 184]}, "prediction_text": "Right to select students"}
{"answers": {"text": ["$45,000", "more than $45,000", "$45,000"], "answer_start": [500, 490, 500]}, "prediction_text": "More than $45,000"}
{"answers": {"text": ["'tuition-free", "tuition-free", "tuition-free"], "answer_start": [464, 465, 465]}, "prediction_text": "Tuition-free schools"}
{"answers": {"text": ["Australia", "Australia", "Australia"], "answer_start": [73, 73, 73]}, "prediction_text": "Australia"}
{"answers": {"text": ["North America", "North America", "North America"], "answer_start": [278, 278, 278]}, "prediction_text": "North America"}
{"answers": {"text": ["lower sixth", "lower sixth", "lower sixth"], "answer_start": [90, 90, 90]}, "prediction_text": "Upper sixth"}
{"answers": {"text": ["upper sixth", "upper sixth", "upper sixth"], "answer_start": [116, 116, 116]}, "prediction_text": "Upper sixth"}
{"answers": {"text": ["prep schools", "prep schools", "prep schools"], "answer_start": [188, 188, 188]}, "prediction_text": "Prep schools"}
{"answers": {"text": ["peer tuitions", "peer tuitions", "peer tuitions and the school's financial endowment"], "answer_start": [405, 405, 405]}, "prediction_text": "Financial endowment"}
{"answers": {"text": ["teachers", "teachers", "best teachers"], "answer_start": [530, 530, 525]}, "prediction_text": "The best teachers"}
{"answers": {"text": ["Roman Catholic", "Roman Catholic"], "answer_start": [515, 515]}, "prediction_text": "Roman Catholic"}
{"answers": {"text": ["Orthodox Christians", "Roman Catholic", "Orthodox Christians"], "answer_start": [654, 515, 654]}, "prediction_text": "Orthodox Christians"}
{"answers": {"text": ["religious", "religious", "the usual academic subjects"], "answer_start": [113, 113, 148]}, "prediction_text": "Religious education"}
{"answers": {"text": ["expulsion", "expulsion", "offer a higher quality of education"], "answer_start": [483, 483, 284]}, "prediction_text": "expulsion"}
{"answers": {"text": ["blazer", "blazer", "blazer"], "answer_start": [688, 688, 688]}, "prediction_text": "compulsory blazer."}
{"answers": {"text": ["more expensive", "more expensive", "more expensive"], "answer_start": [736, 736, 736]}, "prediction_text": "Australian private schools are more expensive."}
{"answers": {"text": ["Presbyterian", "Presbyterian Church", "Presbyterian Church"], "answer_start": [188, 188, 188]}, "prediction_text": "Presbyterian Church"}
{"answers": {"text": ["Catholic", "Catholic", "Catholic"], "answer_start": [493, 493, 493]}, "prediction_text": "Anglican Church"}
{"answers": {"text": ["Sydney", "Sydney", "Sydney"], "answer_start": [680, 680, 680]}, "prediction_text": "Sydney"}
{"answers": {"text": ["girls", "girls", "girls"], "answer_start": [837, 837, 837]}, "prediction_text": "Girls"}
{"answers": {"text": ["7", "7", "7"], "answer_start": [61, 61, 61]}, "prediction_text": "Article 7 (Paragraph 4)"}
{"answers": {"text": ["second Gleichschaltung", "a second Gleichschaltung", "a second Gleichschaltung"], "answer_start": [289, 287, 287]}, "prediction_text": "Gleichschaltung or similar event"}
{"answers": {"text": ["7.8", "7.8%", "7.8"], "answer_start": [505, 505, 505]}, "prediction_text": "11.1%"}
{"answers": {"text": ["11.1", "11.1%", "11.1"], "answer_start": [616, 616, 616]}, "prediction_text": "11.1%"}
{"answers": {"text": ["0.5", "0.5%", "6.1"], "answer_start": [531, 531, 497]}, "prediction_text": "6.1%"}
{"answers": {"text": ["Sonderungsverbot", "Sonderungsverbot", "Sonderungsverbot"], "answer_start": [633, 633, 633]}, "prediction_text": "Sonderungsverbot"}
{"answers": {"text": ["Ersatzschulen", "Ersatzschulen", "Ersatzschulen"], "answer_start": [0, 0, 0]}, "prediction_text": "Ersatzschulen"}
{"answers": {"text": ["very low", "very low", "very low tuition fees"], "answer_start": [687, 687, 687]}, "prediction_text": "Low tuition fees"}
{"answers": {"text": ["Erg\u00e4nzungsschulen", "Erg\u00e4nzungsschulen", "Erg\u00e4nzungsschulen"], "answer_start": [0, 0, 0]}, "prediction_text": "Erg\u00e4nzungsschulen"}
{"answers": {"text": ["vocational", "secondary or post-secondary", "vocational schools"], "answer_start": [260, 22, 260]}, "prediction_text": "Vocational schools"}
{"answers": {"text": ["tuition", "tuition", "tuition fees"], "answer_start": [494, 494, 494]}, "prediction_text": "By charging tuition fees"}
{"answers": {"text": ["religious", "religious groups", "religious"], "answer_start": [145, 145, 145]}, "prediction_text": "Religious groups"}
{"answers": {"text": ["independent", "independent schools", "independent schools"], "answer_start": [37, 37, 37]}, "prediction_text": "Independent school"}
{"answers": {"text": ["CBSE", "CBSE", "CBSE"], "answer_start": [991, 991, 991]}, "prediction_text": "CBSE"}
{"answers": {"text": ["30", "30", "30"], "answer_start": [803, 803, 803]}, "prediction_text": "30 Examination Boards"}
{"answers": {"text": ["union government", "the union government", "union government"], "answer_start": [607, 603, 607]}, "prediction_text": "Union government"}
{"answers": {"text": ["societies", "societies", "societies"], "answer_start": [36, 36, 36]}, "prediction_text": "Societies and non-profit trusts."}
{"answers": {"text": ["India", "India", "India"], "answer_start": [65, 65, 710]}, "prediction_text": "India"}
{"answers": {"text": ["Annual Status of Education Report", "Annual Status of Education Report", "Annual Status of Education Report"], "answer_start": [627, 627, 627]}, "prediction_text": "Annual Status of Education Report"}
{"answers": {"text": ["evaluates learning levels in rural India", "evaluates learning levels in rural India", "evaluates learning levels in rural India"], "answer_start": [675, 675, 675]}, "prediction_text": "Evaluating learning levels in rural India."}
{"answers": {"text": ["English", "English", "English"], "answer_start": [925, 925, 925]}, "prediction_text": "English"}
{"answers": {"text": ["scoil phr\u00edobh\u00e1ideach", "scoil phr\u00edobh\u00e1ideach", "scoil phr\u00edobh\u00e1ideach"], "answer_start": [36, 36, 36]}, "prediction_text": "scoil phr\u00edobh\u00e1ideach"}
{"answers": {"text": ["teacher's salaries are paid by the State", "a certain number of teacher's salaries are paid by the State", "certain number of teacher's salaries are paid by the State"], "answer_start": [98, 78, 80]}, "prediction_text": "Private schools are usually run by religious orders."}
{"answers": {"text": ["\u20ac5,000", "\u20ac5,000", "\u20ac5,000"], "answer_start": [679, 679, 679]}, "prediction_text": "Around \u20ac5,000"}
{"answers": {"text": ["Society of Jesus", "the Society of Jesus", "Society of Jesus"], "answer_start": [883, 879, 883]}, "prediction_text": "Society of Jesus"}
{"answers": {"text": ["\u20ac25,000 per year", "\u20ac25,000", "\u20ac25,000 per year"], "answer_start": [794, 794, 794]}, "prediction_text": "\u20ac25,000 per year."}
{"answers": {"text": ["1957", "1957", "1957"], "answer_start": [33, 33, 33]}, "prediction_text": "1957"}
{"answers": {"text": ["Chinese", "Chinese", "Chinese"], "answer_start": [497, 497, 497]}, "prediction_text": "Chinese"}
{"answers": {"text": ["English", "English", "English"], "answer_start": [589, 589, 589]}, "prediction_text": "English-medium"}
{"answers": {"text": ["National School", "National Type", "National School"], "answer_start": [135, 271, 135]}, "prediction_text": "National School system"}
{"answers": {"text": ["60", "60", "all"], "answer_start": [618, 618, 65]}, "prediction_text": "About 60 schools"}
{"answers": {"text": ["aided", "aided", "aided"], "answer_start": [189, 189, 189]}, "prediction_text": "Aided schools"}
{"answers": {"text": ["fully funded by private parties", "fully funded by private parties", "fully funded by private parties"], "answer_start": [240, 240, 240]}, "prediction_text": "They accept government funds."}
{"answers": {"text": ["Kathmandu", "Kathmandu", "Kathmandu"], "answer_start": [489, 489, 489]}, "prediction_text": "Kathmandu"}
{"answers": {"text": ["English", "English", "English"], "answer_start": [666, 666, 666]}, "prediction_text": "English"}
{"answers": {"text": ["Nepali", "Nepali", "Nepali"], "answer_start": [704, 704, 704]}, "prediction_text": "English"}
{"answers": {"text": ["88", "88", "88"], "answer_start": [28, 28, 28]}, "prediction_text": "88 private schools"}
{"answers": {"text": ["28,000", "28,000", "28,000"], "answer_start": [83, 83, 83]}, "prediction_text": "Around 28,000 students"}
{"answers": {"text": ["3.7", "3.7%", "3.7"], "answer_start": [102, 102, 102]}, "prediction_text": "3.7%"}
{"answers": {"text": ["Catholic", "Catholic", "Catholic"], "answer_start": [853, 853, 853]}, "prediction_text": "Catholic"}
{"answers": {"text": ["Auckland", "Auckland", "Auckland"], "answer_start": [982, 982, 982]}, "prediction_text": "Auckland"}
{"answers": {"text": ["Anglican", "Anglican", "Anglican"], "answer_start": [26, 26, 26]}, "prediction_text": "Presbyterian"}
{"answers": {"text": ["Wellington", "Wellington", "Wellington"], "answer_start": [211, 211, 211]}, "prediction_text": "Cambridge"}
{"answers": {"text": ["Presbyterian", "Presbyterian", "Presbyterian"], "answer_start": [290, 290, 290]}, "prediction_text": "Presbyterian"}
{"answers": {"text": ["Christchurch", "Christchurch", "Christchurch"], "answer_start": [487, 487, 487]}, "prediction_text": "Christchurch"}
{"answers": {"text": ["Society of St Pius X", "the Society of St Pius X", "Catholic schismatic"], "answer_start": [893, 889, 862]}, "prediction_text": "Society of St Pius X"}
{"answers": {"text": ["7.5", "7.5%", "7.5"], "answer_start": [111, 111, 111]}, "prediction_text": "About 7.5%"}
{"answers": {"text": ["32", "32%", "32"], "answer_start": [139, 139, 139]}, "prediction_text": "About 80%"}
{"answers": {"text": ["80", "80%", "80"], "answer_start": [177, 177, 177]}, "prediction_text": "About 80%"}
{"answers": {"text": ["August 1992", "August 1992", "August 1992"], "answer_start": [870, 870, 870]}, "prediction_text": "August 1992"}
{"answers": {"text": ["natural science", "natural science", "English, mathematics and natural science"], "answer_start": [753, 753, 728]}, "prediction_text": "Natural science"}
{"answers": {"text": ["Education Service Contracting", "Education Service Contracting", "Education Service Contracting"], "answer_start": [4, 4, 4]}, "prediction_text": "Education Service Contracting scheme"}
{"answers": {"text": ["Tuition Fee Supplement", "Tuition Fee Supplement", "Tuition Fee Supplement"], "answer_start": [209, 209, 209]}, "prediction_text": "Financial assistance"}
{"answers": {"text": ["Private Education Student Financial Assistance", "Private Education Student Financial Assistance", "Private Education Student Financial Assistance"], "answer_start": [376, 376, 376]}, "prediction_text": "Private education student financial assistance"}
{"answers": {"text": ["South African Schools Act", "South African Schools Act", "South African Schools Act"], "answer_start": [296, 296, 296]}, "prediction_text": "\"Public\" and \"independent\""}
{"answers": {"text": ["1996", "1996", "1996"], "answer_start": [325, 325, 325]}, "prediction_text": "1996"}
{"answers": {"text": ["independent", "independent", "independent"], "answer_start": [401, 401, 401]}, "prediction_text": "Independent schools"}
{"answers": {"text": ["traditional private", "traditional private schools", "traditional private schools and schools which are privately governed"], "answer_start": [430, 430, 430]}, "prediction_text": "Traditional private schools"}
{"answers": {"text": ["nineteenth", "nineteenth", "nineteenth century"], "answer_start": [121, 121, 121]}, "prediction_text": "Early nineteenth century"}
{"answers": {"text": ["government schools formerly reserved for white children", "government schools formerly reserved for white children", "semi-private"], "answer_start": [379, 379, 116]}, "prediction_text": "White government schools"}
{"answers": {"text": ["better", "better", "produce better academic results"], "answer_start": [467, 467, 459]}, "prediction_text": "Higher school fees"}
{"answers": {"text": ["higher", "much higher", "much higher"], "answer_start": [813, 808, 808]}, "prediction_text": "Higher school fees"}
{"answers": {"text": ["10", "10%", "10"], "answer_start": [130, 130, 130]}, "prediction_text": "Over 10%"}
{"answers": {"text": ["10,000", "10,000", "nearly 10,000"], "answer_start": [516, 516, 509]}, "prediction_text": "Over 10%"}
{"answers": {"text": ["700", "700", "700"], "answer_start": [483, 483, 483]}, "prediction_text": "700 employees"}
{"answers": {"text": ["The Knowledge School", "The Knowledge School", "The Knowledge School"], "answer_start": [408, 408, 408]}, "prediction_text": "The Knowledge School"}
{"answers": {"text": ["voucher", "voucher", "pupils are free to choose a private school"], "answer_start": [253, 253, 11]}, "prediction_text": "Private school voucher model"}
{"answers": {"text": ["13", "13", "13"], "answer_start": [259, 259, 259]}, "prediction_text": "Up to 13 years old"}
{"answers": {"text": ["public", "public", "public"], "answer_start": [281, 281, 281]}, "prediction_text": "Public schools"}
{"answers": {"text": ["9", "9", "9"], "answer_start": [529, 529, 529]}, "prediction_text": "9%"}
{"answers": {"text": ["13", "13", "13"], "answer_start": [630, 630, 630]}, "prediction_text": "13%"}
{"answers": {"text": ["\u00a321,000", "\u00a321,000", "\u00a321,000"], "answer_start": [782, 782, 782]}, "prediction_text": "\u00a327,000+"}
{"answers": {"text": ["Brown v. Board of Education of Topeka", "Brown v. Board of Education of Topeka", "Brown v. Board of Education of Topeka"], "answer_start": [87, 87, 87]}, "prediction_text": "Brown v. Board of Education"}
{"answers": {"text": ["segregation academies", "segregation academies"], "answer_start": [584, 584]}, "prediction_text": "\"Christian academies\""}
{"answers": {"text": ["South", "South", "U.S. South"], "answer_start": [288, 288, 283]}, "prediction_text": "South"}
{"answers": {"text": ["white", "white", "African-American"], "answer_start": [300, 300, 409]}, "prediction_text": "White students"}
{"answers": {"text": ["African-American", "African-American", "African-American"], "answer_start": [409, 409, 409]}, "prediction_text": "African-American"}
{"answers": {"text": ["endowments", "endowments", "endowments"], "answer_start": [75, 75, 75]}, "prediction_text": "From religious organizations or private individuals."}
{"answers": {"text": ["First", "First", "First Amendment"], "answer_start": [365, 365, 365]}, "prediction_text": "Establishment Clause"}
{"answers": {"text": ["Blaine", "Blaine Amendments", "Blaine Amendments"], "answer_start": [401, 401, 401]}, "prediction_text": "Blaine Amendments"}
{"answers": {"text": ["charter", "charter", "charter"], "answer_start": [657, 657, 657]}, "prediction_text": "Charter status"}
{"answers": {"text": ["Massachusetts", "Massachusetts", "Massachusetts"], "answer_start": [141, 141, 141]}, "prediction_text": "Massachusetts"}
{"answers": {"text": ["1852", "1852", "1852"], "answer_start": [158, 158, 158]}, "prediction_text": "1852"}
{"answers": {"text": ["1972", "1972", "1972"], "answer_start": [443, 443, 443]}, "prediction_text": "1972"}
{"answers": {"text": ["268 U.S. 510", "268 U.S. 510", "268 U.S. 510 (1925)"], "answer_start": [480, 480, 480]}, "prediction_text": "262 U.S. 390"}
{"answers": {"text": ["McCrary", "McCrary", "McCrary"], "answer_start": [379, 379, 379]}, "prediction_text": "The opposing party was the Society of Sisters."}
{"answers": {"text": ["$40,000", "$40,000", "$40,000"], "answer_start": [95, 95, 95]}, "prediction_text": "$40,000"}
{"answers": {"text": ["$50,000", "$50,000", "$50,000"], "answer_start": [157, 157, 157]}, "prediction_text": "$40,000"}
{"answers": {"text": ["Groton School", "Groton School", "Groton School"], "answer_start": [304, 304, 304]}, "prediction_text": "Groton School"}
{"answers": {"text": ["fundraising", "fundraising drives", "fundraising drives"], "answer_start": [404, 404, 404]}, "prediction_text": "Through fundraising drives"}
{"answers": {"text": ["John Harvard", "John Harvard", "John Harvard"], "answer_start": [86, 86, 86]}, "prediction_text": "John Harvard"}
{"answers": {"text": ["1977", "1977", "1977"], "answer_start": [1117, 1117, 1117]}, "prediction_text": "1977"}
{"answers": {"text": ["James Bryant Conant", "James Bryant Conant", "James Bryant Conant"], "answer_start": [899, 899, 899]}, "prediction_text": "James Bryant Conant"}
{"answers": {"text": ["Association of American Universities", "Association of American Universities", "Association of American Universities"], "answer_start": [853, 853, 853]}, "prediction_text": "Association of American Universities"}
{"answers": {"text": ["Charles W. Eliot", "Charles W. Eliot", "Charles W. Eliot"], "answer_start": [678, 678, 678]}, "prediction_text": "James Bryant Conant"}
{"answers": {"text": ["Harvard Library", "Harvard Library", "Harvard"], "answer_start": [263, 263, 263]}, "prediction_text": "Harvard Library"}
{"answers": {"text": ["79 individual libraries", "79", "79"], "answer_start": [357, 357, 357]}, "prediction_text": "79 libraries"}
{"answers": {"text": ["18 million volumes", "18 million", "over 18 million"], "answer_start": [391, 391, 386]}, "prediction_text": "Over 18 million volumes"}
{"answers": {"text": ["eight U.S. presidents", "eight", "eight"], "answer_start": [436, 436, 436]}, "prediction_text": "Eight US presidents"}
{"answers": {"text": ["150 Nobel laureates", "150", "150"], "answer_start": [577, 577, 577]}, "prediction_text": "18 Nobel laureates"}
{"answers": {"text": ["Boston metropolitan area", "Boston", "Boston"], "answer_start": [154, 154, 154]}, "prediction_text": "Boston"}
{"answers": {"text": ["$37.6 billion", "$37.6 billion", "$37.6 billion"], "answer_start": [548, 548, 548]}, "prediction_text": "$37.6 billion"}
{"answers": {"text": ["Charles River", "Charles", "Charles"], "answer_start": [401, 401, 401]}, "prediction_text": "Charles River"}
{"answers": {"text": ["eleven separate academic units", "eleven", "eleven"], "answer_start": [33, 33, 33]}, "prediction_text": "Eleven academic units"}
{"answers": {"text": ["Harvard Yard", "Harvard Yard", "Harvard Yard"], "answer_start": [228, 228, 228]}, "prediction_text": "Charles River"}
{"answers": {"text": ["1636", "1636", "1636"], "answer_start": [22, 22, 22]}, "prediction_text": "1636"}
{"answers": {"text": ["Massachusetts Bay Colony", "Great and General Court of the Massachusetts Bay Colony", "Great and General Court of the Massachusetts Bay Colony"], "answer_start": [73, 42, 42]}, "prediction_text": "Massachusetts Bay Colony"}
{"answers": {"text": ["1638", "1638", "1638"], "answer_start": [171, 171, 171]}, "prediction_text": "1638"}
{"answers": {"text": ["1639", "1639", "1639"], "answer_start": [288, 288, 288]}, "prediction_text": "1638"}
{"answers": {"text": ["1650", "1650", "1650"], "answer_start": [547, 547, 547]}, "prediction_text": "1650"}
{"answers": {"text": ["Puritan ministers", "Puritan", "Puritan"], "answer_start": [44, 44, 44]}, "prediction_text": "Puritanism"}
{"answers": {"text": ["English university model", "English university", "English university"], "answer_start": [331, 331, 331]}, "prediction_text": "University of Cambridge"}
{"answers": {"text": ["It was never affiliated with any particular denomination", "never", "never"], "answer_start": [454, 461, 461]}, "prediction_text": "No, it was not affiliated with any denomination."}
{"answers": {"text": ["1804", "1804", "1804"], "answer_start": [377, 377, 377]}, "prediction_text": "1804"}
{"answers": {"text": ["Samuel Webber", "Samuel Webber", "Samuel Webber"], "answer_start": [490, 490, 490]}, "prediction_text": "Samuel Webber"}
{"answers": {"text": ["1805", "1805", "1805"], "answer_start": [468, 468, 468]}, "prediction_text": "1805"}
{"answers": {"text": ["Louis Agassiz", "Louis Agassiz", "Louis Agassiz"], "answer_start": [41, 41, 41]}, "prediction_text": "Louis Agassiz"}
{"answers": {"text": ["intuition", "intuition", "intuition"], "answer_start": [351, 351, 351]}, "prediction_text": "intuition"}
{"answers": {"text": ["Thomas Reid and Dugald Stewart", "Thomas Reid and Dugald Stewart", "Thomas Reid and Dugald Stewart"], "answer_start": [685, 685, 685]}, "prediction_text": "Platonic treatises"}
{"answers": {"text": ["Charles W. Eliot", "Charles W. Eliot", "Charles W. Eliot"], "answer_start": [0, 0, 0]}, "prediction_text": "Charles W. Eliot"}
{"answers": {"text": ["Transcendentalist Unitarian", "Transcendentalist Unitarian", "Transcendentalist Unitarian"], "answer_start": [308, 308, 308]}, "prediction_text": "Transcendentalist Unitarian convictions"}
{"answers": {"text": ["William Ellery Channing and Ralph Waldo Emerson", "William Ellery Channing and Ralph Waldo Emerson", "William Ellery Channing and Ralph Waldo Emerson"], "answer_start": [362, 362, 362]}, "prediction_text": "William Ellery Channing and Ralph Waldo Emerson"}
{"answers": {"text": ["James Bryant Conant", "James Bryant Conant", "James Bryant Conant"], "answer_start": [0, 0, 0]}, "prediction_text": "James Bryant Conant"}
{"answers": {"text": ["identify, recruit", "Conant devised programs", "programs to identify, recruit, and support talented youth"], "answer_start": [279, 252, 267]}, "prediction_text": "James Bryant Conant's programs"}
{"answers": {"text": ["1945", "1945", "1945"], "answer_start": [508, 508, 508]}, "prediction_text": "1945"}
{"answers": {"text": ["about four men attending Harvard College for every woman studying at Radcliffe", "four men attending Harvard College for every woman studying at Radcliffe", "four men attending Harvard College for every woman"], "answer_start": [165, 171, 171]}, "prediction_text": "About four men to every woman"}
{"answers": {"text": ["1977", "1977", "1977"], "answer_start": [305, 305, 305]}, "prediction_text": "1977"}
{"answers": {"text": ["the proportion of female undergraduates steadily increased, mirroring a trend throughout higher education in the United States", "steadily increased", "increased"], "answer_start": [311, 351, 360]}, "prediction_text": "More and more women attended Harvard College."}
{"answers": {"text": ["3 miles", "3 miles", "about 3 miles"], "answer_start": [87, 87, 81]}, "prediction_text": "About 3 miles (5 km)"}
{"answers": {"text": ["twelve residential Houses", "twelve", "twelve"], "answer_start": [497, 497, 497]}, "prediction_text": "Nine residential dorms"}
{"answers": {"text": ["Charles River", "Charles River", "Charles River"], "answer_start": [582, 582, 582]}, "prediction_text": "South of Harvard Yard"}
{"answers": {"text": ["half a mile northwest of the Yard", "half a mile", "half a mile"], "answer_start": [655, 655, 655]}, "prediction_text": "Half a mile"}
{"answers": {"text": ["Allston", "Allston", "on a 358-acre (145 ha) campus"], "answer_start": [181, 181, 118]}, "prediction_text": "Near Cambridge"}
{"answers": {"text": ["The John W. Weeks Bridge", "John W. Weeks Bridge", "John W. Weeks Bridge"], "answer_start": [190, 194, 194]}, "prediction_text": "John W. Weeks Bridge"}
{"answers": {"text": ["Longwood Medical and Academic Area", "Longwood Medical and Academic Area", "Longwood Medical and Academic Area"], "answer_start": [438, 438, 438]}, "prediction_text": "3.3 miles (5.3 km) south of downtown Boston and 3.3 miles (5.3 km) south of the Cambridge campus."}
{"answers": {"text": ["approximately fifty percent", "fifty percent", "fifty percent more"], "answer_start": [167, 181, 181]}, "prediction_text": "Approximately fifty percent more"}
{"answers": {"text": ["new and enlarged bridges, a shuttle service and/or a tram.", "new and enlarged bridges, a shuttle service and/or a tram", "new and enlarged bridges, a shuttle service and/or a tram"], "answer_start": [313, 313, 313]}, "prediction_text": "New and enlarged bridges, shuttle service, and tram."}
{"answers": {"text": ["enhanced transit infrastructure, possible shuttles open to the public, and park space which will also be publicly accessible.", "enhanced transit infrastructure, possible shuttles open to the public, and park space which will also be publicly accessible", "enhanced transit infrastructure, possible shuttles open to the public, and park space"], "answer_start": [746, 746, 746]}, "prediction_text": "Improved transit infrastructure, possible shuttles, park space."}
{"answers": {"text": ["2,400", "2,400", "2,400"], "answer_start": [10, 10, 10]}, "prediction_text": "2,400"}
{"answers": {"text": ["7,200", "7,200", "7,200"], "answer_start": [64, 64, 64]}, "prediction_text": "7,200"}
{"answers": {"text": ["14,000", "14,000", "14,000"], "answer_start": [89, 89, 89]}, "prediction_text": "14,000 graduate students"}
{"answers": {"text": ["1875", "1875", "1875"], "answer_start": [309, 309, 309]}, "prediction_text": "1875"}
{"answers": {"text": ["1858", "1858", "1858"], "answer_start": [409, 409, 409]}, "prediction_text": "1875"}
{"answers": {"text": ["$32 billion", "$32 billion", "$32 billion"], "answer_start": [170, 170, 170]}, "prediction_text": "$32 billion"}
{"answers": {"text": ["30% loss", "$12 billion", "30% loss"], "answer_start": [272, 653, 272]}, "prediction_text": "About 30%"}
{"answers": {"text": ["Allston Science Complex", "Allston Science Complex", "construction of the $1.2 billion Allston Science Complex"], "answer_start": [798, 798, 765]}, "prediction_text": "Allston Science Complex"}
{"answers": {"text": ["$4.093 million", "$4.093 million", "$4.093 million"], "answer_start": [1046, 1046, 1046]}, "prediction_text": "$4.093 million"}
{"answers": {"text": ["$159 million", "$159 million", "$159 million"], "answer_start": [991, 991, 991]}, "prediction_text": "$159 million"}
{"answers": {"text": ["late 1980s", "late 1980s", "1980s"], "answer_start": [56, 56, 61]}, "prediction_text": "Late 1980s"}
{"answers": {"text": ["South African Vice Consul Duke Kent-Brown.", "Duke Kent-Brown", "Duke Kent-Brown"], "answer_start": [166, 192, 192]}, "prediction_text": "Duke Kent-Brown"}
{"answers": {"text": ["$230 million", "$230 million", "$230 million"], "answer_start": [503, 503, 503]}, "prediction_text": "$230 million"}
{"answers": {"text": ["accepted 5.3% of applicants", "5.3%", "5.3%"], "answer_start": [135, 144, 144]}, "prediction_text": "5.3%"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [324, 324, 324]}, "prediction_text": "2007"}
{"answers": {"text": ["disadvantage low-income and under-represented minority applicants", "believed to disadvantage low-income and under-represented minority applicants", "believed to disadvantage low-income and under-represented minority applicants"], "answer_start": [360, 348, 348]}, "prediction_text": "Discrimination against low-income and under-represented minority applicants."}
{"answers": {"text": ["2016", "2016", "2016"], "answer_start": [483, 483, 483]}, "prediction_text": "2016"}
{"answers": {"text": ["core curriculum of seven classes", "seven", "seven"], "answer_start": [232, 251, 251]}, "prediction_text": "Seven classes"}
{"answers": {"text": ["eight General Education categories", "eight", "eight"], "answer_start": [374, 374, 374]}, "prediction_text": "Eight classes"}
{"answers": {"text": ["reliance on teaching fellows", "reliance on teaching fellows", "reliance on teaching fellows"], "answer_start": [915, 915, 915]}, "prediction_text": "Lack of coexistence between graduate and undergraduate degrees."}
{"answers": {"text": ["beginning in early September and ending in mid-May", "beginning in early September and ending in mid-May", "beginning in early September and ending in mid-May"], "answer_start": [59, 59, 59]}, "prediction_text": "Fall, spring, summer, and fall."}
{"answers": {"text": ["four-course rate average", "four", "four"], "answer_start": [188, 188, 188]}, "prediction_text": "Four courses per term"}
{"answers": {"text": ["summa cum laude", "summa cum laude", "summa cum laude"], "answer_start": [464, 464, 464]}, "prediction_text": "Magna cum laude, cum laude, and magna cum laude."}
{"answers": {"text": ["60%", "60%", "60%"], "answer_start": [1035, 1035, 1035]}, "prediction_text": "60%"}
{"answers": {"text": ["$38,000", "$38,000", "$38,000"], "answer_start": [47, 47, 47]}, "prediction_text": "$38,000"}
{"answers": {"text": ["$57,000", "$57,000", "$57,000"], "answer_start": [91, 91, 91]}, "prediction_text": "$57,000"}
{"answers": {"text": ["nothing for their children to attend, including room and board", "nothing", "nothing"], "answer_start": [156, 156, 156]}, "prediction_text": "$57,000"}
{"answers": {"text": ["$414 million", "$414 million", "$414 million"], "answer_start": [449, 449, 449]}, "prediction_text": "88%"}
{"answers": {"text": ["88%", "88%", "88%"], "answer_start": [654, 654, 654]}, "prediction_text": "88%"}
{"answers": {"text": ["Widener Library", "Widener", "Widener Library"], "answer_start": [53, 53, 53]}, "prediction_text": "Widener Library"}
{"answers": {"text": ["Cabot Science Library, Lamont Library, and Widener Library", "Cabot Science Library, Lamont Library, and Widener Library", "Cabot Science Library, Lamont Library, and Widener Library"], "answer_start": [312, 312, 312]}, "prediction_text": "Cabot Science Library, Lamont Library, and Widener Library."}
{"answers": {"text": ["Pusey Library", "Pusey Library", "Pusey Library"], "answer_start": [850, 850, 850]}, "prediction_text": "Harvard-Yenching Library"}
{"answers": {"text": ["18 million volumes", "18 million", "over 18 million"], "answer_start": [143, 143, 138]}, "prediction_text": "Over 18 million volumes"}
{"answers": {"text": ["three museums.", "three", "three"], "answer_start": [99, 99, 99]}, "prediction_text": "Three museums"}
{"answers": {"text": ["Western art from the Middle Ages to the present", "Western art from the Middle Ages to the present", "Western art from the Middle Ages to the present"], "answer_start": [348, 348, 348]}, "prediction_text": "Western art from the Middle Ages to the present."}
{"answers": {"text": ["Peabody Museum of Archaeology and Ethnology", "Peabody Museum of Archaeology and Ethnology", "Peabody Museum of Archaeology and Ethnology"], "answer_start": [802, 802, 802]}, "prediction_text": "Semitic Museum"}
{"answers": {"text": ["2003", "2003", "2003"], "answer_start": [158, 158, 158]}, "prediction_text": "2003"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [208, 208, 208]}, "prediction_text": "2011"}
{"answers": {"text": ["second most commonly", "second", "second"], "answer_start": [813, 813, 813]}, "prediction_text": "In the Princeton Review rankings."}
{"answers": {"text": ["42", "42", "42"], "answer_start": [32, 32, 32]}, "prediction_text": "42"}
{"answers": {"text": ["Yale University", "Yale", "Yale University"], "answer_start": [138, 138, 138]}, "prediction_text": "Yale University"}
{"answers": {"text": ["every two years when the Harvard and Yale Track and Field teams come together to compete against a combined Oxford University and Cambridge University team", "every two years", "every two years"], "answer_start": [276, 276, 276]}, "prediction_text": "Every two years"}
{"answers": {"text": ["1875", "1875", "1875"], "answer_start": [164, 164, 164]}, "prediction_text": "1903"}
{"answers": {"text": ["1903", "1903", "1903"], "answer_start": [434, 434, 434]}, "prediction_text": "1903"}
{"answers": {"text": ["1906", "1906", "1906"], "answer_start": [1014, 1014, 1014]}, "prediction_text": "1906"}
{"answers": {"text": ["former captain of the Yale football team", "Yale", "Yale"], "answer_start": [758, 780, 780]}, "prediction_text": "Yale University"}
{"answers": {"text": ["Lavietes Pavilion", "Lavietes Pavilion", "Lavietes Pavilion"], "answer_start": [53, 53, 53]}, "prediction_text": "Lavietes Pavilion"}
{"answers": {"text": ["Malkin Athletic Center", "Malkin Athletic Center", "Malkin Athletic Center"], "answer_start": [140, 140, 140]}, "prediction_text": "Lavietes Pavilion"}
{"answers": {"text": ["three weight rooms", "three", "three"], "answer_start": [511, 511, 511]}, "prediction_text": "Three weight rooms"}
{"answers": {"text": ["23 years", "23", "23"], "answer_start": [23, 23, 23]}, "prediction_text": "23 years"}
{"answers": {"text": ["Thames River", "Thames River", "Thames River"], "answer_start": [166, 166, 166]}, "prediction_text": "Thames River"}
{"answers": {"text": ["strong rivalry against Cornell", "Cornell", "Cornell"], "answer_start": [412, 435, 435]}, "prediction_text": "Cornell"}
{"answers": {"text": ["2003", "2003", "2003"], "answer_start": [600, 600, 600]}, "prediction_text": "2003"}
{"answers": {"text": ["General Ban Ki-moon", "Ban Ki-moon", "Ban Ki-moon"], "answer_start": [25, 33, 33]}, "prediction_text": "John Hancock"}
{"answers": {"text": ["Juan Manuel Santos", "Juan Manuel Santos", "Juan Manuel Santos"], "answer_start": [297, 297, 297]}, "prediction_text": "Juan Manuel Santos"}
{"answers": {"text": ["Jos\u00e9 Mar\u00eda Figueres", "Jos\u00e9 Mar\u00eda Figueres", "Jos\u00e9 Mar\u00eda Figueres"], "answer_start": [339, 339, 339]}, "prediction_text": "Juan Manuel Santos"}
{"answers": {"text": ["Benjamin Netanyahu", "Benazir Bhutto"], "answer_start": [809, 861]}, "prediction_text": "Murtaza Bhutto"}
{"answers": {"text": ["Conan O'Brien", "Conan O'Brien", "Conan O'Brien"], "answer_start": [384, 384, 384]}, "prediction_text": "Conan O'Brien"}
{"answers": {"text": ["Leonard Bernstein", "Leonard Bernstein", "Leonard Bernstein"], "answer_start": [235, 235, 235]}, "prediction_text": "Leonard Bernstein"}
{"answers": {"text": ["Yo Yo Ma", "Yo Yo Ma", "Yo Yo Ma"], "answer_start": [262, 262, 262]}, "prediction_text": "Yo Yo Ma"}
{"answers": {"text": ["W. E. B. Du Bois", "W. E. B. Du Bois", "W. E. B. Du Bois"], "answer_start": [27, 27, 27]}, "prediction_text": "W. E. B. Du Bois"}
{"answers": {"text": ["Shing-Tung Yau", "Shing-Tung Yau", "Shing-Tung Yau"], "answer_start": [641, 641, 641]}, "prediction_text": "Robert Barro"}
{"answers": {"text": ["Alan Dershowitz and Lawrence Lessig", "Alan Dershowitz and Lawrence Lessig", "Alan Dershowitz and Lawrence Lessig"], "answer_start": [830, 830, 830]}, "prediction_text": "Alan Dershowitz, Lawrence Lessig."}
{"answers": {"text": ["Stephen Greenblatt", "Stephen Greenblatt", "Stephen Greenblatt"], "answer_start": [290, 290, 290]}, "prediction_text": "Stephen Greenblatt"}
{"answers": {"text": ["Jacksonville", "Jacksonville", "Jacksonville"], "answer_start": [0, 0, 0]}, "prediction_text": "Jacksonville"}
{"answers": {"text": ["1,345,596", "1,345,596", "1,345,596"], "answer_start": [608, 608, 608]}, "prediction_text": "1,345,596"}
{"answers": {"text": ["12th", "12th", "12th"], "answer_start": [472, 472, 472]}, "prediction_text": "12th most populous city"}
{"answers": {"text": ["Duval", "Duval County", "Duval County"], "answer_start": [164, 164, 164]}, "prediction_text": "Duval County"}
{"answers": {"text": ["1968", "1968", "1968"], "answer_start": [225, 225, 225]}, "prediction_text": "1968"}
{"answers": {"text": ["St. Johns", "St. Johns River", "St. Johns River"], "answer_start": [99, 99, 99]}, "prediction_text": "St. Johns River"}
{"answers": {"text": ["340 miles", "340 miles", "340 miles"], "answer_start": [181, 181, 181]}, "prediction_text": "About 340 miles (550 km)"}
{"answers": {"text": ["Fort Caroline", "Fort Caroline", "Fort Caroline"], "answer_start": [398, 398, 398]}, "prediction_text": "Fort Caroline"}
{"answers": {"text": ["the Timucua", "Timucua", "the Timucua people"], "answer_start": [329, 333, 329]}, "prediction_text": "Timucua people"}
{"answers": {"text": ["Andrew Jackson", "Andrew Jackson", "Andrew Jackson"], "answer_start": [786, 786, 786]}, "prediction_text": "Andrew Jackson"}
{"answers": {"text": ["third largest", "third largest military presence", "third largest"], "answer_start": [344, 344, 344]}, "prediction_text": "Third largest"}
{"answers": {"text": ["golf", "golf", "golf"], "answer_start": [619, 619, 619]}, "prediction_text": "Golf"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [248, 152, 152]}, "prediction_text": "Three naval bases"}
{"answers": {"text": ["\"Jacksonvillians\" or \"Jaxsons\"", "\"Jacksonvillians\"", "\"Jacksonvillians\" or \"Jaxsons\""], "answer_start": [664, 664, 664]}, "prediction_text": "\"Jaxsons\""}
{"answers": {"text": ["thousands", "thousands of years", "thousands of years"], "answer_start": [67, 67, 67]}, "prediction_text": "Thousands of years"}
{"answers": {"text": ["a University of North Florida team", "University of North Florida", "University of North Florida"], "answer_start": [170, 172, 172]}, "prediction_text": "University of North Florida team"}
{"answers": {"text": ["Timucua", "Timucua people", "Mocama"], "answer_start": [420, 420, 386]}, "prediction_text": "Timucuan Ecological and Historic Preserve"}
{"answers": {"text": ["the historical era", "historical era", "beginning of the historical era"], "answer_start": [334, 338, 321]}, "prediction_text": "Historical era"}
{"answers": {"text": ["Ossachite", "Ossachite", "Ossachite"], "answer_start": [668, 668, 668]}, "prediction_text": "Ossachite"}
{"answers": {"text": ["Jean Ribault", "Jean Ribault", "Jean Ribault"], "answer_start": [25, 25, 25]}, "prediction_text": "Jean Ribault"}
{"answers": {"text": ["France", "France", "France"], "answer_start": [235, 235, 235]}, "prediction_text": "France"}
{"answers": {"text": ["Pedro Men\u00e9ndez de Avil\u00e9s", "Pedro Men\u00e9ndez de Avil\u00e9s", "Pedro Men\u00e9ndez de Avil\u00e9s"], "answer_start": [422, 422, 422]}, "prediction_text": "Pedro Men\u00e9ndez de Avil\u00e9s"}
{"answers": {"text": ["San Mateo", "fort San Mateo", "San Mateo"], "answer_start": [731, 726, 731]}, "prediction_text": "San Mateo"}
{"answers": {"text": ["Fort Caroline", "Fort Caroline", "Fort Caroline"], "answer_start": [885, 885, 885]}, "prediction_text": "Fort Caroline"}
{"answers": {"text": ["French and Indian War", "French and Indian War", "French and Indian War"], "answer_start": [53, 53, 53]}, "prediction_text": "French and Indian War"}
{"answers": {"text": ["constructed the King's Road", "constructed the King's Road", "constructed the King's Road"], "answer_start": [97, 97, 97]}, "prediction_text": "Built the King's Road"}
{"answers": {"text": ["cattle were brought across the river there.", "cattle were brought across", "cattle were brought across the river there"], "answer_start": [351, 351, 351]}, "prediction_text": "Cowford was a name given to cattle brought across the river."}
{"answers": {"text": ["Spain", "Spain", "Spain"], "answer_start": [773, 646, 646]}, "prediction_text": "Britain"}
{"answers": {"text": ["February 9, 1832", "1832.", "February 9, 1832"], "answer_start": [1137, 1149, 1137]}, "prediction_text": "February 9, 1832"}
{"answers": {"text": ["Confederate", "Confederate", "the Confederate cause"], "answer_start": [125, 125, 121]}, "prediction_text": "Confederate cause"}
{"answers": {"text": ["The Skirmish of the Brick Church", "Skirmish of the Brick Church", "Skirmish of the Brick Church"], "answer_start": [359, 363, 363]}, "prediction_text": "Battle of Olustee"}
{"answers": {"text": ["Battle of Olustee", "Battle of Olustee", "Battle of Olustee"], "answer_start": [576, 576, 576]}, "prediction_text": "Battle of Cedar Creek"}
{"answers": {"text": ["Warfare and the long occupation", "Warfare and the long occupation", "Warfare and the long occupation"], "answer_start": [828, 828, 828]}, "prediction_text": "Warfare and long occupation"}
{"answers": {"text": ["Battle of Cedar Creek", "Battle of Cedar Creek", "1864"], "answer_start": [805, 805, 731]}, "prediction_text": "1864"}
{"answers": {"text": ["Gilded Age", "Reconstruction", "Reconstruction and the Gilded Age"], "answer_start": [30, 7, 7]}, "prediction_text": "Reconstruction and Gilded Age"}
{"answers": {"text": ["Grover Cleveland", "Grover Cleveland", "President Grover Cleveland"], "answer_start": [198, 198, 188]}, "prediction_text": "President Grover Cleveland"}
{"answers": {"text": ["yellow fever outbreaks", "yellow fever outbreaks", "yellow fever outbreaks"], "answer_start": [468, 468, 468]}, "prediction_text": "Yellow fever outbreaks"}
{"answers": {"text": ["extension of the Florida East Coast Railway further south", "Florida East Coast Railway", "the Florida East Coast Railway"], "answer_start": [505, 522, 518]}, "prediction_text": "Florida Old Confederate Soldiers and Sailors Home"}
{"answers": {"text": ["railroad", "railroad", "railroad"], "answer_start": [178, 178, 178]}, "prediction_text": "Railroad and railroad cars"}
{"answers": {"text": ["Spanish moss", "kitchen fire", "Spanish moss"], "answer_start": [92, 78, 92]}, "prediction_text": "Spanish moss at a nearby mattress factory"}
{"answers": {"text": ["over 2,000", "2,000 buildings", "over 2,"], "answer_start": [271, 276, 271]}, "prediction_text": "Over 2,000 buildings were razed."}
{"answers": {"text": ["declare martial law", "declare martial law", "declare martial law and sent the state militia to maintain order"], "answer_start": [454, 454, 454]}, "prediction_text": "declared martial law and sent the state militia to maintain order."}
{"answers": {"text": ["Great Fire of 1901", "Great Fire of 1901", "Great Fire of 1901"], "answer_start": [715, 715, 715]}, "prediction_text": "\"Great Fire of 1901\""}
{"answers": {"text": ["New York\u2013based filmmakers", "filmmakers", "New York\u2013based filmmakers"], "answer_start": [14, 29, 14]}, "prediction_text": "New York-based filmmakers"}
{"answers": {"text": ["silent film", "silent film", "silent"], "answer_start": [189, 189, 189]}, "prediction_text": "Silent films"}
{"answers": {"text": ["Winter Film Capital of the World", "Winter Film Capital of the World", "Winter Film Capital of the World"], "answer_start": [262, 262, 262]}, "prediction_text": "Winter Film Capital of the World"}
{"answers": {"text": ["Hollywood", "Hollywood", "the emergence of Hollywood"], "answer_start": [323, 323, 306]}, "prediction_text": "Hollywood's emergence as a major film production center."}
{"answers": {"text": ["highways", "construction of highways", "The construction of highways"], "answer_start": [152, 136, 132]}, "prediction_text": "Rapid urban sprawl"}
{"answers": {"text": ["55.1%", "55.1%", "55.1%"], "answer_start": [812, 812, 812]}, "prediction_text": "55.1%"}
{"answers": {"text": ["\"white flight\"", "white flight", "white flight"], "answer_start": [646, 647, 647]}, "prediction_text": "\"white flight\""}
{"answers": {"text": ["Mayor W. Haydon Burns", "Mayor W. Haydon Burns'", "Mayor W. Haydon Burns"], "answer_start": [384, 384, 384]}, "prediction_text": "Mayor W. Haydon Burns"}
{"answers": {"text": ["World War II", "World War II", "World War II"], "answer_start": [118, 222, 222]}, "prediction_text": "World War II"}
{"answers": {"text": ["Much of the city's tax base dissipated", "tax base dissipated"], "answer_start": [0, 19]}, "prediction_text": "Tax base dissipated"}
{"answers": {"text": ["unincorporated suburbs", "suburbs", "unincorporated suburbs"], "answer_start": [166, 181, 166]}, "prediction_text": "Unincorporated suburbs"}
{"answers": {"text": ["annexing outlying communities", "annexing outlying communities", "annexing outlying communities"], "answer_start": [345, 345, 345]}, "prediction_text": "Annexation of outlying communities"}
{"answers": {"text": ["Voters outside the city limits", "Voters outside the city limits", "Voters outside the city limits"], "answer_start": [457, 457, 457]}, "prediction_text": "Residents outside the city limits"}
{"answers": {"text": ["old boy network", "old boy network", "the traditional old boy network"], "answer_start": [137, 137, 121]}, "prediction_text": "Through the traditional old boy network"}
{"answers": {"text": ["11", "11", "11"], "answer_start": [202, 202, 202]}, "prediction_text": "11 officials were indicted."}
{"answers": {"text": ["Jacksonville Consolidation", "Jacksonville Consolidation", "Jacksonville Consolidation"], "answer_start": [261, 261, 261]}, "prediction_text": "J. J. Daniel and Claude Yates"}
{"answers": {"text": ["public high schools lost their accreditation", "high schools lost their accreditation", "public high schools lost their accreditation"], "answer_start": [570, 577, 570]}, "prediction_text": "Corruption scandals"}
{"answers": {"text": ["voters approved the plan", "governments merged to create the Consolidated City of Jacksonville"], "answer_start": [50, 100]}, "prediction_text": "Approved the plan."}
{"answers": {"text": ["Hans Tanzler", "Hans Tanzler", "Hans Tanzler"], "answer_start": [339, 339, 339]}, "prediction_text": "Hans Tanzler"}
{"answers": {"text": ["\"Bold New City of the South\"", "Bold New City of the South", "Consolidated City of Jacksonville"], "answer_start": [428, 429, 133]}, "prediction_text": "\"Bold New City of the South\""}
{"answers": {"text": ["Better Jacksonville Plan", "The Better Jacksonville Plan", "The Better Jacksonville Plan"], "answer_start": [496, 492, 492]}, "prediction_text": "Better Jacksonville Plan"}
{"answers": {"text": ["authorized a half-penny sales tax", "half-penny sales tax", "a half-penny sales tax"], "answer_start": [617, 630, 628]}, "prediction_text": "$2.25 billion"}
{"answers": {"text": ["874.3 square miles", "874.3 square miles", "874.3 square miles"], "answer_start": [75, 75, 75]}, "prediction_text": "2,264 km2"}
{"answers": {"text": ["The St. Johns River", "St. Johns River", "St. Johns River"], "answer_start": [519, 523, 523]}, "prediction_text": "Atlantic Ocean"}
{"answers": {"text": ["The Trout River", "Trout River", "The Trout River"], "answer_start": [557, 561, 557]}, "prediction_text": "Trout River"}
{"answers": {"text": ["13.34%", "13.34%", "13.34%"], "answer_start": [247, 247, 247]}, "prediction_text": "13.34% (116.7 sq mi or 302 km2)"}
{"answers": {"text": ["Baldwin", "Baldwin", "Baldwin"], "answer_start": [324, 324, 324]}, "prediction_text": "Baldwin"}
{"answers": {"text": ["tallest building in Downtown Jacksonville", "tallest precast, post-tensioned concrete structure", "tallest building in Downtown Jacksonville"], "answer_start": [4, 505, 4]}, "prediction_text": "The tallest building in Downtown Jacksonville's skyline."}
{"answers": {"text": ["Barnett Center", "Barnett Center", "Barnett Center"], "answer_start": [113, 113, 113]}, "prediction_text": "Barnett Center"}
{"answers": {"text": ["617 ft", "617 ft", "617 ft ("], "answer_start": [148, 148, 148]}, "prediction_text": "617 ft (188 m)"}
{"answers": {"text": ["28", "42", "42"], "answer_start": [440, 176, 176]}, "prediction_text": "28 floors"}
{"answers": {"text": ["its distinctive flared base", "distinctive flared base", "distinctive flared base"], "answer_start": [258, 262, 262]}, "prediction_text": "flared base"}
{"answers": {"text": ["subtropical", "humid subtropical", "humid subtropical climate"], "answer_start": [86, 80, 80]}, "prediction_text": "Humid subtropical"}
{"answers": {"text": ["May through September", "May through September", "the warmest months from May through September"], "answer_start": [256, 256, 232]}, "prediction_text": "From May through September"}
{"answers": {"text": ["mild", "mild and sunny.", "mild and sunny"], "answer_start": [125, 459, 459]}, "prediction_text": "Mild and sunny"}
{"answers": {"text": ["low latitude", "low latitude", "low latitude"], "answer_start": [358, 358, 358]}, "prediction_text": "Low latitude and coastal location."}
{"answers": {"text": ["104 \u00b0F", "104 \u00b0F", "104 \u00b0F"], "answer_start": [297, 297, 297]}, "prediction_text": "104 \u00b0F (40 \u00b0C)"}
{"answers": {"text": ["thunderstorms", "thunderstorms", "thunderstorms"], "answer_start": [365, 365, 365]}, "prediction_text": "Thunderstorms erupt"}
{"answers": {"text": ["high humidity", "high humidity", "extremely high humidity"], "answer_start": [520, 520, 510]}, "prediction_text": "High humidity"}
{"answers": {"text": ["July", "July", "July"], "answer_start": [71, 315, 71]}, "prediction_text": "July"}
{"answers": {"text": ["Hurricane Dora", "Hurricane Dora", "Hurricane Dora"], "answer_start": [534, 534, 534]}, "prediction_text": "Tropical Storm Bonnie"}
{"answers": {"text": ["110 mph", "110 mph", "110 mph"], "answer_start": [719, 719, 719]}, "prediction_text": "110 mph (180 km/h)"}
{"answers": {"text": ["Tropical Storm Beryl", "Beryl", "Tropical Storm Beryl"], "answer_start": [1528, 1543, 1528]}, "prediction_text": "Tropical Storm Bonnie"}
{"answers": {"text": ["Saffir-Simpson Scale", "Saffir-Simpson", "Saffir-Simpson Scale"], "answer_start": [776, 776, 776]}, "prediction_text": "Saffir-Simpson Scale"}
{"answers": {"text": ["2008", "Fay", "2008"], "answer_start": [837, 859, 837]}, "prediction_text": "2004"}
{"answers": {"text": ["Arab", "Arab", "Arab"], "answer_start": [235, 235, 235]}, "prediction_text": "Arab population"}
{"answers": {"text": ["821,784", "821,784", "821,784"], "answer_start": [139, 139, 139]}, "prediction_text": "821,784"}
{"answers": {"text": ["largest", "largest Filipino American community", "largest"], "answer_start": [356, 356, 356]}, "prediction_text": "Tenth-largest"}
{"answers": {"text": ["Filipino", "Filipino community", "Filipino"], "answer_start": [476, 476, 476]}, "prediction_text": "Filipino American community"}
{"answers": {"text": ["29.7%", "29.7%", "29.7%"], "answer_start": [266, 266, 266]}, "prediction_text": "11.8%"}
{"answers": {"text": ["23.9%", "23.9%", "23.9%"], "answer_start": [508, 508, 508]}, "prediction_text": "23.9%"}
{"answers": {"text": ["females", "females", "females"], "answer_start": [688, 688, 688]}, "prediction_text": "Males"}
{"answers": {"text": ["91.3", "91.3", "91.3"], "answer_start": [769, 769, 769]}, "prediction_text": "91.3"}
{"answers": {"text": ["40%", "40%", "40%", "40"], "answer_start": [145, 145, 145, 145]}, "prediction_text": "40%"}
{"answers": {"text": ["about 3.5 billion people", "3.5 billion", "50%", "3.5 billion"], "answer_start": [557, 563, 523, 563]}, "prediction_text": "3.5 billion people"}
{"answers": {"text": ["$759,900", "$759,900", "$759,900"], "answer_start": [1371, 1371, 1371]}, "prediction_text": "$759,900"}
{"answers": {"text": ["the methodology used", "basis of the methodology used", "\"silly argument\" and \"a non-issue . . . a diversion.\"", "basis of the methodology"], "answer_start": [1579, 1570, 2024, 1570]}, "prediction_text": "Using debt as a proxy for wealth."}
{"answers": {"text": ["a diversion", "the basis of the methodology used", "there are more poor people in the United States and Western Europe than in China"], "answer_start": [2064, 1566, 1706]}, "prediction_text": "Their methodology is flawed."}
{"answers": {"text": ["40%", "40%", "40%", "40"], "answer_start": [145, 145, 145, 145]}, "prediction_text": "40%"}
{"answers": {"text": ["financial assets", "financial assets", "possess more financial assets than the lowest 48 nations combined.", "financial assets"], "answer_start": [235, 235, 222, 235]}, "prediction_text": "Financial assets"}
{"answers": {"text": ["nearly $41 trillion", "$41 trillion", "the \"10 million dollar millionaires\" grew to nearly $41 trillion in 2008", "$41 trillion"], "answer_start": [357, 364, 312, 364]}, "prediction_text": "$41 trillion"}
{"answers": {"text": ["half", "more than half", "own more than half of the global wealth by 2016", "more than half"], "answer_start": [949, 939, 935, 939]}, "prediction_text": "Over half of the global wealth."}
{"answers": {"text": ["greater tendency to take on debts", "greater tendency to take on debts", "greater tendency to take on debts"], "answer_start": [1797, 1797, 1797]}, "prediction_text": "A greater tendency to take on debts."}
{"answers": {"text": ["400", "400", "400"], "answer_start": [32, 32, 32]}, "prediction_text": "The top 400 Americans"}
{"answers": {"text": ["New York Times", "New York Times", "New York Times"], "answer_start": [127, 127, 127]}, "prediction_text": "New York Times"}
{"answers": {"text": ["Inherited wealth", "Inherited wealth", "Inherited wealth"], "answer_start": [253, 253, 253]}, "prediction_text": "Substantial privilege"}
{"answers": {"text": ["grew up in substantial privilege", "substantial privilege", "substantial privilege"], "answer_start": [489, 500, 500]}, "prediction_text": "Significant privilege"}
{"answers": {"text": ["wealth", "wealth", "wealth"], "answer_start": [65, 65, 65]}, "prediction_text": "More wealth than the bottom 90 percent."}
{"answers": {"text": ["richest 1 percent", "richest 1 percent", "richest 1 percent"], "answer_start": [165, 165, 165]}, "prediction_text": "The \"richest 1 percent\""}
{"answers": {"text": ["Inherited wealth", "Inherited wealth", "Inherited wealth"], "answer_start": [253, 253, 253]}, "prediction_text": "Inherited wealth"}
{"answers": {"text": ["over 60 percent", "over 60 percent", "over 60 percent"], "answer_start": [435, 435, 435]}, "prediction_text": "Over 60%"}
{"answers": {"text": ["Institute for Policy Studies", "Institute for Policy Studies", "PolitiFact"], "answer_start": [404, 404, 13]}, "prediction_text": "Over 60 percent grew up in substantial privilege."}
{"answers": {"text": ["Neoclassical economics", "Neoclassical economics", "Neoclassical economics"], "answer_start": [0, 0, 0]}, "prediction_text": "Neoclassical economics"}
{"answers": {"text": ["differences in value added by labor, capital and land", "differences in value added by labor, capital and land", "differences in value added by different classifications of workers"], "answer_start": [88, 88, 186]}, "prediction_text": "Differences in value added by labor, capital, and land."}
{"answers": {"text": ["different classifications of workers", "differences in value added by different classifications of workers", "differences in value added by different classifications of workers"], "answer_start": [216, 186, 186]}, "prediction_text": "Differences in value added by labor"}
{"answers": {"text": ["productivity gap", "productivity gap", "productivity gap"], "answer_start": [467, 467, 467]}, "prediction_text": "Productivity gap"}
{"answers": {"text": ["marginal value added of each economic actor", "differences in value", "marginal value added of each economic actor"], "answer_start": [315, 186, 315]}, "prediction_text": "By marginal value added of each economic actor."}
{"answers": {"text": ["differences in value added by labor, capital and land", "differences in value added by labor, capital and land", "differences in value added by labor, capital and land"], "answer_start": [88, 88, 88]}, "prediction_text": "Differences in value added by labor, capital, and land."}
{"answers": {"text": ["value added by different classifications of workers", "value added by labor, capital and land", "value added"], "answer_start": [201, 103, 201]}, "prediction_text": "Value added by labor and capital"}
{"answers": {"text": ["wages and profits", "wages and profits", "wages and profits"], "answer_start": [275, 275, 275]}, "prediction_text": "Wage and profits"}
{"answers": {"text": ["worker, capitalist/business owner, landlord", "worker, capitalist/business owner, landlord", "worker, capitalist/business owner, landlord"], "answer_start": [360, 360, 360]}, "prediction_text": "Workers, capitalists, landlord."}
{"answers": {"text": ["productivity gap between highly-paid professions and lower-paid professions", "productivity gap", "productivity gap"], "answer_start": [467, 467, 467]}, "prediction_text": "productivity gap"}
{"answers": {"text": ["reduce costs and maximize profits", "substitution of capital equipment for labor", "pressure to reduce costs and maximize profits"], "answer_start": [137, 431, 125]}, "prediction_text": "Competitive pressure"}
{"answers": {"text": ["less workers are required", "raises the productivity of each worker,"], "answer_start": [262, 506]}, "prediction_text": "Increases productivity"}
{"answers": {"text": ["increasing unemployment", "increasing unemployment", "increasing unemployment"], "answer_start": [321, 321, 321]}, "prediction_text": "Slower wages for working class"}
{"answers": {"text": ["rising levels of property income", "rising levels of property income", "downward pressure on wages"], "answer_start": [629, 629, 399]}, "prediction_text": "Lowering wages for higher earners."}
{"answers": {"text": ["labor inputs", "labor inputs (workers)", "labor inputs"], "answer_start": [84, 84, 84]}, "prediction_text": "Workers' labor inputs"}
{"answers": {"text": ["reduce costs and maximize profits", "to reduce costs and maximize profits", "raises the productivity of each worker"], "answer_start": [137, 134, 506]}, "prediction_text": "To reduce costs and maximize profits."}
{"answers": {"text": ["substitute capital equipment", "increasingly substitute capital equipment for labor inputs", "pressure to reduce costs and maximize profits"], "answer_start": [51, 38, 125]}, "prediction_text": "Substitution of capital equipment for labor"}
{"answers": {"text": ["productivity", "organic composition of capital", "productivity"], "answer_start": [517, 217, 517]}, "prediction_text": "Higher productivity"}
{"answers": {"text": ["stagnant", "stagnant wages", "stagnant"], "answer_start": [585, 585, 585]}, "prediction_text": "Slower wages"}
{"answers": {"text": ["workers wages", "workers wages", "wages"], "answer_start": [131, 131, 301]}, "prediction_text": "Wages"}
{"answers": {"text": ["supply and demand", "law of supply and demand", "supply and demand"], "answer_start": [433, 426, 433]}, "prediction_text": "Supply and demand law"}
{"answers": {"text": ["business is chronically understaffed", "their business is chronically understaffed", "chronically understaffed"], "answer_start": [904, 898, 916]}, "prediction_text": "They take advantage of the situation."}
{"answers": {"text": ["offering a higher wage", "by offering a higher wage", "offering a higher wage the best of their labor"], "answer_start": [1000, 997, 1000]}, "prediction_text": "By offering a below market wage."}
{"answers": {"text": ["unfair", "unfair", "unfair"], "answer_start": [834, 834, 834]}, "prediction_text": "As a function of market price of skill."}
{"answers": {"text": ["the market", "market", "market"], "answer_start": [226, 230, 230]}, "prediction_text": "Professional and labor organizations"}
{"answers": {"text": ["prices", "function of market price of skill", "prices"], "answer_start": [268, 330, 268]}, "prediction_text": "As a function of market price of skill."}
{"answers": {"text": ["wages", "wages", "wages"], "answer_start": [301, 301, 301]}, "prediction_text": "Wages"}
{"answers": {"text": ["markets", "markets", "markets"], "answer_start": [595, 595, 595]}, "prediction_text": "Markets"}
{"answers": {"text": ["unfair", "high levels of inequality", "high levels of inequality"], "answer_start": [834, 772, 772]}, "prediction_text": "High levels of inequality"}
{"answers": {"text": ["Competition amongst workers", "high demand", "competition between employers for employees"], "answer_start": [319, 558, 628]}, "prediction_text": "Competition between employers for employees"}
{"answers": {"text": ["low demand", "high supply", "low wage"], "answer_start": [126, 75, 155]}, "prediction_text": "Low wage"}
{"answers": {"text": ["high wages", "high wages", "high wages"], "answer_start": [587, 587, 587]}, "prediction_text": "Higher incomes for members."}
{"answers": {"text": ["collective bargaining, political influence, or corruption", "collective bargaining, political influence, or corruption", "collective bargaining, political influence, or corruption"], "answer_start": [1149, 1149, 1149]}, "prediction_text": "Collective bargaining, political influence, corruption, or corruption."}
{"answers": {"text": ["Professional and labor organizations", "Professional and labor organizations", "Professional and labor organizations"], "answer_start": [970, 970, 970]}, "prediction_text": "Professional and labor organizations"}
{"answers": {"text": ["low wage", "competition", "low wage"], "answer_start": [155, 194, 155]}, "prediction_text": "Low wage"}
{"answers": {"text": ["competition between workers", "competition", "competition"], "answer_start": [194, 194, 194]}, "prediction_text": "Competition between employers for employees."}
{"answers": {"text": ["expendable nature of the worker", "(high supply) competing for a job that few require (low demand)", "the expendable nature of the worker in relation to his or her particular job"], "answer_start": [384, 74, 380]}, "prediction_text": "Competition drives down wages."}
{"answers": {"text": ["high", "high wages", "high"], "answer_start": [587, 587, 587]}, "prediction_text": "High wages"}
{"answers": {"text": ["employers", "employers", "employers"], "answer_start": [831, 831, 831]}, "prediction_text": "Competition between employers for employees"}
{"answers": {"text": ["entrepreneurship rates", "entrepreneurship rates", "entrepreneurship rates"], "answer_start": [64, 64, 64]}, "prediction_text": "Entrepreneurialism increases entrepreneurship rates."}
{"answers": {"text": ["Necessity-based entrepreneurship", "Necessity-based entrepreneurship", "Necessity-based entrepreneurship"], "answer_start": [203, 203, 203]}, "prediction_text": "Survival needs"}
{"answers": {"text": ["push", "\"push\" motivations", "\"push\""], "answer_start": [305, 304, 304]}, "prediction_text": "Survival needs"}
{"answers": {"text": ["pull", "\"pull\"", "\"pull\""], "answer_start": [416, 415, 415]}, "prediction_text": "Survival needs"}
{"answers": {"text": ["opportunity-based entrepreneurship", "opportunity-based entrepreneurship", "opportunity-based"], "answer_start": [333, 333, 333]}, "prediction_text": "Necessity-based entrepreneurship"}
{"answers": {"text": ["higher economic inequality", "higher economic inequality", "higher economic inequality"], "answer_start": [19, 19, 19]}, "prediction_text": "Higher economic inequality"}
{"answers": {"text": ["necessity", "necessity rather than opportunity"], "answer_start": [168, 168]}, "prediction_text": "Necessity-based entrepreneurship"}
{"answers": {"text": ["Necessity-based", "Necessity-based entrepreneurship", "Necessity-based"], "answer_start": [203, 203, 203]}, "prediction_text": "Necessity-based entrepreneurship"}
{"answers": {"text": ["achievement-oriented", "achievement-oriented motivations (\"pull\")", "achievement-oriented motivations"], "answer_start": [381, 381, 381]}, "prediction_text": "Survival needs"}
{"answers": {"text": ["positive", "positive", "more positive"], "answer_start": [705, 705, 700]}, "prediction_text": "Drives technological progress."}
{"answers": {"text": ["progressive tax", "progressive tax", "progressive"], "answer_start": [103, 103, 103]}, "prediction_text": "A progressive tax"}
{"answers": {"text": ["top tax rate", "progressive tax", "top"], "answer_start": [244, 203, 244]}, "prediction_text": "Top tax rate"}
{"answers": {"text": ["social spending", "social spending", "steeper tax progressivity applied to social spending"], "answer_start": [502, 502, 465]}, "prediction_text": "Steeper tax progressivity"}
{"answers": {"text": ["tax system", "progressive tax system", "progressive tax"], "answer_start": [89, 203, 103]}, "prediction_text": "A progressive tax system"}
{"answers": {"text": ["the tax rate", "tax rate", "tax rate"], "answer_start": [137, 141, 141]}, "prediction_text": "The top tax rate increases."}
{"answers": {"text": ["level of the top tax rate", "level of the top tax rate", "top tax rate"], "answer_start": [231, 231, 244]}, "prediction_text": "Income change"}
{"answers": {"text": ["steeper tax", "social spending", "steeper tax progressivity"], "answer_start": [465, 502, 465]}, "prediction_text": "Steeper tax progressivity"}
{"answers": {"text": ["the Gini index", "Gini", "Gini"], "answer_start": [671, 613, 613]}, "prediction_text": "Gini index"}
{"answers": {"text": ["access to education", "Education", "education"], "answer_start": [79, 100, 214]}, "prediction_text": "Education"}
{"answers": {"text": ["optional education", "education", "education"], "answer_start": [409, 374, 374]}, "prediction_text": "Education"}
{"answers": {"text": ["lower wages", "lower wages", "lower wages"], "answer_start": [452, 452, 452]}, "prediction_text": "Lower incomes"}
{"answers": {"text": ["poor", "poor", "poor"], "answer_start": [719, 719, 719]}, "prediction_text": "The poor"}
{"answers": {"text": ["savings and investment", "education,", "education"], "answer_start": [578, 374, 418]}, "prediction_text": "Education"}
{"answers": {"text": ["access to education", "access to education", "access to education"], "answer_start": [79, 79, 79]}, "prediction_text": "Variation in education access"}
{"answers": {"text": ["high wages", "high wages", "high wages"], "answer_start": [183, 183, 183]}, "prediction_text": "High wages"}
{"answers": {"text": ["lower", "lower wages", "lower wages"], "answer_start": [452, 452, 452]}, "prediction_text": "Lower wages"}
{"answers": {"text": ["lower incomes", "lower incomes", "lower incomes"], "answer_start": [538, 538, 538]}, "prediction_text": "Lower incomes"}
{"answers": {"text": ["education", "education", "education"], "answer_start": [614, 614, 614]}, "prediction_text": "Education"}
{"answers": {"text": ["increasing access to education", "increasing access to education", "increasing access to education"], "answer_start": [348, 348, 348]}, "prediction_text": "Increase access to education."}
{"answers": {"text": ["$105 billion", "$105 billion", "$105 billion"], "answer_start": [505, 505, 505]}, "prediction_text": "$105 billion"}
{"answers": {"text": ["boom-and-bust cycles", "boom-and-bust cycles", "boom-and-bust cycles"], "answer_start": [244, 244, 244]}, "prediction_text": "Boom-and-bust cycles"}
{"answers": {"text": ["Standard & Poor", "Standard & Poor", "economists with the Standard & Poor's rating agency"], "answer_start": [29, 29, 9]}, "prediction_text": "Standard & Poor's"}
{"answers": {"text": ["2014", "2014", "2014"], "answer_start": [3, 3, 3]}, "prediction_text": "In 2014"}
{"answers": {"text": ["2008-2009", "2008-2009"], "answer_start": [198, 198]}, "prediction_text": "More prone to boom-and-bust cycles."}
{"answers": {"text": ["increasing access to education", "increasing access to education", "increasing access to education"], "answer_start": [348, 348, 348]}, "prediction_text": "Increase access to education."}
{"answers": {"text": ["$105 billion", "$105 billion", "$105 billion"], "answer_start": [505, 505, 505]}, "prediction_text": "$105 billion"}
{"answers": {"text": ["boom-and-bust cycles", "boom-and-bust cycles", "boom-and-bust cycles"], "answer_start": [244, 244, 244]}, "prediction_text": "Boom-and-bust cycles"}
{"answers": {"text": ["1910\u20131940", "1910\u20131940", "1910\u20131940"], "answer_start": [52, 52, 52]}, "prediction_text": "1910\u20131940"}
{"answers": {"text": ["increase", "an increase", "increase"], "answer_start": [76, 73, 76]}, "prediction_text": "Increase in skilled labor"}
{"answers": {"text": ["decrease", "decrease in the price of skilled labor", "decrease"], "answer_start": [120, 120, 120]}, "prediction_text": "Decreased wages"}
{"answers": {"text": ["gender inequality in education", "gender inequality in education", "education"], "answer_start": [792, 792, 733]}, "prediction_text": "Lagerlof and Galor stated that gender inequality in wages can lead to low economic growth."}
{"answers": {"text": ["period of compression", "decrease in wages", "decrease in wages"], "answer_start": [459, 432, 432]}, "prediction_text": "Education"}
{"answers": {"text": ["from 1910\u20131940", "1910\u20131940", "1910\u20131940"], "answer_start": [47, 52, 52]}, "prediction_text": "1910\u20131940"}
{"answers": {"text": ["a decrease in the price of skilled labor", "decrease in the price of skilled labor", "decrease in the price of skilled labor"], "answer_start": [118, 120, 120]}, "prediction_text": "Decrease in wages"}
{"answers": {"text": ["designed to equip students with necessary skill sets to be able to perform at work", "designed to equip students with necessary skill sets to be able to perform at work", "designed to equip students with necessary skill sets to be able to perform at work"], "answer_start": [204, 204, 204]}, "prediction_text": "Education was designed to equip students with necessary skill sets."}
{"answers": {"text": ["Education", "Education", "Education"], "answer_start": [545, 545, 545]}, "prediction_text": "Education"}
{"answers": {"text": ["gender inequality in education", "low economic growth", "continued gender inequality in education"], "answer_start": [712, 757, 782]}, "prediction_text": "Gender inequality"}
{"answers": {"text": ["unions", "union membership", "unions"], "answer_start": [338, 145, 338]}, "prediction_text": "Unions"}
{"answers": {"text": ["continental European countries", "continental European countries", "continental European"], "answer_start": [961, 961, 961]}, "prediction_text": "All the continental European countries"}
{"answers": {"text": ["little", "little support", "little"], "answer_start": [717, 717, 717]}, "prediction_text": "Little support"}
{"answers": {"text": ["continental European liberalism", "European liberalism", "continental European liberalism"], "answer_start": [299, 311, 299]}, "prediction_text": "U.S.-style labor-market flexibility"}
{"answers": {"text": ["economic inequality", "economic inequality", "economic inequality"], "answer_start": [186, 186, 186]}, "prediction_text": "Economic inequality"}
{"answers": {"text": ["social exclusion", "social exclusion", "social exclusion"], "answer_start": [459, 459, 459]}, "prediction_text": "Social exclusion, poor health outcomes, high rates of crime and incarceration."}
{"answers": {"text": ["CEPR", "CEPR", "CEPR"], "answer_start": [44, 44, 44]}, "prediction_text": "CEPR"}
{"answers": {"text": ["little", "little support", "little"], "answer_start": [717, 717, 717]}, "prediction_text": "Little support"}
{"answers": {"text": ["lower", "lower level", "lower"], "answer_start": [915, 915, 915]}, "prediction_text": "Lower level compared to European countries."}
{"answers": {"text": ["Scandinavia", "Scandinavia", "Scandinavia"], "answer_start": [421, 421, 421]}, "prediction_text": "Scandinavia"}
{"answers": {"text": ["high inequality", "high inequality", "high inequality"], "answer_start": [555, 555, 555]}, "prediction_text": "High inequality"}
{"answers": {"text": ["decline of organized labor", "decline of organized labor", "decline of organized labor"], "answer_start": [77, 77, 77]}, "prediction_text": "Technology changes and globalization."}
{"answers": {"text": ["technological changes and globalization", "decline of organized labor", "technological changes and globalization"], "answer_start": [193, 77, 193]}, "prediction_text": "Unions and inequality"}
{"answers": {"text": ["Sociologist", "Sociologist", "Sociologist"], "answer_start": [0, 0, 0]}, "prediction_text": "Sociologist"}
{"answers": {"text": ["University of Washington", "University of Washington", "University of Washington"], "answer_start": [35, 35, 35]}, "prediction_text": "University of Washington"}
{"answers": {"text": ["decline of organized labor", "decline of organized labor", "decline of organized labor"], "answer_start": [77, 77, 77]}, "prediction_text": "Organized labor"}
{"answers": {"text": ["high", "high rates", "high"], "answer_start": [377, 377, 377]}, "prediction_text": "High"}
{"answers": {"text": ["weak labor movements", "weak labor movements", "weak labor movements"], "answer_start": [594, 594, 594]}, "prediction_text": "Weak labor movements and vice-versa."}
{"answers": {"text": ["reduced wages", "reduced wages", "reduced wages"], "answer_start": [187, 187, 187]}, "prediction_text": "Increased wages for low-skilled workers."}
{"answers": {"text": ["increased wages", "increased wages", "increased wages"], "answer_start": [289, 289, 289]}, "prediction_text": "Increased wages for low-skilled workers."}
{"answers": {"text": ["technological innovation", "technological innovation", "technological innovation"], "answer_start": [734, 734, 734]}, "prediction_text": "Increased trade with poor countries"}
{"answers": {"text": ["machine labor", "machine labor", "machine labor"], "answer_start": [1298, 1298, 1298]}, "prediction_text": "Machine labor"}
{"answers": {"text": ["global", "global", "global"], "answer_start": [58, 58, 58]}, "prediction_text": "Global scale"}
{"answers": {"text": ["workers in the poor countries", "low-skilled workers in the poor countries", "poor"], "answer_start": [251, 239, 266]}, "prediction_text": "Low-skilled workers in poor countries"}
{"answers": {"text": ["trade liberalisation", "trade liberalisation", "trade liberalisation"], "answer_start": [350, 350, 350]}, "prediction_text": "Trade liberalization"}
{"answers": {"text": ["minor", "minor", "minor"], "answer_start": [689, 689, 689]}, "prediction_text": "Minor"}
{"answers": {"text": ["machine labor", "machine labor", "machine labor"], "answer_start": [1298, 1298, 1298]}, "prediction_text": "Machine labor"}
{"answers": {"text": ["53%", "53%", "53%"], "answer_start": [705, 705, 705]}, "prediction_text": "53%"}
{"answers": {"text": ["-40%", "-40%", "-40%"], "answer_start": [724, 724, 724]}, "prediction_text": "-40%"}
{"answers": {"text": ["less willing to travel or relocate", "women not taking jobs due to marriage or pregnancy", "not taking jobs due to marriage or pregnancy"], "answer_start": [266, 392, 398]}, "prediction_text": "Marriage or pregnancy"}
{"answers": {"text": ["males", "males", "males"], "answer_start": [57, 57, 57]}, "prediction_text": "Men"}
{"answers": {"text": ["Gender", "ranges from 53% in Botswana to -40% in Bahrain", "Gender"], "answer_start": [30, 693, 30]}, "prediction_text": "Gender pay gap"}
{"answers": {"text": ["males in the labor market", "males", "males"], "answer_start": [57, 57, 57]}, "prediction_text": "Males"}
{"answers": {"text": ["women", "women", "women"], "answer_start": [166, 166, 166]}, "prediction_text": "Women"}
{"answers": {"text": ["Thomas Sowell", "Thomas Sowell", "Thomas Sowell"], "answer_start": [302, 302, 302]}, "prediction_text": "Thomas Sowell"}
{"answers": {"text": ["a difference", "difference", "difference in earnings"], "answer_start": [611, 613, 613]}, "prediction_text": "Income gap in other countries."}
{"answers": {"text": ["social welfare", "social welfare", "social welfare"], "answer_start": [451, 451, 451]}, "prediction_text": "Social welfare programs"}
{"answers": {"text": ["relatively equal", "relatively equal distributions of wealth", "low"], "answer_start": [189, 189, 158]}, "prediction_text": "Lower levels of inequality."}
{"answers": {"text": ["more capital", "more capital", "more capital"], "answer_start": [266, 266, 266]}, "prediction_text": "More developed countries move back to lower levels of inequality."}
{"answers": {"text": ["redistribution mechanisms", "redistribution mechanisms such as social welfare programs", "redistribution mechanisms"], "answer_start": [417, 417, 417]}, "prediction_text": "Capital accumulation and development"}
{"answers": {"text": ["Economist", "Economist", "Economist"], "answer_start": [0, 0, 0]}, "prediction_text": "Economist"}
{"answers": {"text": ["levels of economic inequality", "economic inequality", "economic inequality"], "answer_start": [36, 46, 46]}, "prediction_text": "Equal distributions of wealth"}
{"answers": {"text": ["more capital", "more capital", "more capital"], "answer_start": [266, 266, 266]}, "prediction_text": "More capital"}
{"answers": {"text": ["more wealth", "more wealth and income", "wealth and income"], "answer_start": [329, 329, 334]}, "prediction_text": "More wealth and income."}
{"answers": {"text": ["lower levels of inequality", "lower levels of inequality", "lower levels of inequality"], "answer_start": [514, 514, 514]}, "prediction_text": "Lower levels of inequality"}
{"answers": {"text": ["1910 to 1940", "1910 to 1940", "1910 to 1940"], "answer_start": [543, 543, 543]}, "prediction_text": "1970s"}
{"answers": {"text": ["1970s", "1970s", "1970s"], "answer_start": [676, 676, 676]}, "prediction_text": "1970s"}
{"answers": {"text": ["service", "service"], "answer_start": [872, 872]}, "prediction_text": "Service sector"}
{"answers": {"text": ["manufacturing", "manufacturing"], "answer_start": [844, 844]}, "prediction_text": "Service sector"}
{"answers": {"text": ["Kuznets", "Kuznets", "Kuznets"], "answer_start": [66, 66, 66]}, "prediction_text": "Kuznets (in the context of the text)"}
{"answers": {"text": ["Kuznets curve", "Kuznets curve", "Kuznets curve"], "answer_start": [178, 178, 178]}, "prediction_text": "Kuznets curve"}
{"answers": {"text": ["very weak", "very weak", "very weak"], "answer_start": [348, 348, 348]}, "prediction_text": "Weak."}
{"answers": {"text": ["eventually decrease", "eventually decrease", "decrease"], "answer_start": [411, 411, 422]}, "prediction_text": "Income inequality will decrease."}
{"answers": {"text": ["effect", "in effect", "effect"], "answer_start": [980, 977, 980]}, "prediction_text": "Multiple Kuznets' cycles"}
{"answers": {"text": ["Wealth concentration", "Wealth concentration", "Wealth concentration"], "answer_start": [0, 0, 0]}, "prediction_text": "Wealth concentration"}
{"answers": {"text": ["means to invest", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "means to invest in new sources of creating wealth"], "answer_start": [263, 259, 263]}, "prediction_text": "They have the means to invest."}
{"answers": {"text": ["greater return of capital", "wealth condensation", "wealth condensation"], "answer_start": [648, 423, 423]}, "prediction_text": "Capital in the Twenty-First Century"}
{"answers": {"text": ["larger fortunes", "wealth condensation", "wealth"], "answer_start": [713, 423, 247]}, "prediction_text": "Capital (r)"}
{"answers": {"text": ["the possession of already-wealthy individuals", "in the possession of already-wealthy individuals or entities", "already-wealthy individuals"], "answer_start": [139, 136, 157]}, "prediction_text": "In the possession of already-wealthy individuals or entities."}
{"answers": {"text": ["those who already hold wealth", "those who already hold wealth", "those who already hold wealth"], "answer_start": [224, 224, 224]}, "prediction_text": "Those who already hold wealth"}
{"answers": {"text": ["wealth condensation", "wealth condensation", "wealth condensation"], "answer_start": [423, 423, 423]}, "prediction_text": "Wealth condensation"}
{"answers": {"text": ["Thomas Piketty", "Thomas Piketty", "Thomas Piketty"], "answer_start": [521, 521, 521]}, "prediction_text": "Thomas Piketty"}
{"answers": {"text": ["higher returns", "higher returns", "higher returns"], "answer_start": [738, 738, 738]}, "prediction_text": "Higher returns"}
{"answers": {"text": ["market", "market forces", "market"], "answer_start": [98, 98, 98]}, "prediction_text": "Market forces"}
{"answers": {"text": ["Economist", "Economist", "Economist"], "answer_start": [0, 0, 0]}, "prediction_text": "Economist"}
{"answers": {"text": ["rare and desired", "rare and desired skills", "rare and desired skills"], "answer_start": [284, 284, 284]}, "prediction_text": "Rare and desired skills"}
{"answers": {"text": ["political power generated by wealth", "political power", "political power"], "answer_start": [588, 588, 588]}, "prediction_text": "Political power"}
{"answers": {"text": ["rent-seeking", "rent-seeking"], "answer_start": [740, 740]}, "prediction_text": "Rent-seeking"}
{"answers": {"text": ["inequality", "inequality", "inequality"], "answer_start": [11, 11, 11]}, "prediction_text": "inequality researchers' findings"}
{"answers": {"text": ["human capital is neglected", "a lower level of economic utility in society", "human capital is neglected"], "answer_start": [270, 130, 270]}, "prediction_text": "Human capital neglects high-end consumption."}
{"answers": {"text": ["life expectancy", "life expectancy", "life expectancy"], "answer_start": [394, 394, 394]}, "prediction_text": "Life expectancy"}
{"answers": {"text": ["inequality", "inequality", "inequality"], "answer_start": [11, 11, 11]}, "prediction_text": "Lower rates of social goods."}
{"answers": {"text": ["life expectancy is lower", "life expectancy is lower", "lower"], "answer_start": [394, 394, 413]}, "prediction_text": "Life expectancy is lower."}
{"answers": {"text": ["2013", "2013", "2013"], "answer_start": [0, 0, 0]}, "prediction_text": "2013"}
{"answers": {"text": ["rising inequality", "rising inequality", "rising inequality"], "answer_start": [62, 62, 62]}, "prediction_text": "Rising inequality"}
{"answers": {"text": ["negative", "negative effect", "negative"], "answer_start": [262, 262, 262]}, "prediction_text": "Increases inequality."}
{"answers": {"text": ["Unemployment", "Unemployment", "Unemployment"], "answer_start": [318, 318, 318]}, "prediction_text": "Social dislocation"}
{"answers": {"text": ["economic", "economic", "economic"], "answer_start": [737, 737, 737]}, "prediction_text": "Economic growth"}
{"answers": {"text": ["British", "British", "British"], "answer_start": [0, 0, 0]}, "prediction_text": "British"}
{"answers": {"text": ["higher", "higher rates", "higher"], "answer_start": [69, 69, 69]}, "prediction_text": "Higher rates in countries with high inequality."}
{"answers": {"text": ["lower", "lower rates", "lower"], "answer_start": [211, 211, 211]}, "prediction_text": "Lower in countries with high inequality."}
{"answers": {"text": ["23", "23", "23"], "answer_start": [451, 451, 451]}, "prediction_text": "23 developed countries"}
{"answers": {"text": ["equality", "equality", "equality"], "answer_start": [638, 638, 638]}, "prediction_text": "Equality"}
{"answers": {"text": ["better health and longer lives", "better health and longer lives", "better health and longer lives"], "answer_start": [128, 128, 128]}, "prediction_text": "Better health and longer lives."}
{"answers": {"text": ["poorer countries", "poorer countries", "poorer countries"], "answer_start": [222, 222, 222]}, "prediction_text": "In poorer countries"}
{"answers": {"text": ["life expectancy", "life expectancy", "life expectancy"], "answer_start": [246, 246, 246]}, "prediction_text": "Life expectancy increases rapidly."}
{"answers": {"text": ["Americans", "Americans", "Americans"], "answer_start": [452, 452, 452]}, "prediction_text": "Americans"}
{"answers": {"text": ["more equally", "more equally", "more equally distributed"], "answer_start": [675, 675, 675]}, "prediction_text": "Income was more equally distributed."}
{"answers": {"text": ["income inequality", "income inequality", "income inequality"], "answer_start": [102, 102, 102]}, "prediction_text": "Income inequality"}
{"answers": {"text": ["authors Richard Wilkinson and Kate Pickett", "Richard Wilkinson and Kate Pickett", "Richard Wilkinson and Kate Pickett"], "answer_start": [190, 198, 198]}, "prediction_text": "Richard Wilkinson and Kate Pickett"}
{"answers": {"text": ["nine", "nine factors", "nine"], "answer_start": [176, 176, 176]}, "prediction_text": "Nine factors"}
{"answers": {"text": ["among states in the US with larger income inequalities", "countries with bigger income inequalities", "countries with bigger income inequalities"], "answer_start": [342, 282, 282]}, "prediction_text": "Developed countries"}
{"answers": {"text": ["greater equality", "greater equality", "greater equality but not per capita income"], "answer_start": [560, 560, 560]}, "prediction_text": "Equality"}
{"answers": {"text": ["inequality", "inequality", "inequality"], "answer_start": [53, 53, 53]}, "prediction_text": "Inequality in society."}
{"answers": {"text": ["homicides", "homicides"], "answer_start": [140, 158]}, "prediction_text": "homicides are almost identically defined."}
{"answers": {"text": ["fifty", "over fifty", "fifty"], "answer_start": [258, 253, 258]}, "prediction_text": "Over fifty studies"}
{"answers": {"text": ["differences in the amount of inequality", "differences in the amount of inequality", "inequality"], "answer_start": [731, 731, 760]}, "prediction_text": "Differences in inequality"}
{"answers": {"text": ["tenfold", "tenfold", "tenfold"], "answer_start": [581, 581, 581]}, "prediction_text": "Tenfold difference"}
{"answers": {"text": ["the greatest good", "greatest good", "good"], "answer_start": [47, 51, 60]}, "prediction_text": "The greatest number of people."}
{"answers": {"text": ["distributive efficiency", "distributive efficiency", "\"distributive efficiency\""], "answer_start": [266, 266, 265]}, "prediction_text": "Distribution efficiency"}
{"answers": {"text": ["a great deal of utility", "a great deal of utility", "basic necessities"], "answer_start": [465, 465, 513]}, "prediction_text": "A great deal of utility to that person."}
{"answers": {"text": ["decreases", "decreases", "decreases"], "answer_start": [783, 783, 783]}, "prediction_text": "decreases as wealth increases."}
{"answers": {"text": ["higher aggregate utility", "population-wide satisfaction and happiness", "satisfaction and happiness"], "answer_start": [925, 1053, 1069]}, "prediction_text": "Higher aggregate utility."}
{"answers": {"text": ["consumption", "consumption", "consumption"], "answer_start": [87, 87, 87]}, "prediction_text": "Consumption"}
{"answers": {"text": ["libertarian", "libertarian", "libertarian"], "answer_start": [261, 261, 261]}, "prediction_text": "Libertarian"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [583, 583, 583]}, "prediction_text": "2001"}
{"answers": {"text": ["Thomas B. Edsall", "Thomas B. Edsall", "Thomas B. Edsall"], "answer_start": [687, 687, 687]}, "prediction_text": "Thomas B. Edsall"}
{"answers": {"text": ["journalist", "journalist", "journalist"], "answer_start": [676, 676, 676]}, "prediction_text": "journalist"}
{"answers": {"text": ["economist", "economist", "economist"], "answer_start": [16, 16, 16]}, "prediction_text": "Central Banking economist"}
{"answers": {"text": ["systematic economic inequalities", "systematic economic inequalities", "systematic economic inequalities"], "answer_start": [54, 54, 54]}, "prediction_text": "Systematic economic inequalities"}
{"answers": {"text": ["the Financial crisis of 2007\u201308", "Financial crisis of 2007\u201308", "Financial crisis of 2007\u201308"], "answer_start": [253, 257, 257]}, "prediction_text": "Financial crisis of 2007\u201308"}
{"answers": {"text": ["easier credit", "easier credit to the lower and middle income earners", "easier credit to the lower and middle income earners"], "answer_start": [420, 420, 420]}, "prediction_text": "Easy credit to lower and middle income earners"}
{"answers": {"text": ["easier credit", "easier credit", "easier credit"], "answer_start": [507, 507, 507]}, "prediction_text": "unsustainable monetary stimulation"}
{"answers": {"text": ["inequality in wealth and income", "inequality in wealth and income", "wealth and income"], "answer_start": [53, 53, 67]}, "prediction_text": "High levels of inequality"}
{"answers": {"text": ["quality of a country's institutions", "quality of a country's institutions and high levels of education", "quality of a country's institutions and high levels of education"], "answer_start": [257, 257, 257]}, "prediction_text": "Economic prosperity"}
{"answers": {"text": ["declines", "declines", "declines"], "answer_start": [448, 448, 448]}, "prediction_text": "GDP growth declines."}
{"answers": {"text": ["higher GDP growth", "higher GDP growth", "higher GDP growth"], "answer_start": [629, 629, 629]}, "prediction_text": "Higher GDP growth."}
{"answers": {"text": ["The poor and the middle class", "The poor and the middle class", "poor and the middle class"], "answer_start": [648, 648, 652]}, "prediction_text": "The poor and middle class"}
{"answers": {"text": ["economists", "economists", "economists"], "answer_start": [13, 13, 13]}, "prediction_text": "They are economists."}
{"answers": {"text": ["economic growth", "economic growth", "economic growth"], "answer_start": [97, 97, 97]}, "prediction_text": "Economic growth"}
{"answers": {"text": ["subsequent long-run economic growth", "subsequent long-run economic growth", "long-run economic growth"], "answer_start": [204, 204, 215]}, "prediction_text": "Economic growth"}
{"answers": {"text": ["because it is a waste of resources", "waste of resources", "waste of resources"], "answer_start": [279, 295, 295]}, "prediction_text": "For redistribution pressures and subsequent distortions."}
{"answers": {"text": ["inequality-associated effects", "inequality-associated effects", "inequality"], "answer_start": [622, 622, 622]}, "prediction_text": "Its inequality-associated effects"}
{"answers": {"text": ["evidence", "evidence", "prevent growth"], "answer_start": [36, 36, 113]}, "prediction_text": "Evidence of inequality preventing growth."}
{"answers": {"text": ["by limiting aggregate demand", "limiting aggregate demand", "limiting aggregate demand"], "answer_start": [128, 131, 131]}, "prediction_text": "Limits aggregate demand"}
{"answers": {"text": ["Economist", "Economist", "Economist"], "answer_start": [158, 158, 0]}, "prediction_text": "Economist and Branko Milanovic"}
{"answers": {"text": ["increasing importance of human capital in development", "increasing importance of human capital in development", "increasing importance of human capital"], "answer_start": [393, 393, 393]}, "prediction_text": "Increasing importance of human capital"}
{"answers": {"text": ["widespread education", "widespread education", "widespread education"], "answer_start": [737, 737, 737]}, "prediction_text": "Human capital"}
{"answers": {"text": ["1993", "1993", "1993"], "answer_start": [3, 3, 3]}, "prediction_text": "1993"}
{"answers": {"text": ["detrimental", "long lasting detrimental effect", "long lasting detrimental"], "answer_start": [114, 101, 101]}, "prediction_text": "Negative effect on human capital formation."}
{"answers": {"text": ["channels through which inequality may affect economic growth", "channels through which inequality may affect economic growth", "channels through which inequality may affect economic growth"], "answer_start": [223, 223, 223]}, "prediction_text": "Credit market imperfections"}
{"answers": {"text": ["redistributive taxation", "fertility", "fertility"], "answer_start": [602, 494, 494]}, "prediction_text": "Growth"}
{"answers": {"text": ["politically and socially unstable", "politically and socially unstable", "politically and socially unstable"], "answer_start": [930, 930, 930]}, "prediction_text": "Political and socially unstable."}
{"answers": {"text": ["reduce", "reduce growth", "reduce"], "answer_start": [223, 223, 223]}, "prediction_text": "Reduce growth."}
{"answers": {"text": ["encourage", "encourage growth", "encourage"], "answer_start": [270, 270, 270]}, "prediction_text": "Encourages growth in poorer countries."}
{"answers": {"text": ["growth and investment", "growth and investment", "growth and investment"], "answer_start": [128, 128, 128]}, "prediction_text": "Growth and investment"}
{"answers": {"text": ["Harvard", "Harvard", "Harvard"], "answer_start": [12, 12, 12]}, "prediction_text": "Harvard University"}
{"answers": {"text": ["between 1960 and 2000", "between 1960 and 2000", "between 1960 and 2000"], "answer_start": [336, 336, 336]}, "prediction_text": "1960-2000"}
{"answers": {"text": ["Kuznets curve hypothesis", "Kuznets curve hypothesis", "Kuznets curve hypothesis"], "answer_start": [85, 85, 85]}, "prediction_text": "Kuznets curve hypothesis"}
{"answers": {"text": ["first increases", "inequality first increases", "increases"], "answer_start": [167, 156, 173]}, "prediction_text": "From 1914 to 1945."}
{"answers": {"text": ["Thomas Piketty", "Thomas Piketty", "Thomas Piketty"], "answer_start": [210, 210, 210]}, "prediction_text": "Thomas Piketty"}
{"answers": {"text": ["Economist", "Economist", "Economist"], "answer_start": [200, 200, 200]}, "prediction_text": "Economist"}
{"answers": {"text": ["wars and \"violent economic and political shocks\"", "violent economic and political shocks", "wars and \"violent economic and political shocks\""], "answer_start": [281, 291, 281]}, "prediction_text": "Wars and \"violent economic and political shocks\""}
{"answers": {"text": ["the 1970s", "1970s", "1970s"], "answer_start": [27, 31, 31]}, "prediction_text": "1970s"}
{"answers": {"text": ["reduced consumer demand", "reduced consumer demand", "reduced consumer demand"], "answer_start": [253, 253, 253]}, "prediction_text": "Reduced consumer demand."}
{"answers": {"text": ["risen with increased income inequality", "risen", "risen"], "answer_start": [328, 328, 328]}, "prediction_text": "Increased income inequality."}
{"answers": {"text": ["several years", "several years", "several years"], "answer_start": [603, 603, 603]}, "prediction_text": "Several years"}
{"answers": {"text": ["more equality in the income distribution", "more equality", "equality in the income distribution"], "answer_start": [980, 980, 985]}, "prediction_text": "More equality in the income distribution."}
{"answers": {"text": ["special efforts", "special efforts", "special efforts"], "answer_start": [243, 243, 243]}, "prediction_text": "Special efforts must be made."}
{"answers": {"text": ["existing level of inequality", "existing level of inequality", "existing level of inequality"], "answer_start": [459, 459, 459]}, "prediction_text": "Growth of inequality"}
{"answers": {"text": ["reduction", "halve poverty", "halve poverty"], "answer_start": [726, 616, 616]}, "prediction_text": "60 years"}
{"answers": {"text": ["the United Nations", "United Nations", "United Nations"], "answer_start": [778, 782, 782]}, "prediction_text": "United Nations"}
{"answers": {"text": ["reducing poverty", "reducing poverty", "reducing poverty"], "answer_start": [884, 884, 884]}, "prediction_text": "Poverty reduction"}
{"answers": {"text": ["much land and housing", "land and housing", "land and housing"], "answer_start": [38, 43, 43]}, "prediction_text": "Land and housing"}
{"answers": {"text": ["through various associations and other arrangements", "through various associations and other arrangements", "through various associations"], "answer_start": [188, 188, 188]}, "prediction_text": "Through associations and other arrangements."}
{"answers": {"text": ["extra-legal", "extra-legal", "extra-legal"], "answer_start": [253, 253, 253]}, "prediction_text": "Extra-legal ownership"}
{"answers": {"text": ["200", "200", "200"], "answer_start": [383, 383, 383]}, "prediction_text": "Up to 14 years"}
{"answers": {"text": ["government land", "government land", "government land"], "answer_start": [424, 424, 424]}, "prediction_text": "Expensive bureaucratic red tape"}
{"answers": {"text": ["a shortage of affordable housing", "affordable housing", "affordable housing"], "answer_start": [83, 97, 97]}, "prediction_text": "Income inequality"}
{"answers": {"text": ["quality rental units", "quality rental units", "quality rental units"], "answer_start": [236, 236, 236]}, "prediction_text": "Quality rental units"}
{"answers": {"text": ["demand for higher quality housing increased", "demand for higher quality housing increased", "demand for higher quality housing increased"], "answer_start": [274, 274, 274]}, "prediction_text": "Income inequality"}
{"answers": {"text": ["residents willing to pay higher market rate for housing", "gentrification of older neighbourhoods", "new residents willing to pay higher market rate"], "answer_start": [470, 344, 466]}, "prediction_text": "Gentrification of older neighbourhoods"}
{"answers": {"text": ["ad valorem property tax policy", "ad valorem property tax policy", "property tax policy"], "answer_start": [583, 583, 594]}, "prediction_text": "Ad valorem property tax policy"}
{"answers": {"text": ["by everyone", "by everyone"], "answer_start": [61, 61]}, "prediction_text": "By everyone"}
{"answers": {"text": ["their finances", "finances", "finances"], "answer_start": [323, 329, 329]}, "prediction_text": "Their finances"}
{"answers": {"text": ["aspirational consumption", "aspirational consumption", "aspirational consumption"], "answer_start": [349, 349, 349]}, "prediction_text": "aspirational consumption"}
{"answers": {"text": ["taking on debt", "taking on debt", "taking on debt"], "answer_start": [555, 555, 555]}, "prediction_text": "Taking on debt"}
{"answers": {"text": ["economic instability", "greater inequality and potential economic instability", "greater inequality and potential economic instability"], "answer_start": [629, 596, 596]}, "prediction_text": "Economic instability"}
{"answers": {"text": ["created", "created", "created", "created"], "answer_start": [69, 69, 69, 69]}, "prediction_text": "More environmental degradation"}
{"answers": {"text": ["emissions per person", "this multiplier", "environmental degradation", "environmental degradation"], "answer_start": [709, 800, 855, 855]}, "prediction_text": "Environmental degradation would be lower."}
{"answers": {"text": ["environmental degradation", "this as well", "environmental degradation", "environmental degradation"], "answer_start": [650, 973, 855, 855]}, "prediction_text": "Environmental degradation"}
{"answers": {"text": ["If (as WWF argued), population levels would start to drop to a sustainable level", "If (as WWF argued), population levels would start to drop to a sustainable level", "population levels would start to drop to a sustainable level", "population levels would start to drop to a sustainable level"], "answer_start": [987, 987, 1007, 1007]}, "prediction_text": "Eliminate population levels."}
{"answers": {"text": ["private ownership of the means of production", "private ownership of the means of production", "private ownership of the means of production"], "answer_start": [59, 59, 59]}, "prediction_text": "Private ownership of the means of production by a class of owners."}
{"answers": {"text": ["a small portion of the population lives off unearned property income", "small portion of the population lives off unearned property income", "small portion of the population lives off unearned property income"], "answer_start": [153, 155, 155]}, "prediction_text": "A small portion of the population living off unearned property income."}
{"answers": {"text": ["wage or salary", "wage or salary", "wage or salary"], "answer_start": [401, 401, 401]}, "prediction_text": "Income in the form of a wage or salary."}
{"answers": {"text": ["socially", "socially", "socially"], "answer_start": [509, 509, 509]}, "prediction_text": "Socialized so income differentials reflect individual contributions."}
{"answers": {"text": ["reflective", "reflective", "reflective of individual contributions"], "answer_start": [562, 562, 562]}, "prediction_text": "Reflective of individual contributions"}
{"answers": {"text": ["Robert Nozick", "Robert Nozick", "Robert Nozick"], "answer_start": [0, 0, 0]}, "prediction_text": "Robert Nozick"}
{"answers": {"text": ["taxation", "taxation", "taxation"], "answer_start": [91, 91, 91]}, "prediction_text": "Taxation"}
{"answers": {"text": ["force", "force"], "answer_start": [184, 184]}, "prediction_text": "Force"}
{"answers": {"text": ["forceful taking of property", "forceful taking of property", "forceful taking of property"], "answer_start": [276, 276, 276]}, "prediction_text": "Force created inequalities."}
{"answers": {"text": ["when they improve society as a whole", "when they improve society as a whole", "when they improve society as a whole"], "answer_start": [548, 548, 548]}, "prediction_text": "When improvements improve society."}
{"answers": {"text": ["capability deprivation", "capability deprivation", "\u201ccapability deprivation\u201d"], "answer_start": [129, 129, 128]}, "prediction_text": "Capability deprivation"}
{"answers": {"text": ["the end itself", "the end itself", "the end itself"], "answer_start": [300, 300, 300]}, "prediction_text": "The end itself."}
{"answers": {"text": ["to \u201cwid[en] people\u2019s choices and the level of their achieved well-being\u201d", "wid[en] people\u2019s choices and the level of their achieved well-being", "\u201cwid[en] people\u2019s choices and the level of their achieved well-being\u201d"], "answer_start": [328, 332, 331]}, "prediction_text": "wid[en] people's choices and the level of their achieved well-being."}
{"answers": {"text": ["through increasing functionings", "increasing functionings (the things a person values doing), capabilities (the freedom to enjoy functionings) and agency (the ability to pursue valued goals)", "through increasing functionings"], "answer_start": [401, 409, 401]}, "prediction_text": "Increase functionings, capabilities, and agency."}
{"answers": {"text": ["the ability to pursue valued goals", "the ability to pursue valued goals"], "answer_start": [530, 530]}, "prediction_text": "Freedom to pursue valued goals."}
{"answers": {"text": ["deprived of earning as much", "deprived of earning as much income", "deprived of earning as much income as they would otherwise"], "answer_start": [63, 63, 63]}, "prediction_text": "They are deprived of earning as much income as they would otherwise."}
{"answers": {"text": ["earn as much as a healthy young man", "earn as much as a healthy young man", "earn as much as a healthy young man"], "answer_start": [146, 146, 146]}, "prediction_text": "Cannot earn as much as a healthy young man."}
{"answers": {"text": ["gender roles and customs", "gender roles and customs", "gender roles and customs"], "answer_start": [183, 183, 183]}, "prediction_text": "Gender roles and customs."}
{"answers": {"text": ["for fear of their lives", "fear of their lives", "fear of their lives"], "answer_start": [427, 431, 431]}, "prediction_text": "Fear of their lives."}
{"answers": {"text": ["a better relevant income.", "better relevant income", "a better relevant income"], "answer_start": [871, 873, 871]}, "prediction_text": "A better relevant income."}
{"answers": {"text": ["BBC", "BBC", "BBC"], "answer_start": [77, 77, 77]}, "prediction_text": "BBC"}
{"answers": {"text": ["1963", "1963", "1963"], "answer_start": [87, 87, 87]}, "prediction_text": "1963"}
{"answers": {"text": ["TARDIS", "TARDIS", "TARDIS"], "answer_start": [233, 233, 233]}, "prediction_text": "TARDIS"}
{"answers": {"text": ["a blue British police box", "a blue British police box", "blue British police box"], "answer_start": [304, 304, 306]}, "prediction_text": "Blue British police box"}
{"answers": {"text": ["science-fiction", "science-fiction", "science-fiction"], "answer_start": [24, 24, 24]}, "prediction_text": "Science-fiction television"}
{"answers": {"text": ["1963 to 1989", "1963 to 1989", "1963 to 1989"], "answer_start": [265, 265, 265]}, "prediction_text": "1963 to 1989."}
{"answers": {"text": ["Russell T Davies", "2005", "Russell T Davies"], "answer_start": [447, 439, 447]}, "prediction_text": "Russell T Davies"}
{"answers": {"text": ["K-9 and Company", "K-9 and Company", "K-9 and Company"], "answer_start": [908, 908, 908]}, "prediction_text": "K-9 and Company"}
{"answers": {"text": ["BBC Wales", "Russell T Davies", "BBC Wales"], "answer_start": [562, 447, 562]}, "prediction_text": "Russell T Davies"}
{"answers": {"text": ["Christopher Eccleston", "Christopher Eccleston", "Christopher Eccleston"], "answer_start": [630, 630, 630]}, "prediction_text": "Christopher Eccleston"}
{"answers": {"text": ["Twelve", "Twelve", "Twelve"], "answer_start": [0, 0, 0]}, "prediction_text": "Twelve actors"}
{"answers": {"text": ["Peter Capaldi", "Peter Capaldi", "Peter Capaldi"], "answer_start": [738, 738, 738]}, "prediction_text": "Peter Capaldi"}
{"answers": {"text": ["The Time of the Doctor", "the 2013 Christmas special \"The Time of the Doctor\"", "\"The Time of the Doctor\""], "answer_start": [824, 796, 823]}, "prediction_text": "\"The Time of the Doctor\""}
{"answers": {"text": ["after sustaining an injury", "after sustaining an injury which would be fatal to most other species", "after sustaining an injury"], "answer_start": [433, 433, 433]}, "prediction_text": "After sustaining an injury"}
{"answers": {"text": ["new personality", "new personality", "new personality"], "answer_start": [403, 403, 403]}, "prediction_text": "Different personalities and body parts change."}
{"answers": {"text": ["Gallifrey", "Gallifrey", "Gallifrey"], "answer_start": [94, 94, 94]}, "prediction_text": "Gallifrey"}
{"answers": {"text": ["Mark I Type 40 TARDIS", "Mark I Type 40 TARDIS", "Mark I Type 40 TARDIS"], "answer_start": [182, 182, 182]}, "prediction_text": "Time and Relative Dimension in Space TARDIS"}
{"answers": {"text": ["Time and Relative Dimension in Space", "Time and Relative Dimension in Space", "Time and Relative Dimension in Space"], "answer_start": [207, 207, 207]}, "prediction_text": "Time and Relative Dimension"}
{"answers": {"text": ["chameleon circuit", "chameleon circuit", "chameleon circuit"], "answer_start": [328, 328, 328]}, "prediction_text": "Chameleon circuit"}
{"answers": {"text": ["due to a malfunction in the chameleon circuit", "malfunction in the chameleon circuit", "a malfunction in the chameleon circuit"], "answer_start": [511, 520, 518]}, "prediction_text": "Chameleon circuit malfunction"}
{"answers": {"text": ["rarely", "often", "rarely"], "answer_start": [11, 36, 11]}, "prediction_text": "Occasionally"}
{"answers": {"text": ["the Master", "the Master", "the Master"], "answer_start": [651, 651, 651]}, "prediction_text": "The Master"}
{"answers": {"text": ["regenerate", "regenerate", "regenerate"], "answer_start": [450, 450, 450]}, "prediction_text": "Reverses appearance and personality."}
{"answers": {"text": ["humans", "companions", "usually humans"], "answer_start": [126, 61, 118]}, "prediction_text": "Humans"}
{"answers": {"text": ["Time Lord", "Time", "Time Lord"], "answer_start": [409, 409, 409]}, "prediction_text": "Time Lord"}
{"answers": {"text": ["23 November 1963", "Saturday, 23 November 1963", "23 November 1963"], "answer_start": [126, 116, 126]}, "prediction_text": "November 23, 1963."}
{"answers": {"text": ["The Daleks (a.k.a. The Mutants)", "Daleks", "eponymous aliens"], "answer_start": [1863, 1867, 1922]}, "prediction_text": "The Daleks (the first Doctor Who serial)"}
{"answers": {"text": ["the programme was not permitted to contain any \"bug-eyed monsters\"", "only had the Dalek serial to go", "the programme was not permitted to contain any \"bug-eyed monsters\""], "answer_start": [1270, 1611, 1270]}, "prediction_text": "Not permitted to contain \"bug-eyed monsters\""}
{"answers": {"text": ["Terry Nation", "Terry Nation", "Terry Nation"], "answer_start": [964, 964, 964]}, "prediction_text": "Terry Nation"}
{"answers": {"text": ["25 minutes of transmission length", "25 minutes", "25 minutes"], "answer_start": [198, 198, 198]}, "prediction_text": "25 minutes"}
{"answers": {"text": ["26", "26", "26"], "answer_start": [71, 71, 71]}, "prediction_text": "26 seasons"}
{"answers": {"text": ["Jonathan Powell", "Jonathan Powell", "Jonathan Powell"], "answer_start": [250, 250, 250]}, "prediction_text": "Jonathan Powell"}
{"answers": {"text": ["Doctor Who: More Than 30 Years in the TARDIS", "Doctor Who: More Than 30 Years in the TARDIS", "Doctor Who: More Than 30 Years in the TARDIS"], "answer_start": [358, 358, 358]}, "prediction_text": "Doctor Who: More Than 30 Years in the TARDIS"}
{"answers": {"text": ["the series would return", "the series would return", "the series would return"], "answer_start": [580, 580, 580]}, "prediction_text": "It was cancelled."}
{"answers": {"text": ["BBC 1", "BBC 1", "BBC 1"], "answer_start": [96, 96, 96]}, "prediction_text": "BBC 1"}
{"answers": {"text": ["relaunch the show", "relaunch the show", "relaunch the show"], "answer_start": [97, 97, 97]}, "prediction_text": "Re-launch the show"}
{"answers": {"text": ["Philip Segal", "Philip Segal", "Philip Segal"], "answer_start": [116, 116, 116]}, "prediction_text": "Philip Segal"}
{"answers": {"text": ["the Fox Network", "Fox Network", "the Fox Network"], "answer_start": [418, 422, 418]}, "prediction_text": "Fox Network"}
{"answers": {"text": ["9.1 million", "9.1 million", "9.1 million"], "answer_start": [570, 570, 570]}, "prediction_text": "9.1 million"}
{"answers": {"text": ["the United States", "United States", "the United States"], "answer_start": [610, 614, 610]}, "prediction_text": "United States"}
{"answers": {"text": ["Rose", "Rose", "Rose"], "answer_start": [46, 46, 46]}, "prediction_text": "\"Rose\""}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [75, 75, 75]}, "prediction_text": "2005"}
{"answers": {"text": ["2009", "2009", "2009"], "answer_start": [230, 230, 230]}, "prediction_text": "2009"}
{"answers": {"text": ["Chris Chibnall", "Chris Chibnall", "Chris Chibnall"], "answer_start": [481, 481, 481]}, "prediction_text": "Chris Chibnall"}
{"answers": {"text": ["Christmas Day specials", "Christmas Day specials", "Christmas Day specials"], "answer_start": [155, 155, 155]}, "prediction_text": "Christmas specials"}
{"answers": {"text": ["1963\u20131989", "1963\u20131989", "1963\u20131989"], "answer_start": [77, 77, 77]}, "prediction_text": "1963\u20131989"}
{"answers": {"text": ["The 2005 version", "The 2005 version of Doctor Who", "The 2005 version of Doctor Who"], "answer_start": [0, 0, 0]}, "prediction_text": "Mission Impossible"}
{"answers": {"text": ["1996", "1996", "1996"], "answer_start": [110, 110, 110]}, "prediction_text": "1996"}
{"answers": {"text": ["Battlestar Galactica and Bionic Woman", "Battlestar Galactica and Bionic Woman", "Battlestar Galactica and Bionic Woman"], "answer_start": [280, 280, 280]}, "prediction_text": "Mission Impossible, Battlestar Galactica, Bionic Woman."}
{"answers": {"text": ["Mission Impossible,", "Mission Impossible", "Mission Impossible"], "answer_start": [169, 169, 169]}, "prediction_text": "Mission Impossible, Battlestar Galactica, Bionic Woman, Star Trek: The Next Generation, spin-offs."}
{"answers": {"text": ["30 November 1963", "30 November 1963", "30 November 1963"], "answer_start": [464, 464, 464]}, "prediction_text": "30 November 1963"}
{"answers": {"text": ["eighty seconds", "ten minutes", "ten minutes"], "answer_start": [236, 78, 78]}, "prediction_text": "Eighteen seconds"}
{"answers": {"text": ["ten minutes", "eighty seconds", "ten minutes"], "answer_start": [78, 236, 78]}, "prediction_text": "Eighteen seconds"}
{"answers": {"text": ["the assassination of US President John F. Kennedy", "assassination of US President John F. Kennedy", "the assassination of US President John F. Kennedy"], "answer_start": [123, 127, 123]}, "prediction_text": "Assassination of US President John F. Kennedy"}
{"answers": {"text": ["a series of power blackouts across the country", "power blackouts", "a series of power blackouts across the country"], "answer_start": [385, 397, 385]}, "prediction_text": "Power blackouts"}
{"answers": {"text": ["Hiding behind (or 'watching from behind') the sofa", "Hiding behind (or 'watching from behind') the sofa", "\"Hiding behind (or 'watching from behind') the sofa\""], "answer_start": [12, 12, 11]}, "prediction_text": "\"Hiding behind (or 'watching from behind') the sofa\""}
{"answers": {"text": ["the Museum of the Moving Image", "Museum of the Moving Image", "the Museum of the Moving Image"], "answer_start": [375, 379, 375]}, "prediction_text": "Museum of the Moving Image"}
{"answers": {"text": ["Behind the Sofa", "Behind the Sofa", "Behind the Sofa"], "answer_start": [466, 466, 466]}, "prediction_text": "\"Behind the Sofa\""}
{"answers": {"text": ["scariest TV show of all time", "scariest TV show of all time", "scariest TV show of all time"], "answer_start": [768, 768, 768]}, "prediction_text": "\"Scariest TV show of all time\""}
{"answers": {"text": ["Digital Spy", "Digital Spy", "Digital Spy"], "answer_start": [733, 733, 733]}, "prediction_text": "Digital Spy"}
{"answers": {"text": ["Doctor Who", "Doctor Who", "Doctor Who"], "answer_start": [247, 247, 247]}, "prediction_text": "Doctor Who"}
{"answers": {"text": ["3%", "3%", "3%"], "answer_start": [368, 368, 368]}, "prediction_text": "3%"}
{"answers": {"text": ["Philip Howard", "Philip Howard", "Philip Howard"], "answer_start": [531, 531, 531]}, "prediction_text": "Philip Howard"}
{"answers": {"text": ["Monopoly", "Monopoly", "Monopoly"], "answer_start": [795, 795, 795]}, "prediction_text": "Monopoly"}
{"answers": {"text": ["The Times newspaper", "The Times", "The Times newspaper"], "answer_start": [499, 499, 499]}, "prediction_text": "The Times"}
{"answers": {"text": ["the TARDIS", "the TARDIS", "the TARDIS"], "answer_start": [13, 13, 13]}, "prediction_text": "TARDIS image"}
{"answers": {"text": ["blue police box", "a police box", "blue police box"], "answer_start": [310, 217, 310]}, "prediction_text": "Blue police box"}
{"answers": {"text": ["time machine", "time machine", "time machine"], "answer_start": [235, 235, 235]}, "prediction_text": "Time machine"}
{"answers": {"text": ["the Metropolitan Police Authority", "Metropolitan Police Authority", "the Metropolitan Police Authority"], "answer_start": [387, 391, 387]}, "prediction_text": "The Metropolitan Police Authority"}
{"answers": {"text": ["2002", "2002", "2002"], "answer_start": [472, 472, 472]}, "prediction_text": "2002"}
{"answers": {"text": ["26", "26", "26"], "answer_start": [30, 30, 30]}, "prediction_text": "26 seasons"}
{"answers": {"text": ["6 December 1989", "6 December 1989", "6 December 1989"], "answer_start": [81, 81, 81]}, "prediction_text": "6 December 1989"}
{"answers": {"text": ["12", "12", "12"], "answer_start": [327, 327, 327]}, "prediction_text": "12 episodes"}
{"answers": {"text": ["The Master", "The Master", "The Master"], "answer_start": [823, 823, 823]}, "prediction_text": "The Master Plan"}
{"answers": {"text": ["Black Guardian Trilogy", "Black Guardian Trilogy", "Black Guardian Trilogy"], "answer_start": [952, 952, 952]}, "prediction_text": "Black Guardian Trilogy"}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [34, 34, 34]}, "prediction_text": "2005"}
{"answers": {"text": ["60 minutes", "45-minute", "60 minutes"], "answer_start": [126, 90, 126]}, "prediction_text": "60 minutes"}
{"answers": {"text": ["Christmas Day", "Christmas Day", "Christmas Day"], "answer_start": [222, 222, 222]}, "prediction_text": "Christmas Day"}
{"answers": {"text": ["Journey's End", "Journey's End", "Journey's End"], "answer_start": [574, 574, 574]}, "prediction_text": "\"Journey's End\""}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [628, 628, 628]}, "prediction_text": "2010"}
{"answers": {"text": ["826", "826", "826"], "answer_start": [0, 0, 0]}, "prediction_text": "826 episodes"}
{"answers": {"text": ["25-minute", "25-minute", "25-minute"], "answer_start": [75, 75, 75]}, "prediction_text": "25-minute episodes"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [321, 321, 321]}, "prediction_text": "Four additional specials"}
{"answers": {"text": ["72 minutes", "72 minutes", "72 minutes"], "answer_start": [384, 384, 384]}, "prediction_text": "60 minutes"}
{"answers": {"text": ["2009", "2009", "2009"], "answer_start": [977, 977, 977]}, "prediction_text": "2009"}
{"answers": {"text": ["William Hartnell and Patrick Troughton", "William Hartnell and Patrick Troughton", "William Hartnell and Patrick Troughton"], "answer_start": [340, 340, 340]}, "prediction_text": "William Hartnell and Patrick Troughton"}
{"answers": {"text": ["97", "79", "97"], "answer_start": [388, 539, 388]}, "prediction_text": "79 episodes"}
{"answers": {"text": ["3, 4, & 5", "seasons 3, 4, & 5", "3, 4, & 5"], "answer_start": [517, 509, 517]}, "prediction_text": "Season 3, 4, & 5"}
{"answers": {"text": ["1978", "1978", "1978"], "answer_start": [645, 645, 645]}, "prediction_text": "1978"}
{"answers": {"text": ["Between about 1964 and 1973", "the first six years", "Between about 1964 and 1973"], "answer_start": [0, 423, 0]}, "prediction_text": "1972, 1973"}
{"answers": {"text": ["bought prints for broadcast", "bought prints for broadcast", "bought prints for broadcast"], "answer_start": [85, 85, 85]}, "prediction_text": "By private individuals"}
{"answers": {"text": ["fans", "fans", "fans"], "answer_start": [226, 226, 226]}, "prediction_text": "Fans"}
{"answers": {"text": ["Mission to the Unknown", "Mission to the Unknown", "Mission to the Unknown"], "answer_start": [547, 547, 547]}, "prediction_text": "Mission to the Unknown"}
{"answers": {"text": ["8 mm cine film", "8 mm cine film and clips that were shown on other programmes", "8 mm cine film"], "answer_start": [316, 316, 316]}, "prediction_text": "8 mm cine film"}
{"answers": {"text": ["home viewers who made tape recordings of the show", "home viewers who made tape recordings of the show", "home viewers who made tape recordings"], "answer_start": [432, 432, 432]}, "prediction_text": "Home viewers made tape recordings"}
{"answers": {"text": ["the BBC", "BBC", "BBC"], "answer_start": [54, 58, 58]}, "prediction_text": "BBC (BBC)"}
{"answers": {"text": ["Cosgrove Hall", "Cosgrove Hall", "Cosgrove Hall"], "answer_start": [163, 163, 163]}, "prediction_text": "Cosgrove Hall"}
{"answers": {"text": ["1968", "1968", "1968"], "answer_start": [238, 238, 238]}, "prediction_text": "1968"}
{"answers": {"text": ["Theta-Sigma", "Theta-Sigma", "Theta-Sigma"], "answer_start": [461, 461, 461]}, "prediction_text": "Big Finish"}
{"answers": {"text": ["November 2006", "November 2006", "2006"], "answer_start": [367, 367, 376]}, "prediction_text": "November 2006"}
{"answers": {"text": ["regeneration", "regeneration", "renewal"], "answer_start": [36, 186, 341]}, "prediction_text": "Regeneration"}
{"answers": {"text": ["the Doctor's third on-screen regeneration", "the Doctor's third on-screen regeneration", "the Doctor's third on-screen regeneration"], "answer_start": [237, 237, 237]}, "prediction_text": "Third on-screen regeneration"}
{"answers": {"text": ["William Hartnell's poor health", "to permit the recasting of the main character", "William Hartnell's poor health"], "answer_start": [137, 49, 137]}, "prediction_text": "William Hartnell's poor health"}
{"answers": {"text": ["renewal", "renewal", "renewal"], "answer_start": [341, 341, 341]}, "prediction_text": "Regeneration"}
{"answers": {"text": ["change of appearance", "change of appearance", "change of appearance"], "answer_start": [386, 386, 386]}, "prediction_text": "\"Change of appearance\""}
{"answers": {"text": ["12", "12", "12"], "answer_start": [131, 131, 131]}, "prediction_text": "13 incarnations"}
{"answers": {"text": ["13", "13", "13"], "answer_start": [156, 156, 156]}, "prediction_text": "13 incarnations"}
{"answers": {"text": ["The Time of the Doctor", "The Time of the Doctor", "The Time of the Doctor"], "answer_start": [408, 408, 408]}, "prediction_text": "\"The Time of the Doctor\""}
{"answers": {"text": ["The Deadly Assassin and Mawdryn Undead", "Deadly Assassin and Mawdryn Undead", "Deadly Assassin and Mawdryn Undead"], "answer_start": [12, 16, 16]}, "prediction_text": "The Deadly Assassin and Mawdryn Undead"}
{"answers": {"text": ["1996", "1996", "1996"], "answer_start": [59, 59, 59]}, "prediction_text": "1996"}
{"answers": {"text": ["John Hurt", "John Hurt", "John Hurt"], "answer_start": [138, 138, 138]}, "prediction_text": "John Hurt"}
{"answers": {"text": ["The Day of the Doctor", "The Day of the Doctor", "The Day of the Doctor"], "answer_start": [288, 288, 288]}, "prediction_text": "The Day of the Doctor"}
{"answers": {"text": ["Michael Jayston", "Michael Jayston", "Michael Jayston"], "answer_start": [659, 659, 659]}, "prediction_text": "John Hurt"}
{"answers": {"text": ["The Trial of a Time Lord", "The Trial of a Time Lord", "The Trial of a Time Lord"], "answer_start": [627, 627, 627]}, "prediction_text": "The Trial of a Time Lord"}
{"answers": {"text": ["McGann and Eccleston's Doctors", "McGann and Eccleston", "McGann and Eccleston's"], "answer_start": [447, 447, 447]}, "prediction_text": "McGann and Eccleston"}
{"answers": {"text": ["the War Doctor", "an unknown incarnation of himself", "the War Doctor"], "answer_start": [1800, 1692, 1800]}, "prediction_text": "The Doctor (in \"The Name of the Doctor\")"}
{"answers": {"text": ["The Three Doctors", "The Three Doctors", "The Three Doctors"], "answer_start": [117, 117, 117]}, "prediction_text": "The Three Doctors"}
{"answers": {"text": ["Peter Davison", "Peter Davison", "Peter Davison"], "answer_start": [531, 531, 531]}, "prediction_text": "Patrick Troughton"}
{"answers": {"text": ["The Space Museum", "The Space Museum", "The Space Museum"], "answer_start": [1058, 1058, 1058]}, "prediction_text": "\"The Almost People\""}
{"answers": {"text": ["The Day of the Doctor", "The Day of the Doctor", "The Day of the Doctor"], "answer_start": [685, 685, 685]}, "prediction_text": "\"The Day of the Doctor\""}
{"answers": {"text": ["Peter Davison, Colin Baker and Sylvester McCoy", "Peter Davison, Colin Baker and Sylvester McCoy", "Peter Davison, Colin Baker and Sylvester McCoy"], "answer_start": [109, 109, 109]}, "prediction_text": "Peter Davison, Colin Baker, Sylvester McCoy"}
{"answers": {"text": ["Zagreus", "Zagreus", "Zagreus"], "answer_start": [287, 287, 287]}, "prediction_text": "Zagreus"}
{"answers": {"text": ["Peter Davison, Colin Baker, Sylvester McCoy and Paul McGann", "Peter Davison, Colin Baker, Sylvester McCoy and Paul McGann", "Peter Davison, Colin Baker, Sylvester McCoy and Paul McGann"], "answer_start": [544, 544, 544]}, "prediction_text": "Peter Davison, Colin Baker, Sylvester McCoy"}
{"answers": {"text": ["Colin Baker and Sylvester McCoy", "Colin Baker and Sylvester McCoy", "Colin Baker and Sylvester McCoy"], "answer_start": [444, 444, 444]}, "prediction_text": "Colin Baker, Colin Baker, Sylvester McCoy, Paul McGann."}
{"answers": {"text": ["2003", "2003", "2003"], "answer_start": [259, 259, 259]}, "prediction_text": "2003"}
{"answers": {"text": ["The Time of the Doctor", "The Time of the Doctor", "The Time of the Doctor"], "answer_start": [904, 904, 904]}, "prediction_text": "\"The Time of the Doctor\""}
{"answers": {"text": ["The Brain of Morbius", "The Five Doctors", "The Brain of Morbius"], "answer_start": [128, 595, 128]}, "prediction_text": "\"The Time of the Doctor\""}
{"answers": {"text": ["Mawdryn Undead", "Mawdryn Undead", "Mawdryn Undead"], "answer_start": [420, 420, 420]}, "prediction_text": "\"The Five Doctors\""}
{"answers": {"text": ["The Lodger", "The Lodger", "The Time of the Doctor"], "answer_start": [870, 870, 904]}, "prediction_text": "\"The Time of the Doctor\""}
{"answers": {"text": ["1983", "1983", "1983"], "answer_start": [563, 563, 563]}, "prediction_text": "1983"}
{"answers": {"text": ["An Unearthly Child", "An Unearthly Child", "An Unearthly Child"], "answer_start": [30, 30, 30]}, "prediction_text": "An Unearthly Child"}
{"answers": {"text": ["Susan Foreman", "Susan Foreman", "Susan Foreman"], "answer_start": [93, 93, 93]}, "prediction_text": "Susan Foreman"}
{"answers": {"text": ["2005", "2005"], "answer_start": [351, 351]}, "prediction_text": "2005"}
{"answers": {"text": ["destroyed", "destroyed", "destroyed"], "answer_start": [472, 472, 472]}, "prediction_text": "Destroyed"}
{"answers": {"text": ["Smith and Jones", "Smith and Jones", "Smith and Jones"], "answer_start": [686, 686, 686]}, "prediction_text": "\"Smith and Jones\""}
{"answers": {"text": ["a human", "a human", "usually human, or humanoid aliens"], "answer_start": [33, 33, 1257]}, "prediction_text": "Human or humanoid aliens."}
{"answers": {"text": ["The Deadly Assassin", "The Deadly Assassin", "The Deadly Assassin"], "answer_start": [649, 649, 649]}, "prediction_text": "The Deadly Assassin"}
{"answers": {"text": ["his granddaughter Susan Foreman", "Susan Foreman", "his granddaughter"], "answer_start": [255, 273, 255]}, "prediction_text": "Romana (Mary Tamm and Lalla Ward)"}
{"answers": {"text": ["teachers", "to remind the Doctor of his \"moral duty\"", "teachers"], "answer_start": [313, 163, 313]}, "prediction_text": "Humanoid aliens"}
{"answers": {"text": ["Romana", "Romana", "Sarah Jane Smith"], "answer_start": [722, 722, 770]}, "prediction_text": "Romana"}
{"answers": {"text": ["female", "female", "female"], "answer_start": [68, 68, 68]}, "prediction_text": "Female"}
{"answers": {"text": ["Mickey Smith (Noel Clarke) and Jack Harkness (John Barrowman)", "Mickey Smith (Noel Clarke) and Jack Harkness (John Barrowman)", "Mickey Smith (Noel Clarke) and Jack Harkness (John Barrowman)"], "answer_start": [444, 444, 444]}, "prediction_text": "Rose Tyler, Martha Jones, Donna Noble, Mickey Smith, Jack Harkness, and Jack Harkness."}
{"answers": {"text": ["The Eleventh", "The Eleventh Doctor", "The Eleventh Doctor"], "answer_start": [548, 548, 548]}, "prediction_text": "Amy Pond"}
{"answers": {"text": ["Pearl Mackie as Bill", "Pearl Mackie", "Pearl Mackie as Bill"], "answer_start": [832, 832, 832]}, "prediction_text": "Pearl Mackie"}
{"answers": {"text": ["Catherine Tate", "Catherine Tate", "Catherine Tate"], "answer_start": [423, 423, 423]}, "prediction_text": "Mickey Smith"}
{"answers": {"text": ["Russell T Davies", "Russell T Davies", "Russell T Davies"], "answer_start": [49, 49, 49]}, "prediction_text": "Russell T Davies"}
{"answers": {"text": ["series 1", "series 1", "series 1,"], "answer_start": [206, 206, 206]}, "prediction_text": "Series 1"}
{"answers": {"text": ["Cybermen", "Cybermen", "Cybermen"], "answer_start": [216, 216, 216]}, "prediction_text": "Daleks and Autons."}
{"answers": {"text": ["3", "series 3", "3"], "answer_start": [273, 266, 273]}, "prediction_text": "Series 1"}
{"answers": {"text": ["Zygons", "Zygons", "Zygons"], "answer_start": [550, 550, 550]}, "prediction_text": "Zygons"}
{"answers": {"text": ["The Dalek race", "The Dalek race", "The Dalek race"], "answer_start": [0, 0, 0]}, "prediction_text": "The Dalek race"}
{"answers": {"text": ["Skaro", "Skaro", "Skaro"], "answer_start": [146, 146, 146]}, "prediction_text": "Skaro"}
{"answers": {"text": ["to \"exterminate\" all non-Dalek beings", "to \"exterminate\" all non-Dalek beings", "to \"exterminate\" all non-Dalek beings"], "answer_start": [674, 674, 674]}, "prediction_text": "Exterminate all non-Dalek beings."}
{"answers": {"text": ["Davros", "Davros", "Davros"], "answer_start": [178, 178, 178]}, "prediction_text": "Davros"}
{"answers": {"text": ["their eyestalk", "their eyestalk", "their eyestalk"], "answer_start": [466, 466, 466]}, "prediction_text": "Their eyestalk"}
{"answers": {"text": ["The Master", "The Master", "The Master"], "answer_start": [0, 0, 0]}, "prediction_text": "The Master"}
{"answers": {"text": ["Time Lord", "Time Lord", "Time Lord"], "answer_start": [49, 49, 49]}, "prediction_text": "Doctor Who"}
{"answers": {"text": ["Eric Roberts", "Eric Roberts", "Eric Roberts"], "answer_start": [690, 690, 690]}, "prediction_text": "Eric Roberts"}
{"answers": {"text": ["Professor Moriarty to the Doctor's Sherlock Holmes", "Professor Moriarty to the Doctor's Sherlock Holmes", "Professor Moriarty to the Doctor's Sherlock Holmes"], "answer_start": [107, 107, 107]}, "prediction_text": "\"Professor Moriarty to the Doctor's Sherlock Holmes\""}
{"answers": {"text": ["Roger Delgado", "Roger Delgado", "Roger Delgado"], "answer_start": [359, 359, 359]}, "prediction_text": "Roger Delgado"}
{"answers": {"text": ["Derek Jacobi", "Derek Jacobi", "John Simm"], "answer_start": [38, 38, 169]}, "prediction_text": "John Simm"}
{"answers": {"text": ["Utopia", "Utopia", "Utopia"], "answer_start": [113, 113, 113]}, "prediction_text": "\"Utopia\""}
{"answers": {"text": ["2014", "Dark Water", "2014"], "answer_start": [264, 278, 264]}, "prediction_text": "2007"}
{"answers": {"text": ["Missy", "Missy", "Missy"], "answer_start": [393, 393, 393]}, "prediction_text": "\"Missy\""}
{"answers": {"text": ["Michelle Gomez", "Michelle Gomez", "Michelle Gomez"], "answer_start": [489, 489, 489]}, "prediction_text": "Michelle Gomez"}
{"answers": {"text": ["Ron Grainer", "Ron Grainer", "Ron Grainer"], "answer_start": [35, 35, 35]}, "prediction_text": "Ron Grainer"}
{"answers": {"text": ["the BBC Radiophonic Workshop", "BBC Radiophonic Workshop", "the BBC Radiophonic Workshop"], "answer_start": [83, 87, 83]}, "prediction_text": "BBC Radiophonic Workshop"}
{"answers": {"text": ["musique concr\u00e8te", "musique concr\u00e8te techniques", "musique concr\u00e8te techniques"], "answer_start": [184, 184, 184]}, "prediction_text": "Musique concr\u00e8te techniques"}
{"answers": {"text": ["17", "season 17", "17"], "answer_start": [415, 408, 415]}, "prediction_text": "1979\u201380"}
{"answers": {"text": ["Did I write that?", "Did I write that?", "Did I write that?"], "answer_start": [1054, 1054, 1054]}, "prediction_text": "\"Did I write that?\""}
{"answers": {"text": ["Peter Howell", "Peter Howell", "Peter Howell"], "answer_start": [40, 40, 40]}, "prediction_text": "Peter Howell"}
{"answers": {"text": ["Dominic Glynn", "Dominic Glynn", "Dominic Glynn's"], "answer_start": [105, 105, 105]}, "prediction_text": "Dominic Glynn"}
{"answers": {"text": ["Seventh", "the Seventh Doctor", "the Seventh"], "answer_start": [258, 254, 254]}, "prediction_text": "Seventh Doctor"}
{"answers": {"text": ["Murray Gold", "Murray Gold", "Murray Gold"], "answer_start": [502, 502, 502]}, "prediction_text": "Murray Gold"}
{"answers": {"text": ["The Christmas Invasion", "The Christmas Invasion", "The Christmas Invasion"], "answer_start": [647, 647, 647]}, "prediction_text": "\"The Christmas Invasion\""}
{"answers": {"text": ["Voyage of the Damned", "Voyage of the Damned", "Voyage of the Damned"], "answer_start": [107, 107, 107]}, "prediction_text": "\"Voyage of the Damned\""}
{"answers": {"text": ["Classic FM's Hall of Fame", "Classic FM", "Classic FM's Hall of Fame"], "answer_start": [360, 360, 360]}, "prediction_text": "Classic FM"}
{"answers": {"text": ["2010", "the 2010 series", "the 2010 series"], "answer_start": [164, 160, 160]}, "prediction_text": "2010 series version"}
{"answers": {"text": ["228", "228", "228"], "answer_start": [339, 339, 339]}, "prediction_text": "Number 228"}
{"answers": {"text": ["Gold", "Gold", "Gold"], "answer_start": [444, 444, 46]}, "prediction_text": "The Day of the Doctor"}
{"answers": {"text": ["Jon Pertwee", "Jon Pertwee", "Jon Pertwee"], "answer_start": [108, 108, 108]}, "prediction_text": "Jon Pertwee"}
{"answers": {"text": ["Mankind", "Mankind", "Mankind"], "answer_start": [350, 350, 350]}, "prediction_text": "The Timelords"}
{"answers": {"text": ["number 24", "24", "number 24"], "answer_start": [373, 380, 373]}, "prediction_text": "Number 24 in the UK charts."}
{"answers": {"text": ["Doctorin' the Tardis", "Doctorin' the Tardis", "Doctorin' the Tardis"], "answer_start": [496, 496, 496]}, "prediction_text": "\"Doctorin' the Tardis\""}
{"answers": {"text": ["Doctorin' the Tardis", "Doctorin' the Tardis", "Doctorin' the Tardis"], "answer_start": [496, 496, 496]}, "prediction_text": "\"Doctorin' the Tardis\" by Gary Glitter"}
{"answers": {"text": ["Dudley Simpson", "Dudley Simpson", "Dudley Simpson"], "answer_start": [68, 68, 68]}, "prediction_text": "Dudley Simpson"}
{"answers": {"text": ["Planet of Giants", "Planet of Giants", "Planet of Giants"], "answer_start": [292, 292, 292]}, "prediction_text": "Planet of Giants"}
{"answers": {"text": ["the 1960s and 1970s", "the 1960s and 1970s", "1960s and 1970s"], "answer_start": [369, 369, 373]}, "prediction_text": "1964-1970"}
{"answers": {"text": ["The Horns of Nimon", "The Horns of Nimon", "The Horns of Nimon"], "answer_start": [470, 470, 470]}, "prediction_text": "The Horns of Nimon"}
{"answers": {"text": ["The Talons of Weng-Chiang", "The Talons of Weng-Chiang", "The Talons of Weng-Chiang"], "answer_start": [532, 532, 532]}, "prediction_text": "The Talons of Weng-Chiang"}
{"answers": {"text": ["the BBC National Orchestra of Wales", "BBC National Orchestra of Wales", "the BBC National Orchestra of Wales"], "answer_start": [127, 131, 127]}, "prediction_text": "Murray Gold"}
{"answers": {"text": ["the BBC National Orchestra of Wales", "BBC National Orchestra of Wales", "the BBC National Orchestra of Wales"], "answer_start": [127, 131, 127]}, "prediction_text": "David Tennant"}
{"answers": {"text": ["27 July 2008", "27 July 2008", "27 July 2008"], "answer_start": [691, 691, 691]}, "prediction_text": "July 2008"}
{"answers": {"text": ["Music of the Spheres", "Music of the Spheres", "Music of the Spheres"], "answer_start": [1174, 1174, 1174]}, "prediction_text": "\"Music of the Spheres\""}
{"answers": {"text": ["Murray Gold and Ben Foster", "Murray Gold and Ben Foster", "Murray Gold and Ben Foster"], "answer_start": [74, 74, 74]}, "prediction_text": "Murray Gold"}
{"answers": {"text": ["Six", "Six", "Six"], "answer_start": [0, 0, 0]}, "prediction_text": "Six soundtracks"}
{"answers": {"text": ["the first two series", "the first two series", "the first two"], "answer_start": [86, 86, 86]}, "prediction_text": "First Doctor Who"}
{"answers": {"text": ["music from the 2008\u20132010 specials", "the 2008\u20132010 specials", "music from the 2008\u20132010 specials"], "answer_start": [277, 288, 277]}, "prediction_text": "Music from the 2008\u20132010 specials."}
{"answers": {"text": ["A Christmas Carol", "A Christmas Carol", "A Christmas Carol"], "answer_start": [490, 490, 490]}, "prediction_text": "\"A Christmas Carol\""}
{"answers": {"text": ["8 November 2010", "8 November 2010", "8 November 2010"], "answer_start": [396, 396, 396]}, "prediction_text": "8 November 2010"}
{"answers": {"text": ["The original logo", "The original logo used for the First Doctor", "The original logo"], "answer_start": [0, 0, 0]}, "prediction_text": "The original logo used for the First Doctor was modified and reused for the 50th Anniversary special."}
{"answers": {"text": ["The logo for the Twelfth Doctor", "The logo for the Twelfth Doctor", "The logo for the Twelfth Doctor"], "answer_start": [933, 933, 933]}, "prediction_text": "The logo used for the Ninth Doctor."}
{"answers": {"text": ["the logo used for the Third and Eighth Doctors", "the Third and Eighth Doctors", "the logo used for the Third and Eighth Doctors"], "answer_start": [1080, 1098, 1080]}, "prediction_text": "The current Doctor Who logo"}
{"answers": {"text": ["The logo from 1973\u201380", "The logo from 1973\u201380", "The logo from 1973\u201380"], "answer_start": [340, 340, 340]}, "prediction_text": "The logo used for the Eleventh Doctor was used for the third Doctor's final season."}
{"answers": {"text": ["the Eleventh Doctor", "the Eleventh Doctor", "the Eleventh"], "answer_start": [185, 185, 185]}, "prediction_text": "The Eighth Doctor"}
{"answers": {"text": ["the assassination of John F. Kennedy", "the assassination of John F. Kennedy", "the assassination of John F. Kennedy"], "answer_start": [25, 25, 25]}, "prediction_text": "John F. Kennedy's assassination"}
{"answers": {"text": ["on the BBC's mainstream BBC One channel", "BBC One", "BBC One"], "answer_start": [193, 217, 217]}, "prediction_text": "BBC One channel"}
{"answers": {"text": ["the late 1970s", "the late 1970s", "the late 1970s"], "answer_start": [695, 695, 695]}, "prediction_text": "1964\u20131965, 1965\u20131968, 1969\u20131970."}
{"answers": {"text": ["circa 1964\u20131965", "circa 1964\u20131965", "circa 1964\u20131965"], "answer_start": [517, 517, 517]}, "prediction_text": "1964\u20131965"}
{"answers": {"text": ["BBC Three", "BBC Three", "BBC Three"], "answer_start": [349, 349, 349]}, "prediction_text": "BBC Three"}
{"answers": {"text": ["During the ITV network strike of 1979", "During the ITV network strike of 1979", "1979"], "answer_start": [0, 0, 33]}, "prediction_text": "1979 (16 million viewers)"}
{"answers": {"text": ["Its late 1980s performance of three to five million viewers", "performance of three to five million viewers was seen as poor", "performance"], "answer_start": [254, 269, 269]}, "prediction_text": "Three to five million viewers"}
{"answers": {"text": ["Coronation Street", "Coronation Street", "Coronation Street"], "answer_start": [540, 540, 540]}, "prediction_text": "Coronation Street"}
{"answers": {"text": ["the most popular show at the time", "the most popular show", "the most popular show at the time"], "answer_start": [559, 559, 559]}, "prediction_text": "Most popular show at the time."}
{"answers": {"text": ["After the series' revival in 2005", "the series' revival in 2005", "2005"], "answer_start": [594, 600, 623]}, "prediction_text": "2005"}
{"answers": {"text": ["PBS", "PBS", "PBS"], "answer_start": [221, 221, 221]}, "prediction_text": "PBS"}
{"answers": {"text": ["New Zealand", "New Zealand", "TVNZ"], "answer_start": [374, 374, 366]}, "prediction_text": "United States"}
{"answers": {"text": ["Edmonton, Canada", "Edmonton, Canada", "Edmonton, Canada"], "answer_start": [572, 572, 572]}, "prediction_text": "Edmonton, Canada"}
{"answers": {"text": ["15 days", "15", "15"], "answer_start": [590, 590, 590]}, "prediction_text": "Two days before the BBC One showing."}
{"answers": {"text": ["23 November", "23 November", "23 November"], "answer_start": [157, 157, 157]}, "prediction_text": "November 23, 1983"}
{"answers": {"text": ["Australian Broadcasting Corporation (ABC)", "Australian Broadcasting Corporation", "the Australian Broadcasting Corporation"], "answer_start": [111, 111, 107]}, "prediction_text": "ABC1"}
{"answers": {"text": ["partial funding", "partial funding", "partial funding"], "answer_start": [541, 541, 541]}, "prediction_text": "Funding for The Five Doctors"}
{"answers": {"text": ["SyFy", "SyFy", "SyFy"], "answer_start": [745, 745, 745]}, "prediction_text": "BBC UKTV"}
{"answers": {"text": ["weekly screenings of all available classic episodes", "screenings of all available classic episodes", "repeated episodes"], "answer_start": [234, 241, 198]}, "prediction_text": "Re revived episodes"}
{"answers": {"text": ["ABC1", "Australian Broadcasting Corporation", "the Australian Broadcasting Corporation"], "answer_start": [491, 111, 107]}, "prediction_text": "ABC1"}
{"answers": {"text": ["1976", "1976", "1976"], "answer_start": [32, 32, 32]}, "prediction_text": "1976"}
{"answers": {"text": ["The Three Doctors", "The Three Doctors", "The Three Doctors"], "answer_start": [52, 52, 52]}, "prediction_text": "The Three Doctors"}
{"answers": {"text": ["Space", "Space", "Space"], "answer_start": [662, 662, 662]}, "prediction_text": "Space"}
{"answers": {"text": ["The Talons of Weng-Chiang", "The Talons of Weng-Chiang", "The Talons of Weng-Chiang"], "answer_start": [412, 412, 412]}, "prediction_text": "The Talons of Weng-Chiang"}
{"answers": {"text": ["Judith Merril", "Judith Merril", "Judith Merril"], "answer_start": [215, 215, 215]}, "prediction_text": "Judith Merril"}
{"answers": {"text": ["Christopher Eccleston", "Christopher Eccleston", "Christopher Eccleston"], "answer_start": [28, 28, 28]}, "prediction_text": "Billie Piper"}
{"answers": {"text": ["excerpts from the Doctor Who Confidential documentary", "excerpts from the Doctor Who Confidential", "excerpts from the Doctor Who Confidential documentary"], "answer_start": [166, 166, 166]}, "prediction_text": "A trivia question"}
{"answers": {"text": ["The Christmas Invasion", "The Christmas Invasion", "The Christmas Invasion"], "answer_start": [280, 280, 280]}, "prediction_text": "\"The Christmas Invasion\""}
{"answers": {"text": ["9 October 2006", "9 October 2006", "9 October 2006"], "answer_start": [408, 408, 408]}, "prediction_text": "9 October 2006"}
{"answers": {"text": ["Thanksgiving", "Thanksgiving", "Thanksgiving"], "answer_start": [520, 520, 520]}, "prediction_text": "Thanksgiving"}
{"answers": {"text": ["the United Kingdom, Australia, Canada and the United States", "United Kingdom, Australia, Canada and the United States", "United Kingdom, Australia, Canada and the United States"], "answer_start": [76, 80, 80]}, "prediction_text": "United Kingdom, Australia, Canada, United States."}
{"answers": {"text": ["Eight original series serials", "Eight original series serials", "Eight original series serials"], "answer_start": [341, 341, 341]}, "prediction_text": "Doctor Who (The Infinite Quest)"}
{"answers": {"text": ["The Infinite Quest", "The Infinite Quest", "The Infinite Quest"], "answer_start": [495, 495, 495]}, "prediction_text": "The Infinite Quest"}
{"answers": {"text": ["Spearhead from Space", "Spearhead from Space", "Spearhead from Space"], "answer_start": [622, 622, 622]}, "prediction_text": "Spearhead from Space"}
{"answers": {"text": ["from 2009 onwards", "series from 2009 onwards", "from 2009 onwards"], "answer_start": [552, 545, 552]}, "prediction_text": "2009 onwards"}
{"answers": {"text": ["Trevor Martin", "Trevor Martin", "Trevor Martin"], "answer_start": [69, 69, 69]}, "prediction_text": "Trevor Martin"}
{"answers": {"text": ["Doctor Who \u2013 The Ultimate Adventure", "Doctor Who \u2013 The Ultimate Adventure", "Doctor Who \u2013 The Ultimate Adventure"], "answer_start": [280, 280, 280]}, "prediction_text": "The Ultimate Adventure"}
{"answers": {"text": ["The Curse of the Daleks", "The Curse of the Daleks", "The Curse of the Daleks"], "answer_start": [554, 554, 554]}, "prediction_text": "The Curse of the Daleks"}
{"answers": {"text": ["Doctor Who and the Daleks in the Seven Keys to Doomsday", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Doctor Who and the Daleks in the Seven Keys to Doomsday"], "answer_start": [102, 102, 102]}, "prediction_text": "Doctor Who \u2013 The Ultimate Adventure"}
{"answers": {"text": ["David Banks", "David Banks", "David Banks"], "answer_start": [362, 362, 362]}, "prediction_text": "Jon Pertwee"}
{"answers": {"text": ["Torchwood", "Torchwood", "Torchwood"], "answer_start": [143, 143, 143]}, "prediction_text": "Torchwood"}
{"answers": {"text": ["22 October 2006", "22 October 2006", "22 October 2006"], "answer_start": [290, 290, 290]}, "prediction_text": "October 22, 2006"}
{"answers": {"text": ["2008", "2008", "2008"], "answer_start": [724, 724, 724]}, "prediction_text": "2008"}
{"answers": {"text": ["Children of Earth", "Children of Earth", "Children of Earth"], "answer_start": [937, 937, 937]}, "prediction_text": "Children of Earth"}
{"answers": {"text": ["Torchwood: Miracle Day", "Torchwood: Miracle Day", "Torchwood: Miracle Day"], "answer_start": [1005, 1005, 1005]}, "prediction_text": "Miracle Day"}
{"answers": {"text": ["Elisabeth Sladen", "Elisabeth Sladen", "Elisabeth Sladen"], "answer_start": [36, 36, 36]}, "prediction_text": "Elisabeth Sladen"}
{"answers": {"text": ["24 September 2007", "24 September 2007", "24 September 2007"], "answer_start": [210, 210, 210]}, "prediction_text": "September 24, 2007"}
{"answers": {"text": ["2009", "2009", "2009"], "answer_start": [357, 357, 357]}, "prediction_text": "2009"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [454, 454, 454]}, "prediction_text": "In 2009."}
{"answers": {"text": ["due to the death of Elisabeth Sladen", "the death of Elisabeth Sladen", "the death of Elisabeth Sladen"], "answer_start": [688, 695, 695]}, "prediction_text": "Elisabeth Sladen's death."}
{"answers": {"text": ["Dimensions in Time", "Dimensions in Time", "Dimensions in Time"], "answer_start": [79, 79, 79]}, "prediction_text": "Dimensions in Time"}
{"answers": {"text": ["Children in Need", "Children in Need", "Children in Need"], "answer_start": [115, 115, 115]}, "prediction_text": "Children in Need"}
{"answers": {"text": ["EastEnders", "EastEnders", "EastEnders"], "answer_start": [279, 279, 279]}, "prediction_text": "EastEnders"}
{"answers": {"text": ["glasses with one darkened lens", "glasses with one darkened lens", "one darkened lens"], "answer_start": [524, 524, 537]}, "prediction_text": "One darkened lens"}
{"answers": {"text": ["the Pulfrich effect", "Pulfrich effect", "Pulfrich effect"], "answer_start": [494, 498, 498]}, "prediction_text": "Pulfrich effect"}
{"answers": {"text": ["Doctor Who and the Curse of Fatal Death", "Curse of Fatal Death,", "Doctor Who and the Curse of Fatal Death"], "answer_start": [26, 45, 26]}, "prediction_text": "Doctor Who and the Curse of Fatal Death"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [187, 187, 187]}, "prediction_text": "Four segments"}
{"answers": {"text": ["Rowan Atkinson", "Rowan Atkinson", "Richard E. Grant"], "answer_start": [430, 430, 629]}, "prediction_text": "Richard E. Grant"}
{"answers": {"text": ["Joanna Lumley", "Joanna Lumley", "Joanna Lumley"], "answer_start": [677, 677, 677]}, "prediction_text": "Richard E. Grant"}
{"answers": {"text": ["head writer and executive producer", "Steven Moffat", "head writer and executive producer"], "answer_start": [745, 718, 745]}, "prediction_text": "Head writer and executive producer"}
{"answers": {"text": ["The Neutral Zone", "The Neutral Zone", "The Neutral Zone"], "answer_start": [140, 140, 140]}, "prediction_text": "The Next Generation"}
{"answers": {"text": ["\"Blue Harvest\" and \"420\"", "\"Blue Harvest\" and \"420\"", "\"Blue Harvest\" and \"420\""], "answer_start": [828, 828, 828]}, "prediction_text": "\"Blue Harvest\" and \"420\""}
{"answers": {"text": ["Queer as Folk", "Queer as Folk", "Queer as Folk"], "answer_start": [197, 197, 197]}, "prediction_text": "Queer as Folk"}
{"answers": {"text": ["Oliver", "Oliver", "Oliver"], "answer_start": [470, 470, 470]}, "prediction_text": "Oliver"}
{"answers": {"text": ["Brisingr and High Wizardry,", "Brisingr and High Wizardry", "Brisingr and High Wizardry"], "answer_start": [681, 681, 681]}, "prediction_text": "Brisingr and High Wizardry"}
{"answers": {"text": ["The Chase", "The Chase", "The Chase"], "answer_start": [120, 120, 120]}, "prediction_text": "The Chase"}
{"answers": {"text": ["21-minute", "21-minute", "21-minute"], "answer_start": [52, 52, 52]}, "prediction_text": "Ten years"}
{"answers": {"text": ["Doctor Who and the Pescatons", "Doctor Who and the Pescatons", "Doctor Who and the Pescatons"], "answer_start": [228, 228, 228]}, "prediction_text": "The Chase"}
{"answers": {"text": ["1981", "1966", "1981"], "answer_start": [398, 142, 398]}, "prediction_text": "1981"}
{"answers": {"text": ["Slipback", "Doctor Who and the Pescatons", "Slipback"], "answer_start": [453, 228, 453]}, "prediction_text": "Slipback"}
{"answers": {"text": ["the Fifth, Sixth and Seventh Doctors", "Fifth, Sixth and Seventh Doctors", "the Fifth, Sixth and Seventh Doctors"], "answer_start": [132, 136, 132]}, "prediction_text": "Fifth, Sixth, Seventh Doctors"}
{"answers": {"text": ["Destiny of the Doctor", "The 2013 series", "Destiny of the Doctor"], "answer_start": [473, 457, 473]}, "prediction_text": "Destiny of the Doctor"}
{"answers": {"text": ["Big Finish Productions", "Big Finish Productions", "Big Finish Productions"], "answer_start": [12, 12, 12]}, "prediction_text": "Big Finish Productions"}
{"answers": {"text": ["1999", "1999", "1999"], "answer_start": [6, 6, 6]}, "prediction_text": "1999"}
{"answers": {"text": ["2012", "2012", "2012"], "answer_start": [288, 288, 288]}, "prediction_text": "2001"}
{"answers": {"text": ["1991", "1991", "1991"], "answer_start": [197, 197, 197]}, "prediction_text": "1991"}
{"answers": {"text": ["the mid-sixties", "the mid-sixties", "1965"], "answer_start": [42, 42, 91]}, "prediction_text": "1965 to 1991"}
{"answers": {"text": ["since 1979", "1979", "since 1979"], "answer_start": [618, 624, 618]}, "prediction_text": "Since 1979"}
{"answers": {"text": ["Panini", "Panini", "Panini"], "answer_start": [651, 651, 651]}, "prediction_text": "Panini"}
{"answers": {"text": ["BBC Books", "BBC Books", "BBC Books"], "answer_start": [401, 401, 401]}, "prediction_text": "BBC Books"}
{"answers": {"text": ["the early 1960s", "the early 1960s", "the early 1960s"], "answer_start": [68, 68, 68]}, "prediction_text": "Early 1960s"}
{"answers": {"text": ["BBC Television", "BBC Television", "BBC Television"], "answer_start": [50, 50, 50]}, "prediction_text": "BBC Television"}
{"answers": {"text": ["producers of the show", "producers of the show", "producers of the show"], "answer_start": [522, 522, 522]}, "prediction_text": "BBC producers"}
{"answers": {"text": ["the BBC", "the BBC", "the BBC"], "answer_start": [450, 450, 450]}, "prediction_text": "BBC"}
{"answers": {"text": ["2006", "2006", "2006"], "answer_start": [96, 96, 96]}, "prediction_text": "2005-2010"}
{"answers": {"text": ["2005\u20132010", "2005\u20132010", "2005\u20132010"], "answer_start": [178, 178, 178]}, "prediction_text": "2005\u20132010"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [288, 288, 288]}, "prediction_text": "2011"}
{"answers": {"text": ["Michelle Gomez", "Michelle Gomez", "Michelle Gomez"], "answer_start": [402, 402, 402]}, "prediction_text": "Michelle Gomez"}
{"answers": {"text": ["Best Supporting Actress", "Best Supporting Actress", "Best Supporting Actress"], "answer_start": [497, 497, 497]}, "prediction_text": "Best Supporting Actress"}
{"answers": {"text": ["Guinness World Records", "Guinness World Records", "Guinness World Records"], "answer_start": [202, 202, 202]}, "prediction_text": "Guinness World Records"}
{"answers": {"text": ["Doctor Who", "Doctor Who", "Doctor Who"], "answer_start": [37, 37, 37]}, "prediction_text": "50th anniversary special"}
{"answers": {"text": ["electronic", "electronic music", "electronic"], "answer_start": [647, 647, 647]}, "prediction_text": "Electronic music"}
{"answers": {"text": ["2013", "2013", "2013"], "answer_start": [3, 3, 3]}, "prediction_text": "2013"}
{"answers": {"text": ["50th anniversary special", "50th anniversary special", "50th anniversary special"], "answer_start": [490, 490, 490]}, "prediction_text": "50th anniversary special"}
{"answers": {"text": ["Season 11", "1975", "11"], "answer_start": [9, 3, 16]}, "prediction_text": "Season 11"}
{"answers": {"text": ["Doctor Who", "Doctor Who", "Doctor Who"], "answer_start": [269, 269, 269]}, "prediction_text": "Doctor Who"}
{"answers": {"text": ["third", "third", "third"], "answer_start": [447, 447, 447]}, "prediction_text": "Number eight"}
{"answers": {"text": ["SFX magazine", "SFX magazine", "SFX magazine"], "answer_start": [659, 659, 659]}, "prediction_text": "SFX magazine"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [858, 858, 858]}, "prediction_text": "Number eight"}
{"answers": {"text": ["Best Drama Series", "Best Drama Series", "Best Drama Series"], "answer_start": [146, 146, 146]}, "prediction_text": "Best Drama Series (twice)"}
{"answers": {"text": ["five", "25", "five", "five"], "answer_start": [114, 329, 114, 114]}, "prediction_text": "Five BAFTA TV awards"}
{"answers": {"text": ["25", "25", "25", "25"], "answer_start": [329, 329, 329, 329]}, "prediction_text": "Five BAFTA Cymru Awards"}
{"answers": {"text": ["2009", "2009", "2009", "2009"], "answer_start": [552, 552, 552, 552]}, "prediction_text": "2009"}
{"answers": {"text": ["a Mind Award at the 2010 Mind Mental Health Media Awards", "Mind Award", "Mind Award", "Mind Award"], "answer_start": [721, 723, 723, 723]}, "prediction_text": "Mind Award"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [139, 139, 139]}, "prediction_text": "Six times"}
{"answers": {"text": ["over 200", "over 200", "over 200"], "answer_start": [596, 596, 596]}, "prediction_text": "Over 200 awards"}
{"answers": {"text": ["over a hundred", "over a hundred", "over a hundred"], "answer_start": [624, 624, 624]}, "prediction_text": "Over 200 awards"}
{"answers": {"text": ["Matt Smith", "Matt Smith", "Matt Smith"], "answer_start": [452, 452, 452]}, "prediction_text": "Matt Smith"}
{"answers": {"text": ["The Waters of Mars", "The Waters of Mars", "The Waters of Mars"], "answer_start": [331, 331, 331]}, "prediction_text": "\"The Waters of Mars\""}
{"answers": {"text": ["Spike Milligan", "Spike Milligan", "Spike Milligan"], "answer_start": [83, 83, 83]}, "prediction_text": "Spike Milligan"}
{"answers": {"text": ["Jon Culshaw", "Jon Culshaw", "Jon Culshaw"], "answer_start": [191, 191, 191]}, "prediction_text": "Jon Culshaw"}
{"answers": {"text": ["a soap sponge", "a soap sponge", "soap sponge"], "answer_start": [153, 153, 155]}, "prediction_text": "A soap sponge"}
{"answers": {"text": ["Doctor Who fandom", "Doctor Who", "Doctor Who"], "answer_start": [277, 277, 277]}, "prediction_text": "Doctor Who"}
{"answers": {"text": ["BBC Dead Ringers", "Dead Ringers", "Dead Ringers"], "answer_start": [252, 256, 256]}, "prediction_text": "Dead Ringers"}
{"answers": {"text": ["a private research university", "private research", "private research university", "private research university"], "answer_start": [60, 62, 62, 62]}, "prediction_text": "Private research university"}
{"answers": {"text": ["1890", "1890", "1890", "1890"], "answer_start": [133, 133, 133, 133]}, "prediction_text": "1890"}
{"answers": {"text": ["seven", "seven", "seven", "seven"], "answer_start": [272, 272, 272, 272]}, "prediction_text": "Seven professional schools"}
{"answers": {"text": ["four", "four", "four", "four"], "answer_start": [235, 235, 235, 235]}, "prediction_text": "Four academic research divisions"}
{"answers": {"text": ["5,000", "around 15,000", "15,000", "15,000"], "answer_start": [728, 762, 769, 769]}, "prediction_text": "5,000 students"}
{"answers": {"text": ["various academic disciplines", "various academic disciplines", "the world's first man-made, self-sustaining nuclear reaction", "the world's first man-made, self-sustaining nuclear reaction"], "answer_start": [78, 78, 404, 404]}, "prediction_text": "Chicago school of economics development"}
{"answers": {"text": ["Chicago's physics department", "Chicago's physics department", "Chicago's physics department", "Chicago's physics department"], "answer_start": [360, 360, 360, 360]}, "prediction_text": "University of Chicago scholars"}
{"answers": {"text": ["beneath the university's Stagg Field", "Stagg Field", "beneath the university's Stagg Field", "beneath the university's Stagg Field"], "answer_start": [465, 490, 465, 465]}, "prediction_text": "Stagg Field"}
{"answers": {"text": ["University of Chicago Press", "University of Chicago Press", "University of Chicago Press", "University of Chicago Press"], "answer_start": [741, 741, 741, 741]}, "prediction_text": "University of Chicago Press"}
{"answers": {"text": ["2020", "2020", "2020", "2020"], "answer_start": [858, 858, 858, 858]}, "prediction_text": "2020"}
{"answers": {"text": ["the American Baptist Education Society", "American Baptist Education Society", "American Baptist Education Society", "American Baptist Education Society"], "answer_start": [11, 15, 15, 15]}, "prediction_text": "American Baptist Education Society"}
{"answers": {"text": ["John D. Rockefeller", "John D. Rockefeller", "John D. Rockefeller", "John D. Rockefeller"], "answer_start": [113, 113, 113, 113]}, "prediction_text": "John D. Rockefeller"}
{"answers": {"text": ["William Rainey Harper", "William Rainey Harper", "William Rainey Harper", "William Rainey Harper"], "answer_start": [186, 186, 186, 186]}, "prediction_text": "William Rainey Harper"}
{"answers": {"text": ["1891", "1891", "1891", "1891"], "answer_start": [251, 251, 251, 251]}, "prediction_text": "1891"}
{"answers": {"text": ["1892", "1892", "1892", "1892"], "answer_start": [292, 292, 292, 292]}, "prediction_text": "1892"}
{"answers": {"text": ["Marshall Field", "Marshall Field", "Marshall Field", "Marshall Field"], "answer_start": [235, 235, 235, 235]}, "prediction_text": "John D. Rockefeller"}
{"answers": {"text": ["Silas B. Cobb", "Silas B. Cobb", "Silas B. Cobb", "Silas B. Cobb"], "answer_start": [497, 497, 497, 497]}, "prediction_text": "Silas B. Cobb"}
{"answers": {"text": ["Cobb Lecture Hall", "Cobb Lecture Hall", "Cobb Lecture Hall", "Cobb Lecture Hall"], "answer_start": [566, 566, 566, 566]}, "prediction_text": "Cobb Lecture Hall"}
{"answers": {"text": ["$100,000", "$100,000", "$100,000", "$100,000"], "answer_start": [624, 624, 624, 624]}, "prediction_text": "$100,000"}
{"answers": {"text": ["Charles L. Hutchinson", "Charles L. Hutchinson", "Charles L. Hutchinson", "Charles L. Hutchinson"], "answer_start": [679, 679, 679, 679]}, "prediction_text": "Silas B. Cobb"}
{"answers": {"text": ["several regional colleges and universities", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Des Moines College, Kalamazoo College, Butler University, and Stetson University"], "answer_start": [149, 193, 193, 193]}, "prediction_text": "Des Moines College"}
{"answers": {"text": ["1896", "1896", "1896", "1896"], "answer_start": [278, 278, 278, 278]}, "prediction_text": "1896"}
{"answers": {"text": ["made a grade of A for all four years", "made a grade of A for all four years, and on any other graduate who took twelve weeks additional study at the University of Chicago", "made a grade of A for all four years", "made a grade of A for all four years"], "answer_start": [796, 796, 796, 796]}, "prediction_text": "Made a grade of A for all four years."}
{"answers": {"text": ["passed", "Several University of Chicago professors", "Several University of Chicago professors"], "answer_start": [1751, 1541, 1541]}, "prediction_text": "University of Chicago professors"}
{"answers": {"text": ["1910", "1910", "Several University of Chicago professors", "1910"], "answer_start": [1774, 1774, 1541, 1774]}, "prediction_text": "1910"}
{"answers": {"text": ["Robert Maynard Hutchins", "Robert Maynard Hutchins", "Robert Maynard Hutchins", "Robert Maynard Hutchins"], "answer_start": [43, 43, 43, 43]}, "prediction_text": "Robert Maynard Hutchins"}
{"answers": {"text": ["the Common Core", "Common Core", "Common Core", "Common Core"], "answer_start": [328, 332, 332, 332]}, "prediction_text": "Common Core"}
{"answers": {"text": ["to emphasize academics over athletics", "emphasize academics", "an attempt to emphasize academics over athletics", "to emphasize academics over athletics,"], "answer_start": [217, 220, 206, 217]}, "prediction_text": "To emphasize academics over athletics."}
{"answers": {"text": ["24-year tenure", "24-year", "24-year tenure.", "24-year"], "answer_start": [130, 130, 130, 130]}, "prediction_text": "24 years"}
{"answers": {"text": ["1929", "1929", "1929", "1929"], "answer_start": [3, 3, 3, 3]}, "prediction_text": "1929"}
{"answers": {"text": ["1950s", "early 1950s", "the early 1950s", "the early 1950s"], "answer_start": [13, 7, 3, 3]}, "prediction_text": "Early 1950s"}
{"answers": {"text": ["a result of increasing crime and poverty", "increasing crime and poverty in the Hyde Park neighborhood", "increasing crime and poverty in the Hyde Park neighborhood", "increasing crime and poverty in the Hyde Park neighborhood"], "answer_start": [53, 65, 65, 65]}, "prediction_text": "Increasing crime and poverty."}
{"answers": {"text": ["after their second year", "early 1950s", "after their second year", "after their second year"], "answer_start": [576, 7, 576, 576]}, "prediction_text": "After their second year"}
{"answers": {"text": ["Hyde Park", "Hyde Park", "Hyde Park", "Hyde Park"], "answer_start": [221, 101, 101, 101]}, "prediction_text": "Hyde Park"}
{"answers": {"text": ["allowed very young students to attend college", "allowed very young students to attend college", "allowed very young students to attend college", "allowed very young students to attend college"], "answer_start": [420, 420, 420, 420]}, "prediction_text": "Enrolled young students at Shimer College."}
{"answers": {"text": ["1962", "1962", "1962", "1962"], "answer_start": [86, 86, 86, 86]}, "prediction_text": "1962"}
{"answers": {"text": ["the university's off-campus rental policies.", "the university's off-campus rental policies", "the university's off-campus rental policies", "the university's off-campus rental policies"], "answer_start": [166, 166, 166, 166]}, "prediction_text": "Off-campus rental policies"}
{"answers": {"text": ["1967", "1967", "1967", "1967"], "answer_start": [262, 262, 262, 262]}, "prediction_text": "1967"}
{"answers": {"text": ["a two-page statement", "two", "two", "two"], "answer_start": [326, 328, 328, 328]}, "prediction_text": "Two pages"}
{"answers": {"text": ["social and political action", "social and political action", "social and political action", "social and political action"], "answer_start": [378, 378, 378, 378]}, "prediction_text": "Excessive environment of freedom of inquiry and independence from political fashions."}
{"answers": {"text": ["mid-2000s", "mid-2000s", "mid-2000s", "the mid-2000s"], "answer_start": [9, 9, 9, 5]}, "prediction_text": "Mid-2000s"}
{"answers": {"text": ["Milton Friedman Institute", "Milton Friedman Institute", "Milton Friedman Institute", "Milton Friedman Institute"], "answer_start": [161, 161, 161, 161]}, "prediction_text": "Milton Friedman Institute"}
{"answers": {"text": ["around $200 million", "$200 million", "$200 million", "$200 million"], "answer_start": [291, 298, 298, 298]}, "prediction_text": "Around $200 million"}
{"answers": {"text": ["the Chicago Theological Seminary", "Chicago Theological Seminary", "Chicago Theological Seminary", "Chicago Theological Seminary"], "answer_start": [339, 343, 343, 343]}, "prediction_text": "Chicago Theological Seminary"}
{"answers": {"text": ["David G. Booth", "David G. Booth", "David G. Booth", "David G. Booth"], "answer_start": [404, 404, 404, 404]}, "prediction_text": "David G. Booth"}
{"answers": {"text": ["the Main Quadrangles", "Main Quadrangles", "the Main Quadrangles", "the Main Quadrangles"], "answer_start": [92, 96, 92, 92]}, "prediction_text": "Main Quadrangles"}
{"answers": {"text": ["six", "six quadrangles", "six", "six"], "answer_start": [273, 273, 273, 273]}, "prediction_text": "Six quadrangles"}
{"answers": {"text": ["Cobb, Shepley, Rutan and Coolidge, Holabird & Roche,", "Henry Ives Cobb", "Cobb, Shepley, Rutan and Coolidge, Holabird & Roche, and other architectural firms", "Cobb, Shepley, Rutan and Coolidge, Holabird & Roche, and other architectural firms"], "answer_start": [408, 224, 408, 408]}, "prediction_text": "Henry Ives Cobb"}
{"answers": {"text": ["Oxford's Magdalen Tower", "Magdalen Tower", "Magdalen Tower", "Magdalen Tower"], "answer_start": [660, 669, 669, 669]}, "prediction_text": "Magdalen Tower"}
{"answers": {"text": ["Christ Church Hall", "Christ Church Hall", "Christ Church Hall", "Christ Church Hall"], "answer_start": [741, 741, 741, 741]}, "prediction_text": "Christ Church Hall"}
{"answers": {"text": ["the 1940s", "After the 1940s"], "answer_start": [6, 0]}, "prediction_text": "After the 1940s"}
{"answers": {"text": ["Eero Saarinen", "Eero Saarinen", "Eero Saarinen"], "answer_start": [89, 89, 89]}, "prediction_text": "Eero Saarinen"}
{"answers": {"text": ["School of Social Service Administration", "School of Social Service Administration", "the university's School of Social Service Administration"], "answer_start": [401, 401, 384]}, "prediction_text": "School of Social Service Administration"}
{"answers": {"text": ["Harris School of Public Policy Studies", "Harris School of Public Policy Studies", "the Harris School of Public Policy Studies"], "answer_start": [489, 489, 485]}, "prediction_text": "School of Social Service Administration"}
{"answers": {"text": ["2003", "2003"], "answer_start": [813, 813]}, "prediction_text": "2003"}
{"answers": {"text": ["Singapore, London, and the downtown Streeterville neighborhood of Chicago", "Singapore, London, and the downtown Streeterville neighborhood of Chicago", "Singapore, London, and the downtown Streeterville neighborhood of Chicago"], "answer_start": [144, 144, 144]}, "prediction_text": "Singapore, London, and the downtown Streeterville neighborhood."}
{"answers": {"text": ["Seine", "Seine", "the Seine"], "answer_start": [281, 281, 277]}, "prediction_text": "Seine"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [362, 362, 362]}, "prediction_text": "2014"}
{"answers": {"text": ["Renmin University", "Renmin University", "Renmin University"], "answer_start": [432, 432, 432]}, "prediction_text": "Renmin University"}
{"answers": {"text": ["2015", "2015", "2015"], "answer_start": [604, 604, 604]}, "prediction_text": "2015"}
{"answers": {"text": ["a board of trustees", "board of trustees", "The Board of Trustees"], "answer_start": [41, 43, 62]}, "prediction_text": "Board of Trustees"}
{"answers": {"text": ["50", "50", "50"], "answer_start": [199, 199, 199]}, "prediction_text": "50 people"}
{"answers": {"text": ["fourteen", "fourteen", "fourteen"], "answer_start": [294, 294, 294]}, "prediction_text": "Fifty members"}
{"answers": {"text": ["Andrew Alper", "Andrew Alper", "Andrew Alper"], "answer_start": [616, 616, 616]}, "prediction_text": "Andrew Alper"}
{"answers": {"text": ["Robert Zimmer", "Daniel Diermeier", "Daniel Diermeier"], "answer_start": [669, 851, 851]}, "prediction_text": "Daniel Diermeier"}
{"answers": {"text": ["The Higher Learning Commission", "The Higher Learning Commission", "The Higher Learning Commission"], "answer_start": [499, 499, 499]}, "prediction_text": "The Higher Learning Commission"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [73, 73, 73]}, "prediction_text": "Four divisions"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [113, 113, 113]}, "prediction_text": "Seven professional schools"}
{"answers": {"text": ["50", "50", "50"], "answer_start": [100, 100, 100]}, "prediction_text": "50 majors"}
{"answers": {"text": ["28", "28", "28"], "answer_start": [123, 123, 123]}, "prediction_text": "28 minors"}
{"answers": {"text": ["five", "five", "five"], "answer_start": [175, 175, 175]}, "prediction_text": "Five divisions"}
{"answers": {"text": ["the New Collegiate Division", "New Collegiate Division", "New Collegiate Division"], "answer_start": [470, 474, 474]}, "prediction_text": "New Collegiate Division"}
{"answers": {"text": ["the Common Core", "Common Core", "Common Core"], "answer_start": [123, 127, 127]}, "prediction_text": "Common Core"}
{"answers": {"text": ["17", "17", "17"], "answer_start": [198, 198, 198]}, "prediction_text": "17 students"}
{"answers": {"text": ["the most rigorous, intense", "the most rigorous, intense"], "answer_start": [756, 756]}, "prediction_text": "Heavy workload and academic difficulty."}
{"answers": {"text": ["Uni in the USA", "Uni in the USA", "Uni in the USA"], "answer_start": [565, 565, 565]}, "prediction_text": "Uni in the USA"}
{"answers": {"text": ["University of Chicago Laboratory Schools", "University of Chicago Laboratory Schools", "University of Chicago Laboratory Schools"], "answer_start": [138, 138, 138]}, "prediction_text": "Sonia Shankman Orthogenic School"}
{"answers": {"text": ["the Sonia Shankman Orthogenic School", "Sonia Shankman Orthogenic School", "the Sonia Shankman Orthogenic School"], "answer_start": [234, 238, 234]}, "prediction_text": "Sonia Shankman Orthogenic School"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [359, 359, 359]}, "prediction_text": "Four public charter schools"}
{"answers": {"text": ["four public charter schools", "four public charter schools", "public charter schools on the South Side of Chicago"], "answer_start": [359, 359, 364]}, "prediction_text": "University of Chicago Laboratory Schools"}
{"answers": {"text": ["the University of Chicago campus", "University of Chicago campus", "the University of Chicago campus"], "answer_start": [589, 593, 589]}, "prediction_text": "University of Chicago"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [53, 53, 53]}, "prediction_text": "Nine libraries"}
{"answers": {"text": ["9.8 million", "9.8 million", "9.8 million"], "answer_start": [91, 91, 91]}, "prediction_text": "One of the largest collections in the US."}
{"answers": {"text": ["the Regenstein Library", "Regenstein Library", "the Regenstein Library"], "answer_start": [203, 207, 203]}, "prediction_text": "Regenstein Library"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [356, 356, 356]}, "prediction_text": "2011"}
{"answers": {"text": ["more than 1.3 million", "1.3 million", "more than 1.3 million"], "answer_start": [474, 484, 474]}, "prediction_text": "Over 1.3 million volumes"}
{"answers": {"text": ["12", "12", "12"], "answer_start": [24, 24, 24]}, "prediction_text": "12 research institutes"}
{"answers": {"text": ["113", "113", "113"], "answer_start": [51, 51, 51]}, "prediction_text": "113 research centers"}
{"answers": {"text": ["the Oriental Institute", "Oriental Institute", "the Oriental Institute"], "answer_start": [99, 103, 99]}, "prediction_text": "Oriental Institute"}
{"answers": {"text": ["Fermilab", "Fermilab", "Fermilab"], "answer_start": [581, 581, 581]}, "prediction_text": "Apache Point Observatory"}
{"answers": {"text": ["Sunspot, New Mexico", "Sunspot, New Mexico", "Sunspot, New Mexico"], "answer_start": [683, 683, 683]}, "prediction_text": "Sunspot, New Mexico"}
{"answers": {"text": ["shaping ideas about the free market", "shaping ideas about the free market", "shaping ideas about the free market"], "answer_start": [159, 159, 159]}, "prediction_text": "shaping ideas about the free market"}
{"answers": {"text": ["Chicago Pile-1", "Chicago Pile-1"], "answer_start": [537, 537]}, "prediction_text": "Manhattan Project"}
{"answers": {"text": ["Miller\u2013Urey experiment", "Miller\u2013Urey experiment", "Chicago Pile-1"], "answer_start": [872, 872, 537]}, "prediction_text": "Miller\u2013Urey experiment"}
{"answers": {"text": ["1953", "1953", "1953"], "answer_start": [975, 975, 975]}, "prediction_text": "1953"}
{"answers": {"text": ["1933", "1933", "1933"], "answer_start": [509, 509, 509]}, "prediction_text": "1933"}
{"answers": {"text": ["2000", "2000", "2000"], "answer_start": [550, 550, 550]}, "prediction_text": "2000"}
{"answers": {"text": ["1996", "1996", "1996"], "answer_start": [803, 803, 803]}, "prediction_text": "1996"}
{"answers": {"text": ["2002", "2002", "2002"], "answer_start": [844, 844, 844]}, "prediction_text": "2000"}
{"answers": {"text": ["Several thousand", "Several thousand", "Several thousand"], "answer_start": [1047, 1047, 1047]}, "prediction_text": "Around 1,000 students annually."}
{"answers": {"text": ["5,792", "5,792", "5,792"], "answer_start": [64, 64, 64]}, "prediction_text": "5,792 students"}
{"answers": {"text": ["3,468", "3,468", "3,468"], "answer_start": [95, 95, 95]}, "prediction_text": "3,468 students"}
{"answers": {"text": ["5,984", "5,984", "5,984"], "answer_start": [142, 142, 142]}, "prediction_text": "3,468 students"}
{"answers": {"text": ["15,244", "15,244", "15,244"], "answer_start": [190, 190, 190]}, "prediction_text": "5,792 students"}
{"answers": {"text": ["international students", "international students", "international students"], "answer_start": [243, 243, 243]}, "prediction_text": "International students"}
{"answers": {"text": ["the University Athletic Association", "University Athletic Association (UAA)", "University Athletic Association (UAA)"], "answer_start": [61, 65, 65]}, "prediction_text": "University Athletic Association (UAA)"}
{"answers": {"text": ["NCAA's Division III", "NCAA's Division III"], "answer_start": [27, 27]}, "prediction_text": "NCAA Division III"}
{"answers": {"text": ["the Big Ten Conference", "Big Ten Conference", "the Big Ten Conference"], "answer_start": [144, 148, 144]}, "prediction_text": "Big Ten Conference"}
{"answers": {"text": ["Jay Berwanger", "Jay Berwanger", "Jay Berwanger"], "answer_start": [406, 406, 406]}, "prediction_text": "Jay Berwanger"}
{"answers": {"text": ["Robert Maynard Hutchins de-emphasized varsity athletics", "University President Robert Maynard Hutchins de-emphasized varsity athletics", "University President Robert Maynard Hutchins de-emphasized varsity athletics in 1939"], "answer_start": [564, 543, 543]}, "prediction_text": "De-emphasized varsity athletics"}
{"answers": {"text": ["over 400", "over 400", "over 400"], "answer_start": [42, 42, 42]}, "prediction_text": "400 clubs"}
{"answers": {"text": ["Recognized Student Organizations", "Recognized Student Organizations (RSOs)"], "answer_start": [84, 84]}, "prediction_text": "Recognized Student Organizations (RSOs)"}
{"answers": {"text": ["the University of Chicago College Bowl Team", "University of Chicago College Bowl Team", "University of Chicago College Bowl Team"], "answer_start": [270, 274, 274]}, "prediction_text": "University of Chicago College Bowl Team"}
{"answers": {"text": ["Doc Films", "Doc Films", "Doc Films"], "answer_start": [625, 625, 625]}, "prediction_text": "Doc Films"}
{"answers": {"text": ["Off-Off Campus", "Off-Off Campus", "Off-Off Campus"], "answer_start": [905, 905, 905]}, "prediction_text": "Off-Off Campus"}
{"answers": {"text": ["graduate and undergraduate students", "graduate and undergraduate students", "graduate and undergraduate students elected to represent members from their respective academic unit"], "answer_start": [256, 256, 256]}, "prediction_text": "Graduate and undergraduate students"}
{"answers": {"text": ["an Executive Committee", "Executive Committee", "an Executive Committee"], "answer_start": [371, 374, 371]}, "prediction_text": "Executive Committee"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [441, 441, 441]}, "prediction_text": "Two Vice Presidents"}
{"answers": {"text": ["greater than $2 million", "$2 million", "greater than $2 million"], "answer_start": [599, 612, 599]}, "prediction_text": "$2 million"}
{"answers": {"text": ["fifteen", "fifteen", "fifteen"], "answer_start": [10, 10, 10]}, "prediction_text": "Fifteen fraternities"}
{"answers": {"text": ["seven", "seven", "seven"], "answer_start": [35, 35, 35]}, "prediction_text": "Five sororities"}
{"answers": {"text": ["Alpha Phi Omega", "Alpha Phi Omega", "Alpha Phi Omega"], "answer_start": [133, 133, 133]}, "prediction_text": "Alpha Phi Omega"}
{"answers": {"text": ["Alpha Phi Omega", "Four", "Four"], "answer_start": [133, 150, 150]}, "prediction_text": "Ten sororities"}
{"answers": {"text": ["ten", "ten", "ten"], "answer_start": [229, 229, 229]}, "prediction_text": "Ten fraternities"}
{"answers": {"text": ["May", "May", "May"], "answer_start": [6, 6, 6]}, "prediction_text": "May"}
{"answers": {"text": ["1987", "1987", "1987"], "answer_start": [16, 16, 16]}, "prediction_text": "1987"}
{"answers": {"text": ["Festival of the Arts", "Festival of the Arts", "Festival of the Arts"], "answer_start": [206, 206, 206]}, "prediction_text": "University of Chicago Scavenger Hunt"}
{"answers": {"text": ["Kuviasungnerk/Kangeiko", "Kuviasungnerk/Kangeiko", "Kuviasungnerk/Kangeiko"], "answer_start": [382, 382, 382]}, "prediction_text": "Kuviasungnerk/Kangeiko"}
{"answers": {"text": ["Summer Breeze", "Summer Breeze", "Summer Breeze"], "answer_start": [547, 547, 547]}, "prediction_text": "Summer Breeze"}
{"answers": {"text": ["Satya Nadella", "Satya Nadella", "Satya Nadella"], "answer_start": [50, 50, 50]}, "prediction_text": "Satya Nadella"}
{"answers": {"text": ["Larry Ellison", "Larry Ellison", "Larry Ellison"], "answer_start": [129, 129, 129]}, "prediction_text": "Larry Ellison"}
{"answers": {"text": ["Larry Ellison", "Larry Ellison", "Larry Ellison"], "answer_start": [129, 129, 129]}, "prediction_text": "Larry Ellison"}
{"answers": {"text": ["Jon Corzine", "Jon Corzine", "Jon Corzine"], "answer_start": [217, 217, 217]}, "prediction_text": "Larry Ellison"}
{"answers": {"text": ["James O. McKinsey", "James O. McKinsey", "James O. McKinsey"], "answer_start": [312, 312, 312]}, "prediction_text": "James O. McKinsey"}
{"answers": {"text": ["Saul Alinsky", "Saul Alinsky", "Saul Alinsky"], "answer_start": [106, 106, 106]}, "prediction_text": "Saul Alinsky"}
{"answers": {"text": ["David Axelrod", "David Axelrod", "David Axelrod"], "answer_start": [195, 195, 195]}, "prediction_text": "David Axelrod"}
{"answers": {"text": ["Robert Bork", "Robert Bork", "Robert Bork"], "answer_start": [245, 245, 245]}, "prediction_text": "Eliot Ness"}
{"answers": {"text": ["Masaaki Shirakawa", "Masaaki Shirakawa", "Masaaki Shirakawa"], "answer_start": [487, 487, 487]}, "prediction_text": "Carol Moseley Braun"}
{"answers": {"text": ["Eliot Ness", "Eliot Ness", "Eliot Ness"], "answer_start": [307, 307, 307]}, "prediction_text": "Eliot Ness"}
{"answers": {"text": ["Allan Bloom", "Allan Bloom", "Allan Bloom"], "answer_start": [335, 335, 335]}, "prediction_text": "Allan Bloom"}
{"answers": {"text": ["Kurt Vonnegut", "Kurt Vonnegut", "Kurt Vonnegut"], "answer_start": [598, 598, 598]}, "prediction_text": "Kurt Vonnegut"}
{"answers": {"text": ["Lauren Oliver", "Lauren Oliver", "Lauren Oliver"], "answer_start": [69, 69, 69]}, "prediction_text": "Philip Roth"}
{"answers": {"text": ["Studs Terkel", "Studs Terkel", "Studs Terkel"], "answer_start": [371, 371, 371]}, "prediction_text": "Kurt Vonnegut"}
{"answers": {"text": ["Philip Roth", "Philip Roth", "Philip Roth"], "answer_start": [116, 116, 116]}, "prediction_text": "Philip Roth"}
{"answers": {"text": ["Philip Glass", "Philip Glass", "Philip Glass"], "answer_start": [51, 51, 51]}, "prediction_text": "Philip Glass"}
{"answers": {"text": ["Alex Seropian", "Alex Seropian", "Alex Seropian"], "answer_start": [210, 210, 210]}, "prediction_text": "Katherine Dunham"}
{"answers": {"text": ["Halo", "Halo", "Halo"], "answer_start": [187, 187, 187]}, "prediction_text": "Halo"}
{"answers": {"text": ["Ed Asner", "Ed Asner", "Ed Asner"], "answer_start": [257, 257, 257]}, "prediction_text": "Ed Asner"}
{"answers": {"text": ["Mike Nichols", "Mike Nichols", "Mike Nichols"], "answer_start": [417, 417, 417]}, "prediction_text": "Mike Nichols"}
{"answers": {"text": ["Carl Sagan", "Carl Sagan", "Carl Sagan"], "answer_start": [39, 39, 39]}, "prediction_text": "Carl Sagan"}
{"answers": {"text": ["John M. Grunsfeld", "John M. Grunsfeld", "John M. Grunsfeld"], "answer_start": [187, 187, 187]}, "prediction_text": "John M. Grunsfeld"}
{"answers": {"text": ["David Suzuki,", "David Suzuki", "David Suzuki"], "answer_start": [358, 358, 358]}, "prediction_text": "David Suzuki"}
{"answers": {"text": ["John B. Goodenough", "John B. Goodenough", "John B. Goodenough"], "answer_start": [551, 551, 551]}, "prediction_text": "John B. Goodenough"}
{"answers": {"text": ["Clair Cameron Patterson", "Clair Cameron Patterson", "Clair Cameron Patterson"], "answer_start": [646, 646, 646]}, "prediction_text": "Clair Cameron Patterson"}
{"answers": {"text": ["Milton Friedman", "Milton Friedman", "Milton Friedman"], "answer_start": [72, 72, 72]}, "prediction_text": "Thomas Sowell"}
{"answers": {"text": ["George Stigler", "George Stigler", "George Stigler"], "answer_start": [207, 207, 207]}, "prediction_text": "Margaret Thatcher"}
{"answers": {"text": ["Paul Samuelson", "Paul Samuelson", "Paul Samuelson"], "answer_start": [475, 475, 475]}, "prediction_text": "Herbert A. Simon"}
{"answers": {"text": ["Eugene Fama", "Eugene Fama", "Eugene Fama"], "answer_start": [568, 568, 568]}, "prediction_text": "Eugene Fama"}
{"answers": {"text": ["David Graeber and Donald Johanson", "David Graeber", "David Graeber and Donald Johanson"], "answer_start": [47, 47, 47]}, "prediction_text": "David Graeber, Donald Johanson, Harold Innis, Samuel Reshevsky, Samuel P. Huntington."}
{"answers": {"text": ["Samuel Reshevsky", "Samuel Reshevsky", "Samuel Reshevsky"], "answer_start": [373, 373, 373]}, "prediction_text": "Samuel Reshevsky"}
{"answers": {"text": ["Samuel P. Huntington", "Samuel P. Huntington", "Samuel P. Huntington"], "answer_start": [523, 523, 523]}, "prediction_text": "Samuel P. Huntington"}
{"answers": {"text": ["A. A. Michelson", "A. A. Michelson", "A. A. Michelson"], "answer_start": [71, 71, 71]}, "prediction_text": "A. A. Michelson"}
{"answers": {"text": ["Arthur H. Compton", "Robert A. Millikan", "Arthur H. Compton"], "answer_start": [170, 117, 170]}, "prediction_text": "Arthur H. Compton"}
{"answers": {"text": ["Enrico Fermi", "Enrico Fermi", "Enrico Fermi"], "answer_start": [230, 230, 230]}, "prediction_text": "Arthur H. Compton"}
{"answers": {"text": ["Edward Teller", "Edward Teller", "Edward Teller"], "answer_start": [278, 278, 278]}, "prediction_text": "Edward Teller"}
{"answers": {"text": ["Maria Goeppert-Mayer", "Maria Goeppert-Mayer", "Maria Goeppert-Mayer"], "answer_start": [478, 478, 478]}, "prediction_text": "Maria Goeppert-Mayer"}
{"answers": {"text": ["James Henry Breasted", "James Henry Breasted", "James Henry Breasted"], "answer_start": [45, 45, 45]}, "prediction_text": "James Henry Breasted"}
{"answers": {"text": ["Alberto Calder\u00f3n", "Alberto Calder\u00f3n", "Alberto Calder\u00f3n"], "answer_start": [81, 81, 81]}, "prediction_text": "Alberto Calder\u00f3n"}
{"answers": {"text": ["Ted Fujita", "Ted Fujita", "Ted Fujita"], "answer_start": [194, 194, 194]}, "prediction_text": "Ted Fujita"}
{"answers": {"text": ["Yuan T. Lee", "Yuan T. Lee", "Glenn T. Seaborg"], "answer_start": [294, 294, 215]}, "prediction_text": "Ted Fujita"}
{"answers": {"text": ["Charles Brenton Huggins and Janet Rowley", "Charles Brenton Huggins and Janet Rowley", "Charles Brenton Huggins and Janet Rowley"], "answer_start": [414, 414, 414]}, "prediction_text": "Charles Brenton Huggins and Janet Rowley"}
{"answers": {"text": ["Raghuram Rajan", "Raghuram Rajan", "Raghuram Rajan"], "answer_start": [473, 473, 473]}, "prediction_text": "Raghuram Rajan"}
{"answers": {"text": ["Goldman Sachs", "Goldman Sachs", "Goldman Sachs"], "answer_start": [549, 549, 549]}, "prediction_text": "Obama's Council of Economic Advisors"}
{"answers": {"text": ["David Bevington", "David Bevington", "John Mearsheimer and Robert Pape"], "answer_start": [704, 704, 755]}, "prediction_text": "David Bevington"}
{"answers": {"text": ["John Mearsheimer and Robert Pape", "John Mearsheimer and Robert Pape"], "answer_start": [755, 755]}, "prediction_text": "David Bevington, Robert Pape, John Mearsheimer, Robert Pape."}
{"answers": {"text": ["Neil Shubin and Paul Sereno", "Neil Shubin and Paul Sereno", "Neil Shubin and Paul Sereno"], "answer_start": [107, 107, 107]}, "prediction_text": "Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin, Neil Shubin,"}
{"answers": {"text": ["Yu\u00e1n Ch\u00e1o", "Yu\u00e1n Ch\u00e1o", "\u5143\u671d"], "answer_start": [39, 39, 27]}, "prediction_text": "Yuan dynasty"}
{"answers": {"text": ["the Great Yuan", "the Great Yuan", "the Great Yuan"], "answer_start": [62, 62, 62]}, "prediction_text": "Yuan dynasty"}
{"answers": {"text": ["Kublai Khan", "Kublai Khan", "Kublai Khan"], "answer_start": [196, 196, 196]}, "prediction_text": "Kublai Khan"}
{"answers": {"text": ["Kublai Khan", "Kublai Khan", "Kublai Khan"], "answer_start": [196, 196, 196]}, "prediction_text": "Kublai Khan"}
{"answers": {"text": ["1271", "1271", "1271"], "answer_start": [351, 351, 351]}, "prediction_text": "1271"}
{"answers": {"text": ["Mongol Empire", "Mongol Empire", "Mongol Empire"], "answer_start": [55, 55, 55]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["Song dynasty", "Mongol Empire", "the Song dynasty"], "answer_start": [291, 55, 287]}, "prediction_text": "Three Sovereigns and Five Emperors"}
{"answers": {"text": ["Ming dynasty", "Ming dynasty", "the Ming dynasty"], "answer_start": [322, 322, 318]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["Genghis Khan", "Genghis Khan", "Genghis Khan"], "answer_start": [410, 410, 410]}, "prediction_text": "Genghis Khan"}
{"answers": {"text": ["1271", "1271", "1271"], "answer_start": [3, 3, 3]}, "prediction_text": "1271"}
{"answers": {"text": ["the Commentaries on the Classic of Changes (I Ching)", "the Commentaries on the Classic of Changes"], "answer_start": [228, 228]}, "prediction_text": "Commentaries on the Classic of Changes (I Ching) section regarding Qi\u00e1n (\u4e7e) in the Commentaries on the Classic of Changes section regarding the Yuan dynasty."}
{"answers": {"text": ["Dai \u00d6n Ulus, also rendered as Ikh Yuan \u00dcls or Yekhe Yuan Ulus", "Dai \u00d6n Ulus", "Dai \u00d6n Ulus"], "answer_start": [351, 351, 351]}, "prediction_text": "\"Mongol dynasty\" or \"Khanate of the Great Khan\""}
{"answers": {"text": ["Great Mongol State", "Great Mongol State", "Great Mongol State"], "answer_start": [514, 514, 514]}, "prediction_text": "\"Great Mongol State\""}
{"answers": {"text": ["Great Khan", "Great Khan", "Great Khan"], "answer_start": [1012, 1012, 1012]}, "prediction_text": "Great Khan"}
{"answers": {"text": ["Mongol and Turkic tribes", "Mongol and Turkic tribes", "the Mongol and Turkic tribes"], "answer_start": [24, 24, 20]}, "prediction_text": "Mongol and Turkic tribes"}
{"answers": {"text": ["1206", "1206", "1206"], "answer_start": [89, 89, 89]}, "prediction_text": "1206"}
{"answers": {"text": ["\u00d6gedei Khan", "\u00d6gedei Khan", "\u00d6gedei Khan"], "answer_start": [196, 196, 196]}, "prediction_text": "\u00d6gedei Khan"}
{"answers": {"text": ["1251", "1251", "1251"], "answer_start": [627, 627, 627]}, "prediction_text": "1206"}
{"answers": {"text": ["nephew", "nephew", "nephew"], "answer_start": [319, 319, 319]}, "prediction_text": "Kublai Khan's relation to Ogedei Khan was not mentioned in the context."}
{"answers": {"text": ["the Jin", "Jin", "the Jin"], "answer_start": [69, 73, 69]}, "prediction_text": "The Khitan Generals Shimobeidier, Tabuyir, and Xiaozhacizhizhongxi."}
{"answers": {"text": ["Xiao Zhala", "Xiao Zhala", "Xiao Zhala"], "answer_start": [155, 155, 155]}, "prediction_text": "Shi Tianze"}
{"answers": {"text": ["Shi Tianze, Liu Heima", "Shi Tianze, Liu Heima", "Shi Tianze, Liu Heima"], "answer_start": [103, 103, 103]}, "prediction_text": "Shi Tianze"}
{"answers": {"text": ["10,000", "10,000", "10,000"], "answer_start": [424, 424, 424]}, "prediction_text": "10,000 troops"}
{"answers": {"text": ["3", "three"], "answer_start": [377, 552]}, "prediction_text": "4 Khitan Tumens"}
{"answers": {"text": ["Han Chinese", "Han Chinese", "Han Chinese"], "answer_start": [17, 17, 17]}, "prediction_text": "Han Chinese"}
{"answers": {"text": ["Jin dynasty", "Jin dynasty", "Jin"], "answer_start": [46, 46, 46]}, "prediction_text": "Jin dynasty"}
{"answers": {"text": ["between Han and Jurchen", "marriage between Han and Jurchen", "Han and Jurchen"], "answer_start": [80, 71, 88]}, "prediction_text": "Han and Jurchen marriage"}
{"answers": {"text": ["Shi Bingzhi", "Shi Bingzhi", "Shi Bingzhi"], "answer_start": [147, 147, 147]}, "prediction_text": "Shi Bingzhi"}
{"answers": {"text": ["Song dynasty", "Song dynasty", "the Song dynasty"], "answer_start": [1141, 1141, 1137]}, "prediction_text": "Song dynasty"}
{"answers": {"text": ["M\u00f6ngke Khan", "M\u00f6ngke Khan", "M\u00f6ngke Khan"], "answer_start": [0, 0, 0]}, "prediction_text": "M\u00f6ngke Khan"}
{"answers": {"text": ["southern China", "southern China", "in southern China"], "answer_start": [78, 78, 75]}, "prediction_text": "Southern China"}
{"answers": {"text": ["1259", "1259", "in 1259"], "answer_start": [226, 226, 223]}, "prediction_text": "1259"}
{"answers": {"text": ["Ariq B\u00f6ke", "Ariq B\u00f6ke", "Ariq B\u00f6ke"], "answer_start": [333, 333, 333]}, "prediction_text": "Ariq B\u00f6ke"}
{"answers": {"text": ["Zhongtong", "Zhongtong. Ariq B\u00f6ke", "Zhongtong"], "answer_start": [809, 809, 809]}, "prediction_text": "Zhongtong"}
{"answers": {"text": ["Ogedei", "Ogedei", "Ogedei"], "answer_start": [61, 61, 61]}, "prediction_text": "Kaidu's grandson"}
{"answers": {"text": ["south", "the south", "the western frontier"], "answer_start": [235, 231, 128]}, "prediction_text": "South of Kublai's domain"}
{"answers": {"text": ["Wonjong", "prince Wonjong", "prince Wonjong"], "answer_start": [319, 312, 312]}, "prediction_text": "Wonjong"}
{"answers": {"text": ["northeast", "northeast", "the northeast"], "answer_start": [261, 261, 257]}, "prediction_text": "South of Kublai's domain"}
{"answers": {"text": ["1262", "1262", "1262"], "answer_start": [523, 523, 523]}, "prediction_text": "1262"}
{"answers": {"text": ["preserving Mongol interests in China and satisfying the demands of his Chinese subjects", "preserving Mongol interests in China and satisfying the demands of his Chinese subjects", "preserving Mongol interests in China and satisfying the demands of his Chinese subjects"], "answer_start": [56, 56, 56]}, "prediction_text": "Mongol interests in China and satisfying Chinese demands."}
{"answers": {"text": ["local administrative structure of past Chinese dynasties", "local administrative structure", "local"], "answer_start": [390, 390, 390]}, "prediction_text": "Local administrative structure"}
{"answers": {"text": ["Han Chinese", "Han Chinese", "the Han Chinese"], "answer_start": [601, 601, 597]}, "prediction_text": "Han Chinese"}
{"answers": {"text": ["three, later four", "four", "three"], "answer_start": [565, 578, 565]}, "prediction_text": "Three divisions"}
{"answers": {"text": ["salt and iron", "salt and iron", "salt and iron"], "answer_start": [325, 325, 325]}, "prediction_text": "Salt and iron"}
{"answers": {"text": ["Karakorum", "Karakorum", "Karakorum"], "answer_start": [51, 51, 51]}, "prediction_text": "Karakorum in Mongolia"}
{"answers": {"text": ["Khanbaliq", "Khanbaliq", "Khanbaliq"], "answer_start": [76, 76, 76]}, "prediction_text": "Khanbaliq"}
{"answers": {"text": ["1264", "1264", "1264"], "answer_start": [89, 89, 89]}, "prediction_text": "1264"}
{"answers": {"text": ["Zhongdu", "Zhongdu", "Zhongdu"], "answer_start": [151, 151, 151]}, "prediction_text": "Zhongdu"}
{"answers": {"text": ["Confucian propriety and ancestor veneration", "Confucian propriety and ancestor veneration", "Confucian propriety and ancestor veneration"], "answer_start": [889, 889, 889]}, "prediction_text": "Confucian propriety rituals"}
{"answers": {"text": ["commercial, scientific, and cultural", "commercial, scientific, and cultural", "commercial, scientific, and cultural"], "answer_start": [21, 21, 21]}, "prediction_text": "Commercial, scientific, cultural growth."}
{"answers": {"text": ["Mongol peace", "Mongol peace", "Mongol peace"], "answer_start": [316, 316, 316]}, "prediction_text": "Mongol peace"}
{"answers": {"text": ["southern China", "southern China", "southern China"], "answer_start": [456, 456, 456]}, "prediction_text": "Southern China"}
{"answers": {"text": ["Daidu in the north", "Daidu", "Daidu"], "answer_start": [474, 474, 474]}, "prediction_text": "Daidu"}
{"answers": {"text": ["Marco Polo", "Marco Polo", "Marco Polo"], "answer_start": [615, 615, 615]}, "prediction_text": "Christopher Columbus"}
{"answers": {"text": ["the Song Emperor", "Song Emperor", "the Song Emperor to Quzhou"], "answer_start": [117, 121, 117]}, "prediction_text": "Confucius's descendants"}
{"answers": {"text": ["1115", "1115", "1115"], "answer_start": [186, 186, 186]}, "prediction_text": "1115\u20131234"}
{"answers": {"text": ["1234", "1234", "1234"], "answer_start": [191, 191, 191]}, "prediction_text": "1234"}
{"answers": {"text": ["Kong Duancao", "Kong Duancao", "Kong Duancao"], "answer_start": [243, 243, 243]}, "prediction_text": "Kong Duancao"}
{"answers": {"text": ["30,000", "30,000", "30,000"], "answer_start": [777, 777, 777]}, "prediction_text": "30,000 people"}
{"answers": {"text": ["northern China", "northern China", "northern China"], "answer_start": [38, 38, 38]}, "prediction_text": "Northern China"}
{"answers": {"text": ["between 1268 and 1273", "between 1268 and 1273", "between 1268 and 1273"], "answer_start": [246, 246, 246]}, "prediction_text": "1268"}
{"answers": {"text": ["Yangzi River basin", "Yangzi River basin", "the Song dynasty"], "answer_start": [318, 318, 189]}, "prediction_text": "Yangzi River basin"}
{"answers": {"text": ["Hangzhou", "Hangzhou", "Hangzhou"], "answer_start": [445, 445, 445]}, "prediction_text": "Hangzhou"}
{"answers": {"text": ["drowned", "drowned", "drowned"], "answer_start": [675, 675, 675]}, "prediction_text": "He drowned in 1279."}
{"answers": {"text": ["after 1279", "after 1279", "after 1279"], "answer_start": [49, 49, 49]}, "prediction_text": "1279"}
{"answers": {"text": ["an inauspicious typhoon", "inauspicious typhoon", "inauspicious typhoon"], "answer_start": [343, 346, 346]}, "prediction_text": "A tropical terrain and a tropical terrain unsuitable for mounted warfare."}
{"answers": {"text": ["Annam (Dai Viet)", "Annam", "Annam"], "answer_start": [641, 641, 641]}, "prediction_text": "Fujian region"}
{"answers": {"text": ["Battle of B\u1ea1ch \u0110\u1eb1ng", "Battle of B\u1ea1ch \u0110\u1eb1ng", "the Battle of B\u1ea1ch \u0110\u1eb1ng"], "answer_start": [698, 698, 694]}, "prediction_text": "Battle of B\u1ea1ch \u0110\u1eb1ng"}
{"answers": {"text": ["1288", "1288", "1288"], "answer_start": [719, 719, 719]}, "prediction_text": "1288"}
{"answers": {"text": ["1253", "1253", "1253"], "answer_start": [34, 34, 34]}, "prediction_text": "1253"}
{"answers": {"text": ["his eldest son, Zhenjin", "Zhenjin", "Zhenjin"], "answer_start": [420, 436, 436]}, "prediction_text": "Zhenjin"}
{"answers": {"text": ["before Kublai in 1285", "1285", "1285"], "answer_start": [478, 495, 495]}, "prediction_text": "1285"}
{"answers": {"text": ["Emperor Chengzong", "Emperor Chengzong", "Emperor Chengzong"], "answer_start": [640, 640, 640]}, "prediction_text": "Emperor Chengzong"}
{"answers": {"text": ["1294 to 1307", "1294 to 1307", "from 1294 to 1307"], "answer_start": [664, 664, 659]}, "prediction_text": "1294 to 1307"}
{"answers": {"text": ["Buyantu Khan", "Buyantu Khan", "Buyantu Khan"], "answer_start": [25, 25, 25]}, "prediction_text": "Buyantu Khan"}
{"answers": {"text": ["actively support and adopt mainstream Chinese culture", "actively support and adopt mainstream Chinese culture", "adopt mainstream Chinese culture"], "answer_start": [111, 111, 132]}, "prediction_text": "Supported mainstream Chinese culture"}
{"answers": {"text": ["Li Meng", "Li Meng", "Li Meng"], "answer_start": [256, 256, 256]}, "prediction_text": "Li Meng"}
{"answers": {"text": ["the Department of State Affairs", "Department of State Affairs", "the Department of State Affairs"], "answer_start": [338, 342, 338]}, "prediction_text": "Department of State Affairs"}
{"answers": {"text": ["1313", "1313", "1313"], "answer_start": [472, 472, 472]}, "prediction_text": "1313"}
{"answers": {"text": ["Gegeen Khan", "Gegeen Khan", "Gegeen Khan"], "answer_start": [8, 8, 8]}, "prediction_text": "Emperor Gegeen Khan"}
{"answers": {"text": ["1321 to 1323", "1321 to 1323", "from 1321 to 1323"], "answer_start": [85, 85, 80]}, "prediction_text": "1321 to 1323"}
{"answers": {"text": ["Baiju", "Baiju", "Baiju"], "answer_start": [248, 248, 248]}, "prediction_text": "Baiju"}
{"answers": {"text": ["\"the comprehensive institutions of the Great Yuan\"", "the comprehensive institutions of the Great Yuan", "the comprehensive institutions of the Great Yuan"], "answer_start": [310, 311, 311]}, "prediction_text": "Comprehensive institutions of the Yuan dynasty"}
{"answers": {"text": ["five", "five", "five"], "answer_start": [517, 517, 517]}, "prediction_text": "Five princes"}
{"answers": {"text": ["Shangdu", "Shangdu", "Shangdu"], "answer_start": [25, 25, 25]}, "prediction_text": "Shangdu"}
{"answers": {"text": ["the War of the Two Capitals", "War of the Two Capitals", "the War of the Two Capitals"], "answer_start": [490, 494, 490]}, "prediction_text": "War of the Two Capitals"}
{"answers": {"text": ["four days", "four days", "four days"], "answer_start": [712, 712, 712]}, "prediction_text": "Four days"}
{"answers": {"text": ["El Tem\u00fcr", "El Tem\u00fcr"], "answer_start": [795, 795]}, "prediction_text": "El Tem\u00fcr"}
{"answers": {"text": ["Tugh Tem\u00fcr", "Tugh Tem\u00fcr", "Tugh Tem\u00fcr"], "answer_start": [809, 809, 743]}, "prediction_text": "Tugh Tem\u00fcr"}
{"answers": {"text": ["his cultural contribution", "his cultural contribution", "his cultural contribution"], "answer_start": [88, 88, 88]}, "prediction_text": "Adopted Confucianism and promoting Chinese cultural values."}
{"answers": {"text": ["Academy of the Pavilion of the Star of Literature", "Academy of the Pavilion of the Star of Literature", "Academy of the Pavilion of the Star of Literature"], "answer_start": [281, 281, 281]}, "prediction_text": "Academy of the Pavilion of the Star of Literature (Chinese: \u594e\u7ae0\u95a3\u5b78\u58eb\u9662)"}
{"answers": {"text": ["spring of 1329", "1329", "the spring of 1329"], "answer_start": [375, 385, 371]}, "prediction_text": "1329"}
{"answers": {"text": ["Jingshi Dadian", "Jingshi Dadian", "Jingshi Dadian"], "answer_start": [704, 704, 704]}, "prediction_text": "Jingshi Dadian (Chinese: \u7d93\u4e16\u5927\u5178)"}
{"answers": {"text": ["supported Zhu Xi's Neo-Confucianism and also devoted himself in Buddhism", "Buddhism", "Neo-Confucianism and also devoted himself in Buddhism"], "answer_start": [747, 811, 766]}, "prediction_text": "Neo-Confucianism"}
{"answers": {"text": ["1332", "1332", "1332"], "answer_start": [33, 33, 33]}, "prediction_text": "1332"}
{"answers": {"text": ["Emperor Ningzong", "Emperor Ningzong", "Emperor Ningzong"], "answer_start": [74, 74, 74]}, "prediction_text": "Rinchinbal (Emperor Ningzong)"}
{"answers": {"text": ["13", "13", "13"], "answer_start": [111, 111, 111]}, "prediction_text": "1332"}
{"answers": {"text": ["nine", "nine", "nine"], "answer_start": [171, 171, 171]}, "prediction_text": "Nine successors"}
{"answers": {"text": ["Liao, Jin, and Song", "Liao, Jin, and Song", "the Liao, Jin, and Song"], "answer_start": [872, 872, 868]}, "prediction_text": "Liao, Jin, and Song dynasties"}
{"answers": {"text": ["struggle, famine, and bitterness", "struggle, famine, and bitterness", "struggle, famine, and bitterness"], "answer_start": [51, 51, 51]}, "prediction_text": "Fulfillment of administration, dissension, unrest."}
{"answers": {"text": ["Mongols beyond the Middle Kingdom saw them as too Chinese", "saw them as too Chinese"], "answer_start": [202, 236]}, "prediction_text": "They lost influence in China."}
{"answers": {"text": ["both the army and the populace", "army and the populace", "the army and the populace"], "answer_start": [455, 464, 460]}, "prediction_text": "The army and the populace"}
{"answers": {"text": ["Outlaws ravaged the country", "Outlaws", "Outlaws"], "answer_start": [532, 532, 532]}, "prediction_text": "Outlaws"}
{"answers": {"text": ["administration", "administration", "administration"], "answer_start": [414, 414, 414]}, "prediction_text": "Administration"}
{"answers": {"text": ["From the late 1340s onwards", "1340s onwards", "the late 1340s"], "answer_start": [0, 14, 5]}, "prediction_text": "1340s"}
{"answers": {"text": ["the Red Turban Rebellion", "Red Turban Rebellion", "Red Turban Rebellion"], "answer_start": [237, 241, 241]}, "prediction_text": "Red Turban Rebellion"}
{"answers": {"text": ["fear of betrayal", "fear of betrayal", "fear of betrayal"], "answer_start": [420, 420, 420]}, "prediction_text": "Fear of betrayal."}
{"answers": {"text": ["the Red Turban rebels", "Red Turban rebels", "the Red Turban rebels"], "answer_start": [357, 361, 357]}, "prediction_text": "Red Turban rebels"}
{"answers": {"text": ["1368\u20131644", "1368\u20131644", "1368\u20131644"], "answer_start": [849, 849, 849]}, "prediction_text": "1368\u20131644"}
{"answers": {"text": ["The political unity of China and much of central Asia", "political unity of China and much of central Asia", "political unity"], "answer_start": [186, 190, 190]}, "prediction_text": "Political unity and cultural exchange"}
{"answers": {"text": ["The Mongols' extensive West Asian and European contacts", "The Mongols' extensive West Asian and European contacts"], "answer_start": [278, 278]}, "prediction_text": "Political unity and trade between East and West."}
{"answers": {"text": ["the Ilkhanate", "Ilkhanate"], "answer_start": [627, 631]}, "prediction_text": "Ilkhanate"}
{"answers": {"text": ["carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton"], "answer_start": [966, 966, 966]}, "prediction_text": "carrots, turnips, new varieties of lemons, eggplants, melons, high-quality granulated sugar, and cotton."}
{"answers": {"text": ["Western", "Western", "Western"], "answer_start": [0, 0, 0]}, "prediction_text": "Western musical instruments"}
{"answers": {"text": ["Nestorianism and Roman Catholicism", "Nestorianism and Roman Catholicism", "Nestorianism and Roman Catholicism"], "answer_start": [217, 217, 217]}, "prediction_text": "Taoism"}
{"answers": {"text": ["Taoism", "Taoism", "Taoism"], "answer_start": [349, 349, 349]}, "prediction_text": "Taoism"}
{"answers": {"text": ["Confucian", "Confucian governmental practices and examinations", "Confucian"], "answer_start": [432, 432, 432]}, "prediction_text": "Advances in travel literature, cartography, geography, and scientific education."}
{"answers": {"text": ["travel literature, cartography, geography, and scientific education", "travel literature, cartography, geography, and scientific education", "literature, cartography, geography, and scientific education"], "answer_start": [715, 715, 722]}, "prediction_text": "Travel literature, cartography, geography, and scientific education."}
{"answers": {"text": ["Marco Polo", "Marco Polo", "Marco Polo"], "answer_start": [135, 135, 135]}, "prediction_text": "Venetian Marco Polo"}
{"answers": {"text": ["Cambaluc", "Cambaluc", "Cambaluc"], "answer_start": [177, 177, 177]}, "prediction_text": "\"Cambaluc\""}
{"answers": {"text": ["Travels of Marco Polo", "Travels of Marco Polo", "the Travels of Marco Polo"], "answer_start": [350, 350, 346]}, "prediction_text": "Travels of Marco Polo"}
{"answers": {"text": ["Il milione", "Il milione", "Il milione"], "answer_start": [297, 297, 297]}, "prediction_text": "Il milione"}
{"answers": {"text": ["through contact with Persian traders", "through contact with Persian traders", "through contact with Persian traders"], "answer_start": [753, 753, 753]}, "prediction_text": "Lack of mentioning the Great Wall of China."}
{"answers": {"text": ["Guo Shoujing", "Guo Shoujing", "Guo Shoujing"], "answer_start": [111, 111, 111]}, "prediction_text": "astronomer Guo Shoujing"}
{"answers": {"text": ["26 seconds off the modern Gregorian calendar", "365.2425 days of the year", "365.2425 days of the year"], "answer_start": [290, 248, 248]}, "prediction_text": "26 seconds off Gregorian calendar's measurement."}
{"answers": {"text": ["granaries were ordered built throughout the empire", "granaries were ordered built throughout the empire", "granaries were ordered built"], "answer_start": [448, 448, 448]}, "prediction_text": "Build granaries and ordered new palace grounds."}
{"answers": {"text": ["Beijing", "Beijing", "Beijing"], "answer_start": [644, 644, 644]}, "prediction_text": "Beijing"}
{"answers": {"text": ["sorghum", "sorghum", "sorghum"], "answer_start": [1071, 1071, 1071]}, "prediction_text": "Sorghum"}
{"answers": {"text": ["non-native Chinese people", "non-native Chinese people", "non-native Chinese"], "answer_start": [41, 41, 41]}, "prediction_text": "Non-native Chinese people"}
{"answers": {"text": ["the Eternal Heaven", "Eternal Heaven", "the Eternal Heaven"], "answer_start": [230, 234, 230]}, "prediction_text": "Eternal Heaven"}
{"answers": {"text": ["Song", "Song dynasty", "the Song dynasty"], "answer_start": [641, 641, 637]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["Ming", "Ming dynasty", "the Ming dynasty"], "answer_start": [662, 662, 658]}, "prediction_text": "Mongol Empire"}
{"answers": {"text": ["a period of foreign domination", "continuation of the Mongol Empire", "a period of foreign domination"], "answer_start": [1239, 159, 1239]}, "prediction_text": "A period of foreign domination."}
{"answers": {"text": ["Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists", "Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists.", "the Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists"], "answer_start": [113, 113, 109]}, "prediction_text": "Han Chinese, Khitans, Jurchens, Mongols, Tibetan Buddhists."}
{"answers": {"text": ["Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties", "native Chinese dynasties", "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties"], "answer_start": [478, 292, 478]}, "prediction_text": "Khitans, Jurchens, Mongols, and Tibetan Buddhists."}
{"answers": {"text": ["Liu Bingzhong and Yao Shu", "Liu Bingzhong and Yao Shu", "Liu Bingzhong and Yao Shu"], "answer_start": [565, 565, 565]}, "prediction_text": "Liu Bingzhong and Yao Shu"}
{"answers": {"text": ["tripartite", "tripartite division", "tripartite"], "answer_start": [787, 787, 787]}, "prediction_text": "Civil and military jurisdiction"}
{"answers": {"text": ["civil, military, and censorial offices", "civil, military, and censorial", "civil, military, and censorial offices"], "answer_start": [826, 826, 826]}, "prediction_text": "Central Secretariat, Privy Council, Censorate."}
{"answers": {"text": ["the Privy Council", "Privy Council", "the Privy Council"], "answer_start": [785, 789, 785]}, "prediction_text": "Privy Council"}
{"answers": {"text": ["since the Sui and Tang dynasties", "Sui and Tang dynasties", "since the Sui and Tang dynasties"], "answer_start": [110, 120, 110]}, "prediction_text": "Since the Sui and Tang dynasties"}
{"answers": {"text": ["Mongols and Semuren", "Mongols and Semuren", "Mongols and Semuren"], "answer_start": [451, 451, 451]}, "prediction_text": "Members of more than one ethnic group"}
{"answers": {"text": ["the Ministry of War", "Ministry of War", "the Ministry of War"], "answer_start": [669, 673, 669]}, "prediction_text": "Privy Council"}
{"answers": {"text": ["1269", "1269", "1269"], "answer_start": [23, 23, 23]}, "prediction_text": "1269"}
{"answers": {"text": ["Mongolian, Tibetan, and Chinese", "Mongolian, Tibetan, and Chinese", "Mongolian, Tibetan, and Chinese"], "answer_start": [81, 81, 81]}, "prediction_text": "Mongolian, Tibetan, and Chinese languages."}
{"answers": {"text": ["could not master written Chinese, but they could generally converse well", "could not master written Chinese, but they could generally converse well", "well"], "answer_start": [202, 202, 270]}, "prediction_text": "They could converse well in the language."}
{"answers": {"text": ["Tugh Temur", "Tugh Temur", "Tugh Temur"], "answer_start": [456, 456, 456]}, "prediction_text": "Tugh Temur"}
{"answers": {"text": ["Emperor Wenzong", "Emperor Wenzong", "Wenzong"], "answer_start": [723, 723, 731]}, "prediction_text": "Onggirat"}
{"answers": {"text": ["1290", "1290", "1290"], "answer_start": [283, 283, 283]}, "prediction_text": "1290"}
{"answers": {"text": ["1291", "1291", "1291"], "answer_start": [430, 430, 430]}, "prediction_text": "1291"}
{"answers": {"text": ["income from the harvests of their Chinese tenants", "harvests of their Chinese tenants", "harvests of their Chinese tenants"], "answer_start": [114, 130, 130]}, "prediction_text": "From harvests of their Chinese tenants"}
{"answers": {"text": ["painting, mathematics, calligraphy, poetry, and theater", "painting, mathematics, calligraphy, poetry, and theater", "painting, mathematics, calligraphy, poetry, and theater"], "answer_start": [151, 151, 151]}, "prediction_text": "Painting, poetry, calligraphy, theater."}
{"answers": {"text": ["painting, poetry, and calligraphy", "painting, poetry, and calligraphy", "painting, poetry, and calligraphy"], "answer_start": [294, 294, 294]}, "prediction_text": "Painting, poetry, calligraphy."}
{"answers": {"text": ["Song", "Song", "the Song dynasty"], "answer_start": [658, 658, 654]}, "prediction_text": "Song dynasty"}
{"answers": {"text": ["the qu", "the qu", "qu"], "answer_start": [934, 934, 938]}, "prediction_text": "Qu"}
{"answers": {"text": ["zaju", "zaju", "zaju"], "answer_start": [1281, 1281, 1281]}, "prediction_text": "Qu"}
{"answers": {"text": ["western", "Yuan dynasty", "western"], "answer_start": [221, 243, 221]}, "prediction_text": "Western khanates"}
{"answers": {"text": ["Buddhism, especially the Tibetan variants", "Buddhism", "Buddhism"], "answer_start": [345, 345, 345]}, "prediction_text": "Buddhism"}
{"answers": {"text": ["Tibetan Buddhism", "Tibetan Buddhism", "Tibetan Buddhism"], "answer_start": [401, 401, 401]}, "prediction_text": "Tibetan Buddhism"}
{"answers": {"text": ["Bureau of Buddhist and Tibetan Affairs", "Bureau of Buddhist and Tibetan Affairs", "the Bureau of Buddhist and Tibetan Affairs"], "answer_start": [526, 526, 522]}, "prediction_text": "Bureau of Buddhist and Tibetan Affairs (Xuanzheng Yuan)"}
{"answers": {"text": ["Sakya", "Sakya sect", "Sakya sect"], "answer_start": [710, 710, 710]}, "prediction_text": "Sakya sect"}
{"answers": {"text": ["1249", "1249", "1249"], "answer_start": [110, 110, 110]}, "prediction_text": "1249-1314"}
{"answers": {"text": ["1314", "1314", "1314"], "answer_start": [115, 115, 115]}, "prediction_text": "1314"}
{"answers": {"text": ["matrices", "matrices", "matrices"], "answer_start": [240, 240, 240]}, "prediction_text": "Matrices"}
{"answers": {"text": ["polynomial algebra", "polynomial algebra", "polynomial algebra"], "answer_start": [12, 12, 12]}, "prediction_text": "Polynomial algebra"}
{"answers": {"text": ["1303", "1303", "1303"], "answer_start": [440, 440, 440]}, "prediction_text": "1303"}
{"answers": {"text": ["applied mathematics to the construction of calendars", "applied mathematics", "applied mathematics"], "answer_start": [13, 13, 13]}, "prediction_text": "Applied mathematics to calendars."}
{"answers": {"text": ["a cubic interpolation formula", "cubic interpolation formula", "derived a cubic interpolation formula"], "answer_start": [162, 164, 154]}, "prediction_text": "Mathematics"}
{"answers": {"text": ["Shoushi Li", "\u6388\u6642\u66a6", "\u6388\u6642\u66a6"], "answer_start": [245, 257, 257]}, "prediction_text": "Calendar for Fixing the Seasons"}
{"answers": {"text": ["Calendar for Fixing the Seasons", "Calendar for Fixing the Seasons", "Calendar for Fixing the Seasons"], "answer_start": [265, 265, 265]}, "prediction_text": "Calendar for Fixing the Seasons"}
{"answers": {"text": ["1281", "1281", "1281"], "answer_start": [318, 318, 318]}, "prediction_text": "1281"}
{"answers": {"text": ["non-Mongol physicians", "non-Mongol physicians", "non-Mongol physicians"], "answer_start": [87, 87, 87]}, "prediction_text": "Traditional Mongol shamans"}
{"answers": {"text": ["herbal remedies", "herbal", "herbal remedies"], "answer_start": [212, 212, 212]}, "prediction_text": "herbal remedies"}
{"answers": {"text": ["spiritual cures", "spiritual", "spiritual"], "answer_start": [262, 262, 262]}, "prediction_text": "Traditional Mongol shamans used herbal remedies."}
{"answers": {"text": ["Imperial Academy of Medicine", "Imperial Academy of Medicine", "Imperial Academy of Medicine"], "answer_start": [421, 421, 421]}, "prediction_text": "Imperial Academy of Medicine"}
{"answers": {"text": ["it ensured a high income and medical ethics were compatible with Confucian virtues", "it ensured a high income and medical ethics were compatible with Confucian virtues", "it ensured a high income and medical ethics were compatible with Confucian virtues"], "answer_start": [580, 580, 580]}, "prediction_text": "A high income and ethical standards."}
{"answers": {"text": ["four", "Four", "Four"], "answer_start": [117, 47, 47]}, "prediction_text": "Four schools"}
{"answers": {"text": ["inherited from the Jin dynasty", "inherited from the Jin dynasty", "inherited from the Jin dynasty"], "answer_start": [81, 81, 81]}, "prediction_text": "Yuan inherited the Yuan dynasty's intellectual foundation."}
{"answers": {"text": ["Chinese physicians were brought along military campaigns by the Mongols", "to other parts of the empire", "Under the Mongols"], "answer_start": [331, 301, 242]}, "prediction_text": "Through military campaigns"}
{"answers": {"text": ["acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs", "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs", "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs"], "answer_start": [473, 473, 473]}, "prediction_text": "Acupuncture, moxibustion, pulse diagnosis, herbal drugs and elixirs."}
{"answers": {"text": ["1347", "1347", "1347"], "answer_start": [711, 711, 711]}, "prediction_text": "1347"}
{"answers": {"text": ["Muslim medicine", "Muslim medicine", "Muslim medicine"], "answer_start": [136, 136, 136]}, "prediction_text": "Muslim medicine"}
{"answers": {"text": ["Jesus the Interpreter", "Jesus the Interpreter", "Jesus the Interpreter"], "answer_start": [177, 177, 177]}, "prediction_text": "Kublai (1263)"}
{"answers": {"text": ["1263", "1263", "1263"], "answer_start": [241, 241, 241]}, "prediction_text": "1263"}
{"answers": {"text": ["its humoral system", "its humoral system", "humoral system"], "answer_start": [451, 451, 455]}, "prediction_text": "Humoral system"}
{"answers": {"text": ["yin-yang and wuxing", "yin-yang and wuxing", "yin-yang and wuxing philosophy"], "answer_start": [487, 487, 487]}, "prediction_text": "Yin-yang and wuxing"}
{"answers": {"text": ["through Kingdom of Qocho and Tibetan intermediaries", "through Kingdom of Qocho and Tibetan intermediaries", "through Kingdom of Qocho and Tibetan intermediaries"], "answer_start": [116, 116, 116]}, "prediction_text": "Through Kingdom of Qocho and Tibetan intermediaries."}
{"answers": {"text": ["Wang Zhen", "Wang Zhen", "Wang Zhen"], "answer_start": [197, 197, 197]}, "prediction_text": "Wang Zhen"}
{"answers": {"text": ["in the 12th century", "12th century", "the 12th century"], "answer_start": [284, 291, 287]}, "prediction_text": "12th century"}
{"answers": {"text": ["T\u00f6regene Khatun", "T\u00f6regene Khatun", "T\u00f6regene Khatun"], "answer_start": [462, 462, 462]}, "prediction_text": "\u00d6gedei's wife"}
{"answers": {"text": ["1273", "1273", "In 1273"], "answer_start": [557, 557, 554]}, "prediction_text": "1273"}
{"answers": {"text": ["chao", "chao", "the chao"], "answer_start": [68, 68, 64]}, "prediction_text": "Chao"}
{"answers": {"text": ["bark of mulberry trees", "bark of mulberry trees", "bark of mulberry trees"], "answer_start": [127, 127, 127]}, "prediction_text": "Mulberry trees"}
{"answers": {"text": ["1275", "1275", "1275"], "answer_start": [242, 242, 242]}, "prediction_text": "1275"}
{"answers": {"text": ["woodblocks", "woodblocks", "woodblocks"], "answer_start": [176, 176, 176]}, "prediction_text": "Mulberry trees"}
{"answers": {"text": ["1294", "1294", "1294"], "answer_start": [545, 545, 545]}, "prediction_text": "1294"}
{"answers": {"text": ["patrimonial feudalism", "patrimonial feudalism", "patrimonial feudalism"], "answer_start": [111, 111, 111]}, "prediction_text": "Mongolian patrimonial feudalism and Chinese autocratic-bureaucratic system."}
{"answers": {"text": ["traditional Chinese autocratic-bureaucratic system", "autocratic-bureaucratic", "autocratic-bureaucratic system"], "answer_start": [141, 161, 161]}, "prediction_text": "Mongolian patrimonial feudalism and Chinese autocratic-bureaucratic system."}
{"answers": {"text": ["allied groups from Central Asia and the western end of the empire", "various allied groups from Central Asia and the western end of the empire", "various allied groups"], "answer_start": [474, 466, 466]}, "prediction_text": "Various allied groups from Central Asia and the western end of the empire."}
{"answers": {"text": ["colonial", "somewhat strong \"colonial\" coloration", "colonial"], "answer_start": [662, 645, 662]}, "prediction_text": "A \"colonial\" coloration."}
{"answers": {"text": ["Ilkhanate", "Ilkhanate", "reaching the highest-post in the government"], "answer_start": [1130, 1130, 1028]}, "prediction_text": "In the Ilkhanate"}
{"answers": {"text": ["Central Asian Muslims", "Central Asian Muslims", "Central Asian Muslims"], "answer_start": [38, 38, 38]}, "prediction_text": "Central Asian Muslims"}
{"answers": {"text": ["Han Chinese and Khitans", "Han Chinese and Khitans", "Han Chinese and Khitans"], "answer_start": [119, 119, 119]}, "prediction_text": "Han Chinese and Khitans"}
{"answers": {"text": ["Besh Baliq, Almaliq, and Samarqand", "Besh Baliq, Almaliq, and Samarqand", "Bukhara"], "answer_start": [361, 361, 211]}, "prediction_text": "Bukhara"}
{"answers": {"text": ["artisans and farmers", "artisans and farmers", "artisans and farmers"], "answer_start": [432, 432, 432]}, "prediction_text": "Sent Han Chinese and Khitans to serve as administrators."}
{"answers": {"text": ["a Qara-Khitay (Khitan", "Ahai", "Ahai"], "answer_start": [1136, 1226, 1226]}, "prediction_text": "Chinese general Qi Kongzhi"}
{"answers": {"text": ["restricting Halal slaughter and other Islamic practices like circumcision", "circumcision", "restricting Halal slaughter and other Islamic practices like circumcision"], "answer_start": [116, 177, 116]}, "prediction_text": "Restrictions on Halal slaughter, Kosher butchering, and Mongol butchering."}
{"answers": {"text": ["Kosher butchering", "Kosher butchering"], "answer_start": [202, 202]}, "prediction_text": "Circumcision"}
{"answers": {"text": ["Zhu Yuanzhang", "Zhu Yuanzhang", "thanks"], "answer_start": [426, 426, 624]}, "prediction_text": "Zhu Yuanzhang"}
{"answers": {"text": ["thanks", "thanks", "thanks"], "answer_start": [624, 624, 624]}, "prediction_text": "\"Thanks\""}
{"answers": {"text": ["Muslims in the semu class", "Muslims in the semu class", "Muslims in the semu class"], "answer_start": [919, 919, 919]}, "prediction_text": "Muslims in the semu class"}
{"answers": {"text": ["Frederick W. Mote", "Frederick W. Mote", "Frederick W. Mote"], "answer_start": [14, 14, 14]}, "prediction_text": "Frederick W. Mote"}
{"answers": {"text": ["degrees of privilege", "degrees of privilege", "degrees of privilege"], "answer_start": [256, 256, 256]}, "prediction_text": "People's rights and wealth."}
{"answers": {"text": ["rich and well socially standing", "rich and well", "rich and well socially standing"], "answer_start": [433, 433, 433]}, "prediction_text": "Less rich"}
{"answers": {"text": ["lived in poverty and were ill treated", "poverty", "poverty and were ill treated"], "answer_start": [552, 561, 561]}, "prediction_text": "Less rich"}
{"answers": {"text": ["Northern", "Northern Chinese", "Northern"], "answer_start": [316, 316, 316]}, "prediction_text": "Southern China"}
{"answers": {"text": ["Southern", "Southern Chinese", "southern"], "answer_start": [356, 356, 399]}, "prediction_text": "Southern China"}
{"answers": {"text": ["southern China withstood and fought to the last", "because southern China withstood and fought to the last before caving in", "withstood and fought to the last"], "answer_start": [399, 391, 414]}, "prediction_text": "They fought to the last."}
{"answers": {"text": ["The earlier they surrendered to the Mongols, the higher they were placed", "The earlier they surrendered to the Mongols", "they surrendered"], "answer_start": [187, 187, 199]}, "prediction_text": "They fought to the last."}
{"answers": {"text": ["private southern Chinese manufacturers and merchants", "private southern Chinese manufacturers and merchants", "southern Chinese manufacturers and merchants"], "answer_start": [534, 534, 542]}, "prediction_text": "Southern China"}
{"answers": {"text": ["Uighurs", "Uighurs of the Kingdom of Qocho"], "answer_start": [28, 28]}, "prediction_text": "The Koreans"}
{"answers": {"text": ["the Karluk Kara-Khanid ruler", "Karluk Kara-Khanid", "the Karluk Kara-Khanid ruler"], "answer_start": [237, 241, 237]}, "prediction_text": "Karluk Kara-Khanid ruler"}
{"answers": {"text": ["the Korean King", "Korean King", "the Korean King"], "answer_start": [302, 306, 302]}, "prediction_text": "The Korean King"}
{"answers": {"text": ["the Uighurs surrendered peacefully without violently resisting", "Uighurs surrendered peacefully without violently resisting", "surrendered peacefully without violently resisting"], "answer_start": [480, 484, 492]}, "prediction_text": "surrendered peacefully."}
{"answers": {"text": ["The Central Region", "Central Region", "Central"], "answer_start": [0, 4, 4]}, "prediction_text": "Inner Mongolia"}
{"answers": {"text": ["the Central Secretariat", "Central Secretariat", "the Central Secretariat"], "answer_start": [259, 263, 259]}, "prediction_text": "Zhongshu Sheng"}
{"answers": {"text": ["Khanbaliq", "Khanbaliq", "Khanbaliq"], "answer_start": [306, 306, 306]}, "prediction_text": "Khanbaliq (modern Beijing)"}
{"answers": {"text": ["Beijing", "Beijing", "Beijing"], "answer_start": [324, 324, 324]}, "prediction_text": "Beijing"}
{"answers": {"text": ["Zhongshu Sheng", "Zhongshu Sheng", "Zhongshu Sheng"], "answer_start": [287, 287, 287]}, "prediction_text": "Zhongshu Sheng"}
{"answers": {"text": ["in Africa", "Africa"], "answer_start": [92, 95]}, "prediction_text": "East Africa"}
{"answers": {"text": ["East African Community", "East African Community", "East African Community"], "answer_start": [131, 131, 131]}, "prediction_text": "East African Community (EAC)"}
{"answers": {"text": ["Nairobi", "Nairobi", "Nairobi"], "answer_start": [193, 193, 193]}, "prediction_text": "Nairobi"}
{"answers": {"text": ["Tanzania", "Tanzania", "Tanzania"], "answer_start": [464, 464, 464]}, "prediction_text": "Uganda"}
{"answers": {"text": ["45 million people", "45 million people", "approximately 45 million"], "answer_start": [671, 671, 657]}, "prediction_text": "45 million"}
{"answers": {"text": ["a warm and humid tropical climate on its Indian Ocean coastline", "warm and humid tropical climate", "tropical"], "answer_start": [10, 12, 27]}, "prediction_text": "Warm and humid tropical climate"}
{"answers": {"text": ["The climate is cooler", "cooler", "cooler"], "answer_start": [75, 90, 90]}, "prediction_text": "Cooler in the savannah grasslands."}
{"answers": {"text": ["Mount Kenya", "Mount Kenya,", "Mount Kenya"], "answer_start": [183, 183, 183]}, "prediction_text": "Mount Kenya"}
{"answers": {"text": ["Somalia and Ethiopia", "Somalia and Ethiopia", "Somalia and Ethiopia"], "answer_start": [536, 536, 536]}, "prediction_text": "Somalia and Ethiopia"}
{"answers": {"text": ["its safaris, diverse climate and geography, and expansive wildlife reserves and national parks", "safaris, diverse climate and geography", "safaris, diverse climate and geography, and expansive wildlife reserves"], "answer_start": [634, 638, 638]}, "prediction_text": "Safaris, diverse climate, and expansive wildlife reserves."}
{"answers": {"text": ["Lower Paleolithic period", "since the Lower Paleolithic period", "since the Lower Paleolithic period"], "answer_start": [97, 87, 87]}, "prediction_text": "Since the Lower Paleolithic period."}
{"answers": {"text": ["By the first millennium AD", "By the first millennium AD", "first millennium AD"], "answer_start": [123, 123, 130]}, "prediction_text": "First millennium AD"}
{"answers": {"text": ["Bantu and Nilotic", "Bantu and Nilotic", "Bantu and Nilotic"], "answer_start": [424, 424, 424]}, "prediction_text": "Mombasa (Nileotic)"}
{"answers": {"text": ["19th century", "19th century", "19th century"], "answer_start": [642, 642, 642]}, "prediction_text": "19th century"}
{"answers": {"text": ["December 1963", "December 1963", "December 1963"], "answer_start": [809, 809, 809]}, "prediction_text": "December 1963"}
{"answers": {"text": ["Mount Kenya", "Mount Kenya", "Mount Kenya"], "answer_start": [37, 37, 37]}, "prediction_text": "Mount Kenya"}
{"answers": {"text": ["Kirinyaga, Kirenyaa and Kiinyaa", "Kikuyu, Embu and Kamba", "Kikuyu, Embu and Kamba"], "answer_start": [148, 119, 119]}, "prediction_text": "Kikuyu, Embu, Kirenyaa, Kiinyaa"}
{"answers": {"text": ["God's resting place", "God's resting place", "God's resting place"], "answer_start": [192, 192, 192]}, "prediction_text": "God's resting place"}
{"answers": {"text": ["both Kenia and Kegnia", "Kenia and Kegnia", "Kenia and Kegnia"], "answer_start": [34, 39, 39]}, "prediction_text": "Kenia and Kegnia"}
{"answers": {"text": ["a very precise notation of a correct African pronunciation", "precise", "precise"], "answer_start": [155, 162, 162]}, "prediction_text": "Corruption of the Kamba version."}
{"answers": {"text": ["Joseph Thompsons", "Joseph Thompsons", "Joseph Thompsons"], "answer_start": [245, 245, 245]}, "prediction_text": "Joseph Thompsons"}
{"answers": {"text": ["1862", "1862", "1862"], "answer_start": [334, 334, 334]}, "prediction_text": "1862"}
{"answers": {"text": ["The \"Big Five\"", "Big Five", "Big Five"], "answer_start": [0, 5, 5]}, "prediction_text": "Lion, leopard, buffalo, rhinoceros, elephant."}
{"answers": {"text": ["lion, leopard, buffalo, rhinoceros, and elephant", "lion, leopard, buffalo, rhinoceros, and elephant", "lion, leopard, buffalo, rhinoceros, and elephant"], "answer_start": [51, 51, 51]}, "prediction_text": "Lion, leopard, buffalo, rhinoceros, elephant."}
{"answers": {"text": ["Masai Mara", "national parks", "Masai Mara"], "answer_start": [134, 247, 134]}, "prediction_text": "Kenya and Masai Mara"}
{"answers": {"text": ["between June and September", "June and September", "between June and September"], "answer_start": [331, 339, 331]}, "prediction_text": "Between June and September"}
{"answers": {"text": ["2,900 kilometres (1,802 mi)", "2,900 kilometres", "2,900 kilometres"], "answer_start": [478, 478, 478]}, "prediction_text": "2,900 kilometres (1,802 mi)"}
{"answers": {"text": ["more than 20 million years ago", "20 million years ago", "20 million years ago"], "answer_start": [61, 71, 71]}, "prediction_text": "More than 20 million years ago"}
{"answers": {"text": ["in the Pleistocene epoch", "Pleistocene epoch", "Pleistocene epoch"], "answer_start": [328, 335, 335]}, "prediction_text": "Pleistocene epoch"}
{"answers": {"text": ["Richard Leakey", "Kamoya Kimeu", "Kamoya Kimeu"], "answer_start": [418, 445, 445]}, "prediction_text": "Richard Leakey"}
{"answers": {"text": [".6-million-year-old", "1.6-million-year-old", "1.6-million-year-old"], "answer_start": [489, 488, 488]}, "prediction_text": "1.6-million years old"}
{"answers": {"text": ["Mary Leakey and Louis Leakey", "Mary Leakey and Louis Leakey", "Mary Leakey and Louis Leakey"], "answer_start": [611, 611, 611]}, "prediction_text": "Richard Leakey"}
{"answers": {"text": ["The Swahili", "Swahili", "Swahili"], "answer_start": [0, 4, 4]}, "prediction_text": "Swahili built Mombasa"}
{"answers": {"text": ["Mombasa", "Mombasa", "Mombasa"], "answer_start": [18, 18, 18]}, "prediction_text": "Mombasa"}
{"answers": {"text": ["Duarte Barbosa", "Duarte Barbosa", "Duarte Barbosa"], "answer_start": [213, 213, 213]}, "prediction_text": "Duarte Barbosa"}
{"answers": {"text": ["the Kenyan Coast", "Kenyan Coast", "Kenyan Coast"], "answer_start": [26, 30, 30]}, "prediction_text": "Malindi"}
{"answers": {"text": ["City of Malindi", "City of Malindi", "City of Malindi"], "answer_start": [143, 143, 143]}, "prediction_text": "City of Malindi"}
{"answers": {"text": ["14th century", "14th century", "14th century"], "answer_start": [218, 218, 218]}, "prediction_text": "14th century"}
{"answers": {"text": ["August 1914", "August 1914", "August 1914"], "answer_start": [34, 34, 34]}, "prediction_text": "August 1914"}
{"answers": {"text": ["governors of British East Africa (as the Protectorate was generally known) and German East Africa", "British East Africa (as the Protectorate was generally known) and German East Africa", "British East Africa (as the Protectorate was generally known) and German East Africa"], "answer_start": [51, 64, 64]}, "prediction_text": "Lt Col Paul von Lettow-Vorbeck and Lt Col Paul von Lettow-Vorbeck's son, Lt Col Paul von Lettow-Vorbeck."}
{"answers": {"text": ["Lt Col Paul von Lettow-Vorbeck", "Lt Col Paul von Lettow-Vorbeck", "Paul von Lettow-Vorbeck"], "answer_start": [232, 232, 239]}, "prediction_text": "Lt Col Paul von Lettow-Vorbeck"}
{"answers": {"text": ["effective guerrilla warfare campaign, living off the land, capturing British supplies, and remaining undefeated", "guerrilla warfare campaign", "guerrilla warfare"], "answer_start": [426, 436, 436]}, "prediction_text": "He conducted guerrilla warfare."}
{"answers": {"text": ["Northern Rhodesia", "Northern Rhodesia", "Northern Rhodesia"], "answer_start": [568, 568, 568]}, "prediction_text": "Northern Rhodesia"}
{"answers": {"text": ["The central highlands", "central highlands", "central highlands"], "answer_start": [0, 4, 4]}, "prediction_text": "Central highlands"}
{"answers": {"text": ["as itinerant farmers", "itinerant farmers", "itinerant farmers"], "answer_start": [148, 151, 151]}, "prediction_text": "As itinerant farmers"}
{"answers": {"text": ["banned the growing of coffee, introduced a hut tax, and the landless were granted less and less land in exchange for their labour", "banned the growing of coffee, introduced a hut tax, and the landless were granted less and less land", "banned the growing of coffee, introduced a hut tax, and the landless were granted less and less land"], "answer_start": [211, 211, 211]}, "prediction_text": "Ban coffee, introduced hut tax, granted less land."}
{"answers": {"text": ["80,000", "80,000", "80,000"], "answer_start": [452, 452, 452]}, "prediction_text": "80,000"}
{"answers": {"text": ["15 January 1954", "15 January 1954", "15 January 1954"], "answer_start": [52, 52, 52]}, "prediction_text": "January 1954"}
{"answers": {"text": ["the subsequent interrogation led to a better understanding of the Mau Mau command structure", "better understanding of the Mau Mau command structure", "a better understanding of the Mau Mau command structure"], "answer_start": [72, 110, 108]}, "prediction_text": "Eliminated military offensive"}
{"answers": {"text": ["24 April 1954", "24 April 1954", "24 April 1954"], "answer_start": [191, 191, 191]}, "prediction_text": "25 April 1954"}
{"answers": {"text": ["4,686 Mau Mau", "4,686", "4,686"], "answer_start": [652, 652, 652]}, "prediction_text": "4,686"}
{"answers": {"text": ["the Swynnerton Plan, which was used to both reward loyalists and punish Mau Mau.", "Swynnerton Plan", "Swynnerton Plan"], "answer_start": [967, 971, 971]}, "prediction_text": "Swynnerton Plan"}
{"answers": {"text": ["1957", "1957", "1957"], "answer_start": [87, 87, 87]}, "prediction_text": "1957"}
{"answers": {"text": ["Kenya African National Union (KANU) of Jomo Kenyatta", "Kenya African National Union", "Kenya African National Union"], "answer_start": [171, 171, 171]}, "prediction_text": "Kenya African National Union (KANU) of Jomo Kenyatta"}
{"answers": {"text": ["12 December 1963", "12 December 1963", "8 October 1963"], "answer_start": [323, 323, 483]}, "prediction_text": "1963"}
{"answers": {"text": ["1963", "Kenya Independence Act", "1963"], "answer_start": [810, 787, 810]}, "prediction_text": "1963"}
{"answers": {"text": ["Republic of Kenya", "Republic of Kenya", "Republic of Kenya"], "answer_start": [923, 923, 923]}, "prediction_text": "Republic of Kenya"}
{"answers": {"text": ["where voters were supposed to line up behind their favoured candidates instead of a secret ballot", "voters were supposed to line up behind their favoured candidates", "voters were supposed to line up behind their favoured candidates"], "answer_start": [75, 81, 81]}, "prediction_text": "Voting system for mlolongo (queuing)"}
{"answers": {"text": ["agitation for constitutional reform", "widespread agitation for constitutional reform", "widespread agitation for constitutional reform"], "answer_start": [257, 246, 246]}, "prediction_text": "widespread agitation for constitutional reform."}
{"answers": {"text": ["Daniel arap Moi", "Daniel arap Moi", "Daniel arap Moi"], "answer_start": [470, 470, 470]}, "prediction_text": "Daniel arap Moi"}
{"answers": {"text": ["a presidential representative democratic republic", "presidential representative democratic republic", "presidential representative democratic republic"], "answer_start": [9, 11, 11]}, "prediction_text": "Presidential representative democratic republic"}
{"answers": {"text": ["the head of state and head of government", "head of state and head of government", "head of state and head of government"], "answer_start": [82, 86, 86]}, "prediction_text": "Head of state and head of government."}
{"answers": {"text": ["exercised by the government", "government", "government."], "answer_start": [172, 189, 189]}, "prediction_text": "Daniel arap Moi"}
{"answers": {"text": ["both the government and the National Assembly and the Senate", "government and the National Assembly and the Senate", "both the government and the National Assembly and the Senate"], "answer_start": [232, 241, 232]}, "prediction_text": "The National Assembly"}
{"answers": {"text": ["The Judiciary", "Judiciary", "Judiciary"], "answer_start": [294, 298, 298]}, "prediction_text": "Judiciary"}
{"answers": {"text": ["low", "low", "low"], "answer_start": [12, 12, 12]}, "prediction_text": "139th out of 176 countries"}
{"answers": {"text": ["gauge the prevalence of public sector corruption in various countries", "public sector corruption", "public sector corruption"], "answer_start": [110, 134, 134]}, "prediction_text": "Transparency International's Corruption Perception Index (CPI)"}
{"answers": {"text": ["139th out of 176 total countries", "139th", "139th"], "answer_start": [208, 208, 208]}, "prediction_text": "139th out of 176 countries"}
{"answers": {"text": ["the establishment of a new and independent Ethics and Anti-Corruption Commission", "Ethics and Anti-Corruption Commission", "establishment of a new and independent Ethics and Anti-Corruption Commission"], "answer_start": [413, 456, 417]}, "prediction_text": "Establishment of EACC"}
{"answers": {"text": ["Party of National Unity", "Party of National Unity", "Party of National Unity"], "answer_start": [58, 58, 58]}, "prediction_text": "Party of National Unity"}
{"answers": {"text": ["the Orange Democratic Movement (ODM)", "Kalonzo Musyoka", "Orange Democratic Movement"], "answer_start": [137, 444, 141]}, "prediction_text": "Orange Democratic Movement (ODM)"}
{"answers": {"text": ["Kibaki closed the gap and then overtook his opponent by a substantial margin after votes from his stronghold arrived later", "Kibaki closed the gap and then overtook his opponent", "votes from his stronghold arrived later"], "answer_start": [757, 757, 840]}, "prediction_text": "Controversy over election results"}
{"answers": {"text": ["Odinga", "Odinga", "Odinga"], "answer_start": [957, 957, 957]}, "prediction_text": "Raila Odinga"}
{"answers": {"text": ["programmes to avoid similar disasters in the future", "programmes", "programmes"], "answer_start": [81, 81, 81]}, "prediction_text": "programmes to avoid similar disasters"}
{"answers": {"text": ["Truth, Justice and Reconciliation Commission", "Truth, Justice and Reconciliation Commission", "Truth, Justice and Reconciliation Commission"], "answer_start": [304, 304, 304]}, "prediction_text": "Truth, Justice and Reconciliation Commission"}
{"answers": {"text": ["Evangelical Lutheran Church", "Evangelical Lutheran Church", "Evangelical Lutheran Church"], "answer_start": [384, 384, 384]}, "prediction_text": "Evangelical Lutheran Church in Kenya"}
{"answers": {"text": ["Kenya National Dialogue and Reconciliation process", "Kenya National Dialogue and Reconciliation", "Kenya National Dialogue and Reconciliation process"], "answer_start": [452, 452, 452]}, "prediction_text": "Community dialogues, peace meetings, Kenya National Dialogue and Reconciliation process."}
{"answers": {"text": ["28 February 2008", "28 February 2008", "28 February 2008"], "answer_start": [3, 3, 3]}, "prediction_text": "28 February 2008"}
{"answers": {"text": ["Prime Minister", "second Prime Minister", "Prime Minister"], "answer_start": [146, 139, 146]}, "prediction_text": "Second Prime Minister"}
{"answers": {"text": ["both PNU and ODM camps", "PNU and ODM camps", "PNU and ODM camps"], "answer_start": [229, 234, 234]}, "prediction_text": "PNU and ODM camps"}
{"answers": {"text": ["depending on each party's strength in Parliament", "each party's strength in Parliament", "each party's strength in Parliament"], "answer_start": [252, 265, 265]}, "prediction_text": "Cabinet ministers from both PNU and ODM camps."}
{"answers": {"text": ["until the end of the current Parliament or if either of the parties withdraws from the deal before then", "end of the current Parliament", "until the end of the current Parliament or if either of the parties withdraws from the deal before then"], "answer_start": [476, 486, 476]}, "prediction_text": "Until end of Parliament or withdrawal."}
{"answers": {"text": ["PM will have power and authority to co-ordinate and supervise the functions of the Government", "co-ordinate and supervise the functions of the Government", "co-ordinate and supervise the functions of the Government"], "answer_start": [22, 58, 58]}, "prediction_text": "Co-ordinate and supervise functions of the Government."}
{"answers": {"text": ["Annan and his UN-backed panel and African Union chairman Jakaya Kikwete", "Annan and his UN-backed panel and African Union chairman Jakaya Kikwete", "Jakaya Kikwete"], "answer_start": [258, 258, 315]}, "prediction_text": "Annan and Kikwete"}
{"answers": {"text": ["the steps of Nairobi's Harambee House", "Nairobi's Harambee House", "steps of Nairobi's Harambee House"], "answer_start": [430, 443, 434]}, "prediction_text": "Nairobi's Harambee House"}
{"answers": {"text": ["29 February 2008", "29 February 2008", "29 February 2008"], "answer_start": [472, 472, 472]}, "prediction_text": "18 March 2008"}
{"answers": {"text": ["the two political parties would share power equally", "two political parties would share power equally", "two political parties would share power equally"], "answer_start": [872, 876, 876]}, "prediction_text": "Sharing power equally."}
{"answers": {"text": ["eliminate the position of Prime Minister and simultaneously reduce the powers of the President", "eliminate the position of Prime Minister", "eliminate the position of Prime Minister"], "answer_start": [50, 50, 50]}, "prediction_text": "Eliminate Prime Minister position and reduce President's powers."}
{"answers": {"text": ["August 2010", "4 August 2010", "4 August 2010"], "answer_start": [210, 208, 208]}, "prediction_text": "August 4, 2010"}
{"answers": {"text": ["delegates more power to local governments and gives Kenyans a bill of rights", "delegates more power to local governments and gives Kenyans a bill of rights", "delegates more power to local governments and gives Kenyans a bill of rights"], "answer_start": [314, 314, 314]}, "prediction_text": "Delegates more power to local governments and gives Kenyans a bill of rights."}
{"answers": {"text": ["27 August 2010", "27 August 2010", "27 August 2010"], "answer_start": [414, 414, 414]}, "prediction_text": "27 August 2010"}
{"answers": {"text": ["the Second Republic", "Second Republic", "Second Republic"], "answer_start": [650, 654, 654]}, "prediction_text": "Second Republic"}
{"answers": {"text": ["December 2014", "December 2014", "December 2014"], "answer_start": [3, 3, 3]}, "prediction_text": "December 2014"}
{"answers": {"text": ["to guard against armed groups", "guard against armed groups", "guard against armed groups"], "answer_start": [134, 137, 137]}, "prediction_text": "To guard against armed groups."}
{"answers": {"text": ["Opposition politicians, human rights groups, and nine Western countries", "Opposition politicians, human rights groups, and nine Western countries", "Opposition politicians, human rights groups, and nine Western countries"], "answer_start": [165, 165, 165]}, "prediction_text": "Opposition politicians, human rights groups, and nine Western countries."}
{"answers": {"text": ["it infringed on democratic freedoms", "infringed on democratic freedoms", "arguing that it infringed on democratic freedoms"], "answer_start": [280, 283, 267]}, "prediction_text": "Uncertainty over the law's impact."}
{"answers": {"text": ["of the United States, Britain, Germany and France", "governments", "governments of the United States, Britain, Germany and France"], "answer_start": [333, 321, 321]}, "prediction_text": "Governments of the United States, Britain, Germany, France, and the United Kingdom."}
{"answers": {"text": ["h International Criminal Court trial dates in 2013 for both President Kenyatta and Deputy President William Ruto", "International Criminal Court trial dates", "International Criminal Court trial dates"], "answer_start": [3, 5, 5]}, "prediction_text": "President Kenyatta was elected."}
{"answers": {"text": ["US President Barack Obama", "US President Barack Obama", "US President Barack Obama"], "answer_start": [156, 156, 156]}, "prediction_text": "Barack Obama"}
{"answers": {"text": ["China", "China", "China"], "answer_start": [285, 285, 285]}, "prediction_text": "China"}
{"answers": {"text": ["In July 2015", "July 2015", "July 2015"], "answer_start": [411, 414, 414]}, "prediction_text": "July 2015"}
{"answers": {"text": ["in peacekeeping missions around the world", "peacekeeping", "peacekeeping"], "answer_start": [40, 43, 43]}, "prediction_text": "Peacekeeping missions"}
{"answers": {"text": ["violence that subsequently engulfed the country", "violence", "violence"], "answer_start": [160, 160, 160]}, "prediction_text": "Violence and armed forces deployment."}
{"answers": {"text": ["human rights violations", "human rights violations", "human rights violations"], "answer_start": [383, 383, 383]}, "prediction_text": "Human rights violations"}
{"answers": {"text": ["Kenya\u2019s armed forces", "Kenya\u2019s armed forces", "armed"], "answer_start": [0, 0, 8]}, "prediction_text": "Kenya's armed forces"}
{"answers": {"text": ["Because the operations of the armed forces have been traditionally cloaked by the ubiquitous blanket of \u201cstate security\u201d", "state security", "state security"], "answer_start": [117, 222, 222]}, "prediction_text": "Lack of public scrutiny and notoriety."}
{"answers": {"text": ["credible claims of corruption were made with regard to recruitment  and procurement of Armoured Personnel Carriers", "recruitment  and procurement of Armoured Personnel Carriers", "recruitment  and procurement of Armoured Personnel Carriers"], "answer_start": [435, 490, 490]}, "prediction_text": "Recruitment and procurement of Armoured Personnel Carriers."}
{"answers": {"text": [", the wisdom and prudence of certain decisions of procurement", "wisdom and prudence of certain decisions", "wisdom and prudence of certain decisions of procurement"], "answer_start": [558, 564, 564]}, "prediction_text": "Procurement decisions"}
{"answers": {"text": ["0.519, ranked 145 out of 186 in the world", "0.519", "0.519"], "answer_start": [162, 162, 162]}, "prediction_text": "0.519"}
{"answers": {"text": ["Kenya", "Kenya", "Kenya"], "answer_start": [9, 9, 9]}, "prediction_text": "Kenya"}
{"answers": {"text": ["less than $1.25 a day", "less than $1.25", "less than $1.25"], "answer_start": [243, 243, 243]}, "prediction_text": "Less than $1.25"}
{"answers": {"text": ["a frontier market or occasionally an emerging market", "frontier", "frontier"], "answer_start": [482, 484, 484]}, "prediction_text": "Frontier market"}
{"answers": {"text": ["rapid expansion in telecommunication and financial activity", "rapid expansion in telecommunication and financial activity", "rapid expansion in telecommunication and financial activity"], "answer_start": [105, 105, 105]}, "prediction_text": "Rapid expansion in telecommunication and financial activity."}
{"answers": {"text": ["food security", "food security", "food security"], "answer_start": [408, 408, 408]}, "prediction_text": "Food security"}
{"answers": {"text": ["Industry and manufacturing", "Industry and manufacturing", "Industry and manufacturing"], "answer_start": [537, 537, 537]}, "prediction_text": "Agriculture"}
{"answers": {"text": ["75% of the labour force", "75%", "75%"], "answer_start": [303, 303, 303]}, "prediction_text": "75%"}
{"answers": {"text": ["61%", "61%", "61%"], "answer_start": [43, 43, 43]}, "prediction_text": "61%"}
{"answers": {"text": ["tourism", "tourism", "tourism"], "answer_start": [71, 71, 71]}, "prediction_text": "Tourism"}
{"answers": {"text": ["steady growth", "growth", "growth"], "answer_start": [113, 120, 120]}, "prediction_text": "Growth or reduction."}
{"answers": {"text": ["the coastal beaches and the game reserves", "coastal beaches and the game reserves,", "coastal beaches and the game reserves"], "answer_start": [341, 345, 345]}, "prediction_text": "The coastal beaches and game reserves."}
{"answers": {"text": ["Germany and the United Kingdom", "Germany and the United Kingdom", "Germany and the United Kingdom"], "answer_start": [285, 285, 285]}, "prediction_text": "Germany and the United Kingdom"}
{"answers": {"text": ["24%", "24%", "24%"], "answer_start": [180, 180, 180]}, "prediction_text": "24%"}
{"answers": {"text": ["tea, horticultural produce, and coffee", "tea, horticultural produce, and coffee", "tea, horticultural produce, and coffee"], "answer_start": [292, 292, 292]}, "prediction_text": "Tea, horticultural produce, and coffee."}
{"answers": {"text": ["Agriculture", "Agriculture", "Agriculture"], "answer_start": [0, 0, 0]}, "prediction_text": "Agriculture"}
{"answers": {"text": ["weather-related fluctuations", "weather-related", "weather"], "answer_start": [513, 513, 513]}, "prediction_text": "Weather-related fluctuations"}
{"answers": {"text": ["International Crops Research Institute for the Semi-Arid Tropics (ICRISAT)", "ICRISAT", "International Crops Research Institute for the Semi-Arid Tropics"], "answer_start": [24, 90, 24]}, "prediction_text": "International Crops Research Institute for the Semi-Arid Tropics (ICRISAT)"}
{"answers": {"text": ["Pigeon peas are very drought resistant,", "drought resistant", "very drought resistant"], "answer_start": [215, 236, 231]}, "prediction_text": "To increase local producer prices."}
{"answers": {"text": ["by stimulating the growth of local seed production and agro-dealer networks for distribution and marketing", "stimulating the growth of local seed production", "stimulating the growth of local seed production"], "answer_start": [384, 387, 387]}, "prediction_text": "Led to increased local producer prices."}
{"answers": {"text": [", helped to increase local producer prices by 20\u201325%", "increase local producer prices by 20\u201325%", "increase"], "answer_start": [550, 562, 562]}, "prediction_text": "Increased local producer prices."}
{"answers": {"text": ["enabling some farmers to buy assets", "enabling some farmers to buy assets", "enabling some farmers to buy assets"], "answer_start": [674, 674, 674]}, "prediction_text": "Increased local producer prices"}
{"answers": {"text": ["the fertile highlands", "fertile highlands", "highlands"], "answer_start": [60, 64, 72]}, "prediction_text": "Africa"}
{"answers": {"text": ["Tea, coffee, sisal, pyrethrum, corn, and wheat", "ea, coffee, sisal, pyrethrum, corn, and wheat", "Tea, coffee, sisal, pyrethrum, corn, and wheat"], "answer_start": [0, 1, 0]}, "prediction_text": "Tea, coffee, sisal, pyrethrum, corn, and wheat."}
{"answers": {"text": ["the semi-arid savanna to the north and east", "savanna to the north and east", "semi-arid savanna to the north and east"], "answer_start": [179, 193, 183]}, "prediction_text": "Semi-arid savanna"}
{"answers": {"text": ["53% of the population", "53%", "53%"], "answer_start": [497, 497, 497]}, "prediction_text": "53%"}
{"answers": {"text": ["Kenyans for Kenya", "Kenyans for Kenya", "Kenyans for Kenya"], "answer_start": [955, 955, 955]}, "prediction_text": "Kenyans for Kenya"}
{"answers": {"text": ["Kenya", "Kenya", "Kenya"], "answer_start": [9, 9, 9]}, "prediction_text": "Kenya"}
{"answers": {"text": ["14%", "14%", "14%"], "answer_start": [131, 131, 131]}, "prediction_text": "14%"}
{"answers": {"text": ["Nairobi, Mombasa and Kisumu", "Nairobi, Mombasa and Kisumu", ", Nairobi, Mombasa and Kisumu"], "answer_start": [221, 221, 219]}, "prediction_text": "Nairobi, Mombasa, Kisumu"}
{"answers": {"text": ["small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "small-scale manufacturing", "small-scale manufacturing"], "answer_start": [702, 702, 702]}, "prediction_text": "Small-scale manufacturing of household goods, motor-vehicle parts, and farm implements."}
{"answers": {"text": ["Kenya's inclusion among the beneficiaries of the US Government's African Growth and Opportunity Act (AGOA)", "AGOA", "African Growth and Opportunity Act"], "answer_start": [0, 101, 65]}, "prediction_text": "Kenya's inclusion in the US Government's African Growth and Opportunity Act (AGOA)"}
{"answers": {"text": ["2000", "2000", "2000"], "answer_start": [185, 185, 185]}, "prediction_text": "2000"}
{"answers": {"text": ["hydroelectric stations at dams", "hydroelectric stations at dams", "dams"], "answer_start": [59, 59, 85]}, "prediction_text": "Hydroelectric stations"}
{"answers": {"text": ["Tana River, as well as the Turkwel Gorge Dam", "upper Tana River, as well as the Turkwel Gorge", "along the upper Tana River"], "answer_start": [106, 100, 90]}, "prediction_text": "Along the upper Tana River"}
{"answers": {"text": ["1997", "1997", "1997"], "answer_start": [473, 473, 473]}, "prediction_text": "1997"}
{"answers": {"text": ["in Turkana", "Turkana", "Turkana"], "answer_start": [33, 36, 36]}, "prediction_text": "Turkana and commercial viability was just discovered."}
{"answers": {"text": ["around 10 billion barrels.", "10 billion", "10 billion"], "answer_start": [142, 149, 149]}, "prediction_text": "10 billion barrels"}
{"answers": {"text": ["Exploration", "Exploration", "Exploration"], "answer_start": [169, 169, 169]}, "prediction_text": "Exploration is still continuing."}
{"answers": {"text": ["r 20% to 25%", "20% to 25%", "20% to 25%"], "answer_start": [478, 480, 480]}, "prediction_text": "20% to 25%"}
{"answers": {"text": ["$474 million", "$474 million", "$474 million"], "answer_start": [201, 201, 201]}, "prediction_text": "$474 million"}
{"answers": {"text": ["Kenya's largest source of foreign direct investment", "largest source of foreign direct investment"], "answer_start": [228, 236]}, "prediction_text": "China's investment in Kenya is a significant source of foreign direct investment."}
{"answers": {"text": ["support from China for a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "support from China for a planned $2.5 billion railway", "support from China for a planned $2.5 billion railway"], "answer_start": [422, 422, 422]}, "prediction_text": "Support for a planned $2.5 billion railway from Mombasa to neighboring Uganda, and a nearly $1.8 billion dam."}
{"answers": {"text": ["Base Titanium, a subsidiary of Base resources of Australia", "Base Titanium", "Base Titanium"], "answer_start": [662, 662, 662]}, "prediction_text": "Kilifi, Kenya"}
{"answers": {"text": ["environmental and social problems", "environmental and social problems", "environmental and social problems"], "answer_start": [973, 973, 973]}, "prediction_text": "Environmental and social problems"}
{"answers": {"text": ["Vision 2030", "Vision 2030", "Vision 2030"], "answer_start": [40, 40, 40]}, "prediction_text": "Low carbon climate resilient development pathway"}
{"answers": {"text": ["an economic development programme it hopes will put the country in the same league as the Asian Economic Tigers by the year 2030", "economic development programme", "an economic development programme"], "answer_start": [53, 56, 53]}, "prediction_text": "Economic development programme for Kenya."}
{"answers": {"text": ["National Climate Change Action Plan", "2013", "National Climate Change Action Plan"], "answer_start": [206, 186, 206]}, "prediction_text": "Vision 2030"}
{"answers": {"text": ["having acknowledged that omitting climate as a key development issue in Vision 2030 was an oversight", "oversight", "oversight"], "answer_start": [243, 334, 334]}, "prediction_text": "To address climate change as an economy-wide issue."}
{"answers": {"text": ["climate will be a central issue in the renewed Medium Term Plan that will be launched in the coming months", "Medium Term Plan", "Medium Term Plan"], "answer_start": [669, 716, 716]}, "prediction_text": "Direct and robust delivery framework"}
{"answers": {"text": ["in agriculture", "agriculture", "agriculture"], "answer_start": [66, 69, 69]}, "prediction_text": "In agriculture"}
{"answers": {"text": ["up to 30%", "30%", "up to 30%"], "answer_start": [113, 119, 113]}, "prediction_text": "Up to 30%"}
{"answers": {"text": ["9\u201318.", "9\u201318", "9\u201318"], "answer_start": [264, 264, 264]}, "prediction_text": "Age 9\u201318"}
{"answers": {"text": ["poverty, the lack of access to education and weak government institutions", "poverty, the lack of access to education and weak government institutions", "poverty, the lack of access to education and weak government institutions"], "answer_start": [394, 394, 394]}, "prediction_text": "Poverty, lack of education, weak government institutions."}
{"answers": {"text": ["Kenya's various ethnic groups typically speak their mother tongues within their own communities", "mother tongues", "mother tongues"], "answer_start": [0, 52, 52]}, "prediction_text": "English"}
{"answers": {"text": ["English and Swahili", "English and Swahili", "English and Swahili,"], "answer_start": [125, 125, 125]}, "prediction_text": "English and Swahili"}
{"answers": {"text": ["in commerce, schooling and government", "commerce, schooling and government.", "commerce, schooling and government"], "answer_start": [252, 255, 255]}, "prediction_text": "In commerce, schooling, government."}
{"answers": {"text": ["in the country", "country", "in the country"], "answer_start": [441, 448, 441]}, "prediction_text": "In the country"}
{"answers": {"text": ["Christian", "Christian", "Christian"], "answer_start": [33, 33, 33]}, "prediction_text": "Christianity"}
{"answers": {"text": ["Protestant", "Protestant", "Protestant"], "answer_start": [85, 85, 85]}, "prediction_text": "Christian (83%)"}
{"answers": {"text": ["3 million followers", "3 million", "3 million"], "answer_start": [186, 186, 186]}, "prediction_text": "3 million followers"}
{"answers": {"text": ["Nairobi", "Nairobi", "Nairobi"], "answer_start": [630, 630, 630]}, "prediction_text": "Nairobi"}
{"answers": {"text": ["2.4%", "2.4%", "2.4%"], "answer_start": [103, 103, 103]}, "prediction_text": "2.4%"}
{"answers": {"text": ["Sixty percent", "Sixty percent", "Sixty percent"], "answer_start": [109, 109, 109]}, "prediction_text": "50%"}
{"answers": {"text": ["mostly Christian", "mostly Christian", "Christian"], "answer_start": [378, 378, 385]}, "prediction_text": "Hindu"}
{"answers": {"text": ["around 300,000", "300,000", "300,000"], "answer_start": [587, 594, 594]}, "prediction_text": "Around 300,000"}
{"answers": {"text": ["Nurses", "Nurses", "Nurses"], "answer_start": [0, 0, 0]}, "prediction_text": "Nurses"}
{"answers": {"text": ["clinical officers, medical officers and medical practitioners", "clinical officers, medical officers and medical practitioners", "clinical officers, medical officers and medical practitioners"], "answer_start": [167, 167, 167]}, "prediction_text": "Medical officers"}
{"answers": {"text": ["65,000", "65,000", "65,000"], "answer_start": [303, 303, 303]}, "prediction_text": "65,000"}
{"answers": {"text": ["7,000 doctors", "7,000", "7,000"], "answer_start": [382, 382, 382]}, "prediction_text": "7,000"}
{"answers": {"text": ["Diseases of poverty", "Diseases of poverty", "Diseases of poverty"], "answer_start": [0, 0, 0]}, "prediction_text": "Diseases of poverty directly correlate with economic performance and wealth distribution."}
{"answers": {"text": ["Half", "Half", "Half"], "answer_start": [102, 102, 102]}, "prediction_text": "Half of Kenyans"}
{"answers": {"text": ["diseases like malaria, HIV/AIDS, pneumonia, diarrhoea and malnutrition", "Preventable diseases like malaria, HIV/AIDS, pneumonia, diarrhoea and malnutrition", "Preventable diseases"], "answer_start": [160, 148, 148]}, "prediction_text": "Malaria, HIV/AIDS, pneumonia, diarrhoea, and malnutrition."}
{"answers": {"text": ["weak policies, corruption, inadequate health workers, weak management and poor leadership in the public health sector", "weak policies, corruption, inadequate health workers, weak management and poor leadership", "weak policies, corruption, inadequate health workers, weak management and poor leadership"], "answer_start": [312, 312, 312]}, "prediction_text": "Weak policies, corruption, inadequate health workers, weak management."}
{"answers": {"text": ["15 million", "15 million", "15 million"], "answer_start": [731, 731, 731]}, "prediction_text": "15 million"}
{"answers": {"text": ["British colonists.", "British colonists", "British colonists"], "answer_start": [52, 52, 52]}, "prediction_text": "British colonists"}
{"answers": {"text": ["12 December 1963", "12 December 1963", "12 December 1963"], "answer_start": [101, 101, 101]}, "prediction_text": "December 1963"}
{"answers": {"text": ["Ominde Commission", "Ominde Commission", "Ominde Commission"], "answer_start": [142, 142, 142]}, "prediction_text": "Ominde Commission"}
{"answers": {"text": ["focused on identity and unity, which were critical issues at the time", "focused on identity and unity", "focused on identity and unity"], "answer_start": [252, 252, 252]}, "prediction_text": "Introduced changes to Kenya's education system."}
{"answers": {"text": ["the 7\u20134\u20132\u20133 system was adopted", "7\u20134\u20132\u20133 system", "7\u20134\u20132\u20133"], "answer_start": [442, 446, 446]}, "prediction_text": "7\u20134\u20132\u20133 system"}
{"answers": {"text": ["look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system", "look at both the possibilities", "look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system"], "answer_start": [85, 85, 85]}, "prediction_text": "Look at both possibilities of setting up a second university in Kenya."}
{"answers": {"text": ["8\u20134\u20134 system", "8\u20134\u20134 system", "an 8\u20134\u20134 system"], "answer_start": [283, 283, 280]}, "prediction_text": "Eight years in primary, four years in secondary, four years in university education."}
{"answers": {"text": ["8\u20134\u20134 system", "7\u20134\u20132\u20133 system", "7\u20134\u20132\u20133"], "answer_start": [467, 251, 494]}, "prediction_text": "8\u20134\u20134"}
{"answers": {"text": ["1992", "1992", "1992"], "answer_start": [672, 672, 672]}, "prediction_text": "1992"}
{"answers": {"text": ["January 1985", "January 1985", "January 1985"], "answer_start": [41, 41, 41]}, "prediction_text": "January 1985"}
{"answers": {"text": ["vocational subjects", "vocational subjects", "vocational subjects"], "answer_start": [79, 79, 79]}, "prediction_text": "Vocational subjects"}
{"answers": {"text": ["the new structure would enable school drop-outs at all levels either to be self-employed or to secure employment in the informal sector", "enable school drop-outs at all levels either to be self-employed or to secure employment", "enable school drop-outs at all levels either to be self-employed or to secure employment"], "answer_start": [122, 146, 146]}, "prediction_text": "For drop-outs at all levels."}
{"answers": {"text": ["January 2003", "January 2003", "January 2003"], "answer_start": [262, 262, 262]}, "prediction_text": "January 2003"}
{"answers": {"text": ["increased by about 70%.", "70%", "70%"], "answer_start": [392, 411, 411]}, "prediction_text": "About 70% increase"}
{"answers": {"text": ["age six years", "six", "six"], "answer_start": [33, 37, 37]}, "prediction_text": "Age six years"}
{"answers": {"text": ["eight years in primary school and four years in high school or secondary school.", "eight years in primary school and four years in high school", "eight years in primary school and four years in high school"], "answer_start": [77, 77, 77]}, "prediction_text": "Eight years in primary school, four years in high school or secondary school."}
{"answers": {"text": ["join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program", "join a vocational youth/village polytechnic", "four years in high school"], "answer_start": [236, 236, 111]}, "prediction_text": "Join a vocational youth/village or make their own arrangements for an apprenticeship program."}
{"answers": {"text": ["join a polytechnic or other technical college and study for three years or proceed directly to the university and study for four years", "join a polytechnic or other technical college", "join a vocational youth/village polytechnic"], "answer_start": [492, 492, 236]}, "prediction_text": "Join a polytechnic or other technical college."}
{"answers": {"text": ["85%", "85%", "85%"], "answer_start": [39, 39, 39]}, "prediction_text": "85%"}
{"answers": {"text": ["age three to five", "three to five", "age three to five"], "answer_start": [107, 111, 107]}, "prediction_text": "From 3 to 5"}
{"answers": {"text": ["a key requirement for admission to Standard One (First Grade)", "admission to Standard One", "admission to Standard One"], "answer_start": [182, 204, 204]}, "prediction_text": "Entry into Standard One (First Grade)"}
{"answers": {"text": ["those who proceed to secondary school or vocational training", "those who proceed to secondary school or vocational training", "those who proceed to secondary school or vocational training"], "answer_start": [357, 357, 357]}, "prediction_text": "Those who proceed to secondary school or vocational training."}
{"answers": {"text": ["the Kenya Certificate of Secondary Education", "Kenya Certificate of Secondary Education", "determines those proceeding to the universities"], "answer_start": [634, 638, 693]}, "prediction_text": "Kenya Certificate of Secondary Education (KCSE)"}
{"answers": {"text": ["the Kenya National Library Service", "Kenya National Library Service", "Kenya National Library Service"], "answer_start": [99, 103, 103]}, "prediction_text": "Kenya National Library Service (KNLS)"}
{"answers": {"text": ["establish, equip, manage and maintain national and public libraries in the country", "establish, equip, manage and maintain national and public libraries", "establish, equip, manage and maintain national and public libraries"], "answer_start": [171, 171, 171]}, "prediction_text": "Establish, equip, manage and maintain national and public libraries."}
{"answers": {"text": ["a peoples university", "peoples university", "peoples university"], "answer_start": [565, 567, 567]}, "prediction_text": "A peoples university"}
{"answers": {"text": ["it is open to all irrespective of age, literacy level and has materials relevant to people of all walks of life", "open to all irrespective of age, literacy level", "open to all irrespective of age, literacy level"], "answer_start": [592, 598, 598]}, "prediction_text": "Open to all regardless of age, literacy level, and materials."}
{"answers": {"text": ["cricket, rallying, football, rugby union and boxing", "cricket, rallying, football, rugby union and boxing", "cricket, rallying, football, rugby union and boxing"], "answer_start": [46, 46, 46]}, "prediction_text": "Cricket, rallying, football, rugby union, boxing."}
{"answers": {"text": ["its dominance in middle-distance and long-distance athletics", "middle-distance and long-distance athletics", "dominance in middle-distance and long-distance athletics"], "answer_start": [132, 149, 136]}, "prediction_text": "Its dominance in distance athletics"}
{"answers": {"text": ["Kenyan athletes (particularly Kalenjin)", "Kenyan athletes", "Kenya"], "answer_start": [380, 380, 0]}, "prediction_text": "Kenya"}
{"answers": {"text": ["Morocco and Ethiopia", "Morocco and Ethiopia", "Morocco and Ethiopia"], "answer_start": [498, 498, 498]}, "prediction_text": "Morocco and Ethiopia"}
{"answers": {"text": ["six gold", "several", "six"], "answer_start": [54, 10, 54]}, "prediction_text": "Six gold medals"}
{"answers": {"text": ["Africa's most successful nation in the 2008 Olympics", "Africa's most successful nation", "Africa's most successful nation"], "answer_start": [103, 103, 103]}, "prediction_text": "Kenya won several medals during the Beijing Olympics."}
{"answers": {"text": ["IAAF Golden League jackpot", "IAAF Golden League jackpot", "IAAF Golden League jackpot"], "answer_start": [268, 268, 268]}, "prediction_text": "Gold medal in 800m"}
{"answers": {"text": ["the defection of a number of Kenyan athletes to represent other countries", "defection of a number of Kenyan athletes", "a number of Kenyan athletes to represent other countries"], "answer_start": [641, 645, 658]}, "prediction_text": "Economic or financial factors."}
{"answers": {"text": ["economic or financial factors", "economic or financial factors", "economic or financial factors"], "answer_start": [953, 953, 953]}, "prediction_text": "Economic or financial factors."}
{"answers": {"text": ["women's volleyball within Africa", "volleyball", "volleyball"], "answer_start": [35, 43, 43]}, "prediction_text": "Women's volleyball"}
{"answers": {"text": ["Cricket", "Cricket", "Cricket"], "answer_start": [293, 293, 293]}, "prediction_text": "Cricket"}
{"answers": {"text": ["2003", "2003", "2003"], "answer_start": [485, 485, 485]}, "prediction_text": "2003"}
{"answers": {"text": ["Rakep Patel", "Rakep Patel", "Rakep Patel"], "answer_start": [635, 635, 635]}, "prediction_text": "Rakep Patel"}
{"answers": {"text": ["March 2007", "March 2007", "March 2007"], "answer_start": [1296, 1296, 1296]}, "prediction_text": "March 2007"}
{"answers": {"text": ["the world famous Safari Rally", "Safari Rally", "world famous Safari Rally"], "answer_start": [46, 63, 50]}, "prediction_text": "Safari Rally"}
{"answers": {"text": ["one of the toughest rallies in the world", "toughest rallies in the world", "toughest rallies in the world."], "answer_start": [102, 113, 113]}, "prediction_text": "One of the toughest rallies in the world."}
{"answers": {"text": ["Bj\u00f6rn Waldeg\u00e5rd, Hannu Mikkola, Tommi M\u00e4kinen, Shekhar Mehta, Carlos Sainz and Colin McRae", "Bj\u00f6rn Waldeg\u00e5rd, Hannu Mikkola, Tommi M\u00e4kinen, Shekhar Mehta, Carlos Sainz and Colin McRae", "Bj\u00f6rn Waldeg\u00e5rd, Hannu Mikkola, Tommi M\u00e4kinen, Shekhar Mehta, Carlos Sainz and Colin McRae"], "answer_start": [369, 369, 369]}, "prediction_text": "Bj\u00f6rn Waldeg\u00e5rd, Hannu Mikkola, Tommi M\u00e4kinen, Shekhar Mehta, Carlos Sainz, Colin McRae."}
{"answers": {"text": ["three meals in a day", "three", "three"], "answer_start": [23, 23, 23]}, "prediction_text": "Three meals a day"}
{"answers": {"text": ["10 o'clock tea (chai ya saa nne) and 4 pm tea", "10 o'clock", "10 o'clock tea (chai ya saa nne) and 4 pm"], "answer_start": [234, 234, 234]}, "prediction_text": "4 pm"}
{"answers": {"text": ["tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams", "porridge with bread, chapati, mahamri, boiled sweet potatoes or yams", "porridge with bread, chapati, mahamri, boiled sweet potatoes or yams"], "answer_start": [321, 328, 328]}, "prediction_text": "Tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams."}
{"answers": {"text": ["Ugali with vegetables, sour milk, meat, fish or any other stew", "Ugali with vegetables, sour milk, meat, fish or any other stew", "Ugali with vegetables, sour milk, meat, fish or any other stew"], "answer_start": [398, 398, 398]}, "prediction_text": "Vegetables, sour milk, meat, fish, or any other stew."}
{"answers": {"text": ["the United Nations", "the United Nations", "the United Nations"], "answer_start": [114, 114, 114]}, "prediction_text": "United Nations (UN)"}
{"answers": {"text": ["the World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP)", "World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP),", "the World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP)"], "answer_start": [249, 253, 249]}, "prediction_text": "World Meteorological Organization (WMO) and UNEP"}
{"answers": {"text": ["greenhouse gas concentrations in the atmosphere", "greenhouse gas concentrations in the atmosphere", "stabilize greenhouse gas concentrations in the atmosphere"], "answer_start": [716, 716, 706]}, "prediction_text": "Climate change"}
{"answers": {"text": ["United Nations Framework Convention on Climate Change", "United Nations Framework Convention on Climate Change (UNFCCC)", "the United Nations Framework Convention on Climate Change (UNFCCC),"], "answer_start": [540, 540, 536]}, "prediction_text": "UNFCCC"}
{"answers": {"text": ["Resolution 43/53", "Resolution 43/53", "Resolution 43/53"], "answer_start": [412, 412, 412]}, "prediction_text": "Resolution 43/53"}
{"answers": {"text": ["Hoesung Lee", "Hoesung Lee", "Hoesung Lee"], "answer_start": [17, 17, 17]}, "prediction_text": "Hoesung Lee"}
{"answers": {"text": ["Korean", "onomist", "Korean"], "answer_start": [0, 9, 0]}, "prediction_text": "Korean"}
{"answers": {"text": ["Ismail El Gizouli", "Ismail El Gizouli", "Ismail El Gizouli"], "answer_start": [181, 181, 181]}, "prediction_text": "Ismail El Gizouli"}
{"answers": {"text": ["Bert Bolin", "Bert Bolin", "Bert Bolin"], "answer_start": [391, 391, 391]}, "prediction_text": "Ismail El Gizouli"}
{"answers": {"text": ["February 2015", "February 2015", "February 2015"], "answer_start": [281, 281, 281]}, "prediction_text": "February 2015"}
{"answers": {"text": ["representatives appointed by governments and organizations", "representatives appointed by governments and organizations", "representatives appointed by governments and organizations"], "answer_start": [30, 30, 30]}, "prediction_text": "Governments and organizations"}
{"answers": {"text": ["350", "350", "350"], "answer_start": [494, 494, 494]}, "prediction_text": "322 persons"}
{"answers": {"text": ["government officials and climate change experts", "government officials and climate change experts", "government officials and climate change experts"], "answer_start": [498, 498, 498]}, "prediction_text": "Government officials and climate change experts."}
{"answers": {"text": ["about seven-eighths", "seven-eighths", "about seven-eighths"], "answer_start": [692, 698, 692]}, "prediction_text": "About seven-eighths"}
{"answers": {"text": ["1989", "1989", "1989"], "answer_start": [70, 70, 70]}, "prediction_text": "1989"}
{"answers": {"text": ["the United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO)", "United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO)", "the United Nations Environment Programme (UNEP) and the World Meteorological Organization (WMO),"], "answer_start": [78, 82, 78]}, "prediction_text": "United Nations Environment Programme (UNEP)"}
{"answers": {"text": ["United Nations Environment Programme", "UNEP", "UNEP"], "answer_start": [82, 260, 260]}, "prediction_text": "UNEP"}
{"answers": {"text": ["the Financial Regulations and Rules of the WMO", "Financial Regulations and Rules of the WMO", "Financial Regulations and Rules of the WMO"], "answer_start": [586, 590, 590]}, "prediction_text": "Financial Regulations and Rules of the WMO."}
{"answers": {"text": ["World Meteorological Organization", "WMO", "the WMO"], "answer_start": [134, 249, 245]}, "prediction_text": "UNEP"}
{"answers": {"text": ["does not carry out research nor does it monitor climate related data", "research", "carry out research nor does it monitor climate related data"], "answer_start": [9, 28, 18]}, "prediction_text": "Conduct research"}
{"answers": {"text": ["available information about climate change based on published sources", "published sources", "peer-reviewed sources"], "answer_start": [119, 171, 252]}, "prediction_text": "From published sources"}
{"answers": {"text": ["non-peer-reviewed sources", "non-peer-reviewed sources", "non-peer-reviewed sources"], "answer_start": [296, 296, 296]}, "prediction_text": "Non-peer-reviewed sources"}
{"answers": {"text": ["model results, reports from government agencies and non-governmental organizations, and industry journals", "model results", "model results, reports from government agencies and non-governmental organizations, and industry journals"], "answer_start": [439, 439, 439]}, "prediction_text": "Non-peer-reviewed sources include industry journals, industry research, and non-governmental organizations."}
{"answers": {"text": ["two", "two", "two"], "answer_start": [119, 119, 119]}, "prediction_text": "Ten to fifteen"}
{"answers": {"text": ["ten to fifteen", "ten to fifteen", "ten to fifteen"], "answer_start": [152, 152, 152]}, "prediction_text": "Ten to fifteen"}
{"answers": {"text": ["a somewhat larger number", "a somewhat larger number of \"contributing authors\"", "a somewhat larger number"], "answer_start": [187, 187, 187]}, "prediction_text": "A larger number"}
{"answers": {"text": ["The coordinating lead authors", "coordinating lead authors", "coordinating lead authors"], "answer_start": [239, 243, 243]}, "prediction_text": "Coordinating lead authors"}
{"answers": {"text": ["the Working Group chairs", "Working Group chairs", "Working Group chairs"], "answer_start": [420, 424, 424]}, "prediction_text": "Working Group chairs"}
{"answers": {"text": ["substantially increasing the atmospheric concentrations", "substantially increasing the atmospheric concentrations of the greenhouse gases", "substantially increasing the atmospheric concentrations"], "answer_start": [139, 139, 139]}, "prediction_text": "Increasing atmospheric concentrations."}
{"answers": {"text": ["additional warming of the Earth's surface", "warming of the Earth's surface", "additional warming of the Earth's surface"], "answer_start": [247, 258, 247]}, "prediction_text": "Increased atmospheric concentrations"}
{"answers": {"text": ["over half", "over half", "over half"], "answer_start": [355, 355, 355]}, "prediction_text": "Over half"}
{"answers": {"text": ["\"business as usual\" (BAU)", "enhanced greenhouse effect", "\"business as usual\" (BAU)"], "answer_start": [423, 369, 423]}, "prediction_text": "Business as usual"}
{"answers": {"text": ["increased by 0.3 to 0.6 \u00b0C", "0.3 to 0.6 \u00b0C", "0.3 to 0.6 \u00b0C"], "answer_start": [607, 620, 620]}, "prediction_text": "0.3 to 0.6 \u00b0C"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [3, 3, 3]}, "prediction_text": "2001"}
{"answers": {"text": ["16 national science academies", "16", "16"], "answer_start": [9, 9, 9]}, "prediction_text": "16 organizations"}
{"answers": {"text": ["Science", "Science", "Science"], "answer_start": [787, 787, 787]}, "prediction_text": "Science"}
{"answers": {"text": ["at least 90%", "at least 90%", "at least 90% certain"], "answer_start": [849, 849, 849]}, "prediction_text": "At least 90% certain"}
{"answers": {"text": ["between 1.4 and 5.8 \u00b0C above 1990 levels", "1.4 and 5.8 \u00b0C", "between 1.4 and 5.8 \u00b0C"], "answer_start": [976, 984, 976]}, "prediction_text": "1.4 to 5.8 \u00b0C"}
{"answers": {"text": ["Richard Lindzen", "Richard Lindzen", "Richard Lindzen"], "answer_start": [12, 12, 12]}, "prediction_text": "Richard Lindzen"}
{"answers": {"text": ["does not faithfully summarize the full WGI report", "understates the uncertainty associated with climate models", "does not faithfully summarize the full WGI report"], "answer_start": [157, 249, 157]}, "prediction_text": "Not faithfully summarizing the full WGI report."}
{"answers": {"text": ["John Houghton", "John Houghton", "John Houghton,"], "answer_start": [309, 309, 309]}, "prediction_text": "John Houghton"}
{"answers": {"text": ["a co-chair of TAR WGI", "co-chair of TAR WGI", "co-chair of TAR WGI"], "answer_start": [332, 334, 334]}, "prediction_text": "Co-chair of TAR WGI"}
{"answers": {"text": ["scientific evidence", "must be supported by scientific evidence", "must be supported by scientific evidence"], "answer_start": [559, 538, 538]}, "prediction_text": "Scientific evidence"}
{"answers": {"text": ["the same procedures as for IPCC Assessment Reports", "follows the same procedures as for IPCC Assessment Reports", "the same procedures as for IPCC Assessment Reports"], "answer_start": [176, 168, 176]}, "prediction_text": "Followed same procedures as for IPCC Reports."}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [240, 240, 240]}, "prediction_text": "2011"}
{"answers": {"text": ["2011", "2011", "2011"], "answer_start": [240, 240, 240]}, "prediction_text": "2011"}
{"answers": {"text": ["requested by governments", "requested by governments", "requested by governments."], "answer_start": [514, 514, 514]}, "prediction_text": "To advance climate change adaptation."}
{"answers": {"text": ["the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "Data Distribution Centre and the National Greenhouse Gas Inventories Programme"], "answer_start": [329, 333, 333]}, "prediction_text": "Data Distribution Centre, National Greenhouse Gas Inventories Programme."}
{"answers": {"text": ["default emission factors", "default emission factors", "default emission factors"], "answer_start": [465, 465, 465]}, "prediction_text": "Default emission factors"}
{"answers": {"text": ["fuel consumption, industrial production and so on", "Greenhouse Gas Inventories", "fuel consumption, industrial production and so on"], "answer_start": [567, 375, 567]}, "prediction_text": "Fuel consumption, industrial production, so on."}
{"answers": {"text": ["WMO Executive Council and UNEP Governing Council", "WMO Executive Council and UNEP Governing Council", "WMO Executive Council and UNEP Governing Council"], "answer_start": [81, 81, 81]}, "prediction_text": "WMO Executive Council, UNEP Governing Council, UNFCCC"}
{"answers": {"text": ["the date", "the date", "the date"], "answer_start": [109, 109, 109]}, "prediction_text": "The date was incorrectly quoted."}
{"answers": {"text": ["\"the poor application of well-established IPCC procedures in this instance\"", "the poor application of well-established IPCC procedures", "poor application of well-established IPCC procedures"], "answer_start": [229, 230, 234]}, "prediction_text": "Poor application of well-established procedures"}
{"answers": {"text": ["the WWF report", "the IPCC from the WWF report", "the WWF report"], "answer_start": [366, 352, 366]}, "prediction_text": "ICSI report"}
{"answers": {"text": ["\"Variations of Snow and Ice in the past and at present on a Global and Regional Scale\"", "the IPCC from the WWF report", "the WWF report"], "answer_start": [433, 352, 366]}, "prediction_text": "WWF report"}
{"answers": {"text": ["IPCC chairman", "chairman", "chairman"], "answer_start": [7, 12, 12]}, "prediction_text": "Former IPCC chairman"}
{"answers": {"text": ["making it seem like climate change is more serious by overstating the impact", "the direction of making it seem like climate change is more serious", "making it seem like climate change is more serious by overstating the impact"], "answer_start": [102, 85, 102]}, "prediction_text": "Overstating impact"}
{"answers": {"text": ["co-chair of the IPCC working group II", "co-chair of the IPCC working group II", "co-chair of the IPCC working group II"], "answer_start": [319, 319, 319]}, "prediction_text": "Climate expert"}
{"answers": {"text": ["Himalayan glaciers", "Himalayan glaciers"], "answer_start": [417, 417]}, "prediction_text": "Overstating the impact of climate change"}
{"answers": {"text": ["\"generally unfounded and also marginal to the assessment\"", "generally unfounded and also marginal to the assessment", "generally unfounded and also marginal to the assessment"], "answer_start": [545, 546, 546]}, "prediction_text": "Indifferent to the assessment."}
{"answers": {"text": ["1999", "1999", "1999"], "answer_start": [142, 142, 142]}, "prediction_text": "1999 paper by Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes."}
{"answers": {"text": ["Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes"], "answer_start": [156, 156, 156]}, "prediction_text": "Michael E. Mann, Raymond S. Bradley, Malcolm K. Hughes, and Michael E. Mann."}
{"answers": {"text": ["the \"hockey stick graph\"", "hockey stick graph", "hockey stick graph"], "answer_start": [253, 258, 258]}, "prediction_text": "Hockey stick graph"}
{"answers": {"text": ["Jones et al. 1998, Pollack, Huang & Shen 1998, Crowley & Lowery 2000 and Briffa 2000", "Jones et al. and Briffa reconstructions", "temperatures increased on the basis of documentary evidence of Medieval vineyards in England"], "answer_start": [1049, 1173, 755]}, "prediction_text": "Pollack, Huang & Shen, Crowley & Lowery, Briffa, Jones et al."}
{"answers": {"text": ["between 1000 and 1900", "1000 and 1900", "1000 and 1900"], "answer_start": [130, 138, 138]}, "prediction_text": "1000 to 1900"}
{"answers": {"text": ["Fred Singer", "Fred Singer", "Fred Singer"], "answer_start": [281, 281, 281]}, "prediction_text": "Fred Singer"}
{"answers": {"text": ["Capitol Hill, Washington, D.C.", "Capitol Hill, Washington, D.C.", "Capitol Hill, Washington, D.C."], "answer_start": [358, 358, 358]}, "prediction_text": "Capitol Hill"}
{"answers": {"text": ["18 July 2000", "May 2000", "18 July 2000"], "answer_start": [560, 272, 560]}, "prediction_text": "18 July 2000"}
{"answers": {"text": ["United States Senate Committee on Commerce, Science and Transportation", "Committee on Commerce, Science and Transportation", "United States Senate Committee on Commerce, Science and Transportation"], "answer_start": [478, 499, 478]}, "prediction_text": "United States Senate Committee on Commerce, Science and Transportation"}
{"answers": {"text": ["Rep. Joe Barton", "Rep. Joe Barton", "Rep. Joe Barton"], "answer_start": [17, 17, 17]}, "prediction_text": "Joe Barton"}
{"answers": {"text": ["Ed Whitfield", "Ed Whitfield", "Ed Whitfield"], "answer_start": [114, 114, 114]}, "prediction_text": "Ed Whitfield"}
{"answers": {"text": ["23 June 2005", "23 June 2005", "23 June 2005"], "answer_start": [3, 3, 3]}, "prediction_text": "June 23, 2005"}
{"answers": {"text": ["Sherwood Boehlert", "Sherwood Boehlert", "Sherwood Boehlert"], "answer_start": [330, 330, 330]}, "prediction_text": "Sherwood Boehlert"}
{"answers": {"text": ["Sherwood Boehlert", "Sherwood Boehlert", "Sherwood Boehlert, chairman of the House Science Committee"], "answer_start": [330, 330, 330]}, "prediction_text": "Sherwood Boehlert"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [166, 166, 166]}, "prediction_text": "2007"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [53, 53, 53]}, "prediction_text": "2007"}
{"answers": {"text": ["Ten", "14", "Ten"], "answer_start": [463, 476, 463]}, "prediction_text": "Ten reconstructions covered 1,000+ years."}
{"answers": {"text": ["divergence", "divergence problem", "divergence"], "answer_start": [740, 740, 740]}, "prediction_text": "divergence problem"}
{"answers": {"text": ["14", "Ten", "14"], "answer_start": [476, 463, 476]}, "prediction_text": "Ten reconstructions"}
{"answers": {"text": ["1 February 2007", "1 February 2007", "1 February 2007"], "answer_start": [3, 3, 3]}, "prediction_text": "February 1, 2007"}
{"answers": {"text": ["temperatures and sea levels have been rising at or above the maximum rates", "temperatures and sea levels have been rising at or above the maximum rates proposed", "temperatures and sea levels have been rising at or above the maximum rates proposed"], "answer_start": [120, 120, 120]}, "prediction_text": "Comparable to reality."}
{"answers": {"text": ["actual temperature rise was near the top end of the range given", "temperature rise was near the top end of the range given", "near the top end of the range given by IPCC's 2001 projection"], "answer_start": [369, 376, 397]}, "prediction_text": "Near the top end of the range"}
{"answers": {"text": ["actual sea level rise was above the top of the range", "actual sea level rise was above the top of the range", "the actual sea level rise was above the top of the range"], "answer_start": [468, 468, 464]}, "prediction_text": "Above the top end of the range."}
{"answers": {"text": ["projected rises in sea levels", "rises in sea levels", "projected rises in sea levels"], "answer_start": [176, 186, 176]}, "prediction_text": "Sea levels were predicted to rise by 50\u2013140 cm."}
{"answers": {"text": ["9\u201388 cm", "0.5\u20131.4 m", "9\u201388 cm"], "answer_start": [478, 398, 478]}, "prediction_text": "9\u201388 cm"}
{"answers": {"text": ["50\u2013140 cm", "9\u201388 cm", "0.5\u20131.4 m [50\u2013140 cm]"], "answer_start": [409, 478, 398]}, "prediction_text": "0.5\u20131.4 m (50\u2013140 cm)"}
{"answers": {"text": ["2001", "2001", "2001"], "answer_start": [563, 563, 563]}, "prediction_text": "2001"}
{"answers": {"text": ["coordinating lead author of the Fifth Assessment Report", "participant in the IPCC and coordinating lead author of the Fifth Assessment Report", "coordinating lead author of the Fifth Assessment Report"], "answer_start": [61, 33, 61]}, "prediction_text": "Coordinating and coordinating with other scientists."}
{"answers": {"text": ["Science Magazine", "Science Magazine", "Science Magazine's"], "answer_start": [129, 129, 129]}, "prediction_text": "Michael Oppenheimer"}
{"answers": {"text": ["concurring, smaller assessments of special problems", "smaller assessments of special problems instead of the large scale approach", "concurring, smaller assessments of special problems"], "answer_start": [239, 251, 239]}, "prediction_text": "Smaller assessments of special problems."}
{"answers": {"text": ["the Montreal Protocol", "Montreal Protocol", "global regulation based on the Montreal Protocol"], "answer_start": [238, 242, 211]}, "prediction_text": "Montreal Protocol"}
{"answers": {"text": ["Climate Change", "Climate Change", "Climate Change"], "answer_start": [292, 292, 292]}, "prediction_text": "Ozone depletion"}
{"answers": {"text": ["states and governments", "states and governments", "states and governments"], "answer_start": [488, 488, 488]}, "prediction_text": "States and governments"}
{"answers": {"text": ["Sheldon Ungar", "Sheldon Ungar", "Sheldon Ungar"], "answer_start": [13, 13, 13]}, "prediction_text": "Sheldon Ungar"}
{"answers": {"text": ["varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions", "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions"], "answer_start": [619, 619]}, "prediction_text": "Cost-benefit analysis and conflicts with emission reductions."}
{"answers": {"text": ["regional burden sharing conflicts", "regional burden sharing conflicts", "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions"], "answer_start": [513, 513, 619]}, "prediction_text": "Regional burden sharing conflicts"}
{"answers": {"text": ["the UK government", "the UK government", "the UK government"], "answer_start": [946, 946, 946]}, "prediction_text": "UK government"}
{"answers": {"text": ["other scientific bodies", "scientific papers and independently documented results", "scientific papers and independently documented results from other scientific bodies"], "answer_start": [140, 80, 80]}, "prediction_text": "Scientific papers and independent documented results."}
{"answers": {"text": ["significant new evidence or events that change our understanding of climate science", "significant new evidence or events that change our understanding", "significant new evidence or events that change our understanding of climate science"], "answer_start": [311, 311, 311]}, "prediction_text": "Significant new evidence or events that change our understanding of climate science."}
{"answers": {"text": ["IPCC", "IPCC", "the IPCC"], "answer_start": [439, 439, 6]}, "prediction_text": "The IPCC"}
{"answers": {"text": ["five", "five", "five"], "answer_start": [97, 97, 97]}, "prediction_text": "Five scientists"}
{"answers": {"text": ["the journal Nature", "the journal Nature", "the journal Nature"], "answer_start": [179, 179, 179]}, "prediction_text": "Nature"}
{"answers": {"text": ["turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC", "turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC", "turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC"], "answer_start": [407, 407, 407]}, "prediction_text": "A small permanent body"}
{"answers": {"text": ["remove government oversight from its processes", "remove government oversight", "remove government oversight from its processes"], "answer_start": [577, 577, 577]}, "prediction_text": "By using a moderated process."}
{"answers": {"text": ["to conduct photosynthesis", "conduct photosynthesis", "conduct photosynthesis"], "answer_start": [27, 30, 30]}, "prediction_text": "Conduct photosynthesis"}
{"answers": {"text": ["energy", "energy", "energy"], "answer_start": [170, 170, 112]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["energy", "energy", "energy"], "answer_start": [170, 170, 112]}, "prediction_text": "Oxygen"}
{"answers": {"text": ["the Calvin cycle", "Calvin cycle", "Calvin cycle"], "answer_start": [342, 346, 346]}, "prediction_text": "Calvin cycle"}
{"answers": {"text": ["1", "1", "1"], "answer_start": [554, 554, 554]}, "prediction_text": "1 in algae"}
{"answers": {"text": ["pinch in two", "pinch in two", "pinch in two"], "answer_start": [105, 105, 105]}, "prediction_text": "They pinch in two to reproduce."}
{"answers": {"text": ["environmental factors like light color and intensity", "environmental factors", "environmental factors like light color and intensity"], "answer_start": [173, 173, 173]}, "prediction_text": "Environmental factors"}
{"answers": {"text": ["contain their own DNA", "contain their own DNA", "contain their own DNA,"], "answer_start": [260, 260, 260]}, "prediction_text": "Chloroplasts are highly dynamic and have their own DNA."}
{"answers": {"text": ["a photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell", "a photosynthetic cyanobacterium", "photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell"], "answer_start": [336, 336, 338]}, "prediction_text": "A photosynthetic cyanobacterium"}
{"answers": {"text": ["must be inherited by each daughter cell during cell division", "inherited", "inherited by each daughter cell during cell division"], "answer_start": [465, 473, 473]}, "prediction_text": "Through cell division"}
{"answers": {"text": ["plants and algae", "plants and algae", "plants and algae."], "answer_start": [590, 590, 590]}, "prediction_text": "Cyanobacteria and eukaryotes"}
{"answers": {"text": ["Russian", "Russian", "Russian"], "answer_start": [418, 418, 418]}, "prediction_text": "Russian"}
{"answers": {"text": ["biologist", "biologist", "biologist"], "answer_start": [426, 426, 426]}, "prediction_text": "Russian biologist"}
{"answers": {"text": ["1905", "1905", "1905"], "answer_start": [464, 464, 464]}, "prediction_text": "1905"}
{"answers": {"text": ["Andreas Schimper", "Andreas Schimper", "Andreas Schimper"], "answer_start": [475, 475, 475]}, "prediction_text": "Konstantin Mereschkowski"}
{"answers": {"text": ["Cyanobacteria", "Cyanobacteria", "Cyanobacteria"], "answer_start": [0, 0, 0]}, "prediction_text": "Cyanobacteria"}
{"answers": {"text": ["prokaryotes", "bacteria", "prokaryotes"], "answer_start": [124, 166, 124]}, "prediction_text": "Prokaryotes"}
{"answers": {"text": ["they have two cell membranes", "two cell membranes", "they have two cell membranes."], "answer_start": [251, 261, 251]}, "prediction_text": "Two cell membranes"}
{"answers": {"text": ["peptidoglycan", "peptidoglycan", "peptidoglycan"], "answer_start": [310, 310, 310]}, "prediction_text": "Thickness between cell membranes"}
{"answers": {"text": ["blue-green algae", "blue-green algae", "sometimes called blue-green algae"], "answer_start": [86, 86, 69]}, "prediction_text": "Blue-green algae"}
{"answers": {"text": ["eukaryotic", "an early eukaryotic cell", "eukaryotic"], "answer_start": [84, 75, 84]}, "prediction_text": "Eukaryotic cell"}
{"answers": {"text": ["around a billion years ago", "a billion years ago", "around a billion years ago"], "answer_start": [10, 17, 10]}, "prediction_text": "Around a billion years ago"}
{"answers": {"text": ["two innermost lipid-bilayer membranes", "phagocytic vacuole", "lipid-bilayer membranes"], "answer_start": [214, 170, 228]}, "prediction_text": "Inner and outer membranes"}
{"answers": {"text": ["phagosomal", "phagosomal", "phagosomal"], "answer_start": [398, 398, 398]}, "prediction_text": "The outer and inner membranes of the ancestral cyanobacterium's gram negative cell wall correspond to the outer and inner membranes of the host's gram negative cell wall."}
{"answers": {"text": ["many of its genes were lost or transferred to the nucleus of the host", "many of its genes were lost or transferred", "many of its genes were lost or transferred to the nucleus of the host"], "answer_start": [640, 640, 640]}, "prediction_text": "Many of its genes were lost or transferred to the nucleus of the host."}
{"answers": {"text": ["almost the same thing as chloroplast", "chloroplast", "chloroplast"], "answer_start": [147, 172, 172]}, "prediction_text": "Almost the same thing as chloroplast."}
{"answers": {"text": ["three", "three", "three"], "answer_start": [228, 228, 228]}, "prediction_text": "Three chloroplast lineages"}
{"answers": {"text": ["red algal chloroplast", "red algal chloroplast lineage", "red algal chloroplast lineage"], "answer_start": [311, 311, 311]}, "prediction_text": "Red algal"}
{"answers": {"text": ["green chloroplast", "green chloroplast lineage", "green chloroplast lineage"], "answer_start": [369, 369, 369]}, "prediction_text": "Green chloroplast lineage"}
{"answers": {"text": ["the green chloroplast lineage", "the green chloroplast lineage", "green chloroplast lineage"], "answer_start": [432, 432, 436]}, "prediction_text": "Rhodophyte chloroplast lineage"}
{"answers": {"text": ["glaucophyte", "glaucophyte", "glaucophyte chloroplast group"], "answer_start": [23, 23, 110]}, "prediction_text": "Glaucophyte chloroplast"}
{"answers": {"text": ["alga", "alga", "glaucophyte"], "answer_start": [4, 4, 23]}, "prediction_text": "Glaucophyte of the alga Cyanophora."}
{"answers": {"text": ["glaucophyte chloroplasts", "glaucophyte chloroplasts", "glaucophyte chloroplasts"], "answer_start": [439, 439, 439]}, "prediction_text": "Glaucophyte chloroplasts"}
{"answers": {"text": ["a carboxysome", "carboxysome", "carboxysome"], "answer_start": [580, 582, 582]}, "prediction_text": "Carboxysomes"}
{"answers": {"text": ["icosahedral", "icosahedral", "icosahedral"], "answer_start": [599, 599, 599]}, "prediction_text": "An icosahedral structure that glaucophyte chloroplasts and cyanobacteria keep their carbon fixation enzyme."}
{"answers": {"text": ["chlorophyll a and phycobilins", "phycobilin", "phycobilin"], "answer_start": [229, 67, 67]}, "prediction_text": "Phycobilin pigments"}
{"answers": {"text": ["phycobilisomes", "phycobilisomes", "phycobilisomes"], "answer_start": [102, 102, 102]}, "prediction_text": "Phycobilin pigments"}
{"answers": {"text": ["the phycobilin phycoerytherin", "phycobilin phycoerytherin", "phycobilin phycoerytherin"], "answer_start": [288, 292, 292]}, "prediction_text": "Phycobilin pigments"}
{"answers": {"text": ["catch more sunlight in deep water", "catch more sunlight in deep water", "catch more sunlight in deep water"], "answer_start": [585, 585, 585]}, "prediction_text": "Red algae can catch more sunlight."}
{"answers": {"text": ["a form of starch", "a form of starch", "a form of starch"], "answer_start": [770, 770, 770]}, "prediction_text": "A form of starch that collects into granules outside the rhodoplast."}
{"answers": {"text": ["phycobilisomes", "phycobilisomes", "phycobilisomes"], "answer_start": [281, 281, 281]}, "prediction_text": "Phycobilisomes"}
{"answers": {"text": ["accessory pigments that override the chlorophylls' green colors", "accessory pigments", "accessory pigments that override the chlorophylls' green colors"], "answer_start": [449, 449, 449]}, "prediction_text": "Due to accessory pigments."}
{"answers": {"text": ["the peptidoglycan wall", "the peptidoglycan wall", "peptidoglycan wall between their double membrane"], "answer_start": [553, 553, 557]}, "prediction_text": "Phycobilisomes"}
{"answers": {"text": ["chloroplast division", "chloroplast division", "chloroplast division"], "answer_start": [785, 785, 785]}, "prediction_text": "chloroplast division"}
{"answers": {"text": ["chlorophyll b", "chlorophyll b", "chlorophyll b"], "answer_start": [309, 309, 309]}, "prediction_text": "Chlorophyll b"}
{"answers": {"text": ["double", "double membrane", "double membrane"], "answer_start": [34, 34, 34]}, "prediction_text": "Double membrane"}
{"answers": {"text": ["additional membranes outside of the original two", "additional membranes", "have additional membranes outside of the original two"], "answer_start": [114, 114, 109]}, "prediction_text": "Additional membranes outside of original two."}
{"answers": {"text": ["a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it", "a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it", "nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it"], "answer_start": [219, 219, 221]}, "prediction_text": "A nonphotosynthetic eukaryote engulfed a chloroplast-containing alga."}
{"answers": {"text": ["sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane", "sometimes the eaten alga's cell membrane", "the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane"], "answer_start": [568, 568, 534]}, "prediction_text": "Additional membranes outside of the original two."}
{"answers": {"text": ["its chloroplast, and sometimes its cell membrane and nucleus", "its chloroplast", "chloroplast"], "answer_start": [421, 421, 425]}, "prediction_text": "Chloroplast and cell membrane."}
{"answers": {"text": ["chloroplasts derived from a green alga", "green alga", "green alga"], "answer_start": [70, 98, 98]}, "prediction_text": "Three chloroplasts"}
{"answers": {"text": ["common flagellated", "common flagellated", "common flagellated"], "answer_start": [29, 29, 29]}, "prediction_text": "Common flagellated protists"}
{"answers": {"text": ["stacked in groups of three", "groups of three", "stacked in groups of three"], "answer_start": [368, 379, 368]}, "prediction_text": "In groups of three."}
{"answers": {"text": ["Starch", "Starch", "Starch"], "answer_start": [396, 396, 396]}, "prediction_text": "Membranes"}
{"answers": {"text": ["the membrane of the primary endosymbiont", "the primary endosymbiont", "primary endosymbiont"], "answer_start": [176, 192, 196]}, "prediction_text": "membrane of the primary endosymbiont"}
{"answers": {"text": ["cryptomonads", "cryptomonads", "cryptomonads"], "answer_start": [17, 17, 17]}, "prediction_text": "Cryptomonads"}
{"answers": {"text": ["red-algal derived chloroplast", "red-algal", "red-algal derived"], "answer_start": [66, 66, 66]}, "prediction_text": "Red-algal derived chloroplast"}
{"answers": {"text": ["nucleomorph", "nucleomorph", "nucleomorph"], "answer_start": [132, 132, 132]}, "prediction_text": "Outermost membrane"}
{"answers": {"text": ["in granules found in the periplastid space", "granules", "in granules found in the periplastid space"], "answer_start": [376, 379, 376]}, "prediction_text": "Outside the original double membrane"}
{"answers": {"text": ["stacks of two", "stacks of two", "in stacks of two"], "answer_start": [580, 580, 577]}, "prediction_text": "Inside cryptophyte chloroplasts is a pyrenoid and thylakoid stack."}
{"answers": {"text": ["helicosproidia", "helicosproidia", "helicosproidia"], "answer_start": [61, 61, 61]}, "prediction_text": "helicosproidia and malaria parasite."}
{"answers": {"text": ["chromalveolates", "chromalveolates", "chromalveolates"], "answer_start": [35, 35, 35]}, "prediction_text": "Chromalveolates"}
{"answers": {"text": ["the malaria parasite", "apicomplexans", "malaria parasite"], "answer_start": [324, 290, 328]}, "prediction_text": "malaria parasite"}
{"answers": {"text": ["a vestigial red algal derived chloroplast", "a vestigial red algal derived chloroplast", "red algal derived chloroplast"], "answer_start": [370, 370, 382]}, "prediction_text": "A chloroplast is a nonphotosynthetic algae."}
{"answers": {"text": ["in amylopectin starch granules that are located in their cytoplasm", "amylopectin starch granules", "amylopectin starch granules"], "answer_start": [589, 592, 592]}, "prediction_text": "Amylopectin starch granules"}
{"answers": {"text": ["fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters", "fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters", "fatty acids, isopentenyl pyrophosphate, iron-sulfur clusters"], "answer_start": [516, 516, 516]}, "prediction_text": "Fatty acids"}
{"answers": {"text": ["apicomplexan-related diseases", "apicomplexan-related diseases", "apicomplexan-related"], "answer_start": [683, 683, 683]}, "prediction_text": "Apicomplexan-related diseases"}
{"answers": {"text": ["isopentenyl pyrophosphate synthesis", "isopentenyl pyrophosphate synthesis", "isopentenyl pyrophosphate synthesis"], "answer_start": [756, 756, 756]}, "prediction_text": "Produce important things."}
{"answers": {"text": ["photosynthetic pigments or true thylakoids", "photosynthetic function", "all photosynthetic function"], "answer_start": [66, 26, 22]}, "prediction_text": "Photosynthetic pigments and true thylakoids."}
{"answers": {"text": ["four", "four", "four"], "answer_start": [130, 130, 130]}, "prediction_text": "Four membranes"}
{"answers": {"text": ["Peridinin", "peridinin", "peridinin"], "answer_start": [191, 113, 113]}, "prediction_text": "Carotenoid pigment peridinin"}
{"answers": {"text": ["peridinin-type chloroplast", "chloroplasts", "chloroplasts"], "answer_start": [45, 132, 132]}, "prediction_text": "In chloroplasts"}
{"answers": {"text": ["triplet-stacked", "triplet-stacked", "triplet-stacked"], "answer_start": [495, 495, 495]}, "prediction_text": "They are triplet-stacked."}
{"answers": {"text": ["the red algal endosymbiont's original cell membrane", "the red algal endosymbiont's original cell membrane", "red algal endosymbiont's original cell membrane"], "answer_start": [338, 338, 342]}, "prediction_text": "Cell membrane"}
{"answers": {"text": ["fucoxanthin dinophyte", "fucoxanthin dinophyte", "fucoxanthin dinophyte"], "answer_start": [4, 4, 4]}, "prediction_text": "Karenia"}
{"answers": {"text": ["fucoxanthin dinophyte", "fucoxanthin dinophyte", "fucoxanthin dinophyte"], "answer_start": [4, 4, 4]}, "prediction_text": "Karlodinium"}
{"answers": {"text": ["four", "four", "four"], "answer_start": [310, 310, 310]}, "prediction_text": "Four membranes"}
{"answers": {"text": ["a six membraned chloroplast", "a six membraned chloroplast", "six membraned chloroplast"], "answer_start": [377, 377, 379]}, "prediction_text": "Six membraned chloroplast"}
{"answers": {"text": ["a cryptophyte", "cryptophyte", "cryptophyte"], "answer_start": [84, 86, 86]}, "prediction_text": "Cryptophyte"}
{"answers": {"text": ["its nucleomorph and outermost two membranes", "its nucleomorph and outermost two membranes", "nucleomorph and outermost two membranes"], "answer_start": [235, 235, 239]}, "prediction_text": "Their nucleomorph"}
{"answers": {"text": ["a phycobilin-containing chloroplast", "phycobilin-containing chloroplast", "phycobilin-containing"], "answer_start": [37, 39, 39]}, "prediction_text": "A two-membraned chloroplast."}
{"answers": {"text": ["a two-membraned chloroplast", "a two-membraned chloroplast", "a two-membraned chloroplast"], "answer_start": [293, 293, 293]}, "prediction_text": "Nucleomorph and outermost two membranes."}
{"answers": {"text": ["heterokontophyte", "heterokontophyte", "heterokontophyte"], "answer_start": [68, 68, 68]}, "prediction_text": "Homokontophyte"}
{"answers": {"text": ["a diatom (heterokontophyte) derived chloroplast", "diatom (heterokontophyte) derived", "diatom (heterokontophyte) derived"], "answer_start": [58, 60, 60]}, "prediction_text": "A diatom-derived chloroplast."}
{"answers": {"text": ["up to five", "up to five", "five"], "answer_start": [141, 141, 147]}, "prediction_text": "Five membranes"}
{"answers": {"text": ["the entire diatom endosymbiont as the chloroplast", "the entire diatom endosymbiont", "diatom endosymbiont"], "answer_start": [195, 195, 206]}, "prediction_text": "Up to five membranes"}
{"answers": {"text": ["granules in the dinophyte host's cytoplasm", "in the dinophyte host", "granules in the dinophyte host's cytoplasm"], "answer_start": [662, 671, 662]}, "prediction_text": "In granules in the host's cytoplasm."}
{"answers": {"text": ["the dinophyte nucleus", "the dinophyte nucleus", "dinophyte nucleus"], "answer_start": [417, 417, 421]}, "prediction_text": "dinophyte nucleus"}
{"answers": {"text": ["Lepidodinium", "Lepidodinium", "Lepidodinium"], "answer_start": [198, 198, 198]}, "prediction_text": "Lepidodinium"}
{"answers": {"text": ["their original peridinin chloroplast", "nucleomorph", "their original peridinin chloroplast"], "answer_start": [69, 354, 69]}, "prediction_text": "Original peridinin chloroplast"}
{"answers": {"text": ["a green algal derived chloroplast", "prasinophyte", "green algal derived chloroplast (more specifically, a prasinophyte)"], "answer_start": [127, 183, 129]}, "prediction_text": "A green algal derived chloroplast."}
{"answers": {"text": ["a green algal derived chloroplast", "a green algal derived chloroplast", "green algal derived chloroplast"], "answer_start": [127, 127, 129]}, "prediction_text": "A dinophyte with a chloroplast."}
{"answers": {"text": ["first set of endosymbiotic events", "first set of endosymbiotic events", "first set of endosymbiotic events"], "answer_start": [44, 44, 44]}, "prediction_text": "From endosymbiotic events"}
{"answers": {"text": ["acquired a photosynthetic cyanobacterial endosymbiont more recently", "acquired a photosynthetic cyanobacterial endosymbiont more recently", "acquired a photosynthetic cyanobacterial endosymbiont more recently"], "answer_start": [125, 125, 125]}, "prediction_text": "It is in the early stages of endosymbiosis."}
{"answers": {"text": ["about a million", "about a million", "about a million"], "answer_start": [659, 659, 659]}, "prediction_text": "About 0.3\u20130.8%"}
{"answers": {"text": ["around 850", "850", "850"], "answer_start": [703, 710, 710]}, "prediction_text": "850 genes"}
{"answers": {"text": ["three million", "150,000", "three million"], "answer_start": [755, 840, 755]}, "prediction_text": "About 1 million base pairs"}
{"answers": {"text": ["ctDNA, or cpDNA", "ctDNA", "ctDNA, or cpDNA"], "answer_start": [54, 54, 54]}, "prediction_text": "cpDNA"}
{"answers": {"text": ["the plastome", "cpDNA", "plastome"], "answer_start": [91, 64, 95]}, "prediction_text": "Plastome"}
{"answers": {"text": ["1962", "1962", "1962"], "answer_start": [139, 139, 139]}, "prediction_text": "1962"}
{"answers": {"text": ["1986", "1986", "1986"], "answer_start": [168, 168, 168]}, "prediction_text": "1986"}
{"answers": {"text": ["two Japanese research teams", "two Japanese research teams", "two Japanese research teams"], "answer_start": [178, 178, 178]}, "prediction_text": "Japanese researchers"}
{"answers": {"text": ["The inverted repeat regions", "inverted repeat regions", "inverted repeat regions"], "answer_start": [0, 4, 4]}, "prediction_text": "Mutations in inverted repeat segments"}
{"answers": {"text": ["direct repeats", "direct repeats", "direct repeats"], "answer_start": [367, 367, 367]}, "prediction_text": "Stabilized the rest of the chloroplast genome."}
{"answers": {"text": ["stabilize the rest of the chloroplast genome", "stabilize the rest of the chloroplast", "help stabilize the rest of the chloroplast genome"], "answer_start": [430, 430, 425]}, "prediction_text": "Stabilize chloroplast genome."}
{"answers": {"text": ["electron microscopy", "via electron microscopy", "electron microscopy"], "answer_start": [197, 193, 197]}, "prediction_text": "By electron microscopy"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [96, 96, 96]}, "prediction_text": "Two main models: D-loop and rolling circle."}
{"answers": {"text": ["a theta intermediary form", "theta intermediary form", "a theta intermediary form"], "answer_start": [423, 425, 423]}, "prediction_text": "A replication intermediate is a DNA replication fork that forms at specific points of origin."}
{"answers": {"text": ["a Cairns replication intermediate", "double displacement loop", "double displacement loop"], "answer_start": [464, 332, 332]}, "prediction_text": "Double displacement loop"}
{"answers": {"text": ["with a rolling circle mechanism", "a rolling circle mechanism", "with a rolling circle mechanism"], "answer_start": [525, 530, 525]}, "prediction_text": "With a rolling circle mechanism."}
{"answers": {"text": ["A \u2192 G deamination", "A \u2192 G deamination gradients", "A \u2192 G deamination"], "answer_start": [28, 28, 28]}, "prediction_text": "A \u2192 G deamination gradients"}
{"answers": {"text": ["when it is single stranded", "when it is single stranded", "replication forks form"], "answer_start": [103, 103, 136]}, "prediction_text": "Single stranded strand"}
{"answers": {"text": ["linear", "linear", "linear"], "answer_start": [622, 622, 622]}, "prediction_text": "By homologous recombination."}
{"answers": {"text": ["homologous recombination", "homologous recombination", "through homologous recombination"], "answer_start": [652, 652, 644]}, "prediction_text": "Through homologous recombination."}
{"answers": {"text": ["in branched, linear, or other complex structures", "branched, linear, or other complex structures", "in branched, linear, or other complex structures"], "answer_start": [793, 796, 793]}, "prediction_text": "Circular chromosomes"}
{"answers": {"text": ["bacteriophage T4", "bacteriophage T4.", "bacteriophage T4"], "answer_start": [162, 162, 162]}, "prediction_text": "bacteriophage T4"}
{"answers": {"text": ["linear", "linear", "linear"], "answer_start": [226, 226, 226]}, "prediction_text": "Linear cpDNA"}
{"answers": {"text": ["circular", "circular", "circular"], "answer_start": [1063, 987, 1063]}, "prediction_text": "Linear and participates in homologous recombination and replication."}
{"answers": {"text": ["via a D loop mechanism", "via a D loop mechanism", "via a D loop mechanism"], "answer_start": [1099, 1099, 1099]}, "prediction_text": "Through a D loop mechanism."}
{"answers": {"text": ["Endosymbiotic gene transfer", "Endosymbiotic gene transfer", "Endosymbiotic gene transfer"], "answer_start": [0, 0, 0]}, "prediction_text": "Endosymbiotic gene transfer"}
{"answers": {"text": ["the lost chloroplast's existence", "for the lost chloroplast's existence", "the lost chloroplast's existence"], "answer_start": [228, 224, 228]}, "prediction_text": "Lost chloroplast existence"}
{"answers": {"text": ["a red algal derived chloroplast", "red algal", "red algal derived"], "answer_start": [319, 321, 321]}, "prediction_text": "Red algal derived chloroplast"}
{"answers": {"text": ["green algal derived chloroplast", "green algal", "green algal derived"], "answer_start": [512, 373, 512]}, "prediction_text": "Green algal genes"}
{"answers": {"text": ["nonfunctional pseudogenes", "nonfunctional", "most became nonfunctional pseudogenes"], "answer_start": [326, 326, 314]}, "prediction_text": "Nonfunctional pseudogenes"}
{"answers": {"text": ["around half", "half", "half"], "answer_start": [11, 18, 18]}, "prediction_text": "Half of the protein products"}
{"answers": {"text": ["participating in cell division, protein routing, and even disease resistance", "cell division, protein routing, and even disease resistance", "cell division, protein routing, and even disease resistance"], "answer_start": [168, 185, 185]}, "prediction_text": "Functioning in cell division, protein routing, disease resistance."}
{"answers": {"text": ["the cell membrane", "the cell membrane", "the cell membrane"], "answer_start": [748, 748, 748]}, "prediction_text": "Cell membrane"}
{"answers": {"text": ["a ribosome", "a ribosome", "ribosome"], "answer_start": [50, 50, 52]}, "prediction_text": "A ribosome"}
{"answers": {"text": ["in the cytosol", "in the cytosol", "cytosol"], "answer_start": [61, 61, 68]}, "prediction_text": "On a ribosome"}
{"answers": {"text": ["helps many proteins bind the polypeptide", "helps many proteins bind the polypeptide", "helps many proteins bind the polypeptide"], "answer_start": [236, 236, 236]}, "prediction_text": "Helps many proteins bind chloroplast proteins."}
{"answers": {"text": ["keeping it from folding prematurely", "keeping it from folding prematurely", "prevents chloroplast proteins from assuming their active form and carrying out their chloroplast functions in the wrong place"], "answer_start": [278, 278, 344]}, "prediction_text": "Prevent chloroplast proteins from assuming their active form."}
{"answers": {"text": ["lens-shaped", "lens-shaped", "lens-shaped"], "answer_start": [43, 43, 43]}, "prediction_text": "Larger and more complex."}
{"answers": {"text": ["5\u20138 \u03bcm in diameter", "5\u20138 \u03bcm", "5\u20138 \u03bcm in diameter"], "answer_start": [56, 56, 56]}, "prediction_text": "5\u20138 \u03bcm in diameter"}
{"answers": {"text": ["1\u20133 \u03bcm", "1\u20133 \u03bcm", "1\u20133 \u03bcm"], "answer_start": [79, 79, 79]}, "prediction_text": "5\u20138 \u03bcm in diameter"}
{"answers": {"text": ["a net", "a net", "net"], "answer_start": [222, 222, 224]}, "prediction_text": "Slightly twisted bands"}
{"answers": {"text": ["a cup", "a cup", "cup"], "answer_start": [248, 248, 250]}, "prediction_text": "Cup-shaped"}
{"answers": {"text": ["a double membrane", "surrounded by a double membrane", "surrounded by a double membrane"], "answer_start": [131, 117, 117]}, "prediction_text": "Double membrane"}
{"answers": {"text": ["the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium", "is the product of the host's cell membrane", "is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium"], "answer_start": [309, 306, 306]}, "prediction_text": "The outer chloroplast membrane is the product of host's cell membrane infolding."}
{"answers": {"text": ["homologous", "homologous", "homologous"], "answer_start": [467, 467, 467]}, "prediction_text": "Homologous to cyanobacterium's original double membranes."}
{"answers": {"text": ["the mitochondrial double membrane", "the mitochondrial double membrane", "mitochondrial double membrane"], "answer_start": [58, 58, 62]}, "prediction_text": "The mitochondrial double membrane"}
{"answers": {"text": ["run proton pumps and carry out oxidative phosphorylation", "to run proton pumps", "run proton pumps and carry out oxidative phosphorylation across to generate ATP energy"], "answer_start": [167, 164, 167]}, "prediction_text": "Runs proton pumps and carries out oxidative phosphorylation."}
{"answers": {"text": ["generate ATP energy", "generate ATP energy", "generate ATP energy"], "answer_start": [234, 234, 234]}, "prediction_text": "Generates ATP energy."}
{"answers": {"text": ["the internal thylakoid system", "the internal thylakoid system", "internal thylakoid system"], "answer_start": [325, 325, 329]}, "prediction_text": "Internal thylakoid system"}
{"answers": {"text": ["the inner chloroplast membrane", "the inner chloroplast membrane", "inner chloroplast membrane"], "answer_start": [547, 547, 551]}, "prediction_text": "Inner chloroplast membrane"}
{"answers": {"text": ["Stromules", "Stromules", "Stromules"], "answer_start": [118, 118, 118]}, "prediction_text": "Amyloplasts"}
{"answers": {"text": ["stroma-containing tubule", "stroma-containing tubule", "stroma-containing tubule"], "answer_start": [92, 92, 92]}, "prediction_text": "A tubule in chloroplasts."}
{"answers": {"text": ["to increase the chloroplast's surface area for cross-membrane transport", "to increase the chloroplast's surface area", "to increase the chloroplast's surface area for cross-membrane transport"], "answer_start": [286, 286, 286]}, "prediction_text": "For cross-membrane transport."}
{"answers": {"text": ["1962", "1962", "1962"], "answer_start": [468, 468, 468]}, "prediction_text": "1962"}
{"answers": {"text": ["in the chloroplasts of C4 plants", "in the chloroplasts of C4 plants,", "chloroplasts of C4 plants"], "answer_start": [101, 101, 108]}, "prediction_text": "In C4 plants"}
{"answers": {"text": ["in some C3 angiosperms, and even some gymnosperms", "C3 angiosperms", "C3 angiosperms, and even some gymnosperms"], "answer_start": [165, 173, 173]}, "prediction_text": "In C4 plants"}
{"answers": {"text": ["The chloroplast peripheral reticulum", "The chloroplast peripheral reticulum"], "answer_start": [216, 216]}, "prediction_text": "A maze of membranous tubes is a type of chloroplasts."}
{"answers": {"text": ["increase the chloroplast's surface area for cross-membrane transport", "to increase the chloroplast's surface area", "increase the chloroplast's surface area for cross-membrane transport between its stroma and the cell cytoplasm"], "answer_start": [449, 446, 449]}, "prediction_text": "Increases chloroplast surface area for cross-membrane transport."}
{"answers": {"text": ["the thylakoids and intermembrane space", "thylakoids and intermembrane space", "thylakoids and intermembrane space"], "answer_start": [656, 660, 660]}, "prediction_text": "Thylakoids and intermembrane space."}
{"answers": {"text": ["synthesize a small fraction of their proteins", "to synthesize a small fraction of their proteins", "synthesize a small fraction of their proteins"], "answer_start": [57, 54, 57]}, "prediction_text": "Synthesizing proteins"}
{"answers": {"text": ["17 nm", "around 17 nm", "17 nm"], "answer_start": [189, 182, 189]}, "prediction_text": "About two-thirds the size of cytoplasmic ribosomes."}
{"answers": {"text": ["25 nm", "25 nm", "25 nm"], "answer_start": [198, 198, 198]}, "prediction_text": "Around 17 nm"}
{"answers": {"text": ["motifs for shine-dalgarno sequence recognition", "motifs for shine-dalgarno sequence recognition", "motifs for shine-dalgarno sequence recognition"], "answer_start": [538, 538, 538]}, "prediction_text": "Maintain motifs for shine-dalgarno sequence recognition."}
{"answers": {"text": ["is considered essential for translation initiation in most chloroplasts and prokaryotes", "translation initiation", "essential for translation initiation in most chloroplasts and prokaryotes"], "answer_start": [592, 620, 606]}, "prediction_text": "For chloroplast translation initiation."}
{"answers": {"text": ["plastoglobulus, sometimes spelled plastoglobule(s)", "plastoglobulus", "plastoglobulus"], "answer_start": [24, 24, 24]}, "prediction_text": "Plastoglobuli"}
{"answers": {"text": ["spherical bubbles", "spherical", "spherical"], "answer_start": [81, 81, 81]}, "prediction_text": "Spherical bubbles"}
{"answers": {"text": ["lipids and proteins", "lipids and proteins", "lipids and proteins"], "answer_start": [102, 102, 102]}, "prediction_text": "Lipids and proteins"}
{"answers": {"text": ["45\u201360 nanometers across", "45\u201360 nanometers across", "45\u201360 nanometers across"], "answer_start": [128, 128, 128]}, "prediction_text": "About 45\u201360 nanometers"}
{"answers": {"text": ["a lipid monolayer", "lipid monolayer", "a lipid monolayer"], "answer_start": [176, 178, 176]}, "prediction_text": "Lipid monolayer"}
{"answers": {"text": ["either to a thylakoid or to another plastoglobulus attached to a thylakoid", "a thylakoid", "thylakoid or to another plastoglobulus attached to a thylakoid"], "answer_start": [124, 134, 136]}, "prediction_text": "Thylakoids"}
{"answers": {"text": ["the thylakoid network", "the thylakoid network", "thylakoid network"], "answer_start": [275, 275, 279]}, "prediction_text": "Thylakoid network"}
{"answers": {"text": ["singularly, attached directly to their parent thylakoid", "singularly", "singularly, attached directly to their parent thylakoid"], "answer_start": [369, 369, 369]}, "prediction_text": "In linked groups or chains."}
{"answers": {"text": ["In old or stressed chloroplasts", "In old or stressed chloroplasts", "In old or stressed chloroplasts"], "answer_start": [426, 426, 426]}, "prediction_text": "In linked groups."}
{"answers": {"text": ["The chloroplasts of some hornworts and algae", "some hornworts and algae", "chloroplasts of some hornworts and algae"], "answer_start": [0, 20, 4]}, "prediction_text": "Higher plants"}
{"answers": {"text": ["roughly spherical", "roughly spherical", "spherical"], "answer_start": [133, 133, 141]}, "prediction_text": "Spherical and highly refractive bodies"}
{"answers": {"text": ["highly refractive", "highly refractive", "roughly spherical and highly refractive"], "answer_start": [155, 155, 133]}, "prediction_text": "Spheres of starch accumulation."}
{"answers": {"text": ["starch", "starch", "starch"], "answer_start": [200, 200, 200]}, "prediction_text": "starch"}
{"answers": {"text": ["divide to form new pyrenoids, or be produced \"de novo\"", "divide", "divide to form new pyrenoids, or be produced \"de novo\""], "answer_start": [568, 568, 568]}, "prediction_text": "In plants with carbon concentrating mechanisms."}
{"answers": {"text": ["the helical thylakoid model", "the helical thylakoid model", "helical thylakoid"], "answer_start": [3, 3, 7]}, "prediction_text": "Helical thylakoid model"}
{"answers": {"text": ["flattened circular", "flattened circular", "flattened circular"], "answer_start": [60, 60, 60]}, "prediction_text": "Folded circular granal thylakoids."}
{"answers": {"text": ["anywhere from two to a hundred", "two to a hundred", "two to a hundred"], "answer_start": [145, 159, 159]}, "prediction_text": "From two to a hundred"}
{"answers": {"text": ["10\u201320", "10\u201320", "10\u201320"], "answer_start": [206, 206, 206]}, "prediction_text": "From two to a hundred"}
{"answers": {"text": ["helicoid stromal thylakoids", "helicoid stromal thylakoids", "helicoid stromal thylakoids"], "answer_start": [269, 269, 269]}, "prediction_text": "Lamellar thylakoids"}
{"answers": {"text": ["light energy", "light energy", "light energy"], "answer_start": [236, 236, 236]}, "prediction_text": "Light energy"}
{"answers": {"text": ["light energy", "light energy", "light energy"], "answer_start": [236, 236, 236]}, "prediction_text": "Light energy"}
{"answers": {"text": ["energize electrons", "to energize electrons", "energize electrons"], "answer_start": [263, 260, 263]}, "prediction_text": "Recharges electrons"}
{"answers": {"text": ["pump hydrogen ions into the thylakoid space", "pump hydrogen ions", "pump hydrogen ions into the thylakoid space"], "answer_start": [350, 350, 350]}, "prediction_text": "Pumping hydrogen ions"}
{"answers": {"text": ["a dam turbine", "a dam turbine", "a dam turbine"], "answer_start": [646, 646, 646]}, "prediction_text": "A large protein complex"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [10, 10, 10]}, "prediction_text": "Two types"}
{"answers": {"text": ["are arranged in grana", "arranged in grana", "arranged in grana"], "answer_start": [59, 63, 63]}, "prediction_text": "Pancake-shaped disks about 300\u2013600 nanometers in diameter."}
{"answers": {"text": ["are in contact with the stroma", "in contact with the stroma", "helicoid sheets"], "answer_start": [112, 116, 257]}, "prediction_text": "Helical shape."}
{"answers": {"text": ["pancake-shaped circular disks", "pancake", "pancake-shaped"], "answer_start": [166, 166, 166]}, "prediction_text": "Circular disks about 300\u2013600 nanometers in diameter."}
{"answers": {"text": ["about 300\u2013600 nanometers in diameter", "300\u2013600 nanometers", "300\u2013600 nanometers in diameter"], "answer_start": [196, 202, 202]}, "prediction_text": "About 300\u2013600 nanometers in diameter."}
{"answers": {"text": ["about thirty", "about thirty", "thirty"], "answer_start": [134, 134, 140]}, "prediction_text": "About thirty"}
{"answers": {"text": ["help transfer and dissipate excess energy", "transfer and dissipate excess energy", "help transfer and dissipate excess energy"], "answer_start": [180, 185, 180]}, "prediction_text": "Transfer and dissipate excess energy."}
{"answers": {"text": ["their bright colors sometimes override the chlorophyll green", "override the chlorophyll green", "override the chlorophyll green"], "answer_start": [227, 257, 257]}, "prediction_text": "They transfer and dissipate excess energy."}
{"answers": {"text": ["a bright red-orange carotenoid", "a bright red-orange carotenoid", "bright red-orange carotenoid found in nearly all chloroplasts"], "answer_start": [375, 375, 377]}, "prediction_text": "Bright red-orange carotenoid"}
{"answers": {"text": ["orange-red zeaxanthin", "zeaxanthin", "orange-red zeaxanthin"], "answer_start": [489, 500, 489]}, "prediction_text": "Orange-red zeaxanthin"}
{"answers": {"text": ["e a third group of pigments found in cyanobacteria", "a third group of pigments", "a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts"], "answer_start": [14, 16, 16]}, "prediction_text": "Third group of pigments found in cyanobacteria."}
{"answers": {"text": ["red", "red", "red"], "answer_start": [227, 217, 217]}, "prediction_text": "Red algae"}
{"answers": {"text": ["red algae", "red algae", "algae"], "answer_start": [217, 217, 221]}, "prediction_text": "Red algae"}
{"answers": {"text": ["relatively large protein complexes", "large protein complexes", "large protein complexes"], "answer_start": [264, 275, 275]}, "prediction_text": "Phycoerytherin-organized phycobilisomes."}
{"answers": {"text": ["about 40 nanometers across", "about 40 nanometers across", "40 nanometers across"], "answer_start": [299, 299, 305]}, "prediction_text": "40 nanometers"}
{"answers": {"text": ["an enzyme called rubisco", "an enzyme called rubisco", "enzyme called rubisco"], "answer_start": [94, 94, 97]}, "prediction_text": "Rubisco"}
{"answers": {"text": ["it has trouble distinguishing between carbon dioxide and oxygen", "trouble distinguishing between carbon dioxide and oxygen", "has trouble distinguishing between carbon dioxide and oxygen"], "answer_start": [142, 149, 145]}, "prediction_text": "It adds oxygen to sugar precursors."}
{"answers": {"text": ["at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors"], "answer_start": [210, 210, 210]}, "prediction_text": "Addition of oxygen to sugar precursors."}
{"answers": {"text": ["the Calvin cycle", "Calvin cycle", "Calvin cycle"], "answer_start": [539, 543, 543]}, "prediction_text": "Calvin cycle"}
{"answers": {"text": ["ATP energy", "ATP energy", "ATP energy"], "answer_start": [331, 331, 331]}, "prediction_text": "CO2's release"}
{"answers": {"text": ["light reactions", "each stage of photosynthesis", "light reactions"], "answer_start": [179, 92, 179]}, "prediction_text": "Light reactions"}
{"answers": {"text": ["rubisco", "rubisco", "rubisco"], "answer_start": [209, 209, 209]}, "prediction_text": "Rubisco and normal grana and thylakoids."}
{"answers": {"text": ["normal grana and thylakoids", "normal grana and thylakoids", "grana and thylakoids"], "answer_start": [227, 227, 234]}, "prediction_text": "Chloroplasts use chloroplasts to make ATP."}
{"answers": {"text": ["a four-carbon compound", "a four-carbon compound", "a four-carbon compound"], "answer_start": [331, 331, 331]}, "prediction_text": "Four-carbon compound"}
{"answers": {"text": ["to carry out the Calvin cycle and make sugar", "the Calvin cycle", "cyclic electron flow"], "answer_start": [1138, 1151, 860]}, "prediction_text": "Light reactions"}
{"answers": {"text": ["All green parts", "green parts", "All green parts"], "answer_start": [61, 65, 61]}, "prediction_text": "Green parts"}
{"answers": {"text": ["the chlorophyll in them", "chlorophyll", "chlorophyll"], "answer_start": [149, 153, 153]}, "prediction_text": "Chloroplasts in plants"}
{"answers": {"text": ["parenchyma cells", "photosynthetic", "parenchyma cells"], "answer_start": [285, 191, 285]}, "prediction_text": "Green parts of a plant"}
{"answers": {"text": ["collenchyma tissue", "in collenchyma tissue", "collenchyma tissue"], "answer_start": [344, 341, 344]}, "prediction_text": "In plants"}
{"answers": {"text": ["A plant cell which contains chloroplasts", "cell which contains chloroplasts", "plant cell which contains chloroplasts"], "answer_start": [364, 372, 366]}, "prediction_text": "A plant cell containing chloroplasts."}
{"answers": {"text": ["in the stems", "stems", "stems"], "answer_start": [53, 60, 60]}, "prediction_text": "In the stems"}
{"answers": {"text": ["concentrated in the leaves", "the leaves", "leaves"], "answer_start": [107, 123, 127]}, "prediction_text": "In the stems"}
{"answers": {"text": ["8\u201315 per cell", "around 8\u201315", "8\u201315"], "answer_start": [438, 431, 438]}, "prediction_text": "Around 8\u201315"}
{"answers": {"text": ["half a million", "half a million", "half a million"], "answer_start": [184, 184, 184]}, "prediction_text": "Half a million"}
{"answers": {"text": ["the mesophyll layers", "mesophyll", "mesophyll"], "answer_start": [261, 265, 265]}, "prediction_text": "Mesophyll layers"}
{"answers": {"text": ["low-light conditions", "low-light conditions", "In low-light conditions"], "answer_start": [101, 101, 98]}, "prediction_text": "Under intense light"}
{"answers": {"text": ["Under intense light", "intense light", "Under intense light"], "answer_start": [200, 206, 200]}, "prediction_text": "Under intense light"}
{"answers": {"text": ["photooxidative damage", "photooxidative damage", "photooxidative damage"], "answer_start": [410, 410, 410]}, "prediction_text": "Photooxidative damage"}
{"answers": {"text": ["to distribute chloroplasts so that they can take shelter behind each other or spread out", "they can take shelter behind each other", "so that they can take shelter behind each other or spread out"], "answer_start": [446, 481, 473]}, "prediction_text": "For smaller chloroplasts."}
{"answers": {"text": ["Mitochondria", "Mitochondria", "Mitochondria"], "answer_start": [760, 760, 760]}, "prediction_text": "Mitochondria"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [12, 12, 12]}, "prediction_text": "Two major immune responses"}
{"answers": {"text": ["infected cells seal themselves off and undergo programmed cell death", "programmed cell death", "infected cells seal themselves off and undergo programmed cell death"], "answer_start": [76, 123, 76]}, "prediction_text": "Tolerates pathogens"}
{"answers": {"text": ["infected cells release signals warning the rest of the plant of a pathogen's presence", "cells release signals", "infected cells release signals warning the rest of the plant of a pathogen's presence"], "answer_start": [186, 195, 186]}, "prediction_text": "Produces reactive oxygen species."}
{"answers": {"text": ["by purposely damaging their photosynthetic system", "purposely damaging their photosynthetic system", "purposely damaging their photosynthetic system"], "answer_start": [311, 314, 314]}, "prediction_text": "By damaging their photosynthetic system."}
{"answers": {"text": ["reactive oxygen species", "reactive oxygen species", "reactive oxygen species"], "answer_start": [372, 372, 372]}, "prediction_text": "Chloroplasts stimulate both responses."}
{"answers": {"text": ["salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species", "salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species", "reactive oxygen species"], "answer_start": [156, 156, 204]}, "prediction_text": "Salicylic acid, jasmonic acid, nitric oxide."}
{"answers": {"text": ["After detecting stress in a cell", "After detecting stress in a cell", "After detecting stress in a cell"], "answer_start": [44, 44, 44]}, "prediction_text": "After detecting stress"}
{"answers": {"text": ["pass on their signal to an unknown second messenger molecule", "pass on their signal", "pass on their signal to an unknown second messenger molecule"], "answer_start": [391, 391, 391]}, "prediction_text": "They pass on their signal to unknown second messenger molecules."}
{"answers": {"text": ["signals from the chloroplast that regulate gene expression in the nucleus", "signals from the chloroplast that regulate gene expression", "signals from the chloroplast that regulate gene expression in the nucleus"], "answer_start": [503, 503, 503]}, "prediction_text": "Signaling from the chloroplast that regulates gene expression in the nucleus."}
{"answers": {"text": ["photosynthesis", "photosynthesis", "its role in photosynthesis"], "answer_start": [60, 60, 48]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["photosynthesis", "photosynthesis", "photosynthesis"], "answer_start": [60, 60, 60]}, "prediction_text": "Photosynthesis"}
{"answers": {"text": ["food in the form of sugars", "light", "food in the form of sugars"], "answer_start": [164, 97, 164]}, "prediction_text": "Food"}
{"answers": {"text": ["Water (H2O) and carbon dioxide (CO2)", "Water (H2O) and carbon dioxide (CO2)", "Water (H2O) and carbon dioxide (CO2)"], "answer_start": [192, 192, 192]}, "prediction_text": "Water and carbon dioxide"}
{"answers": {"text": ["sugar and oxygen (O2)", "sugar and oxygen (O2)", "sugar and oxygen (O2)"], "answer_start": [261, 261, 261]}, "prediction_text": "Water and oxygen"}
{"answers": {"text": ["generate ATP energy", "use the potential energy stored in an H+", "use the potential energy stored in an H+, or hydrogen ion gradient to generate ATP energy"], "answer_start": [102, 32, 32]}, "prediction_text": "Capture light energy to energize electrons."}
{"answers": {"text": ["into the thylakoid space", "thylakoid space", "into the thylakoid space"], "answer_start": [347, 356, 347]}, "prediction_text": "Through an electron transport chain"}
{"answers": {"text": ["up to a thousand times", "up to a thousand times as many", "(up to a thousand times as many) inside the thylakoid system than in the stroma"], "answer_start": [433, 433, 432]}, "prediction_text": "Up to a thousand times as many"}
{"answers": {"text": ["phosphorylate adenosine diphosphate", "phosphorylate adenosine diphosphate", "energy from the flowing hydrogen ions"], "answer_start": [725, 725, 684]}, "prediction_text": "Synthesized ATP"}
{"answers": {"text": ["adenosine triphosphate", "adenosine triphosphate", "adenosine triphosphate"], "answer_start": [766, 766, 766]}, "prediction_text": "ATP synthase"}
{"answers": {"text": ["NADP+", "photosystem I", "NADP+"], "answer_start": [220, 76, 220]}, "prediction_text": "NADP+"}
{"answers": {"text": ["cyclic photophosphorylation", "cyclic photophosphorylation", "cyclic photophosphorylation"], "answer_start": [404, 404, 404]}, "prediction_text": "Cyclic photophosphorylation"}
{"answers": {"text": ["in C4 plants", "in C4 plants", "in C4 plants"], "answer_start": [506, 506, 506]}, "prediction_text": "C4 plants"}
{"answers": {"text": ["more ATP than NADPH", "more ATP than NADPH", "more ATP than NADPH"], "answer_start": [531, 531, 531]}, "prediction_text": "More ATP"}
{"answers": {"text": ["The Calvin cycle", "The Calvin cycle", "Calvin cycle"], "answer_start": [0, 0, 4]}, "prediction_text": "Calvin cycle"}
{"answers": {"text": ["unstable six-carbon molecules that immediately break down", "unstable six-carbon molecules", "unstable six-carbon molecules"], "answer_start": [134, 134, 134]}, "prediction_text": "Stabilized six-carbon molecules"}
{"answers": {"text": ["three-carbon molecules called 3-phosphoglyceric acid", "three-carbon molecules", "three-carbon molecules called 3-phosphoglyceric acid, or 3-PGA"], "answer_start": [197, 197, 197]}, "prediction_text": "Three-carbon molecules"}
{"answers": {"text": ["one out of every six", "out of every six", "one out of every six"], "answer_start": [479, 483, 479]}, "prediction_text": "One out of every six leaves the cycle."}
{"answers": {"text": ["glucose monomers in the chloroplast can be linked together", "glucose monomers", "glucose monomers in the chloroplast"], "answer_start": [15, 15, 15]}, "prediction_text": "Through glucose monomers"}
{"answers": {"text": ["Under conditions such as high atmospheric CO2 concentrations", "high atmospheric CO2 concentrations", "Under conditions such as high atmospheric CO2 concentrations,"], "answer_start": [157, 182, 157]}, "prediction_text": "High atmospheric CO2 concentrations"}
{"answers": {"text": ["distorting the grana and thylakoids", "distorting the grana and thylakoids", "displace the thylakoids, but leave them intact."], "answer_start": [260, 260, 317]}, "prediction_text": "They may grow large."}
{"answers": {"text": ["Waterlogged roots", "Waterlogged", "Waterlogged roots"], "answer_start": [365, 365, 365]}, "prediction_text": "Waterlogged roots"}
{"answers": {"text": ["another photosynthesis-depressing factor", "another photosynthesis-depressing factor", "another photosynthesis-depressing factor"], "answer_start": [835, 835, 835]}, "prediction_text": "Another photosynthesis-depressing factor."}
{"answers": {"text": ["add O2 instead of CO2 to RuBP", "add O2 instead of CO2", "add O2 instead of CO2 to RuBP"], "answer_start": [165, 165, 165]}, "prediction_text": "Add O2 instead of CO2."}
{"answers": {"text": ["when the oxygen concentration is too high", "when the oxygen concentration is too high", "when the oxygen concentration is too high"], "answer_start": [27, 27, 27]}, "prediction_text": "Oxygen is too high."}
{"answers": {"text": ["it consumes ATP and oxygen, releases CO2, and produces no sugar", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "consumes ATP and oxygen, releases CO2, and produces no sugar"], "answer_start": [250, 250, 253]}, "prediction_text": "It consumes ATP and oxygen."}
{"answers": {"text": ["up to half the carbon fixed by the Calvin cycle", "up to half", "half"], "answer_start": [328, 328, 334]}, "prediction_text": "Up to half"}
{"answers": {"text": ["they exhibit a distinct chloroplast dimorphism", "exhibit a distinct chloroplast dimorphism", "exhibit a distinct chloroplast dimorphism"], "answer_start": [761, 766, 766]}, "prediction_text": "distinct chloroplast dimorphism."}
{"answers": {"text": ["in their stroma", "stroma", "in their stroma"], "answer_start": [65, 74, 65]}, "prediction_text": "In the chloroplast (proplastid)"}
{"answers": {"text": ["cysteine and methionine", "cysteine and methionine", "cysteine and methionine"], "answer_start": [120, 120, 120]}, "prediction_text": "Cysteine"}
{"answers": {"text": ["it has trouble crossing membranes to get to where it is needed", "it has trouble crossing membranes", "has trouble crossing membranes to get to where it is needed"], "answer_start": [279, 279, 282]}, "prediction_text": "It is synthesized in the cytosol and mitochondria."}
{"answers": {"text": ["whether the organelle carries out the last leg of the pathway or if it happens in the cytosol", "whether the organelle carries out the last leg of the pathway", "whether the organelle carries out the last leg of the pathway or if it happens in the cytosol"], "answer_start": [423, 423, 423]}, "prediction_text": "They make methionine precursors in the cytosol."}
{"answers": {"text": ["Chloroplasts", "Chloroplasts", "Chloroplasts"], "answer_start": [0, 0, 0]}, "prediction_text": "Chloroplasts"}
{"answers": {"text": ["undifferentiated proplastids found in the zygote, or fertilized egg", "undifferentiated proplastids", "undifferentiated proplastids found in the zygote"], "answer_start": [255, 255, 255]}, "prediction_text": "undifferentiated proplastids"}
{"answers": {"text": ["in an adult plant's apical meristems", "zygote", "adult plant's apical meristems"], "answer_start": [355, 297, 361]}, "prediction_text": "In apical meristems"}
{"answers": {"text": ["the formation of starch-storing amyloplasts", "amyloplasts", "starch-storing amyloplasts"], "answer_start": [478, 510, 495]}, "prediction_text": "Amyloplasts"}
{"answers": {"text": ["proplastids may develop into an etioplast stage before becoming chloroplasts", "proplastids may develop into an etioplast stage before becoming chloroplasts", "proplastids may develop into an etioplast stage before becoming chloroplasts"], "answer_start": [86, 86, 86]}, "prediction_text": "Proplastids develop into an etioplast stage."}
{"answers": {"text": ["a plastid that lacks chlorophyll", "plastid that lacks chlorophyll", "plastid that lacks chlorophyll"], "answer_start": [180, 182, 182]}, "prediction_text": "Plastid lacking chlorophyll."}
{"answers": {"text": ["invaginations that form a lattice of tubes in their stroma", "invaginations", "lattice of tubes in their stroma, called a prolamellar body"], "answer_start": [237, 237, 263]}, "prediction_text": "Yellow chlorophyll precursor"}
{"answers": {"text": ["a yellow chlorophyll precursor", "yellow chlorophyll precursor", "yellow chlorophyll precursor"], "answer_start": [369, 371, 371]}, "prediction_text": "Yellow chlorophyll precursor"}
{"answers": {"text": ["Gymnosperms", "Gymnosperms", "Gymnosperms"], "answer_start": [635, 635, 635]}, "prediction_text": "Gymnosperms"}
{"answers": {"text": ["chromoplasts", "chromoplasts", "chromoplasts"], "answer_start": [119, 119, 119]}, "prediction_text": "Chromoplasts"}
{"answers": {"text": ["pigment-filled plastids responsible for the bright colors seen in flowers and ripe fruit", "pigment-filled plastids", "pigment-filled plastids responsible for the bright colors seen in flowers and ripe fruit"], "answer_start": [143, 143, 143]}, "prediction_text": "Pigment-filled plastids responsible for bright colors."}
{"answers": {"text": ["chromoplasts", "chromoplasts", "chromoplasts"], "answer_start": [285, 285, 285]}, "prediction_text": "Chromoplasts"}
{"answers": {"text": ["chromoplasts", "chromoplasts", "chromoplasts"], "answer_start": [359, 359, 359]}, "prediction_text": "Chromoplasts"}
{"answers": {"text": ["chloroplasts and other plastids", "chloroplasts and other plastids can turn back into proplastids", "chloroplasts and other plastids"], "answer_start": [588, 588, 588]}, "prediction_text": "Chloroplast, amyloplast, chromoplast, proplast, etc."}
{"answers": {"text": ["filaments", "filaments", "filaments"], "answer_start": [76, 76, 76]}, "prediction_text": "FtsZ1 and FtsZ2 assemble into filaments."}
{"answers": {"text": ["proteins", "proteins", "proteins"], "answer_start": [37, 37, 37]}, "prediction_text": "Protein FtsZ1 and FtsZ2 are protein FtsZ1 and FtsZ2."}
{"answers": {"text": ["a structure called a Z-ring", "a Z-ring", "Z-ring"], "answer_start": [129, 148, 150]}, "prediction_text": "Z-ring"}
{"answers": {"text": ["within the chloroplast's stroma", "within the chloroplast's stroma", "within the chloroplast's stroma"], "answer_start": [157, 157, 157]}, "prediction_text": "Near the center of the chloroplast"}
{"answers": {"text": ["The Min system", "The Min system", "Min system"], "answer_start": [190, 190, 194]}, "prediction_text": "Min system"}
{"answers": {"text": ["plastid-dividing rings", "plastid-dividing rings", "plastid-dividing rings"], "answer_start": [14, 14, 14]}, "prediction_text": "Next-generation plastid-dividing rings"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [10, 10, 10]}, "prediction_text": "Two PD rings"}
{"answers": {"text": ["about 5 nanometers across", "about 5 nanometers across", "5 nanometers across"], "answer_start": [288, 288, 294]}, "prediction_text": "About 5 nanometers"}
{"answers": {"text": ["6.4 nanometers", "6.4 nanometers", "6.4 nanometers"], "answer_start": [332, 332, 332]}, "prediction_text": "About 5 nanometers apart"}
{"answers": {"text": ["chloroplasts have a third plastid-dividing ring", "chloroplasts have a third plastid-dividing ring", "chloroplasts have a third plastid-dividing ring located in the chloroplast's intermembrane space"], "answer_start": [486, 486, 486]}, "prediction_text": "Third plastid-dividing ring is located in chloroplast's intermembrane space."}
{"answers": {"text": ["Light", "Light", "Light"], "answer_start": [0, 0, 0]}, "prediction_text": "Bright white light"}
{"answers": {"text": ["bright white light", "white light", "bright white light"], "answer_start": [233, 240, 233]}, "prediction_text": "Bright white light"}
{"answers": {"text": ["large dumbbell-shaped", "dumbbell-shaped", "dumbbell-shaped"], "answer_start": [348, 354, 354]}, "prediction_text": "Large dumbbell-shaped chloroplasts."}
{"answers": {"text": ["poor quality green light", "green light", "poor quality green light"], "answer_start": [148, 161, 148]}, "prediction_text": "Poor quality green light"}
{"answers": {"text": ["transgenes in these plastids cannot be disseminated by pollen", "chloroplasts are not inherited from the male parent", "transgenes in these plastids cannot be disseminated by pollen"], "answer_start": [176, 123, 176]}, "prediction_text": "Not inherited from male parent."}
{"answers": {"text": ["environmental risks", "environmental risks", "environmental risks"], "answer_start": [418, 418, 418]}, "prediction_text": "Environmental risks"}
{"answers": {"text": ["3 in 1,000,000", "3 in 1,000,000", "3 in 1,000,000"], "answer_start": [778, 778, 778]}, "prediction_text": "3 in 1,000,000"}
{"answers": {"text": ["transplastomic", "genetically modified crops", "genetically modified plants"], "answer_start": [753, 62, 325]}, "prediction_text": "genetically modified plants"}
{"answers": {"text": ["itself", "itself", "itself", "itself", "itself"], "answer_start": [110, 110, 110, 110, 110]}, "prediction_text": "1"}
{"answers": {"text": ["composite number", "composite number", "composite number", "primes"], "answer_start": [189, 189, 189, 439]}, "prediction_text": "A composite number"}
{"answers": {"text": ["The fundamental theorem of arithmetic", "fundamental theorem of arithmetic", "arithmetic", "fundamental theorem of arithmetic", "fundamental theorem of arithmetic"], "answer_start": [369, 373, 396, 373, 373]}, "prediction_text": "Fundamental theorem of arithmetic"}
{"answers": {"text": ["a product of primes", "product of primes that is unique up to ordering", "primes", "primes", "primes that is unique up to ordering"], "answer_start": [511, 513, 524, 524, 524]}, "prediction_text": "primes"}
{"answers": {"text": ["because one can include arbitrarily many instances of 1 in any factorization", "one can include arbitrarily many instances of 1 in any factorization", "can include arbitrarily many instances of 1 in any factorization", "one can include arbitrarily many instances of 1 in any factorization", "because one can include arbitrarily many instances of 1 in any factorization"], "answer_start": [625, 633, 637, 633, 625]}, "prediction_text": "Excluding 1 as a prime forces the uniqueness of the fundamental theorem."}
{"answers": {"text": ["primality", "primality", "primality", "primality", "primality"], "answer_start": [47, 47, 47, 47, 47]}, "prediction_text": "Primality"}
{"answers": {"text": ["trial division", "trial division", "trial division", "trial division", "trial division"], "answer_start": [142, 142, 142, 142, 142]}, "prediction_text": "Trial division"}
{"answers": {"text": ["the Miller\u2013Rabin primality test", "Miller\u2013Rabin primality test", "Miller\u2013Rabin primality test", "Miller\u2013Rabin primality test", "Miller\u2013Rabin primality test"], "answer_start": [359, 363, 363, 363, 363]}, "prediction_text": "Miller\u2013Rabin primality test"}
{"answers": {"text": ["the AKS primality test", "AKS primality test", "AKS primality test", "AKS primality test", "AKS primality test"], "answer_start": [448, 452, 452, 452, 452]}, "prediction_text": "Miller\u2013Rabin primality test"}
{"answers": {"text": ["22,338,618 decimal digits", "22,338,618", "22,338,618", "22,338,618", "22,338,618"], "answer_start": [724, 724, 724, 724, 724]}, "prediction_text": "22,338,618 digits"}
{"answers": {"text": ["infinitely many", "infinitely", "infinitely many", "infinitely", "infinitely many"], "answer_start": [10, 10, 10, 10, 10]}, "prediction_text": "infinitely many primes"}
{"answers": {"text": ["Euclid", "Euclid", "Euclid", "Euclid", "Euclid"], "answer_start": [53, 53, 53, 53, 53]}, "prediction_text": "Euclid"}
{"answers": {"text": ["the statistical behaviour", "distribution", "statistical", "statistical", "statistical"], "answer_start": [214, 174, 218, 218, 218]}, "prediction_text": "Statistical behavior"}
{"answers": {"text": ["the prime number theorem", "prime number theorem", "prime number", "prime number theorem", "prime number theorem"], "answer_start": [319, 323, 323, 323, 323]}, "prediction_text": "Theorem (prime number theorem)"}
{"answers": {"text": ["at the end of the 19th century", "end of the 19th century", "end of the 19th century", "end of the 19th century", "end of the 19th century"], "answer_start": [352, 359, 359, 359, 359]}, "prediction_text": "End of the 19th century"}
{"answers": {"text": ["Goldbach's conjecture", "Goldbach's conjecture", "Goldbach's conjecture", "Goldbach's conjecture", "Goldbach's conjecture"], "answer_start": [60, 60, 60, 60, 60]}, "prediction_text": "Goldbach's conjecture"}
{"answers": {"text": ["the twin prime conjecture", "twin prime conjecture", "twin prime conjecture", "twin prime conjecture", "twin prime conjecture"], "answer_start": [170, 174, 174, 174, 174]}, "prediction_text": "Twin prime conjecture"}
{"answers": {"text": ["algebraic aspects", "algebraic", "algebraic", "algebraic", "algebraic aspects"], "answer_start": [369, 369, 369, 369, 369]}, "prediction_text": "Algebraic aspects"}
{"answers": {"text": ["public-key cryptography", "public-key cryptography", "public-key cryptography", "cryptography", "public-key cryptography"], "answer_start": [470, 470, 470, 481, 470]}, "prediction_text": "Public-key cryptography"}
{"answers": {"text": ["prime ideals", "prime elements", "prime elements", "prime elements"], "answer_start": [726, 707, 707, 707]}, "prediction_text": "Prime elements and prime ideals."}
{"answers": {"text": ["2", "2", "2", "2", "2"], "answer_start": [120, 120, 120, 120, 120]}, "prediction_text": "N (in the context)"}
{"answers": {"text": ["1, 2, and n", "1, 2, and n", "1, 2, and n", "1, 2, and n", "1, 2, and n"], "answer_start": [217, 217, 217, 217, 217]}, "prediction_text": "1, 2, 3, 7, 9."}
{"answers": {"text": ["odd prime", "odd prime", "odd prime", "odd prime", "odd prime"], "answer_start": [286, 286, 286, 286, 286]}, "prediction_text": "odd prime"}
{"answers": {"text": ["9", "9", "9", "9", "9"], "answer_start": [443, 443, 443, 443, 443]}, "prediction_text": "9"}
{"answers": {"text": ["even numbers", "even", "even numbers", "even", "even"], "answer_start": [452, 452, 452, 452, 452]}, "prediction_text": "Even numbers"}
{"answers": {"text": ["1", "1", "1", "1", "1"], "answer_start": [40, 40, 40, 40, 40]}, "prediction_text": "1"}
{"answers": {"text": ["Christian Goldbach", "Christian Goldbach", "Christian Goldbach", "mathematicians", "mathematicians"], "answer_start": [220, 220, 220, 143, 143]}, "prediction_text": "Christian Goldbach"}
{"answers": {"text": ["Leonhard Euler", "Leonhard Euler", "Leonhard Euler", "Leonhard Euler", "Leonhard Euler"], "answer_start": [301, 301, 301, 301, 301]}, "prediction_text": "Leonhard Euler"}
{"answers": {"text": ["10,006,721", "primes up to 10,006,721", "10,006,721", "10,006,721", "10,006,721"], "answer_start": [481, 468, 481, 481, 481]}, "prediction_text": "10,006,721"}
{"answers": {"text": ["its own special category as a \"unit\"", "unit", "a \"unit\"", "unit", "a \"unit"], "answer_start": [742, 773, 770, 773, 770]}, "prediction_text": "A prime number"}
{"answers": {"text": ["Euclid's fundamental theorem of arithmetic", "Euclid's fundamental theorem of arithmetic", "arithmetic", "Euclid's fundamental theorem of arithmetic", "Euclid's fundamental theorem of arithmetic"], "answer_start": [83, 83, 115, 83, 83]}, "prediction_text": "Euclid's theorem"}
{"answers": {"text": ["if 1 were considered a prime", "1 were considered a prime", "1 were considered a prime", "if 1 were considered a prime", "if 1 were considered a prime"], "answer_start": [485, 488, 488, 485, 485]}, "prediction_text": "1 was considered a prime."}
{"answers": {"text": ["Euler's totient function", "sum of divisors function", "sum of divisors function", "the sum of divisors function", "sum of divisors"], "answer_start": [834, 866, 866, 862, 866]}, "prediction_text": "Euler's totient function"}
{"answers": {"text": ["the sum of divisors function", "relationship of the number to its corresponding value of Euler's totient function", "relationship of the number to its corresponding value of Euler's totient function", "relationship of the number to its corresponding value of Euler's totient function", "the relationship of the number to its corresponding value of Euler's totient function"], "answer_start": [862, 777, 777, 777, 773]}, "prediction_text": "Euler's totient function"}
{"answers": {"text": ["only the single number 1", "1", "only the single number 1", "eliminate all multiples of 1", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1."], "answer_start": [659, 682, 659, 579, 579]}, "prediction_text": "As output only the single number 1."}
{"answers": {"text": ["the Rhind papyrus", "Rhind", "Rhind", "Egyptian fraction", "Rhind papyrus"], "answer_start": [149, 153, 153, 117, 153]}, "prediction_text": "Rhind papyrus"}
{"answers": {"text": ["the Ancient Greeks", "Ancient Greeks", "Greeks", "Ancient Greeks", "Ancient Greeks"], "answer_start": [329, 333, 341, 333, 333]}, "prediction_text": "Ancient Greeks"}
{"answers": {"text": ["Euclid's Elements", "Euclid's Elements", "Euclid's Elements", "Euclid's Elements", "Euclid's Elements"], "answer_start": [349, 349, 349, 349, 349]}, "prediction_text": "Euclid's Elements"}
{"answers": {"text": ["Euclid", "Euclid", "Euclid", "Euclid", "Euclid"], "answer_start": [501, 501, 501, 501, 501]}, "prediction_text": "Euclid"}
{"answers": {"text": ["compute primes", "compute primes", "compute primes", "compute primes", "compute primes"], "answer_start": [654, 654, 654, 654, 654]}, "prediction_text": "Computes primes."}
{"answers": {"text": ["In 1640", "1640", "1640", "1640", "1640"], "answer_start": [90, 93, 93, 93, 93]}, "prediction_text": "1640"}
{"answers": {"text": ["Euler", "Euler", "Euler", "Euler", "Euler"], "answer_start": [191, 191, 191, 191, 191]}, "prediction_text": "Leibniz"}
{"answers": {"text": ["22n + 1", "22n + 1", "22n + 1", "22n + 1", "22n + 1"], "answer_start": [252, 252, 252, 252, 252]}, "prediction_text": "Formal form"}
{"answers": {"text": ["2p \u2212 1", "2p \u2212 1, with p a prime", "2p \u2212 1", "2p \u2212 1", "2p \u2212 1"], "answer_start": [591, 591, 591, 591, 591]}, "prediction_text": "Primes of the form 2p \u2212 1."}
{"answers": {"text": ["up to n = 4 (or 216 + 1)", "up to n = 4 (or 216 + 1)", "216 + 1", "n = 4", "n = 4"], "answer_start": [324, 324, 340, 330, 330]}, "prediction_text": "Fermat confirmed the validity of Fermat numbers."}
{"answers": {"text": ["trial division", "trial division", "trial division", "trial division", "trial division"], "answer_start": [79, 79, 79, 79, 79]}, "prediction_text": "Trial division"}
{"answers": {"text": ["if a complete list of primes up to  is known", "a complete list of primes up to  is known", "complete list of primes up to  is known", "if a complete list of primes up to  is known", "if a complete list of primes up to  is known"], "answer_start": [591, 594, 596, 591, 591]}, "prediction_text": "Complete list of primes"}
{"answers": {"text": ["greater than 1", "1", "1", "is greater than 1 and less than or equal to the square root of n", "1"], "answer_start": [157, 170, 170, 154, 170]}, "prediction_text": "1 or less than 1"}
{"answers": {"text": ["only three divisions", "only for those m that are prime", "three", "three", "three"], "answer_start": [752, 676, 757, 757, 757]}, "prediction_text": "Three divisions"}
{"answers": {"text": ["less than or equal to the square root of n", "the square root of n", "square root of n", "the square root of n.", "the square root of n."], "answer_start": [176, 198, 202, 198, 198]}, "prediction_text": "The square root of n"}
{"answers": {"text": ["two main classes", "two", "two", "two", "two"], "answer_start": [65, 65, 65, 65, 65]}, "prediction_text": "Two main classes, Monte Carlo and deterministic."}
{"answers": {"text": ["probabilistic (or \"Monte Carlo\")", "probabilistic (or \"Monte Carlo\")", "probabilistic", "probabilistic", "probabilistic"], "answer_start": [83, 83, 83, 83, 83]}, "prediction_text": "Monte Carlo tests"}
{"answers": {"text": ["deterministic", "deterministic algorithms", "deterministic", "deterministic algorithms", "deterministic algorithms"], "answer_start": [120, 120, 120, 120, 120]}, "prediction_text": "Deterministic tests"}
{"answers": {"text": ["deterministic", "deterministic algorithm", "deterministic", "deterministic", "deterministic"], "answer_start": [275, 275, 275, 275, 275]}, "prediction_text": "Deterministic algorithm"}
{"answers": {"text": ["1/(1-p)n", "1/(1-p)n", "1/(1-p)n", "1/(1-p)n", "1/(1-p)n"], "answer_start": [833, 833, 833, 833, 833]}, "prediction_text": "By using a probability distribution."}
{"answers": {"text": ["the Fermat primality test,", "Fermat primality test", "Fermat primality test", "Fermat primality test", "the Fermat primality test"], "answer_start": [57, 61, 61, 61, 57]}, "prediction_text": "Fermat's little theorem"}
{"answers": {"text": ["np\u2261n (mod p)", "np\u2261n (mod p) for any n if p is a prime number", "np\u2261n (mod p) for any n if p is a prime number", "np\u2261n (mod p) for any n if p is a prime number", "the fact (Fermat's little theorem) that np\u2261n (mod p) for any n if p is a prime number"], "answer_start": [140, 140, 140, 140, 100]}, "prediction_text": "Fermat's little theorem"}
{"answers": {"text": ["composite numbers (the Carmichael numbers)", "Carmichael", "Carmichael", "Carmichael numbers", "Carmichael numbers"], "answer_start": [355, 378, 378, 378, 378]}, "prediction_text": "Carmichael numbers"}
{"answers": {"text": ["Baillie-PSW", "Baillie-PSW", "Baillie-PSW", "Baillie-PSW", "Baillie-PSW,"], "answer_start": [739, 739, 739, 739, 739]}, "prediction_text": "Baillie-PSW, Miller-Rabin, Solovay-Strassen tests."}
{"answers": {"text": ["Solovay-Strassen tests", "Miller-Rabin", "Miller-Rabin", "Miller-Rabin", "Miller-Rabin"], "answer_start": [770, 752, 752, 752, 752]}, "prediction_text": "Baillie-PSW, Miller-Rabin, Solovay-Strassen tests."}
{"answers": {"text": ["2p + 1", "2p + 1 with p prime", "2p + 1 with p prime", "2p + 1", "2p + 1"], "answer_start": [189, 189, 189, 189, 189]}, "prediction_text": "Primes of the form 2p + 1."}
{"answers": {"text": ["2p \u2212 1", "2p \u2212 1", "2p \u2212 1, where p is an arbitrary prime", "2p \u2212 1", "2p \u2212 1,"], "answer_start": [308, 308, 308, 308, 308]}, "prediction_text": "Primorial primes"}
{"answers": {"text": ["The Lucas\u2013Lehmer test", "Lucas\u2013Lehmer", "Lucas\u2013Lehmer", "Lucas\u2013Lehmer", "Lucas\u2013Lehmer test"], "answer_start": [347, 351, 351, 351, 351]}, "prediction_text": "Lucas\u2013Lehmer test"}
{"answers": {"text": ["primorial primes", "Fermat", "Sophie Germain", "Sophie Germain", "Sophie Germain"], "answer_start": [211, 229, 147, 147, 147]}, "prediction_text": "Sophie Germain primes"}
{"answers": {"text": ["Fermat primes", "Mersenne", "primorial primes", "primorial primes", "primorial primes"], "answer_start": [229, 247, 211, 211, 211]}, "prediction_text": "Mersenne prime"}
{"answers": {"text": ["distributed computing", "distributed computing", "distributed", "distributed computing", "distributed computing"], "answer_start": [118, 118, 118, 118, 118]}, "prediction_text": "distributed computing"}
{"answers": {"text": ["In 2009", "2009", "2009", "2009", "2009"], "answer_start": [141, 144, 144, 144, 144]}, "prediction_text": "2009"}
{"answers": {"text": ["US$100,000", "US$100,000", "US$100,000", "$100,000", "US$100,000"], "answer_start": [213, 213, 213, 215, 213]}, "prediction_text": "$100,000 prize"}
{"answers": {"text": ["The Electronic Frontier Foundation", "Electronic Frontier Foundation", "Electronic Frontier Foundation", ". The Electronic Frontier Foundation", "$150,000"], "answer_start": [293, 297, 297, 291, 340]}, "prediction_text": "Electronic Frontier Foundation"}
{"answers": {"text": ["[256kn + 1, 256k(n + 1) \u2212 1]", "[256kn + 1, 256k(n + 1) \u2212 1]", "[256kn + 1, 256k(n + 1) \u2212 1]", "[256kn + 1, 256k(n + 1) \u2212 1]", "[256kn + 1, 256k(n + 1) \u2212 1]."], "answer_start": [765, 765, 765, 765, 765]}, "prediction_text": "The Great Internet Mersenne Prime Search project"}
{"answers": {"text": ["the floor function", "floor", "floor", "floor function", "floor function"], "answer_start": [53, 57, 57, 57, 57]}, "prediction_text": "Prime number"}
{"answers": {"text": ["Chebyshev", "Chebyshev", "Chebyshev", "Chebyshev", "Chebyshev"], "answer_start": [212, 212, 212, 212, 212]}, "prediction_text": "Chebyshev"}
{"answers": {"text": ["any natural number n > 3", "n > 3", "n > 3", "> 3.", "n > 3"], "answer_start": [315, 334, 334, 336, 334]}, "prediction_text": "largest integer not greater than the number in question."}
{"answers": {"text": ["n < p < 2n \u2212 2", "n < p < 2n \u2212 2", "A or \u03bc", "n < p < 2n \u2212 2", "n < p < 2n \u2212 2"], "answer_start": [295, 295, 360, 295, 295]}, "prediction_text": "At least one prime number"}
{"answers": {"text": ["Wilson's theorem", "Wilson's", "Wilson's", "Wilson's theorem", "Wilson's theorem"], "answer_start": [459, 459, 459, 459, 459]}, "prediction_text": "Wilson's theorem"}
{"answers": {"text": ["their greatest common divisor is one", "greatest common divisor is one", "their greatest common divisor is one", "their greatest common divisor is one"], "answer_start": [69, 75, 69, 69]}, "prediction_text": "They can exist only if a and q are coprime."}
{"answers": {"text": ["Dirichlet's theorem", "Dirichlet's", "Dirichlet's theorem", "Dirichlet's theorem"], "answer_start": [149, 149, 149, 149]}, "prediction_text": "Dirichlet's theorem"}
{"answers": {"text": ["1/6", "1/6", "1/6", "1/6"], "answer_start": [713, 713, 713, 713]}, "prediction_text": "1/6"}
{"answers": {"text": ["at most one prime number", "one", "one", "at most one"], "answer_start": [469, 477, 477, 469]}, "prediction_text": "One prime"}
{"answers": {"text": ["infinitely many prime numbers", "infinitely many", "infinite", "infinitely many"], "answer_start": [550, 550, 550, 550]}, "prediction_text": "One prime number"}
{"answers": {"text": ["The zeta function", "zeta", "zeta function", "zeta function"], "answer_start": [0, 4, 4, 4]}, "prediction_text": "Zeta function"}
{"answers": {"text": ["a finite value", "finite", "finite", "finite"], "answer_start": [233, 235, 235, 235]}, "prediction_text": "finite value"}
{"answers": {"text": ["diverges", "diverges", "exceeds any given number"], "answer_start": [304, 304, 320]}, "prediction_text": "Diverges (i.e., exceeds any given number)"}
{"answers": {"text": ["exceeds any given number", "exceeds any given number", "exceeds any given number", "exceeds any given number"], "answer_start": [320, 320, 320, 320]}, "prediction_text": "exceeds any given number."}
{"answers": {"text": ["identity", "algebraic", "modern algebraic number theory", "modern algebraic number theory"], "answer_start": [506, 465, 458, 458]}, "prediction_text": "Mathematical nature of the zeta function"}
{"answers": {"text": ["1859", "1859", "1859", "1859"], "answer_start": [45, 45, 45, 45]}, "prediction_text": "1859"}
{"answers": {"text": ["s = \u22122, \u22124, ...,", "\u22122, \u22124, ...,", "\u22122, \u22124", "s = \u22122, \u22124"], "answer_start": [74, 78, 78, 74]}, "prediction_text": "\u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s = \u22122, \u22124,..., s ="}
{"answers": {"text": ["random noise", "random noise", "random noise", "random noise"], "answer_start": [402, 402, 402, 402]}, "prediction_text": "Random noise."}
{"answers": {"text": ["asymptotic distribution", "asymptotic", "asymptotic distribution", "asymptotic distribution"], "answer_start": [474, 474, 474, 474]}, "prediction_text": "Asymptotic distribution"}
{"answers": {"text": ["asymptotic distribution", "asymptotic", "asymptotic distribution", "asymptotic distribution"], "answer_start": [474, 474, 474, 474]}, "prediction_text": "Asymptotic distribution"}
{"answers": {"text": ["Goldbach's conjecture", "Goldbach's", "Goldbach's", "Goldbach's"], "answer_start": [278, 278, 278, 278]}, "prediction_text": "Goldbach's conjecture"}
{"answers": {"text": ["1912", "1912", "1912", "1912"], "answer_start": [238, 238, 238, 238]}, "prediction_text": "1912"}
{"answers": {"text": ["all numbers up to n = 2 \u00b7 1017", "n = 2 \u00b7 1017", "n = 2", "n = 2"], "answer_start": [462, 480, 480, 480]}, "prediction_text": "N = 2 \u00b7 1017"}
{"answers": {"text": ["Vinogradov's theorem", "Vinogradov's", "Vinogradov's theorem", "Vinogradov's theorem"], "answer_start": [552, 552, 552, 552]}, "prediction_text": "Chen's theorem"}
{"answers": {"text": ["Chen's theorem", "Chen's", "Chen's theorem", "Chen's theorem"], "answer_start": [661, 661, 661, 661]}, "prediction_text": "Chen's theorem"}
{"answers": {"text": ["twin prime conjecture", "twin prime conjecture", "twin prime conjecture", "Polignac's"], "answer_start": [173, 173, 173, 197]}, "prediction_text": "Polignac's conjecture"}
{"answers": {"text": ["pairs of primes with difference 2", "pairs of primes with difference 2", "pairs of primes with difference 2", "pairs of primes with difference 2"], "answer_start": [138, 138, 138, 138]}, "prediction_text": "A primes with difference 2."}
{"answers": {"text": ["Polignac's conjecture", "Polignac's", "Polignac's conjecture", "Polignac's"], "answer_start": [197, 197, 197, 197]}, "prediction_text": "Polignac's conjecture"}
{"answers": {"text": ["n2 + 1", "n2 + 1", "n2 + 1.", "n2 + 1"], "answer_start": [439, 439, 439, 439]}, "prediction_text": "Inherent in the broad Schinzel's hypothesis."}
{"answers": {"text": ["Brocard's conjecture", "Brocard's", "Brocard's conjecture", "Brocard's"], "answer_start": [521, 521, 521, 521]}, "prediction_text": "Legendre's conjecture"}
{"answers": {"text": ["number theory", "number theory", "number theory", "number theory"], "answer_start": [17, 17, 17, 17]}, "prediction_text": "Number theory"}
{"answers": {"text": ["G. H. Hardy", "G. H. Hardy", "G. H. Hardy", "G. H. Hardy"], "answer_start": [360, 360, 360, 360]}, "prediction_text": "G. H. Hardy"}
{"answers": {"text": ["the 1970s", "1970s", "1970s", "1970s"], "answer_start": [488, 492, 492, 492]}, "prediction_text": "1970s"}
{"answers": {"text": ["hash tables", "hash tables", "hash tables and pseudorandom number generators", "hash tables and pseudorandom number generators"], "answer_start": [664, 664, 664, 664]}, "prediction_text": "Hash tables and pseudorandom number generators."}
{"answers": {"text": ["pseudorandom number generators", "pseudorandom", "pseudorandom", "pseudorandom"], "answer_start": [680, 680, 680, 680]}, "prediction_text": "Hash tables"}
{"answers": {"text": ["a recurring decimal", "recurring", "recurring", "recurring", "recurring"], "answer_start": [215, 217, 217, 217, 217]}, "prediction_text": "A recurring decimal"}
{"answers": {"text": ["p \u2212 1", "p \u2212 1", "p \u2212 1 or a divisor of p \u2212 1", "p \u2212 1 or a divisor of p \u2212 1", "p \u2212 1 or a divisor of p \u2212 1"], "answer_start": [252, 252, 252, 252, 252]}, "prediction_text": "A divisor of p \u2212 1"}
{"answers": {"text": ["(p \u2212 1)! + 1", "(p \u2212 1)! + 1", "(p \u2212 1)! + 1", "(p \u2212 1)! + 1", "(p \u2212 1)! + 1"], "answer_start": [495, 495, 495, 495, 495]}, "prediction_text": "n \u2212 1"}
{"answers": {"text": ["(n \u2212 1)!", "(n \u2212 1)!", "(n \u2212 1)!", "(n \u2212 1)!", "(n \u2212 1)!"], "answer_start": [582, 582, 582, 582, 582]}, "prediction_text": "n \u2212 1"}
{"answers": {"text": ["p is not a prime factor of q", "p is not a prime factor of q", "p is not a prime factor of q", "p is not a prime factor of q.", "p is not a prime factor of q."], "answer_start": [383, 383, 383, 383, 383]}, "prediction_text": "P is prime."}
{"answers": {"text": ["RSA", "RSA", "RSA", "RSA"], "answer_start": [52, 52, 52, 52]}, "prediction_text": "RSA"}
{"answers": {"text": ["the Diffie\u2013Hellman key exchange", "Diffie\u2013Hellman", "Diffie\u2013Hellman key exchange", "Diffie\u2013Hellman key exchange"], "answer_start": [60, 64, 64, 64]}, "prediction_text": "Diffie\u2013Hellman key exchange"}
{"answers": {"text": ["512-bit", "512", "512", "512"], "answer_start": [140, 140, 140, 140]}, "prediction_text": "512-bit primes"}
{"answers": {"text": ["modular exponentiation", "modular", "modular", "modular"], "answer_start": [541, 541, 541, 541]}, "prediction_text": "Modular exponentiation"}
{"answers": {"text": ["1024-bit", "1024", "1024", "1024"], "answer_start": [187, 187, 187, 187]}, "prediction_text": "1024 bits"}
{"answers": {"text": ["cicadas", "cicadas", "cicadas", "cicadas"], "answer_start": [34, 34, 34, 34]}, "prediction_text": "Magicicada insects"}
{"answers": {"text": ["as grubs underground", "underground", "underground", "underground"], "answer_start": [133, 142, 142, 142]}, "prediction_text": "As grubs underground"}
{"answers": {"text": ["17 years", "17", "17", "17"], "answer_start": [222, 222, 222, 222]}, "prediction_text": "17 years"}
{"answers": {"text": ["make it very difficult for predators to evolve that could specialize as predators", "difficult for predators to evolve that could specialize as predators on Magicicadas", "the prime number intervals between emergences make it very difficult for predators to evolve that could specialize as predators on Magicicadas", "the prime number intervals between emergences make it very difficult for predators to evolve"], "answer_start": [398, 411, 352, 352]}, "prediction_text": "Provides difficult predators with a prime number interval."}
{"answers": {"text": ["up to 2% higher", "2%", "2%", "2%"], "answer_start": [775, 781, 781, 781]}, "prediction_text": "Up to 2% higher."}
{"answers": {"text": ["indecomposability", "minimality", "minimality or indecomposability", "minimality or indecomposability"], "answer_start": [170, 156, 156, 156]}, "prediction_text": "minimality or indecomposability."}
{"answers": {"text": ["the smallest subfield", "the smallest subfield", "Q or the finite field with p elements", "the smallest subfield"], "answer_start": [246, 246, 319, 246]}, "prediction_text": "F containing 0 and 1."}
{"answers": {"text": ["as a connected sum of prime knots", "as a connected sum of prime knots", "as a connected sum of prime knots", "as a connected sum of prime knots"], "answer_start": [728, 728, 728, 728]}, "prediction_text": "As a connected sum of prime knots."}
{"answers": {"text": ["any object can be, essentially uniquely, decomposed into its prime components", "any object can be, essentially uniquely, decomposed into its prime components", "any object can be, essentially uniquely, decomposed into its prime components", "any object can be, essentially uniquely, decomposed into its prime components"], "answer_start": [459, 459, 459, 459]}, "prediction_text": "Any object can be decomposed into its prime components."}
{"answers": {"text": ["it cannot be written as the knot sum of two nontrivial knots", "cannot be written as the knot sum of two nontrivial knots", "cannot be written as the knot sum of two nontrivial knots", "it cannot be written as the knot sum of two nontrivial knots"], "answer_start": [631, 634, 634, 631]}, "prediction_text": "Cannot be written as the knot sum of two nontrivial knots."}
{"answers": {"text": ["commutative ring R", "commutative ring", "ring R", "commutative ring R"], "answer_start": [83, 83, 95, 83]}, "prediction_text": "Arithmetic structure"}
{"answers": {"text": ["prime elements", "prime elements", "prime elements", "prime elements"], "answer_start": [186, 186, 186, 186]}, "prediction_text": "Prime elements"}
{"answers": {"text": ["irreducible elements", "irreducible elements", "irreducible elements", "irreducible elements"], "answer_start": [205, 205, 205, 205]}, "prediction_text": "Prime elements"}
{"answers": {"text": ["it is neither zero nor a unit", "neither zero nor a unit", "it is neither zero nor a unit", "it is neither zero nor a unit"], "answer_start": [272, 278, 272, 272]}, "prediction_text": "Not a unit."}
{"answers": {"text": ["cannot be written as a product of two ring elements that are not units", "not a unit and cannot be written as a product of two ring elements that are not units.", "it is not a unit and cannot be written as a product of two ring elements that are not units", "it is not a unit and cannot be written as a product of two ring elements that are not units"], "answer_start": [518, 503, 497, 497]}, "prediction_text": "Cannot be written as a product of two ring elements."}
{"answers": {"text": ["The fundamental theorem of arithmetic", "theorem of arithmetic", "fundamental theorem of arithmetic", "The fundamental theorem of arithmetic"], "answer_start": [0, 16, 4, 0]}, "prediction_text": "The fundamental theorem of arithmetic"}
{"answers": {"text": ["the Gaussian integers Z[i]", "Gaussian integers", "Gaussian integers Z[i],", "Gaussian integers Z[i]"], "answer_start": [120, 124, 124, 124]}, "prediction_text": "Gaussian integers Z[i], that is, the set of complex numbers of the form a + bi."}
{"answers": {"text": ["a + bi", "a + bi", "a + bi", "a + bi"], "answer_start": [196, 196, 196, 196]}, "prediction_text": "A + bi"}
{"answers": {"text": ["arbitrary integers", "arbitrary integers", "arbitrary integers", "arbitrary integers"], "answer_start": [254, 254, 254, 254]}, "prediction_text": "A and b represent the imaginary unit and a and b represent the real unit."}
{"answers": {"text": ["4k + 3", "4k + 3", "Z"], "answer_start": [522, 522, 507]}, "prediction_text": "Not rational primes."}
{"answers": {"text": ["In ring theory", "ring", "ring theory", "ring theory"], "answer_start": [0, 3, 3, 3]}, "prediction_text": "Ring theory"}
{"answers": {"text": ["Prime ideals", "Prime", "Prime ideals", "Prime ideals"], "answer_start": [79, 79, 79, 79]}, "prediction_text": "Prime ideals"}
{"answers": {"text": ["algebraic number theory", "algebraic", "algebraic", "algebraic"], "answer_start": [276, 276, 276, 276]}, "prediction_text": "Ring theory"}
{"answers": {"text": ["The fundamental theorem of arithmetic", "theorem of arithmetic", "fundamental theorem of arithmetic", "The fundamental theorem of arithmetic"], "answer_start": [413, 429, 417, 413]}, "prediction_text": "Lasker\u2013Noether theorem"}
{"answers": {"text": ["a Noetherian commutative ring", "Noetherian", "Noetherian commutative ring", "Noetherian"], "answer_start": [525, 527, 527, 527]}, "prediction_text": "Noetherian ring"}
{"answers": {"text": ["Prime ideals", "Prime ideals", "Prime ideals", "Prime ideals"], "answer_start": [0, 0, 0, 0]}, "prediction_text": "Ring of algebro-geometric objects"}
{"answers": {"text": ["ramification in geometry", "ramification", "ramification", "ramification in geometry"], "answer_start": [378, 378, 378, 378]}, "prediction_text": "Ramification of prime ideals"}
{"answers": {"text": ["ring of integers of quadratic number fields", "integers of quadratic number fields", "integers of quadratic number fields", "the ring of integers of quadratic number fields"], "answer_start": [538, 546, 546, 534]}, "prediction_text": "Quadratic number fields"}
{"answers": {"text": ["the solvability of quadratic equations", "solvability of quadratic equations", "solvability of quadratic equations", "the solvability of quadratic equations"], "answer_start": [654, 658, 658, 654]}, "prediction_text": "Solvability of quadratic equations."}
{"answers": {"text": ["norm gets smaller", "gets smaller", "gets smaller", "gets smaller"], "answer_start": [20, 25, 25, 25]}, "prediction_text": "The norm gets smaller."}
{"answers": {"text": ["completed (or local) fields", "completed (or local) fields", "the completed (or local) fields", "the completed (or local) fields"], "answer_start": [552, 552, 548, 548]}, "prediction_text": "Local fields"}
{"answers": {"text": ["the absolute value", "the absolute value", "absolute value", "the absolute value"], "answer_start": [223, 223, 227, 223]}, "prediction_text": "P-adic norm"}
{"answers": {"text": ["local-global principle", "local-global", "local-global principle", "local-global principle"], "answer_start": [586, 586, 586, 586]}, "prediction_text": "Ostrowski's theorem"}
{"answers": {"text": ["Olivier Messiaen", "Olivier Messiaen", "Olivier Messiaen", "Olivier Messiaen"], "answer_start": [76, 76, 76, 76]}, "prediction_text": "Olivier Messiaen"}
{"answers": {"text": ["La Nativit\u00e9 du Seigneur", "La Nativit\u00e9 du Seigneur", "La Nativit\u00e9 du Seigneur", "La Nativit\u00e9 du Seigneur"], "answer_start": [184, 184, 184, 184]}, "prediction_text": "La Nativit\u00e9 du Seigneur"}
{"answers": {"text": ["Quatre \u00e9tudes de rythme", "Quatre \u00e9tudes de rythme", "Quatre \u00e9tudes de rythme", "Quatre \u00e9tudes de rythme"], "answer_start": [219, 219, 219, 219]}, "prediction_text": "Quatre \u00e9tudes de rythme"}
{"answers": {"text": ["the third \u00e9tude", "third", "third", "third"], "answer_start": [405, 409, 409, 409]}, "prediction_text": "\"Neumes rythmiques\""}
{"answers": {"text": ["the movements of nature", "the movements of nature, movements of free and unequal durations", "the movements of nature, movements of free and unequal durations", "the movements of nature, movements of free and unequal durations"], "answer_start": [504, 504, 504, 504]}, "prediction_text": "Nature movements"}
{"answers": {"text": ["Swiss canton", "s in the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps,", "Graub\u00fcnden", "Graub\u00fcnden"], "answer_start": [110, 101, 126, 126]}, "prediction_text": "In Graub\u00fcnden, Swiss canton"}
{"answers": {"text": ["North Sea", "the North Sea in the Netherlands", "North Sea", "North Sea"], "answer_start": [344, 340, 344, 344]}, "prediction_text": "North Sea"}
{"answers": {"text": ["Cologne, Germany", "Cologne, Germany", "Cologne"], "answer_start": [413, 413, 413]}, "prediction_text": "Cologne, Germany"}
{"answers": {"text": ["Danube", "the Danube", "Danube", "Danube"], "answer_start": [551, 547, 551, 551]}, "prediction_text": "Danube"}
{"answers": {"text": ["1,230 km (760 mi)", "1,230 km (760 mi)", "1,230 km", "1,230 km"], "answer_start": [569, 569, 569, 569]}, "prediction_text": "About 1,230 km (760 mi)"}
{"answers": {"text": ["Europe", "Central and Western Europe", "Germany", "Germany"], "answer_start": [533, 513, 422, 422]}, "prediction_text": "Swiss canton of Graub\u00fcnden"}
{"answers": {"text": ["Netherlands", "Germany", "Netherlands", "Netherlands"], "answer_start": [361, 422, 361, 361]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["1,230 km", "1,230 km (760 mi)", "1,230 km", "1,230 km"], "answer_start": [569, 569, 569, 569]}, "prediction_text": "About 1,230 km (760 mi)"}
{"answers": {"text": ["Gaulish name R\u0113nos", "R\u0113nos", "the Gaulish name R\u0113nos", "R\u0113nos", "R\u0113nos"], "answer_start": [88, 101, 84, 101, 101]}, "prediction_text": "Gaulish name R\u0113nos"}
{"answers": {"text": ["Rhin", "Rhin", "Rhin", "Rhin", "Rhin"], "answer_start": [290, 290, 290, 290, 290]}, "prediction_text": "Rhei"}
{"answers": {"text": ["R\u012bnaz", "R\u012bnaz", "*R\u012bnaz", "R\u012bnaz", "R\u012bnaz"], "answer_start": [430, 430, 429, 430, 430]}, "prediction_text": "Rhenus"}
{"answers": {"text": ["1st century BC", "1st", "Roman-era", "1st century BC"], "answer_start": [150, 150, 129, 150]}, "prediction_text": "1st century BC"}
{"answers": {"text": ["Gaulish name R\u0113nos", "Rhenus", "the Gaulish name R\u0113nos", "1st century BC", "R\u0113nos"], "answer_start": [88, 197, 84, 150, 101]}, "prediction_text": "The Rhine is a name derived from the Gaulish name R\u0113nos."}
{"answers": {"text": ["Rhin", "Rhin", "Rhin", "Rhin", "Rhin"], "answer_start": [290, 290, 290, 290, 290]}, "prediction_text": "Rhein"}
{"answers": {"text": ["Rijn", "Rijn", "Rijn", "Rijn", "Rijn"], "answer_start": [505, 505, 505, 505, 505]}, "prediction_text": "Rhin"}
{"answers": {"text": ["R\u012bnaz", "R\u012bnaz", "R\u012bnaz", "R\u012bnaz", "R\u012bnaz"], "answer_start": [430, 430, 430, 430, 430]}, "prediction_text": "Old Frankish giving Old English R\u00edn, Old High German R\u012bn, Dutch Rijn (formerly also spelled Rhijn)"}
{"answers": {"text": ["Rhijn", "Rhijn", "Rhijn", "Rhijn", "Rhijn"], "answer_start": [533, 533, 533, 533, 533]}, "prediction_text": "Rhin"}
{"answers": {"text": ["Rhine-kilometers", "Rhine-kilometers", "\"Rhine-kilometers\"", "Rhine-kilometers", "Rhine-kilometers"], "answer_start": [55, 55, 54, 55, 55]}, "prediction_text": "\"Rhine-kilometers\" (Rheinkilometer)"}
{"answers": {"text": ["1939", "1939", "1939", "1939", "1939"], "answer_start": [113, 113, 113, 113, 113]}, "prediction_text": "1939 (Rhine-kilometers)"}
{"answers": {"text": ["Old Rhine Bridge at Constance", "Old Rhine Bridge at Constance", "the Old Rhine Bridge at Constance", "Old Rhine Bridge at Constance", "Old Rhine Bridge"], "answer_start": [138, 138, 134, 138, 138]}, "prediction_text": "Old Rhine Bridge"}
{"answers": {"text": ["Hoek van Holland", "Hoek van Holland", "(1036.20 km)", "Hoek van Holland", "Hoek van Holland"], "answer_start": [178, 178, 195, 178, 178]}, "prediction_text": "At Hoek van Holland (1036.20 km)"}
{"answers": {"text": ["canalisation projects", "canalisation projects", "the river's natural course due to number of canalisation projects completed in the 19th and 20th century", "canalisation projects", "canalisation projects"], "answer_start": [302, 302, 258, 302, 302]}, "prediction_text": "Number of canalisation projects"}
{"answers": {"text": ["Rhine-kilometers\"", "Rhine-kilometers", "kilometres", "Rhine-kilometers", "Rhine-kilometers"], "answer_start": [55, 55, 525, 55, 55]}, "prediction_text": "\"Rhine-kilometers\" (Rheinkilometer)"}
{"answers": {"text": ["1939", "1939", "1939", "1939"], "answer_start": [113, 113, 113, 113]}, "prediction_text": "1939 (Rhine-kilometers)"}
{"answers": {"text": ["Old Rhine Bridge at Constance", "Old Rhine Bridge at Constance", "the Old Rhine Bridge at Constance", "Old Rhine Bridge at Constance", "Old Rhine Bridge"], "answer_start": [138, 138, 134, 138, 138]}, "prediction_text": "Old Rhine Bridge"}
{"answers": {"text": ["canalisation projects", "canalisation projects", "from the river's natural course due to number of canalisation projects completed in the 19th and 20th century", "canalisation projects", "canalisation projects"], "answer_start": [302, 302, 253, 302, 302]}, "prediction_text": "Number of canalisation projects"}
{"answers": {"text": ["Hoek van Holland", "Hoek van Holland", "Hoek van Holland", "Hoek van Holland", "Hoek van Holland"], "answer_start": [178, 178, 178, 178, 178]}, "prediction_text": "Constance (0 km)"}
{"answers": {"text": ["north", "north", "north", "north", "north"], "answer_start": [132, 132, 132, 132, 132]}, "prediction_text": "North"}
{"answers": {"text": ["86 km long,", "86 km", "86 km long", "86 km", "86 km"], "answer_start": [172, 172, 172, 172, 172]}, "prediction_text": "Nearly 86 km long"}
{"answers": {"text": ["Rhine Valley", "Rhine Valley", "Rhine Valley", "Rhine Valley", "Rhine Valley"], "answer_start": [289, 289, 289, 289, 289]}, "prediction_text": "Rhine Valley"}
{"answers": {"text": ["Sargans", "Near Sargans", "Sargans", "Sargans", "Sargans"], "answer_start": [327, 322, 327, 327, 327]}, "prediction_text": "A few metres high"}
{"answers": {"text": ["Austria", "Liechtenstein", "Austria to the East.", "Austria", "Austria"], "answer_start": [664, 640, 664, 664, 664]}, "prediction_text": "Liechtenstein and Austria"}
{"answers": {"text": ["Chur", "Chur", "Chur", "Chur"], "answer_start": [143, 143, 143, 143]}, "prediction_text": "Near Chur"}
{"answers": {"text": ["86 km", "86 km", "86 km long", "86 km", "86 km"], "answer_start": [172, 172, 172, 172, 172]}, "prediction_text": "Nearly 86 km"}
{"answers": {"text": ["599 m", "599 m to 396 m", "599 m to 396 m", "599 m", "599 m"], "answer_start": [214, 214, 214, 214, 214]}, "prediction_text": "599 m"}
{"answers": {"text": ["Rhine Valley", "Rhine Valley", "Rhine Valley", "Rhine Valley", "Rhine Valley"], "answer_start": [289, 289, 289, 289, 289]}, "prediction_text": "Rhine Valley"}
{"answers": {"text": ["Switzerland", "Switzerland", "Liechtenstein", "Switzerland", "Switzerland"], "answer_start": [612, 612, 640, 612, 612]}, "prediction_text": "Switzerland"}
{"answers": {"text": ["Lake Constance", "Lake Constance", "Lake Constance", "Lake Constance"], "answer_start": [28, 28, 28, 28]}, "prediction_text": "Lake Constance"}
{"answers": {"text": ["Alter Rhein", "Alter Rhein", "the Alter Rhein", "Alter Rhein"], "answer_start": [108, 108, 104, 108]}, "prediction_text": "Alter Rhein"}
{"answers": {"text": ["modern canalized section", "modern canalized", "modern canalized section", "canalized section"], "answer_start": [155, 155, 155, 162]}, "prediction_text": "Modern canalized section"}
{"answers": {"text": ["Isel", "Isel", "\"Isel\"", "Isel"], "answer_start": [474, 474, 473, 474]}, "prediction_text": "\"Isel\""}
{"answers": {"text": ["Donkey", "Donkey", "\"Donkey\")", "Donkey"], "answer_start": [531, 531, 530, 531]}, "prediction_text": "Esel"}
{"answers": {"text": ["Lake Constance", "Lake Constance", "West by the Alter Rhein", "Lake Constance"], "answer_start": [28, 28, 96, 28]}, "prediction_text": "Lake Constance"}
{"answers": {"text": ["modern canalized section", "modern canalized", "modern canalized section", "canalized section"], "answer_start": [155, 155, 155, 162]}, "prediction_text": "A modern canalized section"}
{"answers": {"text": ["Alter Rhein", "Alter Rhein", "Alter Rhein", "Alter Rhein"], "answer_start": [108, 108, 108, 108]}, "prediction_text": "Alter Rhein"}
{"answers": {"text": ["small islands", "small islands by precipitating sediments", "small islands", "islands"], "answer_start": [372, 372, 372, 378]}, "prediction_text": "A nature reserve and bird sanctuary."}
{"answers": {"text": ["Isel", "Isel", "\"Isel\"", "Isel"], "answer_start": [474, 474, 473, 474]}, "prediction_text": "Esel (\"Donkey\")"}
{"answers": {"text": ["Diepoldsau", "Diepoldsau", "near Diepoldsau", "Diepoldsau"], "answer_start": [67, 67, 62, 67]}, "prediction_text": "Near Diepoldsau"}
{"answers": {"text": ["Fu\u00dfach", "Fu\u00dfach", "Fu\u00dfach", "Fu\u00dfach"], "answer_start": [99, 99, 99, 99]}, "prediction_text": "Lower canal at Fu\u00dfach"}
{"answers": {"text": ["strong sedimentation", "strong sedimentation", "strong sedimentation in the western Rhine Delta", "strong sedimentation"], "answer_start": [156, 156, 156, 156]}, "prediction_text": "To counter sedimentation"}
{"answers": {"text": ["parallel to the canalized Rhine", "the canalized Rhine", "parallel to the canalized Rhine into the lake.", "into the lake"], "answer_start": [266, 278, 266, 298]}, "prediction_text": "Parallel to the canalized Rhine"}
{"answers": {"text": ["silt", "silt up the lake", "the continuous input of sediment into the lake will silt up the lake", "silt up the lake"], "answer_start": [502, 502, 450, 502]}, "prediction_text": "Silt up the lake."}
{"answers": {"text": ["Fu\u00dfach", "Fu\u00dfach", "Fu\u00dfach", "Fu\u00dfach"], "answer_start": [99, 99, 99, 99]}, "prediction_text": "Near Diepoldsau"}
{"answers": {"text": ["constant flooding", "constant flooding and strong sedimentation", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "to counteract the constant flooding and strong sedimentation"], "answer_start": [134, 134, 116, 116]}, "prediction_text": "Countering flooding and sedimentation."}
{"answers": {"text": ["Diepoldsau", "Diepoldsau", "near Diepoldsau", "Diepoldsau"], "answer_start": [67, 67, 62, 67]}, "prediction_text": "Near Diepoldsau"}
{"answers": {"text": ["Dornbirner Ach", "Dornbirner Ach", "The Dornbirner Ach", "Dornbirner Ach"], "answer_start": [209, 209, 205, 209]}, "prediction_text": "Dornbirner Ach"}
{"answers": {"text": ["continuous input of sediment", "continuous input of sediment", "It is expected that the continuous input of sediment into the lake will silt up the lake", "continuous input of sediment into the lake"], "answer_start": [454, 454, 430, 454]}, "prediction_text": "sediment input"}
{"answers": {"text": ["three", "three", "three bodies of water:", "three"], "answer_start": [27, 27, 27, 27]}, "prediction_text": "Three bodies of water"}
{"answers": {"text": ["lower lake", "lower lake", "\"lower lake\"", "lower lake"], "answer_start": [93, 93, 92, 93]}, "prediction_text": "Lower lake"}
{"answers": {"text": ["Lake Rhine", "Seerhein", "Untersee", "Seerhein"], "answer_start": [168, 157, 82, 157]}, "prediction_text": "Seerhein"}
{"answers": {"text": ["Swiss-Austrian border", "Swiss-Austrian", "Swiss-Austrian border"], "answer_start": [478, 478, 478]}, "prediction_text": "Swiss-Austrian border"}
{"answers": {"text": ["upper lake", "upper lake", "(\"upper lake\"", "upper lake"], "answer_start": [64, 64, 62, 64]}, "prediction_text": "Upper lake"}
{"answers": {"text": ["three", "three", "three bodies of water", "three"], "answer_start": [27, 27, 27, 27]}, "prediction_text": "Three bodies of water"}
{"answers": {"text": ["Austria", "Austria", "Austria", "Austria"], "answer_start": [231, 231, 231, 231]}, "prediction_text": "Austria"}
{"answers": {"text": ["Alps", "Alps", "the Alps", "Alps"], "answer_start": [248, 248, 244, 248]}, "prediction_text": "Alps"}
{"answers": {"text": ["47\u00b039\u2032N 9\u00b019\u2032E\ufeff / \ufeff47.650\u00b0N 9.317\u00b0E\ufeff / 47.650; 9.317.", "47\u00b039\u2032N 9\u00b019\u2032E\ufeff / \ufeff47.650\u00b0N 9.317\u00b0E\ufeff / 47.650; 9.317", "47\u00b039\u2032N 9\u00b019\u2032E\ufeff / \ufeff47.650\u00b0N 9.317\u00b0E\ufeff / 47.650; 9.317"], "answer_start": [532, 532, 532]}, "prediction_text": "Swiss-Austrian border"}
{"answers": {"text": ["Baden-W\u00fcrttemberg", "Baden-W\u00fcrttemberg", "Baden-W\u00fcrttemberg", "Baden-W\u00fcrttemberg"], "answer_start": [323, 323, 323, 323]}, "prediction_text": "Baden-W\u00fcrttemberg"}
{"answers": {"text": ["greater density of cold water", "greater density of cold water", "because of the greater density of cold water"], "answer_start": [290, 290, 275]}, "prediction_text": "Greater density of cold water."}
{"answers": {"text": ["Lake \u00dcberlingen", "Lake \u00dcberlingen", "Lake \u00dcberlingen"], "answer_start": [564, 564, 564]}, "prediction_text": "Hagnau am Bodensee"}
{"answers": {"text": ["Rheinbrech", "Upper Lake", "Rheinbrech"], "answer_start": [216, 177, 216]}, "prediction_text": "Upper Lake"}
{"answers": {"text": ["entire length", "the entire length of the lake", "entire length of the lake"], "answer_start": [769, 765, 769]}, "prediction_text": "Most of the lake"}
{"answers": {"text": ["Lindau", "Lindau", "Lindau"], "answer_start": [417, 417, 417]}, "prediction_text": "Mainau"}
{"answers": {"text": ["Rheinbrech", "Upper Lake", "Rheinrinne"], "answer_start": [216, 177, 639]}, "prediction_text": "Near the surface"}
{"answers": {"text": ["Lindau", "Lindau", "Mainau"], "answer_start": [417, 417, 552]}, "prediction_text": "Mainau"}
{"answers": {"text": ["Lake \u00dcberlingen", "Lake \u00dcberlingen", "Lake \u00dcberlingen"], "answer_start": [564, 564, 564]}, "prediction_text": "Lake \u00dcberlingen"}
{"answers": {"text": ["Rhine Gutter", "Rhine Gutter", "Rhine Gutter"], "answer_start": [652, 652, 652]}, "prediction_text": "Rhine Gutter"}
{"answers": {"text": ["water level", "water level", "water level"], "answer_start": [698, 698, 698]}, "prediction_text": "Water level"}
{"answers": {"text": ["westward", "westward", "westward"], "answer_start": [55, 55, 55]}, "prediction_text": "Westward"}
{"answers": {"text": ["river Aare", "Aare", "river Aare"], "answer_start": [149, 155, 149]}, "prediction_text": "Aare"}
{"answers": {"text": ["1,000 m3/s (35,000 cu ft/s)", "1,000 m3/s"], "answer_start": [241, 241]}, "prediction_text": "Nearly 1,000 m3/s (35,000 cu ft/s)"}
{"answers": {"text": ["Finsteraarhorn", "summit of Finsteraarhorn", "Finsteraarhorn, t"], "answer_start": [412, 402, 412]}, "prediction_text": "At Basel"}
{"answers": {"text": ["Basel", "Basel", "Basel, leaving Switzerland"], "answer_start": [688, 688, 688]}, "prediction_text": "Basel"}
{"answers": {"text": ["westward", "westward", "westward"], "answer_start": [55, 55, 55]}, "prediction_text": "Westward"}
{"answers": {"text": ["Aare", "Aare", "river Aare"], "answer_start": [155, 155, 149]}, "prediction_text": "Aare"}
{"answers": {"text": ["1,000 m3/s (35,000 cu ft/s),", "1,000 m3/s"], "answer_start": [241, 241]}, "prediction_text": "Nearly 1,000 m3/s (35,000 cu ft/s)"}
{"answers": {"text": ["Finsteraarhorn", "summit of Finsteraarhorn", "Finsteraarhorn"], "answer_start": [412, 402, 412]}, "prediction_text": "Finsteraarhorn"}
{"answers": {"text": ["German", "German-Swiss border", "German"], "answer_start": [494, 494, 494]}, "prediction_text": "Germany"}
{"answers": {"text": ["Basel", "Basel", "Basel,"], "answer_start": [17, 17, 17]}, "prediction_text": "Basel"}
{"answers": {"text": ["Rhine knee", "Rhine knee", "Rhine knee"], "answer_start": [90, 90, 90]}, "prediction_text": "Rhine knee"}
{"answers": {"text": ["Central Bridge", "Central Bridge", "Central Bridge"], "answer_start": [233, 233, 233]}, "prediction_text": "Upper Rhine Plain"}
{"answers": {"text": ["300 km long", "300 km long", "300 km long"], "answer_start": [381, 381, 381]}, "prediction_text": "About 300 km long."}
{"answers": {"text": ["40 km wide", "40 km wide", "40 km"], "answer_start": [403, 403, 403]}, "prediction_text": "About 300 km long and up to 40 km wide."}
{"answers": {"text": ["Basel", "Basel", "Basel"], "answer_start": [17, 17, 17]}, "prediction_text": "Basel"}
{"answers": {"text": ["Rhine knee", "Rhine knee", "Rhine knee"], "answer_start": [90, 90, 90]}, "prediction_text": "Rhine knee"}
{"answers": {"text": ["North", "North", "North"], "answer_start": [187, 187, 187]}, "prediction_text": "North"}
{"answers": {"text": ["High Rhine", "High Rhine", "High Rhine"], "answer_start": [203, 203, 203]}, "prediction_text": "The High Rhine ends."}
{"answers": {"text": ["Central Bridge", "Central Bridge", "Central Bridge"], "answer_start": [233, 233, 233]}, "prediction_text": "Central Bridge"}
{"answers": {"text": ["19th Century", "19th", "19th"], "answer_start": [89, 89, 89]}, "prediction_text": "19th century"}
{"answers": {"text": ["increased", "increased", "rate of flow was increased"], "answer_start": [124, 124, 107]}, "prediction_text": "The ground water level fell significantly."}
{"answers": {"text": ["fell significantly", "fell significantly", "level fell significantly"], "answer_start": [161, 161, 155]}, "prediction_text": "Dead branches dried up."}
{"answers": {"text": ["Grand Canal d'Alsace", "Grand Canal d'Alsace", "Grand Canal d'Alsace"], "answer_start": [293, 293, 293]}, "prediction_text": "Grand Canal d'Alsace"}
{"answers": {"text": ["large compensation pools", "large compensation pools", "compensation pools"], "answer_start": [426, 426, 432]}, "prediction_text": "Large compensation pool"}
{"answers": {"text": ["Upper Rhine", "Upper Rhine", "Upper Rhine region"], "answer_start": [4, 4, 4]}, "prediction_text": "Upper Rhine region"}
{"answers": {"text": ["19th Century", "19th", "19th Century"], "answer_start": [89, 89, 89]}, "prediction_text": "19th Century"}
{"answers": {"text": ["increased", "increased", "was increased"], "answer_start": [124, 124, 120]}, "prediction_text": "Dead branches dried up, forested areas decreased sharply."}
{"answers": {"text": ["fell significantly", "fell significantly", "level fell"], "answer_start": [161, 161, 155]}, "prediction_text": "Dead branches dried up."}
{"answers": {"text": ["Grand Canal d'Alsace", "Grand Canal d'Alsace", "Grand Canal d'Alsace"], "answer_start": [293, 293, 293]}, "prediction_text": "The Grand Canal d'Alsace"}
{"answers": {"text": ["Germany", "Germany", "Germany"], "answer_start": [34, 34, 34]}, "prediction_text": "Here in Germany"}
{"answers": {"text": ["300 m3/s (11,000 cu ft/s)", "300 m3/s", "300 m3/s"], "answer_start": [221, 221, 221]}, "prediction_text": "Over 300 m3/s (11,000 cu ft/s)"}
{"answers": {"text": ["Rhine", "Rhine", "The Rhine"], "answer_start": [4, 4, 0]}, "prediction_text": "The Rhine"}
{"answers": {"text": ["Moselle", "Moselle", "the Moselle"], "answer_start": [449, 296, 156]}, "prediction_text": "Main tributary to the Rhine is the Main."}
{"answers": {"text": ["400 m (1,300 ft).", "400 m", "400 m"], "answer_start": [587, 587, 587]}, "prediction_text": "400 m (1,300 ft)"}
{"answers": {"text": ["Germany", "Germany", "Germany"], "answer_start": [34, 34, 34]}, "prediction_text": "Germany"}
{"answers": {"text": ["Germany", "Germany", "Germany"], "answer_start": [34, 34, 34]}, "prediction_text": "Germany"}
{"answers": {"text": ["Moselle", "Neckar", "Neckar"], "answer_start": [160, 127, 127]}, "prediction_text": "The Main and Moselle"}
{"answers": {"text": ["France", "France", "France"], "answer_start": [261, 261, 261]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["2,290 m3/s (81,000 cu ft/s)", "2,290 m3/s", "2,290 m3/s"], "answer_start": [535, 535, 535]}, "prediction_text": "2,290 m3/s (81,000 cu ft/s)"}
{"answers": {"text": ["Middle Rhine", "Middle Rhine", "Middle Rhine"], "answer_start": [29, 29, 29]}, "prediction_text": "Middle Rhine"}
{"answers": {"text": ["Rhine Gorge", "Rhine Gorge", "Rhine Gorge"], "answer_start": [60, 60, 60]}, "prediction_text": "Middle Rhine gorge"}
{"answers": {"text": ["erosion", "erosion", "by erosion"], "answer_start": [106, 106, 103]}, "prediction_text": "By erosion"}
{"answers": {"text": ["the Romantic Rhine", "the Romantic Rhine", "the Romantic Rhine"], "answer_start": [425, 425, 425]}, "prediction_text": "Romantic Rhine"}
{"answers": {"text": ["Middle Rhine", "Middle Rhine", "Middle Rhine"], "answer_start": [29, 29, 29]}, "prediction_text": "Middle Rhine"}
{"answers": {"text": ["Rhine Gorge", "Rhine Gorge", "Rhine Gorge"], "answer_start": [60, 60, 60]}, "prediction_text": "Through the Rhine Gorge"}
{"answers": {"text": ["castles", "castles and vineyards", "castles and vineyards"], "answer_start": [346, 346, 346]}, "prediction_text": "castles and vineyards"}
{"answers": {"text": ["Romantic Rhine", "the Romantic Rhine", "the Romantic Rhine"], "answer_start": [429, 425, 425]}, "prediction_text": "Romantic Rhine"}
{"answers": {"text": ["plants and factories", "industry", "industry"], "answer_start": [85, 23, 23]}, "prediction_text": "Industry and heavy industry"}
{"answers": {"text": ["Duisburg", "Duisburg", "Duisburg"], "answer_start": [298, 298, 298]}, "prediction_text": "Duisburg"}
{"answers": {"text": ["Ruhr", "Ruhr", "The Ruhr"], "answer_start": [432, 432, 428]}, "prediction_text": "The Ruhr"}
{"answers": {"text": ["drinking water", "drinking water", "drinking water"], "answer_start": [728, 728, 728]}, "prediction_text": "Drinking water"}
{"answers": {"text": ["Switzerland", "Lower Rhine", "Lower Rhine"], "answer_start": [143, 172, 172]}, "prediction_text": "Lower Rhine"}
{"answers": {"text": ["pollution", "pollution", "water pollution"], "answer_start": [60, 60, 54]}, "prediction_text": "Produced water pollution"}
{"answers": {"text": ["Lower Rhine", "Lower Rhine", "Lower Rhine"], "answer_start": [172, 172, 172]}, "prediction_text": "Lower Rhine"}
{"answers": {"text": ["Switzerland", "Duisburg", "Switzerland"], "answer_start": [143, 288, 143]}, "prediction_text": "Switzerland"}
{"answers": {"text": ["Duisburg", "Duisburg", "Duisburg"], "answer_start": [298, 298, 298]}, "prediction_text": "Duisburg"}
{"answers": {"text": ["Ruhr", "Ruhr", "The Ruhr"], "answer_start": [432, 432, 428]}, "prediction_text": "Ruhr"}
{"answers": {"text": ["tourism", "tourism", "tourism"], "answer_start": [75, 75, 75]}, "prediction_text": "Tourism"}
{"answers": {"text": ["R\u00fcdesheim am Rhein", "R\u00fcdesheim am Rhein", "R\u00fcdesheim am Rhein"], "answer_start": [108, 108, 108]}, "prediction_text": "R\u00fcdesheim am Rhein"}
{"answers": {"text": ["Lorelei", "Lorelei", "Lorelei"], "answer_start": [245, 245, 245]}, "prediction_text": "Lorelei"}
{"answers": {"text": ["Middle Rhine Valley", "Middle Rhine Valley", "Middle Rhine Valley"], "answer_start": [442, 442, 442]}, "prediction_text": "Middle Rhine Valley"}
{"answers": {"text": ["tourism", "tourism", "tourism"], "answer_start": [75, 75, 75]}, "prediction_text": "Tourism"}
{"answers": {"text": ["UNESCO World Heritage Site.", "UNESCO World Heritage Site", "World Heritage Site"], "answer_start": [154, 154, 161]}, "prediction_text": "UNESCO World Heritage Site"}
{"answers": {"text": ["R\u00fcdesheim am Rhein", "R\u00fcdesheim am Rhein", "R\u00fcdesheim am Rhein"], "answer_start": [108, 108, 108]}, "prediction_text": "R\u00fcdesheim"}
{"answers": {"text": ["Lorelei", "Lorelei", "Lorelei"], "answer_start": [245, 245, 245]}, "prediction_text": "Lorelei"}
{"answers": {"text": ["Sankt Goarshausen", "Near Sankt Goarshausen", "Lorelei"], "answer_start": [187, 182, 245]}, "prediction_text": "Lorelei"}
{"answers": {"text": ["Duisburg", "Duisburg", "Duisburg"], "answer_start": [321, 321, 321]}, "prediction_text": "Duisburg"}
{"answers": {"text": ["Wesel-Datteln Canal", "Wesel-Datteln Canal", "Wesel-Datteln Canal"], "answer_start": [547, 547, 547]}, "prediction_text": "Second east-west shipping route"}
{"answers": {"text": ["Lippe", "Lippe", "Lippe"], "answer_start": [595, 595, 595]}, "prediction_text": "The Rhine-Ruhr region"}
{"answers": {"text": ["Emmerich Rhine Bridge", "Emmerich Rhine Bridge", "Emmerich Rhine Bridge,"], "answer_start": [634, 634, 634]}, "prediction_text": "Emmerich Rhine Bridge"}
{"answers": {"text": ["400 m", "400 m", "400 m"], "answer_start": [711, 711, 711]}, "prediction_text": "400 m wide"}
{"answers": {"text": ["Lower Rhine", "Lower", "Lower Rhine"], "answer_start": [4, 4, 4]}, "prediction_text": "The Lower Rhine flows through North Rhine-Westphalia."}
{"answers": {"text": ["Rhine-Ruhr", "Rhine-Ruhr", "Rhine-Ruhr region"], "answer_start": [251, 251, 251]}, "prediction_text": "Rhine-Ruhr region"}
{"answers": {"text": ["Duisport", "Duisport", "Duisburg"], "answer_start": [369, 369, 321]}, "prediction_text": "Duisport"}
{"answers": {"text": ["Emmerich Rhine Bridge", "Emmerich Rhine Bridge", "Emmerich Rhine Bridge"], "answer_start": [634, 634, 634]}, "prediction_text": "Emmerich Rhine Bridge"}
{"answers": {"text": ["400 m wide", "400 m", "400 m"], "answer_start": [711, 711, 711]}, "prediction_text": "400 m wide"}
{"answers": {"text": ["Meuse", "Meuse", "Meuse"], "answer_start": [287, 287, 287]}, "prediction_text": "The Meuse"}
{"answers": {"text": ["Rijn", "Rijn", "Rijn"], "answer_start": [69, 69, 69]}, "prediction_text": "Rijn no longer coincides with the main flow of water."}
{"answers": {"text": ["Two thirds", "Two thirds", "Two thirds"], "answer_start": [123, 123, 123]}, "prediction_text": "Two thirds"}
{"answers": {"text": ["west", "west", "west"], "answer_start": [186, 186, 186]}, "prediction_text": "Westward"}
{"answers": {"text": ["Waal", "Waal", "through the Waal"], "answer_start": [204, 204, 192]}, "prediction_text": "Through the Waal and Merwede estuaries."}
{"answers": {"text": ["Meuse", "Meuse", "Meuse"], "answer_start": [287, 287, 287]}, "prediction_text": "The Meuse River"}
{"answers": {"text": ["The Oude Maas", "Oude Maas", "Oude Maas"], "answer_start": [629, 633, 633]}, "prediction_text": "Het Scheur"}
{"answers": {"text": ["Pannerdens Kanaal", "Pannerdens Kanaal", "the Pannerdens Kanaal"], "answer_start": [47, 47, 43]}, "prediction_text": "The Nieuwe Maas"}
{"answers": {"text": ["Nederrijn", "Nederrijn", "Nederrijn"], "answer_start": [101, 101, 101]}, "prediction_text": "Nederrijn"}
{"answers": {"text": ["Lek", "Lek", "the Lek"], "answer_start": [406, 406, 402]}, "prediction_text": "Lek"}
{"answers": {"text": ["Noord River", "Nieuwe Maas", "Noord River"], "answer_start": [448, 469, 448]}, "prediction_text": "North Sea"}
{"answers": {"text": ["Pannerdens Kanaal", "Pannerdens Kanaal", "the Pannerdens Kanaal"], "answer_start": [47, 47, 43]}, "prediction_text": "Nieuwe Maas"}
{"answers": {"text": ["Nederrijn", "Nederrijn", "Nederrijn"], "answer_start": [101, 101, 101]}, "prediction_text": "In the IJssel and Nederrijn."}
{"answers": {"text": ["one ninth", "one ninth", "one ninth"], "answer_start": [138, 138, 138]}, "prediction_text": "One ninth of the Rhine flow"}
{"answers": {"text": ["Lek", "Lek", "the Lek"], "answer_start": [406, 406, 402]}, "prediction_text": "Lek"}
{"answers": {"text": ["Wijk bij Duurstede", "at Wijk bij Duurstede", "Wijk bij Duurstede"], "answer_start": [339, 336, 339]}, "prediction_text": "Wijk bij Duurstede"}
{"answers": {"text": ["Rijn", "Rijn", "Rijn"], "answer_start": [9, 9, 9]}, "prediction_text": "Rijn (from here on)"}
{"answers": {"text": ["draining the surrounding land", "draining the surrounding land and polders", "for draining the surrounding land and polders"], "answer_start": [243, 243, 239]}, "prediction_text": "Draining the surrounding land and polders."}
{"answers": {"text": ["Kromme Rijn", "Kromme Rijn", "Kromme Rijn"], "answer_start": [355, 355, 355]}, "prediction_text": "Kromme Rijn"}
{"answers": {"text": ["Bent Rhine", "Bent Rhine", "Bent Rhine"], "answer_start": [369, 369, 369]}, "prediction_text": "Kromme Rijn"}
{"answers": {"text": ["Old Rhine", "Oude Rijn", "Oude Rijn"], "answer_start": [456, 444, 444]}, "prediction_text": "The old north branch of the Rhine flows west."}
{"answers": {"text": ["Rhine-Meuse", "Rhine-Meuse Delta", "Rhine-Meuse"], "answer_start": [4, 4, 4]}, "prediction_text": "Rhine-Meuse Delta"}
{"answers": {"text": ["Millingen aan de Rijn,", "near Millingen aan de Rijn", "near Millingen aan de Rijn"], "answer_start": [88, 83, 83]}, "prediction_text": "Near Millingen aan de Rijn"}
{"answers": {"text": ["Rhine Delta", "Rhine Delta", "Rhine Delta"], "answer_start": [264, 264, 264]}, "prediction_text": "Rhine-Meuse Delta"}
{"answers": {"text": ["Nederrijn at Angeren", "Nederrijn at Angeren", "Nederrijn at Angeren"], "answer_start": [173, 173, 173]}, "prediction_text": "Nederrijn"}
{"answers": {"text": ["three", "three", "three"], "answer_start": [276, 276, 276]}, "prediction_text": "Three main flows"}
{"answers": {"text": ["Waal", "Waal", "Waal"], "answer_start": [381, 381, 381]}, "prediction_text": "Waal"}
{"answers": {"text": ["Old Meuse", "Old Meuse", "Old Meuse"], "answer_start": [973, 973, 973]}, "prediction_text": "Old Meuse"}
{"answers": {"text": ["the Rip", "the Rip", "the Rip"], "answer_start": [540, 540, 540]}, "prediction_text": "\"The Rip\""}
{"answers": {"text": ["St. Elizabeth's", "St. Elizabeth's", "St. Elizabeth's flood"], "answer_start": [11, 11, 11]}, "prediction_text": "St. Elizabeth's flood (1421)"}
{"answers": {"text": ["1421", "1421", "1421"], "answer_start": [34, 34, 34]}, "prediction_text": "1421"}
{"answers": {"text": ["Merwede-Oude Maas", "Merwede-Oude Maas", "North Sea"], "answer_start": [85, 85, 110]}, "prediction_text": "South of today's line Merwede-Oude Maas"}
{"answers": {"text": ["1421 to 1904", "1421 to 1904", "From 1421 to 1904"], "answer_start": [321, 321, 316]}, "prediction_text": "1421 to 1904"}
{"answers": {"text": ["archipelago-like estuary", "archipelago-like estuary", "archipelago-like estuary"], "answer_start": [134, 134, 134]}, "prediction_text": "Archipelago-like estuary"}
{"answers": {"text": ["drainage channels", "drainage channels", "drainage channels"], "answer_start": [226, 226, 226]}, "prediction_text": "Dammed drainage channels"}
{"answers": {"text": ["construction of Delta Works", "construction of Delta Works", "construction of Delta Works"], "answer_start": [274, 274, 274]}, "prediction_text": "Construction of Delta Works"}
{"answers": {"text": ["dammed", "dammed", "dammed"], "answer_start": [200, 200, 200]}, "prediction_text": "Dammed rivers"}
{"answers": {"text": ["20th Century", "20th Century", "second half of the 20th Century"], "answer_start": [346, 346, 327]}, "prediction_text": "20th Century"}
{"answers": {"text": ["tidal delta", "tidal", "tidal delta"], "answer_start": [27, 27, 27]}, "prediction_text": "Tidal delta"}
{"answers": {"text": ["tidal currents", "tidal currents", "tidal currents"], "answer_start": [104, 104, 104]}, "prediction_text": "Tidal currents"}
{"answers": {"text": ["tear huge areas of land into the sea.", "tidal currents", "tear huge areas of land into the sea"], "answer_start": [204, 104, 204]}, "prediction_text": "Strong tidal currents"}
{"answers": {"text": ["Zaltbommel", "Zaltbommel", "Zaltbommel"], "answer_start": [516, 516, 516]}, "prediction_text": "Zaltbommel"}
{"answers": {"text": ["Tethys sea", "Tethys", "Tethys sea"], "answer_start": [301, 301, 301]}, "prediction_text": "Tethys sea"}
{"answers": {"text": ["Jurassic Period", "Jurassic Period", "Jurassic Period"], "answer_start": [338, 338, 338]}, "prediction_text": "Jurassic Period"}
{"answers": {"text": ["Mediterranean geography", "Mediterranean geography", "Mediterranean geography"], "answer_start": [697, 697, 697]}, "prediction_text": "Mediterranean geography"}
{"answers": {"text": ["Mesozoic Era", "Triassic Period", "Triassic Period"], "answer_start": [68, 45, 45]}, "prediction_text": "Triassic Period"}
{"answers": {"text": ["Iberia", "Iberia", "Iberia"], "answer_start": [722, 722, 722]}, "prediction_text": "The compression and orogeny"}
{"answers": {"text": ["N\u2013S", "N\u2013S", "N\u2013S rift system"], "answer_start": [61, 61, 61]}, "prediction_text": "Upper Rhine Graben"}
{"answers": {"text": ["Upper Rhine Graben", "Upper Rhine Graben", "Upper Rhine Graben"], "answer_start": [141, 141, 141]}, "prediction_text": "Upper Rhine Graben, Lower Rhine Embayment"}
{"answers": {"text": ["Miocene", "By the time of the Miocene", "time of the Miocene"], "answer_start": [306, 287, 294]}, "prediction_text": "Miocene"}
{"answers": {"text": ["Danube", "Danube", "Danube"], "answer_start": [538, 538, 538]}, "prediction_text": "The Danube"}
{"answers": {"text": ["stream capture", "stream capture", "stream capture"], "answer_start": [8, 8, 8]}, "prediction_text": "Through stream capture"}
{"answers": {"text": ["Pliocene period", "Pliocene", "Pliocene period"], "answer_start": [75, 75, 75]}, "prediction_text": "Pliocene period"}
{"answers": {"text": ["Vosges Mountains", "Vosges Mountains", "Vosges Mountains,"], "answer_start": [135, 135, 135]}, "prediction_text": "Up to the Vosges Mountains"}
{"answers": {"text": ["Ice Ages", "geological period", "geological period of the Ice Ages"], "answer_start": [88, 63, 63]}, "prediction_text": "Ice Ages"}
{"answers": {"text": ["six", "six", "six"], "answer_start": [137, 137, 137]}, "prediction_text": "Six major ice ages occurred."}
{"answers": {"text": ["120 m", "120 m", "120 m"], "answer_start": [198, 198, 198]}, "prediction_text": "120 m (390 ft)"}
{"answers": {"text": ["northwest", "northwest", "northwest"], "answer_start": [326, 326, 326]}, "prediction_text": "Through the English Channel"}
{"answers": {"text": ["Brest", "Brest, France", "offshore of Brest,"], "answer_start": [746, 746, 734]}, "prediction_text": "Offshore of Brest, France"}
{"answers": {"text": ["74,000 (BP", "~74,000 (BP = Before Present)", "~74,000 (BP = Before Present)"], "answer_start": [27, 26, 26]}, "prediction_text": "Around 70,000 BP"}
{"answers": {"text": ["11,600 BP", "(~11,600 BP", "end of the Pleistocene (~11,600 BP)"], "answer_start": [92, 90, 67]}, "prediction_text": "Around 29,000 BP"}
{"answers": {"text": ["west", "west", "west"], "answer_start": [346, 346, 346]}, "prediction_text": "Westward"}
{"answers": {"text": ["120 m", "120 m", "120 m"], "answer_start": [593, 593, 593]}, "prediction_text": "Approximately 120 m (390 ft) lower."}
{"answers": {"text": ["English Channel", "English Channel", "English Channel"], "answer_start": [474, 474, 474]}, "prediction_text": "Sea level"}
{"answers": {"text": ["glacier", "glacier", "a glacier"], "answer_start": [126, 126, 124]}, "prediction_text": "A tundra"}
{"answers": {"text": ["tundra", "tundra", "A tundra"], "answer_start": [137, 137, 135]}, "prediction_text": "A tundra"}
{"answers": {"text": ["22,000\u201314,000 yr BP", "22,000\u201314,000 yr BP", "ca. 22,000\u201314,000 yr BP"], "answer_start": [295, 295, 291]}, "prediction_text": "22,000\u201314,000 yr BP"}
{"answers": {"text": ["ice-sheets", "ice-sheets", "ice-sheets"], "answer_start": [321, 321, 321]}, "prediction_text": "Ice-sheets covered Scandinavia."}
{"answers": {"text": ["loess", "loess", "loess"], "answer_start": [436, 436, 436]}, "prediction_text": "Loess dust"}
{"answers": {"text": ["22,000 years ago", "22,000 years ago", "22,000 years ago"], "answer_start": [49, 49, 49]}, "prediction_text": "22,000 years ago"}
{"answers": {"text": ["thaw", "thaw and fall-winter snow covers", "thaw"], "answer_start": [127, 127, 127]}, "prediction_text": "Thaw and fall-winter snow covers melted."}
{"answers": {"text": ["Rhine", "Rhine", "the Rhine"], "answer_start": [218, 218, 214]}, "prediction_text": "To Rhine and its downstream extension."}
{"answers": {"text": ["13,000 BP", "13,000 BP", "13,000 BP"], "answer_start": [323, 323, 323]}, "prediction_text": "About 13,000 BP"}
{"answers": {"text": ["9000 BP", "9000 BP", "9000 BP"], "answer_start": [337, 337, 337]}, "prediction_text": "About 13,000 BP"}
{"answers": {"text": ["7500 yr ago", "7500 yr ago", "7500 yr ago"], "answer_start": [6, 6, 6]}, "prediction_text": "7500 yr ago"}
{"answers": {"text": ["Rates of sea-level rise", "sea-level rise had dropped", "Rates of sea-level rise had dropped"], "answer_start": [93, 102, 93]}, "prediction_text": "Natural sedimentation by the Rhine compensated the transgression."}
{"answers": {"text": ["last 7000 years", "7000 years", "last 7000 years"], "answer_start": [263, 268, 263]}, "prediction_text": "About 7000 years"}
{"answers": {"text": ["tectonic subsidence", "tectonic subsidence", "ongoing tectonic subsidence"], "answer_start": [371, 371, 363]}, "prediction_text": "Tides and currents"}
{"answers": {"text": ["1\u20133 cm (0.39\u20131.18 in) per century", "1\u20133 cm (0.39\u20131.18 in) per century", "1\u20133 cm (0.39\u20131.18 in) per century"], "answer_start": [444, 444, 444]}, "prediction_text": "About 1\u20133 cm per century (1 metre or 39 inches in last 3000 years)"}
{"answers": {"text": ["11,700 years ago", "~11,700 years ago", "~11,700 years ago"], "answer_start": [31, 30, 30]}, "prediction_text": "11,700 years ago"}
{"answers": {"text": ["8,000 years ago", "~8,000 years ago", "~8,000 years ago"], "answer_start": [260, 259, 259]}, "prediction_text": "8,000 years ago"}
{"answers": {"text": ["Late-Glacial valley", "Late-Glacial valley", "Late-Glacial valley"], "answer_start": [73, 73, 73]}, "prediction_text": "Late-Glacial valley"}
{"answers": {"text": ["Netherlands", "Netherlands", "Netherlands"], "answer_start": [191, 191, 191]}, "prediction_text": "Netherlands"}
{"answers": {"text": ["3000 yr BP", "~3000 yr BP", "~3000 yr BP"], "answer_start": [7, 6, 6]}, "prediction_text": "Since ~3000 yr BP (before present)"}
{"answers": {"text": ["increased flooding and sedimentation", "Bronze Age agriculture", "increased flooding and sedimentation"], "answer_start": [281, 121, 281]}, "prediction_text": "Increased flooding and sedimentation."}
{"answers": {"text": ["sediment load", "sediment load", "sediment load"], "answer_start": [189, 189, 189]}, "prediction_text": "sediment load"}
{"answers": {"text": ["11\u201313th century", "11\u201313th century AD", "11\u201313th century AD"], "answer_start": [805, 805, 805]}, "prediction_text": "11\u201313th century AD"}
{"answers": {"text": ["80", "80", "80"], "answer_start": [552, 552, 552]}, "prediction_text": "Approximately 80 avulsions"}
{"answers": {"text": ["North Sea", "North Sea", "North Sea", "North Sea"], "answer_start": [65, 65, 65, 65]}, "prediction_text": "North Sea"}
{"answers": {"text": ["Meuse estuary", "Meuse estuary", "Meuse estuary", "Meuse estuary"], "answer_start": [95, 95, 95, 95]}, "prediction_text": "To the North Sea"}
{"answers": {"text": ["IJsselmeer", "IJsselmeer", "IJsselmeer", "IJsselmeer"], "answer_start": [184, 184, 184, 184]}, "prediction_text": "North Sea"}
{"answers": {"text": ["freshwater lake", "freshwater lake", "freshwater lake", "freshwater lake"], "answer_start": [260, 260, 260, 260]}, "prediction_text": "A freshwater lake"}
{"answers": {"text": ["three", "three", "three", "three"], "answer_start": [321, 321, 321, 321]}, "prediction_text": "Three branches"}
{"answers": {"text": ["1st century BC", "1st century BC", "1st century BC"], "answer_start": [83, 83, 83]}, "prediction_text": "1st century BC"}
{"answers": {"text": ["Germania", "Germania", "Germania"], "answer_start": [176, 176, 176]}, "prediction_text": "Germania"}
{"answers": {"text": ["6th century BC", "6th century BC", "6th century BC"], "answer_start": [269, 269, 269]}, "prediction_text": "6th century BC"}
{"answers": {"text": ["Maurus Servius Honoratus", "Maurus Servius Honoratus"], "answer_start": [584, 584]}, "prediction_text": "Herodotus"}
{"answers": {"text": ["AD 14", "AD 14", "AD 14"], "answer_start": [30, 30, 30]}, "prediction_text": "AD 14"}
{"answers": {"text": ["Danube", "upper Danube", "upper Danube"], "answer_start": [136, 130, 130]}, "prediction_text": "Upper Danube"}
{"answers": {"text": ["the empire fell", "until the empire fell", "until the empire fell"], "answer_start": [455, 449, 449]}, "prediction_text": "AD 70"}
{"answers": {"text": ["eastwards", "eastwards", "eastwards"], "answer_start": [867, 867, 867]}, "prediction_text": "Eastwards"}
{"answers": {"text": ["southern", "between the modern Baden and W\u00fcrttemberg"], "answer_start": [476, 664]}, "prediction_text": "The frontier between Baden and W\u00fcrttemberg"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [16, 16, 16]}, "prediction_text": "Eight legions"}
{"answers": {"text": ["army of Germania Inferior", "army of Germania Inferior", "army of Germania Inferior"], "answer_start": [254, 254, 254]}, "prediction_text": "Germania"}
{"answers": {"text": ["Ubiorum", "oppidum Ubiorum", "oppidum Ubiorum"], "answer_start": [383, 375, 375]}, "prediction_text": "Colonia Agrippina"}
{"answers": {"text": ["threat of war", "whether a state or threat of war existed", "whether a state or threat of war existed"], "answer_start": [152, 133, 133]}, "prediction_text": "State or threat of war"}
{"answers": {"text": ["town of the Ubii", "town of the Ubii", "town of the Ubii"], "answer_start": [393, 393, 393]}, "prediction_text": "Colonia Agrippina"}
{"answers": {"text": ["5th century", "Migration period", "5th century"], "answer_start": [66, 41, 66]}, "prediction_text": "5th century"}
{"answers": {"text": ["kingdoms", "kingdoms", "kingdoms"], "answer_start": [95, 95, 95]}, "prediction_text": "Francia and Burgundy"}
{"answers": {"text": ["dragons rock", "dragons rock", "dragons rock"], "answer_start": [371, 371, 371]}, "prediction_text": "Dragons rock"}
{"answers": {"text": ["Siegfried", "Siegfried", "Siegfried"], "answer_start": [307, 307, 307]}, "prediction_text": "Siegfried"}
{"answers": {"text": ["Hagen", "Hagen", "Hagen"], "answer_start": [540, 540, 540]}, "prediction_text": "Hagen"}
{"answers": {"text": ["6th century", "6th century"], "answer_start": [7, 7]}, "prediction_text": "9th century"}
{"answers": {"text": ["10th century", "10th century", "10th century"], "answer_start": [153, 153, 153]}, "prediction_text": "10th century"}
{"answers": {"text": ["Lower Lorraine", "Lower Lorraine", "Lower Lorraine"], "answer_start": [248, 248, 248]}, "prediction_text": "Lower Lorraine"}
{"answers": {"text": ["Archduke Sigismund", "Archduke Sigismund of Austria", "Archduke Sigismund of Austria"], "answer_start": [659, 659, 659]}, "prediction_text": "Archduke Sigismund of Austria"}
{"answers": {"text": ["1469", "1469", "1469"], "answer_start": [692, 692, 692]}, "prediction_text": "1469"}
{"answers": {"text": ["Peace of Westphalia", "Peace of Westphalia", "Peace of Westphalia"], "answer_start": [10, 10, 10]}, "prediction_text": "Peace of Westphalia"}
{"answers": {"text": ["Establishing \"natural borders\"", "Establishing \"natural borders\"", "Establishing \"natural borders\" on the Rhine"], "answer_start": [103, 103, 103]}, "prediction_text": "Establishing \"natural borders\""}
{"answers": {"text": ["Napoleon", "Napoleon", "Napoleon"], "answer_start": [461, 461, 461]}, "prediction_text": "Napoleon Bonaparte"}
{"answers": {"text": ["1806", "1806", "1806"], "answer_start": [500, 500, 500]}, "prediction_text": "1806"}
{"answers": {"text": ["1840", "1840", "1840"], "answer_start": [647, 647, 647]}, "prediction_text": "1840"}
{"answers": {"text": ["end of World War I", "end of World War I", "end of World War I"], "answer_start": [7, 7, 7]}, "prediction_text": "End of World War I"}
{"answers": {"text": ["1935", "1930", "1935"], "answer_start": [142, 434, 142]}, "prediction_text": "1930"}
{"answers": {"text": ["German army", "German army", "German army"], "answer_start": [206, 206, 206]}, "prediction_text": "German army"}
{"answers": {"text": ["Adolf Hitler's rise to power", "helping Adolf Hitler's rise to power", "Adolf Hitler's rise to power"], "answer_start": [370, 362, 370]}, "prediction_text": "Adolf Hitler's rise to power."}
{"answers": {"text": ["1936", "1936", "1936"], "answer_start": [477, 477, 477]}, "prediction_text": "1936"}
{"answers": {"text": ["Arnhem", "Arnhem", "Arnhem"], "answer_start": [165, 165, 165]}, "prediction_text": "Over the Waal distributary of the Rhine"}
{"answers": {"text": ["formidable natural obstacle", "formidable natural obstacle", "natural obstacle"], "answer_start": [66, 66, 77]}, "prediction_text": "A formidable natural obstacle"}
{"answers": {"text": ["September 1944", "September 1944", "September 1944"], "answer_start": [321, 321, 321]}, "prediction_text": "September 1944"}
{"answers": {"text": ["Ludendorff Bridge", "Ludendorff Bridge", "Ludendorff Bridge"], "answer_start": [483, 483, 483]}, "prediction_text": "The Ludendorff Bridge"}
{"answers": {"text": ["Seven Days to the River Rhine", "plan for an invasion of Western Europe", "plan for an invasion of Western Europe during the Cold War"], "answer_start": [731, 783, 783]}, "prediction_text": "Invasion of Western Europe"}
{"answers": {"text": ["1,230 kilometres (764 miles)", "1,230 kilometres", "1,230 kilometres"], "answer_start": [58, 58, 58]}, "prediction_text": "1,230 kilometres (820 miles)"}
{"answers": {"text": ["Knaurs Lexikon", "Knaurs Lexikon", "Knaurs Lexikon"], "answer_start": [120, 120, 120]}, "prediction_text": "German encyclopedia Knaurs Lexikon"}
{"answers": {"text": ["typographical error", "typographical error", "a typographical error"], "answer_start": [199, 199, 197]}, "prediction_text": "Typographical error"}
{"answers": {"text": ["1,320 kilometres (820 miles)", "1,320 kilometres", "1,320 kilometres"], "answer_start": [156, 156, 156]}, "prediction_text": "1,320 kilometres (820 miles)"}
{"answers": {"text": ["2010", "2010", "2010"], "answer_start": [422, 422, 422]}, "prediction_text": "2010"}
{"answers": {"text": ["Following a referendum in 1997", "1998", "1998"], "answer_start": [0, 143, 143]}, "prediction_text": "1997"}
{"answers": {"text": ["Scotland Act 1998", "Scotland Act 1998", "Scotland Act"], "answer_start": [130, 130, 130]}, "prediction_text": "Scotland Act 1998"}
{"answers": {"text": ["in which it can make laws", "the areas in which it can make laws", "powers that are \"reserved\" to the Parliament of the United Kingdom"], "answer_start": [278, 268, 331]}, "prediction_text": "All areas"}
{"answers": {"text": ["Parliament of the United Kingdom", "Parliament of the United Kingdom", "The British Parliament"], "answer_start": [365, 365, 512]}, "prediction_text": "Parliament of the United Kingdom"}
{"answers": {"text": ["Westminster", "Westminster", "Westminster"], "answer_start": [499, 499, 499]}, "prediction_text": "Westminster"}
{"answers": {"text": ["lack of a Parliament of Scotland", "the lack of a Parliament of Scotland", "the lack of a Parliament of Scotland"], "answer_start": [189, 185, 185]}, "prediction_text": "Lack of a Parliament of Scotland"}
{"answers": {"text": ["three hundred", "three hundred years", "three hundred years"], "answer_start": [13, 13, 13]}, "prediction_text": "Three hundred years"}
{"answers": {"text": ["First World War.", "First World War", "the outbreak of the First World War"], "answer_start": [390, 390, 370]}, "prediction_text": "Lack of a Parliament of Scotland"}
{"answers": {"text": ["the late 1960s", "late 1960s", "late 1960s"], "answer_start": [454, 458, 458]}, "prediction_text": "Late 1960s"}
{"answers": {"text": ["directly elected Scottish Assembly", "directly elected Scottish Assembly", "a directly elected Scottish Assembly"], "answer_start": [923, 923, 921]}, "prediction_text": "A directly elected Scottish Assembly"}
{"answers": {"text": ["North", "North Sea", "the North Sea"], "answer_start": [46, 46, 42]}, "prediction_text": "North Sea"}
{"answers": {"text": ["\"It's Scotland's oil\"", "It's Scotland's oil", "\"It's Scotland's oil\""], "answer_start": [74, 75, 74]}, "prediction_text": "Scottish National Party (SNP)"}
{"answers": {"text": ["1974", "1974", "1974"], "answer_start": [449, 449, 449]}, "prediction_text": "1978"}
{"answers": {"text": ["not benefitting Scotland as much as they should", "not benefitting Scotland as much as they should", "the revenues from the oil were not benefitting Scotland as much as they should"], "answer_start": [269, 269, 238]}, "prediction_text": "Not benefitting Scotland as much as they should."}
{"answers": {"text": ["1978", "1978", "1978"], "answer_start": [481, 481, 481]}, "prediction_text": "1978"}
{"answers": {"text": ["Edinburgh", "Edinburgh", "Edinburgh"], "answer_start": [81, 81, 81]}, "prediction_text": "Edinburgh"}
{"answers": {"text": ["majority", "40%", "at least 40%"], "answer_start": [109, 227, 218]}, "prediction_text": "40% of the total electorate"}
{"answers": {"text": ["51.6%", "51.6%", "51.6%"], "answer_start": [368, 368, 368]}, "prediction_text": "32.9%"}
{"answers": {"text": ["failed", "failed", "failed"], "answer_start": [338, 338, 338]}, "prediction_text": "Failed."}
{"answers": {"text": ["32.9%", "32.9%", "32.9%"], "answer_start": [517, 517, 517]}, "prediction_text": "32.9%"}
{"answers": {"text": ["a Scottish Parliament", "Scottish Parliament", "Scottish Parliament grew"], "answer_start": [43, 45, 45]}, "prediction_text": "Scottish Parliament demand grew."}
{"answers": {"text": ["the Conservative Party", "Conservative Party", "the Conservative Party"], "answer_start": [142, 146, 142]}, "prediction_text": "Conservative Party"}
{"answers": {"text": ["1989", "1989", "1989"], "answer_start": [364, 364, 364]}, "prediction_text": "1989"}
{"answers": {"text": ["blueprint", "blueprint", "the Convention"], "answer_start": [536, 536, 570]}, "prediction_text": "Publishing blueprint"}
{"answers": {"text": ["Scottish Parliament Building", "Scottish Parliament Building", "Edinburgh"], "answer_start": [82, 82, 136]}, "prediction_text": "A new Scottish Parliament Building"}
{"answers": {"text": ["Enric Miralles", "Enric Miralles", "Enric Miralles"], "answer_start": [214, 214, 214]}, "prediction_text": "Enric Miralles"}
{"answers": {"text": ["Spanish", "Spanish", "Spanish"], "answer_start": [196, 196, 196]}, "prediction_text": "Spanish"}
{"answers": {"text": ["leaf-shaped", "leaf-shaped", "leaf-shaped buildings"], "answer_start": [389, 389, 389]}, "prediction_text": "Leaf-shaped buildings"}
{"answers": {"text": ["Queen Elizabeth II", "Queen Elizabeth II", "Queen Elizabeth II"], "answer_start": [743, 743, 743]}, "prediction_text": "Queen Elizabeth II"}
{"answers": {"text": ["meeting of the Church's General Assembly", "meeting of the Church's General Assembly", "the meeting of the Church's General Assembly"], "answer_start": [409, 409, 405]}, "prediction_text": "Church's General Assembly"}
{"answers": {"text": ["General Assembly Hall of the Church of Scotland", "General Assembly Hall of the Church of Scotland", "the General Assembly Hall of the Church of Scotland"], "answer_start": [105, 105, 101]}, "prediction_text": "Royal Mile in Edinburgh"}
{"answers": {"text": ["courtyard", "courtyard adjoining the Assembly Hall", "the courtyard"], "answer_start": [249, 249, 245]}, "prediction_text": "In the courtyard adjoining the Assembly Hall."}
{"answers": {"text": ["University of Aberdeen", "University of Aberdeen", "the University of Aberdeen"], "answer_start": [588, 588, 584]}, "prediction_text": "University of Aberdeen"}
{"answers": {"text": ["former Strathclyde Regional Council debating chamber in Glasgow", "former Strathclyde Regional Council debating chamber", "the former Strathclyde Regional Council debating chamber"], "answer_start": [512, 512, 508]}, "prediction_text": "Glasgow"}
{"answers": {"text": ["City of Edinburgh Council", "City of Edinburgh Council", "the City of Edinburgh Council"], "answer_start": [93, 93, 89]}, "prediction_text": "City of Edinburgh Council"}
{"answers": {"text": ["Lothian Regional Council", "Lothian Regional Council", "Lothian Regional Council on George IV Bridge"], "answer_start": [158, 158, 158]}, "prediction_text": "Lothian Regional Council on George IV Bridge"}
{"answers": {"text": ["demolished", "demolished", "demolished"], "answer_start": [292, 292, 292]}, "prediction_text": "The former administrative building was used for the MSP's offices."}
{"answers": {"text": ["Parliament Square, High Street and George IV Bridge in Edinburgh", "Parliament Square, High Street and George IV Bridge", "Parliament Square"], "answer_start": [350, 350, 350]}, "prediction_text": "Parliament Square, High Street, George IV Bridge"}
{"answers": {"text": ["main", "main", "the main hall"], "answer_start": [558, 558, 554]}, "prediction_text": "Main hall"}
{"answers": {"text": ["one MSP", "MSP", "MSP"], "answer_start": [114, 118, 118]}, "prediction_text": "MSPs (MSPs)"}
{"answers": {"text": ["Tricia Marwick", "Tricia Marwick", "Tricia Marwick"], "answer_start": [194, 194, 194]}, "prediction_text": "Tricia Marwick"}
{"answers": {"text": ["secret", "secret", "a secret ballot"], "answer_start": [338, 338, 336]}, "prediction_text": "Secret ballot"}
{"answers": {"text": ["129", "129", "129"], "answer_start": [359, 359, 359]}, "prediction_text": "129 MSPs"}
{"answers": {"text": ["A vote clerk", "vote clerk", "vote clerk"], "answer_start": [873, 875, 875]}, "prediction_text": "Parliamentary clerks"}
{"answers": {"text": ["Presiding Officer", "Presiding Officer", "the Presiding Officer"], "answer_start": [62, 62, 58]}, "prediction_text": "Presiding Officer"}
{"answers": {"text": ["the Parliamentary Bureau", "Presiding Officer", "the Parliamentary Bureau"], "answer_start": [226, 345, 226]}, "prediction_text": "Presiding Officer"}
{"answers": {"text": ["five", "five or more", "five or more seats"], "answer_start": [509, 509, 509]}, "prediction_text": "Five or more seats"}
{"answers": {"text": ["The Presiding Officer", "Presiding Officer", "The Presiding Officer"], "answer_start": [778, 782, 778]}, "prediction_text": "The Presiding Officer"}
{"answers": {"text": ["hemicycle", "hemicycle", "a hemicycle"], "answer_start": [74, 74, 72]}, "prediction_text": "In a hemicycle"}
{"answers": {"text": ["encourage consensus amongst elected members", "encourage consensus amongst elected members", "reflects the desire to encourage consensus amongst elected members"], "answer_start": [114, 114, 91]}, "prediction_text": "To encourage consensus among elected members."}
{"answers": {"text": ["131", "131", "131"], "answer_start": [169, 169, 217]}, "prediction_text": "131 seats"}
{"answers": {"text": ["2", "2", "2"], "answer_start": [282, 282, 282]}, "prediction_text": "2 members"}
{"answers": {"text": ["vote", "vote", "vote"], "answer_start": [604, 604, 604]}, "prediction_text": "Vote in the plenary meetings."}
{"answers": {"text": ["Scottish rivers", "Scottish rivers", "Scottish rivers"], "answer_start": [127, 127, 127]}, "prediction_text": "Scottish rivers"}
{"answers": {"text": ["silver", "silver", "silver and inlaid with gold"], "answer_start": [87, 87, 87]}, "prediction_text": "Silver and inlaid with gold"}
{"answers": {"text": ["the Queen", "the Queen", "the Queen"], "answer_start": [533, 533, 533]}, "prediction_text": "Queen Elizabeth II"}
{"answers": {"text": ["Wisdom, Compassion, Justice and Integrity", "Wisdom, Compassion, Justice and Integrity", "Wisdom, Compassion, Justice and Integrity"], "answer_start": [173, 173, 173]}, "prediction_text": "Wisdom, Compassion, Justice, Integrity."}
{"answers": {"text": ["a glass case suspended from the lid", "glass case", "a glass case"], "answer_start": [608, 610, 608]}, "prediction_text": "Glass case"}
{"answers": {"text": ["April", "April", "April"], "answer_start": [161, 161, 161]}, "prediction_text": "Late September"}
{"answers": {"text": ["debating chamber", "debating chamber", "Wednesday afternoons"], "answer_start": [204, 204, 243]}, "prediction_text": "Wednesdays, Thursdays, and Fridays."}
{"answers": {"text": ["the public", "the public.", "public"], "answer_start": [372, 372, 376]}, "prediction_text": "The public"}
{"answers": {"text": ["free", "free", "free"], "answer_start": [393, 393, 393]}, "prediction_text": "Free entry"}
{"answers": {"text": ["the Official Report", "the Official Report", "the Official Report"], "answer_start": [649, 649, 649]}, "prediction_text": "Official Report"}
{"answers": {"text": ["Wednesdays", "Wednesdays", "Wednesdays"], "answer_start": [30, 30, 30]}, "prediction_text": "Wednesdays"}
{"answers": {"text": ["up to four minutes", "up to four minutes", "up to four minutes"], "answer_start": [114, 114, 114]}, "prediction_text": "Up to four minutes"}
{"answers": {"text": ["Presiding Officer", "Presiding Officer", "the Presiding Officer"], "answer_start": [506, 619, 502]}, "prediction_text": "The Presiding Officer"}
{"answers": {"text": ["religious beliefs", "religious beliefs", "the balance of religious beliefs"], "answer_start": [383, 383, 368]}, "prediction_text": "Religious beliefs according to the Scottish census."}
{"answers": {"text": ["nominate speakers", "nominate speakers", "nominate speakers"], "answer_start": [640, 640, 640]}, "prediction_text": "Nominate speakers"}
{"answers": {"text": ["The Presiding Officer", "Presiding Officer", "The Presiding Officer"], "answer_start": [0, 4, 0]}, "prediction_text": "The Presiding Officer (or Deputy Presiding Officer) decides who gets to speak in chamber debates."}
{"answers": {"text": ["amount of time for which they are allowed to speak", "amount of time for which they are allowed to speak", "the amount of time for which they are allowed to speak"], "answer_start": [98, 98, 94]}, "prediction_text": "Who speaks in chamber debates"}
{"answers": {"text": ["different viewpoints", "different viewpoints and political parties", "a balance between different viewpoints and political parties"], "answer_start": [217, 217, 199]}, "prediction_text": "A balance between different viewpoints and political parties."}
{"answers": {"text": ["ministers or party leaders", "ministers or party leaders", "ministers or party leaders"], "answer_start": [304, 304, 304]}, "prediction_text": "Ministers or party leaders"}
{"answers": {"text": ["Gaelic", "Gaelic", "Scots, Gaelic, or any other language with the agreement of the Presiding Officer"], "answer_start": [954, 954, 819]}, "prediction_text": "Gaelic"}
{"answers": {"text": ["5 pm", "5 pm", "5 pm"], "answer_start": [30, 30, 30]}, "prediction_text": "5 pm"}
{"answers": {"text": ["\"Decision Time\"", "Decision Time", "\"Decision Time\""], "answer_start": [118, 119, 118]}, "prediction_text": "Decision Time"}
{"answers": {"text": ["vote", "vote", "vote"], "answer_start": [292, 292, 292]}, "prediction_text": "Vote orally."}
{"answers": {"text": ["electronic consoles on their desks", "electronic consoles", "electronic consoles on their desks"], "answer_start": [649, 649, 649]}, "prediction_text": "By means of electronic consoles."}
{"answers": {"text": ["seconds", "seconds", "seconds"], "answer_start": [870, 870, 870]}, "prediction_text": "seconds"}
{"answers": {"text": ["votes", "outcome of most votes", "outcome"], "answer_start": [20, 4, 4]}, "prediction_text": "Political parties instruct members which way to vote."}
{"answers": {"text": ["political parties", "political parties", "political parties"], "answer_start": [60, 60, 60]}, "prediction_text": "Political parties"}
{"answers": {"text": ["whips", "whips", "whips"], "answer_start": [159, 159, 159]}, "prediction_text": "MSPs"}
{"answers": {"text": ["moral", "moral", "moral issues"], "answer_start": [865, 865, 865]}, "prediction_text": "Moral issues"}
{"answers": {"text": ["deselected as official party candidates during future elections", "deselected as official party candidates", "deselected as official party candidates during future elections"], "answer_start": [401, 401, 401]}, "prediction_text": "Errant members can be deselected."}
{"answers": {"text": ["Immediately after Decision Time", "Immediately after Decision Time", "Immediately after Decision Time"], "answer_start": [0, 0, 0]}, "prediction_text": "After Decision Time"}
{"answers": {"text": ["not a Scottish minister", "may be of interest to a particular area such as a member's own constituency", "issues which may be of interest to a particular area such as a member's own constituency"], "answer_start": [155, 213, 200]}, "prediction_text": "To discuss issues and issues of interest."}
{"answers": {"text": ["45 minutes", "45 minutes", "45 minutes"], "answer_start": [76, 76, 76]}, "prediction_text": "45 minutes"}
{"answers": {"text": ["other members", "other members", "other members"], "answer_start": [426, 426, 426]}, "prediction_text": "Other members"}
{"answers": {"text": ["winds up", "winds up", "\"winds up\" the debate"], "answer_start": [548, 548, 547]}, "prediction_text": "Speaks after all other participants."}
{"answers": {"text": ["committee", "committee", "in committee"], "answer_start": [55, 55, 52]}, "prediction_text": "In committee"}
{"answers": {"text": ["stronger", "stronger", "stronger in the Scottish Parliament than in other parliamentary systems"], "answer_start": [92, 92, 92]}, "prediction_text": "Stronger role in Scottish Parliament"}
{"answers": {"text": ["no revising chamber", "no revising chamber", "take evidence from witnesses, conduct inquiries and scrutinise legislation"], "answer_start": [313, 313, 400]}, "prediction_text": "Revising chamber"}
{"answers": {"text": ["principal role", "principal role", "principal role"], "answer_start": [338, 338, 338]}, "prediction_text": "Important roles"}
{"answers": {"text": ["other locations throughout Scotland", "other locations throughout Scotland", "other locations throughout Scotland"], "answer_start": [605, 605, 605]}, "prediction_text": "Other locations"}
{"answers": {"text": ["a small number of MSPs", "a small number of MSPs", "a small number of MSPs"], "answer_start": [20, 20, 20]}, "prediction_text": "MSPs"}
{"answers": {"text": ["balance of parties", "balance of parties across Parliament", "the balance of parties across Parliament"], "answer_start": [75, 75, 71]}, "prediction_text": "Parties across Parliament"}
{"answers": {"text": ["functions", "their functions", "their functions"], "answer_start": [155, 149, 149]}, "prediction_text": "Committees with functions set out in different ways."}
{"answers": {"text": ["Mandatory", "Mandatory", "Mandatory Committees"], "answer_start": [192, 192, 192]}, "prediction_text": "Mandatory Committees"}
{"answers": {"text": ["fourth", "fourth", "the fourth Session"], "answer_start": [379, 379, 375]}, "prediction_text": "Fourth Session"}
{"answers": {"text": ["beginning of each parliamentary session", "beginning of each parliamentary session", "at the beginning of each parliamentary session"], "answer_start": [42, 42, 35]}, "prediction_text": "Beginning of each parliamentary session"}
{"answers": {"text": ["one", "one (or more", "one (or more) of the departments (or ministries) of the Scottish Government"], "answer_start": [215, 215, 215]}, "prediction_text": "One (or more)"}
{"answers": {"text": ["current Subject Committees", "Subject Committees", "Subject Committees"], "answer_start": [296, 304, 304]}, "prediction_text": "Subject Committees in the fourth Session"}
{"answers": {"text": ["Session", "Session", "Session"], "answer_start": [337, 337, 337]}, "prediction_text": "Subject Committees"}
{"answers": {"text": ["type of committee", "committee", "committee"], "answer_start": [10, 18, 18]}, "prediction_text": "A further type of committee is normally set up."}
{"answers": {"text": ["large-scale development projects", "large-scale development projects", "large-scale development projects"], "answer_start": [248, 248, 248]}, "prediction_text": "Large-scale development projects"}
{"answers": {"text": ["Scottish Government.", "Committees", "Private Bill Committees"], "answer_start": [194, 368, 355]}, "prediction_text": "The Scottish Parliament or Scottish Government"}
{"answers": {"text": ["Private Bill", "Private Bill", "Private Bill Committees"], "answer_start": [355, 355, 355]}, "prediction_text": "Private Bill Committees"}
{"answers": {"text": ["Scotland Act 1998", "The Scotland Act 1998", "The Scotland Act 1998"], "answer_start": [4, 0, 0]}, "prediction_text": "Scotland Act 1998"}
{"answers": {"text": ["Queen Elizabeth II", "Queen Elizabeth II", "Queen Elizabeth II"], "answer_start": [106, 106, 106]}, "prediction_text": "Queen Elizabeth II"}
{"answers": {"text": ["devolved competencies", "devolved competencies", "the devolved competencies"], "answer_start": [279, 279, 275]}, "prediction_text": "The Scottish Parliament continues to constitute the supreme legislature of Scotland."}
{"answers": {"text": ["Parliament of the United Kingdom at Westminster", "Parliament of the United Kingdom at Westminster", "the Parliament of the United Kingdom at Westminster"], "answer_start": [353, 353, 349]}, "prediction_text": "Scottish Parliament"}
{"answers": {"text": ["Scottish Parliament", "Parliament", "the Parliament"], "answer_start": [901, 1016, 1012]}, "prediction_text": "The Scottish Parliament"}
{"answers": {"text": ["Schedule 5", "Schedule 5", "Schedule 5"], "answer_start": [82, 82, 82]}, "prediction_text": "In the specific devolved matters section."}
{"answers": {"text": ["Scottish Parliament", "Scottish Parliament", "the Scottish Parliament"], "answer_start": [215, 215, 211]}, "prediction_text": "Scottish Parliament"}
{"answers": {"text": ["automatically devolved", "not specifically reserved", "All matters that are not specifically reserved are automatically devolved to the Scottish Parliament"], "answer_start": [185, 155, 134]}, "prediction_text": "For purposes of taxation."}
{"answers": {"text": ["up to 3 pence in the pound", "up to 3 pence in the pound", "up to 3 pence in the pound"], "answer_start": [619, 619, 619]}, "prediction_text": "Up to 3 pence"}
{"answers": {"text": ["2012 Act", "2012 Act", "The 2012 Act"], "answer_start": [651, 651, 647]}, "prediction_text": "2012 Act"}
{"answers": {"text": ["Reserved", "Reserved", "Reserved matters"], "answer_start": [0, 0, 0]}, "prediction_text": "Reserved matters"}
{"answers": {"text": ["Scottish Parliament", "The Scottish Parliament", "The Scottish Parliament"], "answer_start": [106, 102, 102]}, "prediction_text": "Reserved issues"}
{"answers": {"text": ["Westminster", "Westminster", "Westminster"], "answer_start": [205, 205, 205]}, "prediction_text": "Westminster (and where Ministerial functions usually lie with UK Government ministers)"}
{"answers": {"text": ["UK Government ministers", "UK Government ministers", "Westminster"], "answer_start": [267, 267, 205]}, "prediction_text": "UK Government"}
{"answers": {"text": ["Bills", "Bills", "Bills"], "answer_start": [0, 0, 0]}, "prediction_text": "Bills can be presented in various ways."}
{"answers": {"text": ["the Scottish Government", "Scottish Government", "the Scottish Government"], "answer_start": [59, 63, 59]}, "prediction_text": "Scottish Government"}
{"answers": {"text": ["a private member", "a private member", "private member"], "answer_start": [294, 294, 296]}, "prediction_text": "Private member"}
{"answers": {"text": ["an outside proposer", "an outside proposer", "an outside proposer"], "answer_start": [364, 364, 364]}, "prediction_text": "An outside proposer"}
{"answers": {"text": ["in a number of stages", "a number of stages", "in a number of stages"], "answer_start": [500, 503, 500]}, "prediction_text": "Bills pass through Parliament in a number of stages."}
{"answers": {"text": ["introductory", "introductory", "introductory stage of the bill"], "answer_start": [25, 25, 25]}, "prediction_text": "Introductory stage"}
{"answers": {"text": ["accompanying documents", "accompanying documents", "accompanying documents \u2013 Explanatory Notes"], "answer_start": [167, 167, 167]}, "prediction_text": "Explanatory Notes, Policy Memorandum, Financial Memorandum."}
{"answers": {"text": ["whether the bill is within the legislative competence of the Parliament", "whether the bill is within the legislative competence of the Parliament", "whether the bill is within the legislative competence of the Parliament"], "answer_start": [458, 458, 458]}, "prediction_text": "The bill is within the legislative competence of the Parliament."}
{"answers": {"text": ["in the relevant committee or committees", "committee", "the whole Parliament"], "answer_start": [571, 587, 636]}, "prediction_text": "In relevant committees or committees"}
{"answers": {"text": ["Stage 2", "Stage 2", "Stage 2"], "answer_start": [829, 829, 829]}, "prediction_text": "Stage 2"}
{"answers": {"text": ["Stage 3", "Stage 3", "Stage 3"], "answer_start": [0, 0, 0]}, "prediction_text": "Stage 3"}
{"answers": {"text": ["two", "two", "two"], "answer_start": [116, 116, 116]}, "prediction_text": "Two parts"}
{"answers": {"text": ["final", "final", "final vote"], "answer_start": [194, 194, 194]}, "prediction_text": "Final vote on bill"}
{"answers": {"text": ["wrecking", "wrecking", "\"wrecking amendments\""], "answer_start": [248, 248, 247]}, "prediction_text": "wrecking amendments"}
{"answers": {"text": ["Decision Time", "Decision Time", "After a general debate on the final form of the bill"], "answer_start": [491, 491, 410]}, "prediction_text": "Decision Time"}
{"answers": {"text": ["the Monarch", "Monarch", "the Monarch"], "answer_start": [82, 86, 82]}, "prediction_text": "Monarch"}
{"answers": {"text": ["royal assent", "royal assent", "royal assent"], "answer_start": [98, 98, 98]}, "prediction_text": "Royal assent is given."}
{"answers": {"text": ["a 4-week period", "a 4-week period", "4-week period"], "answer_start": [191, 191, 193]}, "prediction_text": "4 weeks"}
{"answers": {"text": ["Supreme Court of the United Kingdom", "Supreme Court of the United Kingdom", "the Supreme Court"], "answer_start": [320, 320, 316]}, "prediction_text": "Supreme Court of the United Kingdom"}
{"answers": {"text": ["[Date]", "[Date]", "\"The Bill for this Act of the Scottish Parliament was passed by the Parliament on [Date] and received royal assent on [Date]\"."], "answer_start": [633, 633, 551]}, "prediction_text": "\"The Bill for this Act of the Scottish Parliament was passed by the Parliament on [Date] and received royal assent on [Date]\"."}
{"answers": {"text": ["hold the majority of seats", "hold the majority of seats", "The party, or parties, that hold the majority of seats in the Parliament"], "answer_start": [28, 28, 0]}, "prediction_text": "The Scottish Government"}
{"answers": {"text": ["Any member", "Any member", "Any member"], "answer_start": [288, 288, 288]}, "prediction_text": "All members of Parliament"}
{"answers": {"text": ["First Minister", "First Minister", "a First Minister"], "answer_start": [173, 173, 171]}, "prediction_text": "First Minister"}
{"answers": {"text": ["elected MSPs", "the elected MSPs", "amongst the elected MSPs"], "answer_start": [898, 894, 886]}, "prediction_text": "MSPs"}
{"answers": {"text": ["the Sovereign", "the Sovereign", "the Sovereign"], "answer_start": [1151, 1151, 1151]}, "prediction_text": "Sovereign"}
{"answers": {"text": ["Thursday", "Thursday", "Thursday"], "answer_start": [106, 106, 106]}, "prediction_text": "First Thursday in May"}
{"answers": {"text": ["May", "May", "May"], "answer_start": [118, 971, 118]}, "prediction_text": "May (first Thursday in May)"}
{"answers": {"text": ["the Monarch", "Monarch", "the Monarch"], "answer_start": [237, 241, 237]}, "prediction_text": "The Monarch"}
{"answers": {"text": ["supplant it.", "supplant it", "reverts to the first Thursday in May, a multiple of four years after 1999"], "answer_start": [893, 893, 938]}, "prediction_text": "Replaces it."}
{"answers": {"text": ["28", "28", "28 days"], "answer_start": [499, 499, 499]}, "prediction_text": "28 days"}
{"answers": {"text": ["Several procedures", "Several procedures", "Several procedures"], "answer_start": [0, 0, 0]}, "prediction_text": "Several procedures"}
{"answers": {"text": ["MSPs", "leaders of the opposition parties and other MSPs", "MSPs"], "answer_start": [173, 437, 173]}, "prediction_text": "MSPs"}
{"answers": {"text": ["legislative programme for the forthcoming year", "a statement", "a statement to the chamber setting out the Government's legislative programme for the forthcoming year"], "answer_start": [345, 289, 289]}, "prediction_text": "Statement to Parliament"}
{"answers": {"text": ["issues related to the substance of the statement", "issues", "issues related to the substance of the statement"], "answer_start": [517, 517, 517]}, "prediction_text": "Issues related to the substance of the statement."}
{"answers": {"text": ["Parliamentary time", "Parliamentary time", "Parliamentary time"], "answer_start": [0, 0, 0]}, "prediction_text": "Parliamentary time"}
{"answers": {"text": ["Thursday", "Thursday", "Thursday"], "answer_start": [126, 126, 126]}, "prediction_text": "Thursday"}
{"answers": {"text": ["any member of the Scottish Government", "any member of the Scottish Government", "ministers in departments that are selected for questioning that sitting day"], "answer_start": [204, 204, 342]}, "prediction_text": "Any member of the Scottish Government"}
{"answers": {"text": ["issues under their jurisdiction", "issues under their jurisdiction", "the First Minister"], "answer_start": [668, 668, 637]}, "prediction_text": "Health and justice, education, transport."}
{"answers": {"text": ["four", "four", "four"], "answer_start": [938, 938, 938]}, "prediction_text": "Four general questions"}
{"answers": {"text": ["73", "73", "73"], "answer_start": [17, 17, 17]}, "prediction_text": "129"}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [371, 371, 371]}, "prediction_text": "2005"}
{"answers": {"text": ["one", "one", "one"], "answer_start": [132, 132, 132]}, "prediction_text": "73 members"}
{"answers": {"text": ["dispersed population and distance", "dispersed population and distance", "their dispersed population and distance from the Scottish Parliament in Edinburgh"], "answer_start": [1004, 1004, 998]}, "prediction_text": "Due to their dispersed population and distance from the Scottish Parliament in Edinburgh."}
{"answers": {"text": ["55,000", "55,000", "55,000"], "answer_start": [571, 571, 571]}, "prediction_text": "55,000 electors"}
{"answers": {"text": ["proportionally to the number of votes received", "proportionally to the number of votes received", "proportionally to the number of votes received in the second vote of the ballot using the d'Hondt method"], "answer_start": [69, 69, 69]}, "prediction_text": "By proportionally to the number of votes received in the second vote."}
{"answers": {"text": ["the d'Hondt method", "d'Hondt", "the d'Hondt method"], "answer_start": [155, 159, 155]}, "prediction_text": "D'Hondt method"}
{"answers": {"text": ["quotient", "quotient", "quotient"], "answer_start": [421, 421, 421]}, "prediction_text": "quotient"}
{"answers": {"text": ["constituency seats", "constituency", "second"], "answer_start": [478, 478, 515]}, "prediction_text": "Allocated constituency seats"}
{"answers": {"text": ["iteratively", "iteratively", "iteratively"], "answer_start": [545, 545, 545]}, "prediction_text": "Repeatedly until all available seats have been determined."}
{"answers": {"text": ["a number of qualifications", "a number of qualifications", "qualifications"], "answer_start": [28, 28, 83]}, "prediction_text": "A number of qualifications"}
{"answers": {"text": ["1981", "1981", "1981"], "answer_start": [199, 199, 199]}, "prediction_text": "1981"}
{"answers": {"text": ["over the age of 18", "over the age of 18", "18"], "answer_start": [235, 235, 251]}, "prediction_text": "Over 18"}
{"answers": {"text": ["police and the armed forces", "police and the armed forces", "the police and the armed forces"], "answer_start": [483, 483, 479]}, "prediction_text": "Police and armed forces"}
{"answers": {"text": ["Mental Health (Care and Treatment) (Scotland) Act 2003", "Mental Health (Care and Treatment) (Scotland) Act 2003", "Mental Health (Care and Treatment) (Scotland) Act 2003"], "answer_start": [781, 781, 781]}, "prediction_text": "Mental Health (Care and Treatment) Act 2003"}
{"answers": {"text": ["a party has commanded a parliamentary majority", "a parliamentary majority", "a party has commanded a parliamentary majority"], "answer_start": [109, 131, 109]}, "prediction_text": "A majority SNP government"}
{"answers": {"text": ["Labour", "Labour", "Labour"], "answer_start": [184, 184, 184]}, "prediction_text": "Labour"}
{"answers": {"text": ["151 votes", "151 votes", "151 votes"], "answer_start": [309, 309, 309]}, "prediction_text": "151 votes"}
{"answers": {"text": ["eight", "eight", "eight"], "answer_start": [343, 343, 343]}, "prediction_text": "One seat"}
{"answers": {"text": ["Scottish independence", "Scottish independence", "Scottish independence"], "answer_start": [535, 535, 535]}, "prediction_text": "Scottish independence"}
{"answers": {"text": ["the Conservatives", "Conservatives", "Conservatives"], "answer_start": [4, 8, 8]}, "prediction_text": "The Conservatives"}
{"answers": {"text": ["Edinburgh Pentlands", "Edinburgh Pentlands", "former party leader"], "answer_start": [63, 63, 96]}, "prediction_text": "Edinburgh Pentlands"}
{"answers": {"text": ["five seats", "five seats", "five seats"], "answer_start": [241, 241, 241]}, "prediction_text": "Five seats"}
{"answers": {"text": ["Annabel Goldie", "Annabel Goldie", "Annabel Goldie"], "answer_start": [265, 265, 265]}, "prediction_text": "Annabel Goldie"}
{"answers": {"text": ["Cameron", "Cameron", "Cameron"], "answer_start": [399, 399, 399]}, "prediction_text": "Cameron"}
{"answers": {"text": ["able to vote on domestic legislation that applies only to England, Wales and Northern Ireland", "able to vote on domestic legislation that applies only to England, Wales and Northern Ireland", "procedural consequence"], "answer_start": [133, 133, 2]}, "prediction_text": "English, Scottish, Welsh, Northern Irish Westminster MPs cannot vote on domestic legislation."}
{"answers": {"text": ["domestic legislation of the Scottish Parliament", "domestic legislation of the Scottish Parliament.", "domestic legislation of the Scottish Parliament"], "answer_start": [322, 322, 322]}, "prediction_text": "Domestic legislation of the Scottish Parliament"}
{"answers": {"text": ["West Lothian question", "West Lothian question", "the West Lothian question"], "answer_start": [403, 403, 399]}, "prediction_text": "West Lothian question"}
{"answers": {"text": ["the Conservative", "Conservative", "Conservative"], "answer_start": [461, 465, 465]}, "prediction_text": "Conservative Party"}
{"answers": {"text": ["England", "England", "England"], "answer_start": [650, 650, 650]}, "prediction_text": "Scotland"}
{"answers": {"text": ["Islamism", "Islamism", "Islamism"], "answer_start": [0, 0, 0]}, "prediction_text": "Islamic revival movement islamism."}
{"answers": {"text": ["all spheres of life.", "all spheres of life", "all spheres"], "answer_start": [211, 211, 211]}, "prediction_text": "All spheres of life"}
{"answers": {"text": ["reordering", "reordering of government and society in accordance with the Shari'a", "reordering"], "answer_start": [253, 253, 253]}, "prediction_text": "Reordering government and society in accordance with the Shari'a."}
{"answers": {"text": ["poles", "two poles", "poles"], "answer_start": [403, 399, 403]}, "prediction_text": "Two poles"}
{"answers": {"text": ["revolution or invasion", "revolution or invasion", "revolution"], "answer_start": [493, 493, 493]}, "prediction_text": "Revolution or invasion"}
{"answers": {"text": ["democratic", "democratic process", "democratic"], "answer_start": [64, 64, 64]}, "prediction_text": "democratic process"}
{"answers": {"text": ["Palestine", "Palestine", "Palestine"], "answer_start": [361, 361, 361]}, "prediction_text": "Palestine"}
{"answers": {"text": ["abolish the state of Israel", "abolish the state of Israel", "abolish the state of Israel"], "answer_start": [456, 456, 456]}, "prediction_text": "Abolishing the state of Israel."}
{"answers": {"text": ["democracy", "democracy", "democracy"], "answer_start": [610, 610, 610]}, "prediction_text": "Democracy"}
{"answers": {"text": ["religious", "religious", "religious"], "answer_start": [778, 778, 778]}, "prediction_text": "On a religious basis"}
{"answers": {"text": ["major division", "major division", "division"], "answer_start": [8, 8, 14]}, "prediction_text": "Fundamentalist Islamism and reformist Islamism."}
{"answers": {"text": ["Sunni pan-Islamism", "Sunni pan-Islamism", "Sunni pan-Islamism"], "answer_start": [299, 299, 299]}, "prediction_text": "Islamisation of pan-Arabism"}
{"answers": {"text": ["sharia rather than the building of Islamic institutions,", "sharia", "sharia"], "answer_start": [527, 527, 527]}, "prediction_text": "Islamisation of pan-Arabism"}
{"answers": {"text": ["democracy", "democracy", "democracy"], "answer_start": [706, 706, 706]}, "prediction_text": "Democracy"}
{"answers": {"text": ["to maintain their legitimacy", "to maintain their legitimacy", "to maintain their legitimacy"], "answer_start": [904, 904, 904]}, "prediction_text": "To maintain legitimacy."}
{"answers": {"text": ["political", "political", "political"], "answer_start": [65, 65, 65]}, "prediction_text": "Political role"}
{"answers": {"text": ["Islam", "Islam", "Islam"], "answer_start": [157, 157, 157]}, "prediction_text": "Islam"}
{"answers": {"text": ["its supporters", "Scholars and observers", "Islamism"], "answer_start": [107, 238, 0]}, "prediction_text": "Scholars and observers"}
{"answers": {"text": ["illiberal Islamic regimes", "illiberal Islamic regimes", "illiberal Islamic regimes"], "answer_start": [517, 517, 517]}, "prediction_text": "Illiberal Islamic regimes"}
{"answers": {"text": ["religion from politics", "religion from politics", "religion from politics"], "answer_start": [607, 607, 607]}, "prediction_text": "Religion from politics."}
{"answers": {"text": ["Muslims", "Muslims"], "answer_start": [201, 201]}, "prediction_text": "Islamists and believe in Islamism."}
{"answers": {"text": ["Americans", "Americans", "Americans"], "answer_start": [393, 393, 393]}, "prediction_text": "Americans"}
{"answers": {"text": ["a historical fluke", "political Islam", "historical fluke"], "answer_start": [470, 358, 472]}, "prediction_text": "A historical fluke of the heyday of secular Arab nationalism."}
{"answers": {"text": ["between 1945 and 1970", "between 1945 and 1970", "between 1945 and 1970"], "answer_start": [555, 555, 555]}, "prediction_text": "1945-1970"}
{"answers": {"text": ["non-political Islam", "quietist/non-political Islam", "quietist/non-political Islam"], "answer_start": [598, 589, 589]}, "prediction_text": "Political Islam"}
{"answers": {"text": ["dangerous enemies", "dangerous enemies", "dangerous enemies"], "answer_start": [170, 170, 170]}, "prediction_text": "Dangerous enemies"}
{"answers": {"text": ["During the 1970s", "the 1970s", "1970s"], "answer_start": [0, 7, 11]}, "prediction_text": "During the 1970s and later."}
{"answers": {"text": ["considerable impact", "experience, ideology, and weapons", "experience, ideology, and weapons"], "answer_start": [626, 582, 582]}, "prediction_text": "\"experience, ideology, and weapons\""}
{"answers": {"text": ["the mujahideen Muslim Afghanistan", "mujahideen", "mujahideen Muslim Afghanistan"], "answer_start": [448, 452, 452]}, "prediction_text": "mujahideen Muslim Afghanistan enemies"}
{"answers": {"text": ["leftist/communist/nationalist insurgents/opposition", "leftist/communist/nationalist insurgents/opposition", "communist"], "answer_start": [306, 306, 314]}, "prediction_text": "Leftists/communists"}
{"answers": {"text": ["considerable impact", "experience, ideology, and weapons", "experience, ideology, and weapons"], "answer_start": [626, 582, 582]}, "prediction_text": "\"experience, ideology, and weapons\""}
{"answers": {"text": ["Anwar Sadat", "Anwar Sadat", "Anwar Sadat"], "answer_start": [19, 19, 19]}, "prediction_text": "Anwar Sadat"}
{"answers": {"text": ["peace", "peace"], "answer_start": [191, 191]}, "prediction_text": "Promoted Islamist preachers"}
{"answers": {"text": ["political support", "making peace with Israel", "political support"], "answer_start": [289, 184, 289]}, "prediction_text": "Political support"}
{"answers": {"text": ["1975", "1975", "1975"], "answer_start": [563, 563, 563]}, "prediction_text": "1975"}
{"answers": {"text": ["assassinated", "Islamists came to completely dominate university student unions", "assassinated"], "answer_start": [664, 583, 664]}, "prediction_text": "He was rewarded for his efforts."}
{"answers": {"text": ["conservative", "strict, conservative", "strict, conservative"], "answer_start": [69, 61, 61]}, "prediction_text": "Salafism promotes strict, conservative Saudi-based Wahhabism or Salafism."}
{"answers": {"text": ["hate", "hate them for their religion", "hate them for their religion"], "answer_start": [225, 225, 225]}, "prediction_text": "Hate and hatred."}
{"answers": {"text": ["wars", "horrible wars", "all the horrible wars"], "answer_start": [329, 320, 312]}, "prediction_text": "Wars of the 20th century"}
{"answers": {"text": ["infidels", "infidels", "infidels"], "answer_start": [401, 401, 401]}, "prediction_text": "Infidels"}
{"answers": {"text": ["Saudi", "the Saudi-interpretation", "Saudi"], "answer_start": [611, 607, 611]}, "prediction_text": "Wahhabism or Salafism"}
{"answers": {"text": ["Islamist", "Islamist", "Islamist"], "answer_start": [0, 0, 0]}, "prediction_text": "Islamic movement"}
{"answers": {"text": ["incompetent, inefficient, or neglectful", "incompetent, inefficient, or neglectful governments", "incompetent, inefficient, or neglectful"], "answer_start": [421, 421, 421]}, "prediction_text": "incompetent, inefficient, or neglectful governments"}
{"answers": {"text": ["housing", "shelters, educational assistance, free or low cost medical clinics, housing assistance", "shelters, educational assistance, free or low cost medical clinics, housing assistance"], "answer_start": [149, 81, 81]}, "prediction_text": "Free or low cost medical clinics"}
{"answers": {"text": ["rhetoric", "rhetoric", "rhetoric"], "answer_start": [522, 522, 522]}, "prediction_text": "rhetoric"}
{"answers": {"text": ["avoid prohibitively costly dowry demands", "to avoid prohibitively costly dowry demands", "avoid prohibitively costly dowry demands"], "answer_start": [279, 276, 279]}, "prediction_text": "To avoid dowry demands."}
{"answers": {"text": ["law and philosophy", "law and philosophy", "law and philosophy"], "answer_start": [15, 15, 15]}, "prediction_text": "Law and philosophy"}
{"answers": {"text": ["the All India Muslim League", "All India Muslim League", "All India Muslim League"], "answer_start": [104, 108, 108]}, "prediction_text": "All India Muslim League"}
{"answers": {"text": ["the mainstream Indian nationalist and secularist Indian National Congress", "mainstream Indian nationalist and secularist Indian National Congress", "mainstream Indian nationalist and secularist Indian National Congress"], "answer_start": [466, 470, 470]}, "prediction_text": "Indian nationalist and secularist Indian National Congress"}
{"answers": {"text": ["1908", "1908", "1908"], "answer_start": [159, 159, 159]}, "prediction_text": "1908"}
{"answers": {"text": ["The Reconstruction of Religious Thought in Islam", "The Reconstruction of Religious Thought in Islam", "The Reconstruction of Religious Thought in Islam"], "answer_start": [639, 639, 639]}, "prediction_text": "The Reconstruction of Religious Thought in Islam"}
{"answers": {"text": ["secularism and secular nationalism", "secularism and secular nationalism", "secularism"], "answer_start": [42, 42, 42]}, "prediction_text": "Hindu-majority population"}
{"answers": {"text": ["crowd out", "crowd out Muslim heritage", "crowd out"], "answer_start": [188, 188, 188]}, "prediction_text": "Crowd out Muslim heritage, culture, and political influence."}
{"answers": {"text": ["nationalist differences", "nationalist differences", "nationalist differences"], "answer_start": [406, 406, 406]}, "prediction_text": "Shedding nationalist differences"}
{"answers": {"text": ["1930", "1930", "1930"], "answer_start": [496, 496, 496]}, "prediction_text": "1930"}
{"answers": {"text": ["Pakistan movement", "the Pakistan movement", "Pakistan movement"], "answer_start": [754, 750, 754]}, "prediction_text": "Pakistan movement"}
{"answers": {"text": ["Sayyid Abul Ala Maududi", "Sayyid Abul Ala Maududi", "Sayyid Abul Ala Maududi"], "answer_start": [0, 0, 0]}, "prediction_text": "Sayyid Abul Ala Maududi"}
{"answers": {"text": ["journalism", "journalism", "journalism"], "answer_start": [207, 207, 207]}, "prediction_text": "Journalism"}
{"answers": {"text": ["1941", "1941", "1941"], "answer_start": [350, 350, 350]}, "prediction_text": "1941"}
{"answers": {"text": ["through his writing", "writing", "writing"], "answer_start": [429, 441, 441]}, "prediction_text": "Through his writing and activism."}
{"answers": {"text": ["in a modern context", "a modern context", "modern context"], "answer_start": [566, 569, 571]}, "prediction_text": "Modern context"}
{"answers": {"text": ["Sayyid Abul Ala Maududi", "Sayyid Abul Ala Maududi", "Sayyid Abul Ala Maududi"], "answer_start": [0, 0, 0]}, "prediction_text": "Sayyid Abul Ala Maududi"}
{"answers": {"text": ["journalism", "journalism", "journalism"], "answer_start": [207, 207, 207]}, "prediction_text": "Journalism"}
{"answers": {"text": ["through his writing", "writing", "writing"], "answer_start": [429, 441, 441]}, "prediction_text": "Through his writing and activism."}
{"answers": {"text": ["a modern context", "a modern context", "modern context"], "answer_start": [569, 569, 571]}, "prediction_text": "Modern context"}
{"answers": {"text": ["Sharia", "Sharia", "Sharia"], "answer_start": [71, 71, 71]}, "prediction_text": "Sharia"}
{"answers": {"text": ["an Islamic state", "an Islamic state", "an Islamic state"], "answer_start": [119, 119, 119]}, "prediction_text": "Islamic state"}
{"answers": {"text": ["unity of God", "unity of God", "unity of God"], "answer_start": [214, 214, 214]}, "prediction_text": "Unity of God"}
{"answers": {"text": ["gradual", "Islamic revolution", "gradual"], "answer_start": [423, 305, 423]}, "prediction_text": "Islamic revolution"}
{"answers": {"text": ["an educational process", "an educational process or da'wah", "educational process or da'wah"], "answer_start": [517, 517, 520]}, "prediction_text": "Education or da'wah"}
{"answers": {"text": ["1928", "1928", "1928"], "answer_start": [104, 104, 104]}, "prediction_text": "1928"}
{"answers": {"text": ["Ismailiyah, Egypt", "Ismailiyah, Egypt", "Egypt"], "answer_start": [83, 83, 95]}, "prediction_text": "Ismailiyah, Egypt"}
{"answers": {"text": ["Hassan al Banna", "Hassan al Banna", "Hassan al Banna"], "answer_start": [112, 112, 112]}, "prediction_text": "Hassan al Banna"}
{"answers": {"text": ["the Qur'an", "the Qur'an", "Qur'an"], "answer_start": [252, 252, 256]}, "prediction_text": "The Qur'an is our constitution."}
{"answers": {"text": ["imperialist", "imperialist influence", "imperialist"], "answer_start": [572, 572, 572]}, "prediction_text": "imperialist influence"}
{"answers": {"text": ["violence", "violence", "violence"], "answer_start": [79, 79, 79]}, "prediction_text": "Violence against the government"}
{"answers": {"text": ["1949", "1949", "1949"], "answer_start": [157, 157, 157]}, "prediction_text": "1949"}
{"answers": {"text": ["Egypt's premier Mahmud Fami Naqrashi", "Mahmud Fami Naqrashi", "Mahmud Fami Naqrashi"], "answer_start": [202, 218, 218]}, "prediction_text": "Mahmud Fami Naqrashi"}
{"answers": {"text": ["1948", "1948", "1948"], "answer_start": [357, 357, 357]}, "prediction_text": "1948"}
{"answers": {"text": ["Gamal Abdul Nasser", "Gamal Abdul Nasser", "Gamal Abdul Nasser"], "answer_start": [435, 435, 435]}, "prediction_text": "Gamal Abdul Nasser"}
{"answers": {"text": ["one of the most influential movements", "one of the most influential movements", "one of the most influential"], "answer_start": [56, 56, 56]}, "prediction_text": "One of the most influential movements"}
{"answers": {"text": ["75% of the total seats", "75%", "75%"], "answer_start": [488, 488, 488]}, "prediction_text": "75%"}
{"answers": {"text": ["\"semi-legal\"", "semi-legal", "semi-legal"], "answer_start": [183, 184, 184]}, "prediction_text": "\"Semi-legal\" opposition group"}
{"answers": {"text": ["field candidates", "field candidates", "field candidates"], "answer_start": [247, 247, 247]}, "prediction_text": "Field candidates"}
{"answers": {"text": ["Mohamed Morsi", "Mohamed Morsi", "Mohamed Morsi"], "answer_start": [512, 512, 512]}, "prediction_text": "Mohamed Morsi"}
{"answers": {"text": ["quick and decisive", "quick and decisive defeat", "quick and decisive"], "answer_start": [4, 4, 4]}, "prediction_text": "A pivotal event in Arab Muslim world."}
{"answers": {"text": ["a pivotal event", "a pivotal event in the Arab Muslim world", "pivotal event"], "answer_start": [102, 102, 104]}, "prediction_text": "A pivotal event"}
{"answers": {"text": ["economic", "economic stagnation", "economic"], "answer_start": [166, 166, 166]}, "prediction_text": "Economic stagnation"}
{"answers": {"text": ["A steep and steady decline", "A steep and steady decline", "steep and steady decline"], "answer_start": [279, 279, 281]}, "prediction_text": "A steep decline in popularity and credibility."}
{"answers": {"text": ["anti-democratic Islamist movements", "anti-democratic Islamist movements inspired by Maududi and Sayyid Qutb", "anti-democratic Islamist movements"], "answer_start": [482, 482, 482]}, "prediction_text": "Arab socialism"}
{"answers": {"text": ["ideological", "ideological", "ideological"], "answer_start": [101, 101, 101]}, "prediction_text": "Ideological father"}
{"answers": {"text": ["Ali Shariati", "Ali Shariati", "Ali Shariati"], "answer_start": [13, 13, 13]}, "prediction_text": "Ali Shariati"}
{"answers": {"text": ["somewhere between", "between", "somewhere between"], "answer_start": [195, 205, 195]}, "prediction_text": "In between beliefs of Sunni Islamic thinkers and Islamic thinkers like Mawdudi and Qutb."}
{"answers": {"text": ["the Prophet Mohammad", "Prophet Mohammad and his successors", "Prophet Mohammad"], "answer_start": [309, 313, 313]}, "prediction_text": "Prophet Mohammad and his successors"}
{"answers": {"text": ["conspiracy", "Westernizing Muslims", "conspiracy"], "answer_start": [594, 434, 594]}, "prediction_text": "Served Western interests"}
{"answers": {"text": ["Islamic", "The Islamic Republic", "Islamic"], "answer_start": [4, 0, 4]}, "prediction_text": "Islamic Republic of Iran"}
{"answers": {"text": ["Shia terrorist", "Shia terrorist groups", "Shia terrorist"], "answer_start": [142, 142, 142]}, "prediction_text": "Shia terrorist groups"}
{"answers": {"text": ["economic", "economic", "economic"], "answer_start": [82, 82, 82]}, "prediction_text": "Economic sanctions"}
{"answers": {"text": ["During the 2006 Israel-Lebanon conflict", "the 2006 Israel-Lebanon conflict", "2006"], "answer_start": [290, 297, 301]}, "prediction_text": "2006 Israel-Lebanon conflict"}
{"answers": {"text": ["President Mahmoud Ahmadinejad", "President Mahmoud Ahmadinejad", "President Mahmoud Ahmadinejad"], "answer_start": [489, 489, 489]}, "prediction_text": "President Mahmoud Ahmadinejad"}
{"answers": {"text": ["the Soviet Union", "the Soviet Union", "Soviet Union"], "answer_start": [9, 9, 13]}, "prediction_text": "Soviet Union"}
{"answers": {"text": ["an Islamic rebellion", "an Islamic rebellion against an allied Marxist regime", "Islamic rebellion"], "answer_start": [90, 90, 93]}, "prediction_text": "Islamic rebellion against an allied Marxist regime."}
{"answers": {"text": ["send aid and sometimes to go themselves to fight for their faith", "send aid and sometimes to go themselves to fight for their faith", "send aid and sometimes to go themselves to fight for their faith"], "answer_start": [326, 326, 326]}, "prediction_text": "Send aid and fight for their faith."}
{"answers": {"text": ["marginal", "marginal", "marginal"], "answer_start": [530, 530, 530]}, "prediction_text": "marginal"}
{"answers": {"text": ["16,000 to 35,000", "16,000 to 35,000", "16,000 to 35,000"], "answer_start": [553, 553, 553]}, "prediction_text": "16,000 to 35,000"}
{"answers": {"text": ["worked to radicalize the Islamist movement", "radicalize the Islamist movement", "radicalize the Islamist movement"], "answer_start": [39, 49, 49]}, "prediction_text": "Radicalized Islamist movement"}
{"answers": {"text": ["Saddam Hussein", "Saddam Hussein's", "Saddam Hussein's"], "answer_start": [222, 222, 222]}, "prediction_text": "Saddam Hussein's occupation"}
{"answers": {"text": ["Islamist", "Islamist", "Islamist"], "answer_start": [337, 337, 337]}, "prediction_text": "Islamist groups"}
{"answers": {"text": ["Saudi", "Saudi", "Saudi"], "answer_start": [529, 529, 529]}, "prediction_text": "Saudi monarchy"}
{"answers": {"text": ["the west", "the west", "the west"], "answer_start": [601, 601, 601]}, "prediction_text": "West's puppet"}
{"answers": {"text": ["conservative Muslims", "Muslims", "conservative Muslims"], "answer_start": [29, 42, 29]}, "prediction_text": "Conservative Muslims"}
{"answers": {"text": ["domestic Islamists", "domestic Islamists", "domestic Islamists"], "answer_start": [350, 350, 350]}, "prediction_text": "Domestic Islamists"}
{"answers": {"text": ["in the kingdom", "in the kingdom", "the kingdom"], "answer_start": [152, 152, 155]}, "prediction_text": "In Saudi Arabia"}
{"answers": {"text": ["Algeria", "Algeria", "Algeria"], "answer_start": [739, 739, 739]}, "prediction_text": "Algeria"}
{"answers": {"text": ["Osama bin Laden", "Osama bin Laden", "Osama bin Laden"], "answer_start": [751, 751, 751]}, "prediction_text": "Saddam Hussein"}
{"answers": {"text": ["Qutb's", "Qutb", "Qutb's"], "answer_start": [6, 6, 6]}, "prediction_text": "Hasan al-Hudaybi's ideas"}
{"answers": {"text": ["1966", "1966", "1966"], "answer_start": [97, 97, 97]}, "prediction_text": "1966"}
{"answers": {"text": ["the Brotherhood", "the Brotherhood", "Brotherhood"], "answer_start": [121, 121, 125]}, "prediction_text": "Brotherhood"}
{"answers": {"text": ["Fringe or splinter", "Fringe or splinter movements", "Fringe"], "answer_start": [235, 235, 235]}, "prediction_text": "Fringe or splinter movements"}
{"answers": {"text": ["By the 1970s", "the 1970s", "1970s"], "answer_start": [452, 455, 459]}, "prediction_text": "By the 1970s"}
{"answers": {"text": ["Egyptian Islamic Jihad organization", "the Egyptian Islamic Jihad organization", "Egyptian Islamic Jihad"], "answer_start": [68, 64, 68]}, "prediction_text": "Egyptian Islamic Jihad organization"}
{"answers": {"text": ["1981", "1981", "1981"], "answer_start": [156, 156, 156]}, "prediction_text": "1981"}
{"answers": {"text": ["apostate", "\"apostate\" leaders of Muslim states,", "apostate"], "answer_start": [273, 272, 273]}, "prediction_text": "Anwar Sadat and other leaders"}
{"answers": {"text": ["promoted Western/foreign ideas and practices into Islamic societies", "held secular leanings or who had introduced or promoted Western/foreign ideas and practices into Islamic societies", "secular leanings"], "answer_start": [368, 321, 326]}, "prediction_text": "Oppression and oppression"}
{"answers": {"text": ["Muhammad Abd al-Salaam Farag", "Muhammad Abd al-Salaam Farag", "Muhammad Abd al-Salaam Farag"], "answer_start": [486, 486, 486]}, "prediction_text": "Muhammad Abd al-Salaam Farag"}
{"answers": {"text": ["violence", "violence", "violence"], "answer_start": [46, 46, 46]}, "prediction_text": "Violence and intimidation"}
{"answers": {"text": ["al-Gama'a al-Islamiyya", "al-Gama'a al-Islamiyya", "Islamic Group"], "answer_start": [95, 95, 119]}, "prediction_text": "al-Gama'a al-Islamiyya"}
{"answers": {"text": ["in 2003", "2003", "2003"], "answer_start": [571, 574, 574]}, "prediction_text": "2003"}
{"answers": {"text": ["unsuccessful", "unsuccessful", "unsuccessful"], "answer_start": [466, 466, 466]}, "prediction_text": "Failed"}
{"answers": {"text": ["political figures", "political figures", "political figures"], "answer_start": [782, 782, 782]}, "prediction_text": "Political figures"}
{"answers": {"text": ["quiescent", "quiescent", "quiescent"], "answer_start": [108, 108, 108]}, "prediction_text": "Quiescent stance"}
{"answers": {"text": ["HAMAS", "HAMAS", "HAMAS"], "answer_start": [459, 459, 459]}, "prediction_text": "HAMAS (Islamic State of Palestine)"}
{"answers": {"text": ["destruction of Israel", "the destruction of Israel", "destruction of Israel"], "answer_start": [627, 623, 627]}, "prediction_text": "Destruction of Israel and establishment of an Islamic state."}
{"answers": {"text": ["alcohol", "alcohol", "alcohol"], "answer_start": [1003, 1003, 1003]}, "prediction_text": "Alcohol"}
{"answers": {"text": ["Palestine", "Palestine", "Palestine"], "answer_start": [694, 694, 694]}, "prediction_text": "Palestine"}
{"answers": {"text": ["Hamas", "Hamas", "Hamas"], "answer_start": [0, 304, 0]}, "prediction_text": "Hamas"}
{"answers": {"text": ["542", "542", "542"], "answer_start": [83, 83, 83]}, "prediction_text": "542 people"}
{"answers": {"text": ["majority of the seats,", "the majority of the seats", "majority of the seats"], "answer_start": [239, 235, 239]}, "prediction_text": "The majority of seats"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [269, 269, 269]}, "prediction_text": "2007"}
{"answers": {"text": ["driving Israel out of the Gaza Strip", "driving Israel out of the Gaza Strip", "driving Israel out of the Gaza Strip"], "answer_start": [342, 342, 342]}, "prediction_text": "Driving Israel out of Gaza."}
{"answers": {"text": ["Islamist", "Islamist", "Islamist"], "answer_start": [29, 29, 29]}, "prediction_text": "Islamist regime"}
{"answers": {"text": ["Hassan al-Turabi", "Hassan al-Turabi", "Hassan al-Turabi"], "answer_start": [69, 69, 69]}, "prediction_text": "Hassan al-Turabi"}
{"answers": {"text": ["National Islamic Front", "National Islamic Front", "National Islamic Front"], "answer_start": [91, 91, 91]}, "prediction_text": "National Islamic Front"}
{"answers": {"text": ["money from foreign Islamist banking systems", "with money from foreign Islamist banking systems", "money from foreign Islamist banking systems"], "answer_start": [273, 268, 273]}, "prediction_text": "From foreign Islamist banking systems"}
{"answers": {"text": ["university and military academy", "the university and military academy", "university and military academy"], "answer_start": [461, 457, 461]}, "prediction_text": "University and military academy"}
{"answers": {"text": ["1985", "1985", "1985"], "answer_start": [35, 35, 35]}, "prediction_text": "1985"}
{"answers": {"text": ["with the help of the military", "with the help of the military", "military"], "answer_start": [160, 160, 181]}, "prediction_text": "Turabi overthrew the elected government."}
{"answers": {"text": ["sharia law", "sharia law", "sharia law"], "answer_start": [338, 338, 338]}, "prediction_text": "Sharia law"}
{"answers": {"text": ["Osama bin Laden", "Osama bin Laden", "Osama bin Laden"], "answer_start": [509, 509, 509]}, "prediction_text": "Osama bin Laden"}
{"answers": {"text": ["American attack on Iraq", "the American attack on Iraq", "American attack on Iraq"], "answer_start": [598, 594, 598]}, "prediction_text": "American attack on Iraq"}
{"answers": {"text": ["staying home", "staying home to alleviate the high rate of unemployment among young Algerian men", "staying home"], "answer_start": [681, 681, 681]}, "prediction_text": "Home to alleviate high unemployment"}
{"answers": {"text": ["1989", "1989", "1989"], "answer_start": [232, 232, 232]}, "prediction_text": "1989"}
{"answers": {"text": ["Algeria", "Algeria", "Afghanistan"], "answer_start": [182, 182, 61]}, "prediction_text": "Algeria"}
{"answers": {"text": ["Front Islamique de Salut", "Front Islamique de Salut", "Front Islamique de Salut"], "answer_start": [124, 124, 124]}, "prediction_text": "Islamic Salvation Front"}
{"answers": {"text": ["a military coup d'\u00e9tat", "a military coup d'\u00e9tat", "a military coup d'\u00e9tat"], "answer_start": [892, 892, 892]}, "prediction_text": "A military coup d'\u00e9tat"}
{"answers": {"text": ["justice and prosperity", "justice and prosperity", "justice and prosperity"], "answer_start": [95, 95, 95]}, "prediction_text": "Justice and prosperity"}
{"answers": {"text": ["vicious and destructive", "vicious and destructive", "civil"], "answer_start": [128, 128, 152]}, "prediction_text": "Civil war between political and tribal warlords."}
{"answers": {"text": ["1992", "1992", "1992"], "answer_start": [262, 262, 262]}, "prediction_text": "1992"}
{"answers": {"text": ["one of the poorest countries on earth", "one of the poorest countries on earth", "one of the poorest countries on earth"], "answer_start": [220, 220, 220]}, "prediction_text": "One of the poorest countries on earth."}
{"answers": {"text": ["80%", "roughly 80%", "roughly 80%"], "answer_start": [587, 579, 579]}, "prediction_text": "About 80%"}
{"answers": {"text": ["The Taliban", "The Taliban", "Taliban"], "answer_start": [0, 0, 4]}, "prediction_text": "Deobandi movement"}
{"answers": {"text": ["Pakistan", "Pakistan", "Pakistan"], "answer_start": [188, 188, 188]}, "prediction_text": "neighboring Pakistan"}
{"answers": {"text": ["neofundamentalist", "Islamic fundamentalist or neofundamentalist", "neofundamentalist"], "answer_start": [335, 309, 335]}, "prediction_text": "Islamic fundamentalist or neofundamentalist."}
{"answers": {"text": ["Sharia", "an idealized and systematized version of conservative tribal village customs", "Sharia"], "answer_start": [476, 379, 476]}, "prediction_text": "An idealized and systematized version of conservative tribal village customs."}
{"answers": {"text": ["Osama bin Laden", "Osama bin Laden", "Osama bin Laden"], "answer_start": [615, 615, 615]}, "prediction_text": "Wahhabism and Osama bin Laden"}
{"answers": {"text": ["July 1977", "July 1977", "1977"], "answer_start": [3, 3, 8]}, "prediction_text": "July 1977"}
{"answers": {"text": ["alcohol and nightclubs", "alcohol and nightclubs", "alcohol and nightclubs"], "answer_start": [186, 186, 186]}, "prediction_text": "Alcohol and nightclubs"}
{"answers": {"text": ["Islamism", "Islamism", "Islamism"], "answer_start": [429, 429, 429]}, "prediction_text": "Islamization"}
{"answers": {"text": ["his means of seizing power", "his means of seizing", "seizing power"], "answer_start": [870, 870, 883]}, "prediction_text": "His means of seizing power."}
{"answers": {"text": ["1988", "1988", "1988"], "answer_start": [1094, 1094, 1094]}, "prediction_text": "1988"}
{"answers": {"text": ["Wahhabi/Salafi jihadist extremist militant", "Wahhabi/Salafi jihadist extremist militant group", "extremist militant"], "answer_start": [190, 190, 214]}, "prediction_text": "Wahhabi/Salafi extremist group"}
{"answers": {"text": ["Sunni Arabs", "Sunni Arabs", "Sunni Arabs"], "answer_start": [278, 278, 278]}, "prediction_text": "Abu Bakr al-Baghdadi"}
{"answers": {"text": ["ten million", "ten million", "ten million"], "answer_start": [506, 506, 506]}, "prediction_text": "Ten million people"}
{"answers": {"text": ["recognition", "international recognition", "recognition"], "answer_start": [674, 660, 674]}, "prediction_text": "International recognition"}
{"answers": {"text": ["a caliphate", "a caliphate", "caliphate"], "answer_start": [348, 348, 350]}, "prediction_text": "A caliphate"}
{"answers": {"text": ["2004", "2004", "2004"], "answer_start": [93, 93, 93]}, "prediction_text": "1999"}
{"answers": {"text": ["2003", "March 2003", "March 200"], "answer_start": [160, 154, 154]}, "prediction_text": "March 2003"}
{"answers": {"text": ["notorious intransigence", "its failure to consult and \"notorious intransigence\"", "notorious intransigence"], "answer_start": [362, 334, 362]}, "prediction_text": "To avoid being blamed for human rights abuses and war crimes."}
{"answers": {"text": ["March 2011", "March 2011", "March 2011"], "answer_start": [255, 255, 255]}, "prediction_text": "March 2011"}
{"answers": {"text": ["a terrorist organisation", "a terrorist organisation", "terrorist organisation"], "answer_start": [906, 906, 908]}, "prediction_text": "A terrorist organisation"}
{"answers": {"text": ["a different view", "Islam's pivotal turning point as occurring not with the death of Ali", "different view"], "answer_start": [47, 139, 49]}, "prediction_text": "Islamic history is a focus of the party."}
{"answers": {"text": ["7th century", "the 7th century", "7th century"], "answer_start": [264, 260, 264]}, "prediction_text": "1924"}
{"answers": {"text": ["1924", "1924", "1924"], "answer_start": [328, 328, 328]}, "prediction_text": "1924"}
{"answers": {"text": ["true Islamic", "the true Islamic system", "true Islamic"], "answer_start": [369, 365, 369]}, "prediction_text": "Islamic system"}
{"answers": {"text": ["ended the true Islamic system", "working through Turkish modernist Mustafa Kemal Atat\u00fcrk", "abolition of the Ottoman Caliphate"], "answer_start": [359, 463, 290]}, "prediction_text": "The Islamic system's abolition"}
{"answers": {"text": ["armed", "armed jihad", "armed"], "answer_start": [22, 22, 22]}, "prediction_text": "Armed jihad"}
{"answers": {"text": ["ideological struggle", "ideological struggle", "ideological struggle"], "answer_start": [100, 100, 100]}, "prediction_text": "Through ideological struggle and influence of elites."}
{"answers": {"text": ["elites", "government", "elites"], "answer_start": [181, 227, 181]}, "prediction_text": "Muslim public opinion"}
{"answers": {"text": ["Egypt", "Egypt", "Egypt"], "answer_start": [361, 361, 361]}, "prediction_text": "Egypt"}
{"answers": {"text": ["terrorist groups", "terrorist groups", "terrorist groups"], "answer_start": [446, 446, 446]}, "prediction_text": "Terrorist groups"}
{"answers": {"text": ["over 900,000", "900,000", "over 900,000"], "answer_start": [19, 24, 19]}, "prediction_text": "900,000"}
{"answers": {"text": ["strong Islamist", "a strong Islamist outlook", "Islamist"], "answer_start": [192, 190, 199]}, "prediction_text": "Islamic outlook"}
{"answers": {"text": ["2007", "2007", "2007"], "answer_start": [336, 336, 336]}, "prediction_text": "2007"}
{"answers": {"text": ["Londonistan", "Londonistan", "Londonistan"], "answer_start": [419, 419, 419]}, "prediction_text": "Londonistan"}
{"answers": {"text": ["incitement to terrorism", "incitement to terrorism", "incitement to terrorism"], "answer_start": [557, 557, 557]}, "prediction_text": "incitement to terrorism"}
{"answers": {"text": ["since 2001", "since 2001", "2001"], "answer_start": [85, 85, 91]}, "prediction_text": "Since 2001"}
{"answers": {"text": ["State", "State Department", "State"], "answer_start": [188, 188, 188]}, "prediction_text": "State Department"}
{"answers": {"text": ["Christian Whiton", "George W. Bush", "Christian Whiton"], "answer_start": [334, 371, 334]}, "prediction_text": "Christian Whiton"}
{"answers": {"text": ["U.S. Defense Secretary", "Defense Secretary", "Defense Secretary"], "answer_start": [519, 524, 524]}, "prediction_text": "Defense Secretary"}
{"answers": {"text": ["undermining the communist ideology", "undermining the communist ideology", "undermining the communist ideology"], "answer_start": [660, 660, 660]}, "prediction_text": "Defeating communist ideology"}
{"answers": {"text": ["Latin", "Latin", "Latin", "Latin", "Latin"], "answer_start": [74, 74, 74, 74, 74]}, "prediction_text": "Latin"}
{"answers": {"text": ["military force", "colonization, use of military force, or other means", "colonization, use of military force, or other means", "colonization, use of military force, or other", "colonization"], "answer_start": [240, 219, 219, 219, 219]}, "prediction_text": "Through colonization, use of military force, or other means."}
{"answers": {"text": ["Japan", "Japan", "Japanese", "Japanese", "Japan"], "answer_start": [450, 450, 450, 450, 450]}, "prediction_text": "Japan"}
{"answers": {"text": ["technologies and ideas", "technologies and ideas", "technologies and ideas", "technologies and ideas", "technologies and ideas."], "answer_start": [372, 372, 372, 372, 372]}, "prediction_text": "technologies and ideas"}
{"answers": {"text": ["influence", "influence", "influence", "influence", "influence"], "answer_start": [71, 71, 71, 71, 71]}, "prediction_text": "Influence"}
{"answers": {"text": ["\"Formal imperialism\"", "formal", "\"Formal imperialism", "Formal imperialism", "Formal"], "answer_start": [401, 365, 401, 402, 402]}, "prediction_text": "Formal imperialism"}
{"answers": {"text": ["othering", "othering", "othering", "othering", "othering"], "answer_start": [279, 279, 279, 279, 279]}, "prediction_text": "Diplomacy or military force"}
{"answers": {"text": ["direct", "direct", "direct", "direct", "direct"], "answer_start": [517, 517, 517, 517, 517]}, "prediction_text": "Directly dominant"}
{"answers": {"text": ["\"informal\" imperialism", "Informal rule", "informal\" imperialism", "imperialism"], "answer_start": [450, 639, 451, 18]}, "prediction_text": "Informal rule"}
{"answers": {"text": ["\"formal\"", "formal", "formal", "formal", "formal"], "answer_start": [437, 438, 438, 438, 438]}, "prediction_text": "Formal and informal imperialism"}
{"answers": {"text": ["aggressiveness", "aggressiveness", "aggressiveness", "aggressiveness", "aggressiveness"], "answer_start": [161, 161, 161, 161, 161]}, "prediction_text": "All kinds of domination or control by a group of people."}
{"answers": {"text": ["ownership of private industries", "technological superiority", "technological superiority", "ownership of private industries", "technological superiority,"], "answer_start": [888, 796, 796, 888, 796]}, "prediction_text": "Technology superiority"}
{"answers": {"text": ["informal", "Informal rule is generally less costly", "Informal rule", "formal", "formal"], "answer_start": [739, 639, 639, 438, 438]}, "prediction_text": "Informal rule"}
{"answers": {"text": ["distinction", "distinction", "distinction", "distinction", "distinction"], "answer_start": [167, 167, 167, 167, 167]}, "prediction_text": "The largest empire in the world."}
{"answers": {"text": ["the world systems theory", "world systems theory", "world systems theory.", "world systems theory"], "answer_start": [948, 952, 952, 952]}, "prediction_text": "Geopolitics"}
{"answers": {"text": ["Lenin", "Lenin", "Lenin"], "answer_start": [1349, 1349, 1349]}, "prediction_text": "Lenin"}
{"answers": {"text": ["empires", "empires"], "answer_start": [1751, 1751]}, "prediction_text": "Empire"}
{"answers": {"text": ["seaborne", "land", "sea and trade routes", "sea"], "answer_start": [818, 301, 364, 551]}, "prediction_text": "Sea and trade routes"}
{"answers": {"text": ["colonialism", "colonialism", "colonialism", "colonialism", "colonialism"], "answer_start": [48, 48, 48, 48, 48]}, "prediction_text": "colonialism"}
{"answers": {"text": ["political focus", "political focus", "political focus", "political focus", "ideological"], "answer_start": [1222, 1222, 1222, 1222, 392]}, "prediction_text": "Political focus."}
{"answers": {"text": ["ideological", "ideological", "ideological", "commercial"], "answer_start": [392, 392, 392, 490]}, "prediction_text": "Political reasons"}
{"answers": {"text": ["Ottoman", "Ottoman", "Ottoman", "Ottoman", "Ottoman"], "answer_start": [1003, 1003, 1003, 1003, 1003]}, "prediction_text": "Ottoman Turks"}
{"answers": {"text": ["person or group of people", "a person or group of people", "a person or group of people", "person or group of people"], "answer_start": [257, 255, 255, 257]}, "prediction_text": "A person or group of people."}
{"answers": {"text": ["Imperialism and colonialism", "Imperialism and colonialism", "Imperialism and colonialism", "Imperialism and colonialism"], "answer_start": [0, 0, 0, 0]}, "prediction_text": "Imperialism and colonialism"}
{"answers": {"text": ["taking physical control of another", "a conquest over an area", "the process of a country taking physical control of another", "dominating areas", "country taking physical control of another"], "answer_start": [347, 700, 322, 536, 339]}, "prediction_text": "Taking physical control of another"}
{"answers": {"text": ["conquering the other state's lands", "conquering the other state's lands and therefore increasing its own dominance", "by conquering the other state's lands", "political and monetary dominance"], "answer_start": [1061, 1061, 1058, 409]}, "prediction_text": "By conquering other state's lands and increasing its own dominance."}
{"answers": {"text": ["exploitation", "the exploitation of the valuable assets and supplies", "the exploitation of the valuable assets and supplies of the nation that was conquered", "exploitation of the valuable assets and supplies of the nation that was conquered and the conquering nation then gaining the benefits", "exploitation of the valuable assets and supplies of the nation that was conquered"], "answer_start": [845, 841, 841, 845, 845]}, "prediction_text": "Exploitation of valuable assets and supplies of the nation."}
{"answers": {"text": ["characteristics", "characteristics of the conquering peoples", "characteristics of the conquering peoples", "the characteristics of the conquering peoples", "characteristics"], "answer_start": [1403, 1403, 1403, 1399, 1403]}, "prediction_text": "Characteristics of the conquered indigenous populations."}
{"answers": {"text": ["empire-building", "defense and justification of empire-building", "is the defense and justification of empire-building based on seemingly rational grounds", "defense and justification of empire-building based on seemingly rational grounds", "defense and justification of empire-building"], "answer_start": [74, 45, 38, 45, 45]}, "prediction_text": "Defense and justification of empire-building based on rational grounds."}
{"answers": {"text": ["imperialism", "imperialism", "imperialism", "imperialism", "imperialism"], "answer_start": [526, 526, 526, 526, 526]}, "prediction_text": "imperialism"}
{"answers": {"text": ["highest 'social efficiency'", "highest 'social efficiency'", "the races of highest 'social efficiency'\"", "of highest 'social efficiency", "races of highest 'social efficiency'\""], "answer_start": [352, 352, 339, 349, 343]}, "prediction_text": "The races of highest social efficiency."}
{"answers": {"text": ["theory of races", "Social Darwinism", "Social Darwinism", "Social Darwinism"], "answer_start": [737, 713, 713, 713]}, "prediction_text": "Social Darwinism"}
{"answers": {"text": ["whiteness", "whiteness", "whiteness", "whiteness", "whiteness"], "answer_start": [940, 940, 940, 940, 940]}, "prediction_text": "Whiteness"}
{"answers": {"text": ["Germany", "Germany", "Germany", "Germany", "Germany"], "answer_start": [316, 316, 316, 316, 316]}, "prediction_text": "Berlin"}
{"answers": {"text": ["Britain", "Britain", "Britain", "Britain", "Britain"], "answer_start": [349, 349, 349, 349, 349]}, "prediction_text": "Britain"}
{"answers": {"text": ["Political", "Political", "Political", "Political", "Political"], "answer_start": [266, 266, 266, 266, 266]}, "prediction_text": "British imperial geographers"}
{"answers": {"text": ["geographical societies in Europe", "necessary for a state\u2019s survival", "survival", "necessary", "necessary"], "answer_start": [51, 415, 439, 415, 415]}, "prediction_text": "Necessary for survival"}
{"answers": {"text": ["fund", "fund travelers who would come back with tales of their discoveries", "fund travelers", "able to fund travelers", "fund"], "answer_start": [121, 121, 121, 113, 121]}, "prediction_text": "They supported travelers."}
{"answers": {"text": ["environmental determinism", "environmental determinism", "environmental determinism", "environmental determinism", "environmental determinism"], "answer_start": [30, 30, 30, 30, 30]}, "prediction_text": "Environmental determinism"}
{"answers": {"text": ["temperate", "temperate zone", "the temperate zone", "temperate zone", "temperate"], "answer_start": [324, 324, 320, 324, 324]}, "prediction_text": "Tropic"}
{"answers": {"text": ["Orientalism", "Orientalism", "Orientalism", "Orientalism", "Orientalism"], "answer_start": [389, 389, 389, 389, 389]}, "prediction_text": "Orientalism"}
{"answers": {"text": ["uncivilized", "uncivilized", "fully human", "uncivilized people", "uncivilized"], "answer_start": [106, 106, 305, 106, 106]}, "prediction_text": "Uncivilized people"}
{"answers": {"text": ["superior", "superior", "the superior and the norm", "superior", "superior"], "answer_start": [529, 529, 525, 529, 529]}, "prediction_text": "superior and norm"}
{"answers": {"text": ["Terra nullius", "Terra nullius", "Terra nullius", "Terra nullius"], "answer_start": [247, 247, 247, 247]}, "prediction_text": "Roman law"}
{"answers": {"text": ["the eighteenth century", "eighteenth century", "eighteenth century", "eighteenth century", "eighteenth century,"], "answer_start": [449, 453, 453, 453, 453]}, "prediction_text": "eighteenth century"}
{"answers": {"text": ["the British Empire", "Terra nullius", "the British Empire", "British Empire", "British"], "answer_start": [87, 247, 87, 91, 91]}, "prediction_text": "British Empire"}
{"answers": {"text": ["Aboriginal", "Aboriginal", "Aboriginal inhabitants", "Aboriginal"], "answer_start": [562, 562, 562, 562]}, "prediction_text": "Terra nullius settlers"}
{"answers": {"text": ["empty land", "empty land", "empty land", "empty land", "'empty land'"], "answer_start": [315, 315, 315, 315, 314]}, "prediction_text": "Empty land"}
{"answers": {"text": ["an imaginative geography", "imaginative geography", "imaginative geography", "imaginative geography", "imaginative geography"], "answer_start": [75, 78, 78, 78, 78]}, "prediction_text": "Imaginary geography"}
{"answers": {"text": ["irrational and backward", "them", "as irrational and backward", "irrational and backward", "irrational and backward"], "answer_start": [605, 404, 602, 605, 605]}, "prediction_text": "irrational and backward"}
{"answers": {"text": ["inferior", "irrational and backward", "its inferior", "irrational and backward", "inferior"], "answer_start": [738, 605, 734, 605, 738]}, "prediction_text": "irrational and backward"}
{"answers": {"text": ["Orientalism", "inferior", "Defining the East as a negative vision of itself", "Orientalism", "Orientalism"], "answer_start": [928, 738, 681, 928, 928]}, "prediction_text": "The discourse of Orientalism"}
{"answers": {"text": ["progressive", "rational and progressive", "rational and progressive", "rational and progressive"], "answer_start": [663, 650, 650, 650]}, "prediction_text": "Rational and progressive"}
{"answers": {"text": ["nineteenth-century maps", "nineteenth-century maps", "the role of nineteenth-century maps", "the role of nineteenth-century maps", "the role of nineteenth-century maps during the \"scramble for Africa\""], "answer_start": [76, 76, 64, 64, 64]}, "prediction_text": "The role of nineteenth-century maps during the \"scramble for Africa\""}
{"answers": {"text": ["blank spaces on contemporary maps", "fill in blank spaces on contemporary maps", "maps", "maps", "blank space"], "answer_start": [519, 511, 149, 149, 372]}, "prediction_text": "Blank space for unknown or unexplored territory."}
{"answers": {"text": ["unexplored territory", "unknown or unexplored territory", "unknown or unexplored territory", "to denote unknown or unexplored territory", "unknown or unexplored territory"], "answer_start": [405, 394, 394, 384, 394]}, "prediction_text": "Encouraged imperial and colonial powers to obtain information to fill in blank spaces."}
{"answers": {"text": ["nineteenth-century cartographic techniques", "nineteenth-century maps", "nineteenth-century cartographic techniques", "nineteenth-century maps", "role of nineteenth-century maps"], "answer_start": [303, 76, 303, 76, 68]}, "prediction_text": "Maps contributed to empire by promoting, assisting, and legitimizing French and British power into West Africa."}
{"answers": {"text": ["French", "French", "French", "French", "French"], "answer_start": [236, 236, 236, 236, 236]}, "prediction_text": "French and British colonized Africa."}
{"answers": {"text": ["the pre-Columbian era", "pre-Columbian", "pre-Columbian era", "pre-Columbian", "pre-Columbian"], "answer_start": [669, 673, 673, 673, 673]}, "prediction_text": "Pre-Columbian era"}
{"answers": {"text": ["Genghis Khan", "Genghis Khan", "Genghis Khan", "Genghis Khan", "Genghis Khan"], "answer_start": [324, 324, 324, 324, 324]}, "prediction_text": "Genghis Khan"}
{"answers": {"text": ["dozens", "dozens", "dozens", "dozens", "dozens"], "answer_start": [485, 440, 440, 440, 440]}, "prediction_text": "Dozens"}
{"answers": {"text": ["Ethiopian Empire", "the Ethiopian Empire", "Ethiopian", "Ethiopian"], "answer_start": [559, 555, 559, 559]}, "prediction_text": "Ethiopian Empire"}
{"answers": {"text": ["Sub-Saharan Africa", "Sub-Saharan Africa", "Sub-Saharan Africa", "Sub-Saharan Africa"], "answer_start": [448, 448, 448, 448]}, "prediction_text": "Africa"}
{"answers": {"text": ["Cultural imperialism", "Cultural imperialism", "Cultural imperialism", "Cultural imperialism", "Cultural imperialism"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Cultural imperialism"}
{"answers": {"text": ["soft power", "soft power", "soft power", "soft power", "soft power"], "answer_start": [687, 100, 100, 100, 100]}, "prediction_text": "Cultural imperialism"}
{"answers": {"text": ["Dallas", "Dallas", "Dallas", "Dallas", "Dallas"], "answer_start": [510, 510, 510, 510, 510]}, "prediction_text": "Dallas"}
{"answers": {"text": ["Roman", "Roman", "Roman", "Roman", "Roman"], "answer_start": [991, 911, 911, 911, 911]}, "prediction_text": "Roman Empire"}
{"answers": {"text": ["bans", "bans on foreign popular culture, control of the internet and unauthorised satellite dishes", "bans on foreign popular culture, control of the internet and unauthorised satellite dishes", "bans"], "answer_start": [765, 765, 765, 765]}, "prediction_text": "Fighting with bans on foreign popular culture, internet and satellite dishes."}
{"answers": {"text": ["around 1700", "around 1700", "1700", "around 1700", "1700"], "answer_start": [48, 48, 55, 48, 55]}, "prediction_text": "Around 1700"}
{"answers": {"text": ["colonizing", "process of colonizing, influencing, and annexing other parts of the world", "colonizing, influencing, and annexing other parts of the world in order to gain political power", "colonizing, influencing, and annexing"], "answer_start": [137, 126, 137, 137]}, "prediction_text": "Colonizing, influencing, annexing other parts of the world."}
{"answers": {"text": ["thousands", "thousands", "thousands", "thousands", "thousands"], "answer_start": [299, 299, 299, 299, 299]}, "prediction_text": "Thousands of years"}
{"answers": {"text": ["middle of the 20th century", "20th century", "20th century", "middle of the 20th century", "20th century,"], "answer_start": [446, 460, 460, 446, 460]}, "prediction_text": "Around 1700"}
{"answers": {"text": ["Open Door Policy", "Open Door Policy", "Open Door Policy", "Open Door Policy", "Open Door Policy"], "answer_start": [561, 561, 561, 561, 561]}, "prediction_text": "\"Open Door Policy\""}
{"answers": {"text": ["1919", "1919", "1919", "1919", "1919"], "answer_start": [52, 52, 52, 52, 52]}, "prediction_text": "1919"}
{"answers": {"text": ["1999", "1999", "1999", "1999", "1999"], "answer_start": [89, 89, 89, 89, 89]}, "prediction_text": "1999"}
{"answers": {"text": ["historians", "historians", "historians", "historians", "historians"], "answer_start": [25, 25, 25, 25, 25]}, "prediction_text": "Historians"}
{"answers": {"text": ["the world's economy", "economy", "economy", "world's economy", "world's economy"], "answer_start": [723, 735, 735, 727, 727]}, "prediction_text": "World economy"}
{"answers": {"text": ["many imperial powers", "imperial powers", "imperial powers", "imperial powers"], "answer_start": [844, 849, 849, 849]}, "prediction_text": "Imperial powers"}
{"answers": {"text": ["economic growth", "economic growth", "economic growth", "economic growth", "economic growth"], "answer_start": [71, 71, 71, 71, 71]}, "prediction_text": "Economic growth"}
{"answers": {"text": ["mid-18th century", "18th century", "mid-18th century", "mid-18th century", "mid-18th century"], "answer_start": [239, 243, 239, 239, 239]}, "prediction_text": "Mid-18th century"}
{"answers": {"text": ["colonies", "collecting resources from colonies", "colonies", "colonies", "colonies"], "answer_start": [116, 90, 116, 116, 116]}, "prediction_text": "Colonies and political control"}
{"answers": {"text": ["the Mughal state", "Mughal state", "Mughal state", "Mughal state", "Mughal state"], "answer_start": [345, 349, 349, 349, 349]}, "prediction_text": "Mughal state"}
{"answers": {"text": ["communication", "communication", "communication", "communication", "communication"], "answer_start": [27, 27, 27, 27, 27]}, "prediction_text": "Chemists made deadly explosives, machinery was improved."}
{"answers": {"text": ["deadly explosives", "explosives", "explosives", "deadly explosives", "deadly explosives"], "answer_start": [122, 129, 129, 122, 122]}, "prediction_text": "Deadly explosives"}
{"answers": {"text": ["the machine gun", "machine gun", "machine gun", "machine gun", "machine gun"], "answer_start": [267, 271, 271, 271, 271]}, "prediction_text": "Machine gun"}
{"answers": {"text": ["arrows, swords, and leather shields", "arrows, swords, and leather shields", "arrows, swords, and leather shields", "arrows, swords, and leather shields", "arrows, swords, and leather shields"], "answer_start": [462, 462, 462, 462, 462]}, "prediction_text": "Arrows, swords, leather shields."}
{"answers": {"text": ["European", "European", "European", "Europe"], "answer_start": [348, 348, 348, 42]}, "prediction_text": "Europe"}
{"answers": {"text": ["British", "British", "British", "British"], "answer_start": [84, 84, 84, 84]}, "prediction_text": "Britain"}
{"answers": {"text": ["in the late 1870s", "1870s", "1870s", "late 1870s", "1870s"], "answer_start": [187, 199, 199, 194, 199]}, "prediction_text": "Late 1870s"}
{"answers": {"text": ["philanthropy", "idealism and philanthropy", "philanthropy", "idealism and philanthropy"], "answer_start": [471, 458, 471, 458]}, "prediction_text": "Idealized value of imperialism was a natural extension of capitalism."}
{"answers": {"text": ["to constantly expand investment", "to constantly expand investment", "to constantly expand investment, material resources and manpower", "need for capitalist economies to constantly expand investment, material resources and manpower", "need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion."], "answer_start": [1009, 1009, 1009, 979, 979]}, "prediction_text": "To expand investment, material resources, and manpower."}
{"answers": {"text": ["aristocracy", "aristocracy", "aristocracy", "aristocracy", "aristocracy"], "answer_start": [36, 36, 36, 36, 36]}, "prediction_text": "capitalism"}
{"answers": {"text": ["the 1950s", "1950s", "1950s", "1950s", "1950s"], "answer_start": [616, 620, 620, 620, 620]}, "prediction_text": "1950s"}
{"answers": {"text": ["before World War I", "World War I", "before World War I", "before World War I", "before World War I,"], "answer_start": [361, 368, 361, 361, 361]}, "prediction_text": "Before World War I"}
{"answers": {"text": ["disease", "disease", "disease", "disease", "disease"], "answer_start": [699, 699, 699, 699, 699]}, "prediction_text": "disease"}
{"answers": {"text": ["taxation", "removing its economic foundation", "domestic social reforms", "removing its economic foundation", "removing its economic foundation."], "answer_start": [808, 725, 646, 725, 725]}, "prediction_text": "State intervention through taxation"}
{"answers": {"text": ["environmental determinism", "environmental determinism", "environmental determinism", "environmental determinism", "environmental determinism"], "answer_start": [12, 12, 12, 12, 12]}, "prediction_text": "Environmental determinism"}
{"answers": {"text": ["the environment in which they lived", "environment in which they lived", "environment", "the environment in which they lived", "environment"], "answer_start": [191, 195, 195, 191, 195]}, "prediction_text": "The environment in which they lived"}
{"answers": {"text": ["less civilized", "less civilized", "less civilized", "less civilized", "less civilized"], "answer_start": [330, 330, 330, 330, 330]}, "prediction_text": "Less civilized"}
{"answers": {"text": ["Africa", "Africa", "Africa", "Africa", "Africa"], "answer_start": [509, 509, 509, 509, 509]}, "prediction_text": "Africa"}
{"answers": {"text": ["orientalism and tropicality", "orientalism and tropicality", "orientalism and tropicality", "orientalism and tropicality", "orientalism and tropicality."], "answer_start": [639, 639, 639, 639, 639]}, "prediction_text": "orientalism and tropicality."}
{"answers": {"text": ["geographic scholars", "geographic scholars", "geographic scholars", "geographic scholars", "geographic scholars"], "answer_start": [13, 13, 13, 13, 13]}, "prediction_text": "geographic scholars"}
{"answers": {"text": ["Northern Europe and the Mid-Atlantic", "Northern Europe and the Mid-Atlantic", "Northern Europe and the Mid-Atlantic", "Mid-Atlantic", "Northern Europe and the Mid-Atlantic"], "answer_start": [134, 134, 134, 158, 134]}, "prediction_text": "Northern Europe and Mid-Atlantic"}
{"answers": {"text": ["guidance", "guidance and intervention", "guidance and intervention", "guidance and intervention", "guidance"], "answer_start": [424, 424, 424, 424, 424]}, "prediction_text": "Guidance and intervention."}
{"answers": {"text": ["orientalism", "orientalism", "orientalism", "orientalism", "orientalism"], "answer_start": [590, 590, 590, 590, 590]}, "prediction_text": "Orientalism"}
{"answers": {"text": ["colonizing empires", "colonizing empires", "colonizing empires", "colonizing empires", "colonizing empires"], "answer_start": [39, 39, 39, 39, 39]}, "prediction_text": "European empire"}
{"answers": {"text": ["the sixteenth century", "sixteenth century", "sixteenth century", "sixteenth century", "sixteenth century"], "answer_start": [56, 60, 60, 60, 60]}, "prediction_text": "Sixteenth century"}
{"answers": {"text": ["1599", "1599", "1599", "1599", "1599"], "answer_start": [82, 82, 82, 82, 82]}, "prediction_text": "1599"}
{"answers": {"text": ["Queen Elizabeth", "Queen Elizabeth", "Queen Elizabeth", "Queen Elizabeth", "Queen Elizabeth"], "answer_start": [155, 155, 155, 155, 155]}, "prediction_text": "Queen Elizabeth"}
{"answers": {"text": ["exploitation", "political activity caused exploitation", "political activity caused exploitation", "exploitation", "exploitation"], "answer_start": [418, 392, 392, 418, 418]}, "prediction_text": "Political activity caused exploitation."}
{"answers": {"text": ["the Portuguese", "Portuguese", "Portuguese", "Portuguese", "Portuguese"], "answer_start": [322, 326, 326, 326, 326]}, "prediction_text": "Portugal"}
{"answers": {"text": ["1830", "1830", "1830", "1830", "1830"], "answer_start": [34, 34, 34, 34, 34]}, "prediction_text": "1830"}
{"answers": {"text": ["1850", "after 1850", "after 1850", "after 1850", "1850"], "answer_start": [98, 92, 92, 92, 98]}, "prediction_text": "1850"}
{"answers": {"text": ["Catholicism", "Catholicism", "Catholicism", "Catholicism", "Catholicism"], "answer_start": [609, 609, 609, 609, 609]}, "prediction_text": "Catholicism"}
{"answers": {"text": ["Africa", "North and West Africa", "North and West Africa", "North and West Africa, as well as South-East Asia, with other conquests in Central and East Africa, as well as the South Pacific", "North and West Africa, as well as South-East Asia,"], "answer_start": [144, 129, 129, 129, 129]}, "prediction_text": "North and West Africa"}
{"answers": {"text": ["when Germany started to build her own", "Germany started to build her own colonial empire", "when Germany started to build her own colonial empire", "when Germany started to build her own colonial empire", "when Germany started to build her own colonial empire."], "answer_start": [323, 328, 323, 323, 323]}, "prediction_text": "1850"}
{"answers": {"text": ["civilize the inferior", "civilize the inferior", "civilize the inferior", "to civilize the inferior", "civilize"], "answer_start": [290, 290, 290, 287, 290]}, "prediction_text": "Civilize the inferior"}
{"answers": {"text": ["assimilation", "Full citizenship rights", "assimilation", "assimilation", "Full citizenship rights"], "answer_start": [342, 314, 342, 342, 314]}, "prediction_text": "Assimilation rights"}
{"answers": {"text": ["small numbers of settlers", "sent small numbers of settlers to its colonies", "sent small numbers of settlers to its colonies,", "sent small numbers of settlers to its colonies", "small numbers of settlers"], "answer_start": [479, 474, 474, 474, 479]}, "prediction_text": "Small numbers of settlers"}
{"answers": {"text": ["Christianity and French culture", "Christianity", "Christianity and French culture", "Christianity and French culture"], "answer_start": [85, 85, 85, 85]}, "prediction_text": "Christianity and French culture"}
{"answers": {"text": ["Algeria", "Algeria", "Algeria", "Algeria"], "answer_start": [557, 557, 557, 557]}, "prediction_text": "Algeria"}
{"answers": {"text": ["overseas colonies", "overseas colonies", "overseas colonies", "overseas colonies", "overseas colonies"], "answer_start": [64, 64, 64, 64, 64]}, "prediction_text": "Overseas colonies"}
{"answers": {"text": ["anti-colonial movements", "anti-colonial movements", "anti-colonial movements", "anti-colonial movements", "anti-colonial movements"], "answer_start": [153, 153, 153, 153, 153]}, "prediction_text": "Anti-colonial movements"}
{"answers": {"text": ["Vietnam", "Vietnam", "Vietnam", "Vietnam", "Vietnam"], "answer_start": [247, 247, 247, 247, 247]}, "prediction_text": "Algeria"}
{"answers": {"text": ["Algeria", "Algeria", "Algeria", "Algeria", "Algeria"], "answer_start": [297, 297, 297, 297, 297]}, "prediction_text": "Algeria"}
{"answers": {"text": ["1960", "1960", "1960", "1960", "1960"], "answer_start": [525, 525, 525, 525, 525]}, "prediction_text": "By 1960"}
{"answers": {"text": ["Scandinavia", "Scandinavia and northern Europe", "Scandinavia and northern Europe", "Scandinavia and northern Europe", "Scandinavia and northern Europe,"], "answer_start": [33, 33, 33, 33, 33]}, "prediction_text": "Scandinavia and northern Europe"}
{"answers": {"text": ["Muslim Iberia", "Muslim Iberia", "Muslim Iberia", "Muslim Iberia", "Muslim Iberia"], "answer_start": [738, 738, 738, 738, 738]}, "prediction_text": "Central, western, and southern Europe"}
{"answers": {"text": ["middle period of classical antiquity", "the middle period of classical antiquity", "the middle period of classical antiquity", "the middle period of classical antiquity", "middle period of classical antiquity"], "answer_start": [137, 133, 133, 133, 137]}, "prediction_text": "From their original homelands in Scandinavia and northern Europe."}
{"answers": {"text": ["800 CE", "in late antiquity", "late antiquity", "late antiquity", "by 800 CE"], "answer_start": [254, 191, 194, 194, 251]}, "prediction_text": "Late antiquity"}
{"answers": {"text": ["central Europe", "amorphous area of central Europe", "an amorphous area of central Europe", "central Europe", "amorphous area of central Europe."], "answer_start": [906, 888, 885, 906, 888]}, "prediction_text": "Central Europe"}
{"answers": {"text": ["late 19th century", "late 19th century", "19th century", "late 19th century", "late 19th century."], "answer_start": [149, 149, 154, 149, 149]}, "prediction_text": "Late 19th century"}
{"answers": {"text": ["1862", "1862", "1862", "1862", "1862"], "answer_start": [712, 712, 712, 712, 712]}, "prediction_text": "1862"}
{"answers": {"text": ["after the Franco-German War", "after the Franco-German War", "after the Franco-German War", "after the Franco-German War", "after the Franco-German War,"], "answer_start": [638, 638, 638, 638, 638]}, "prediction_text": "1872"}
{"answers": {"text": ["Napoleon", "Napoleon", "the defeat of Napoleon", "Napoleon", "defeat of Napoleon"], "answer_start": [356, 356, 342, 356, 346]}, "prediction_text": "Napoleon"}
{"answers": {"text": ["Europe", "Europe", "Europe", "Europe", "Europe itself."], "answer_start": [1092, 1092, 1092, 1092, 1092]}, "prediction_text": "Europe itself"}
{"answers": {"text": ["the South Pacific", "South Pacific", "South Pacific", "South Pacific", "South Pacific"], "answer_start": [75, 79, 79, 79, 79]}, "prediction_text": "South Pacific"}
{"answers": {"text": ["prestige", "prestige", "prestige", "prestige"], "answer_start": [329, 329, 329, 329]}, "prediction_text": "prestige"}
{"answers": {"text": ["1884", "1884", "1884", "1884", "1884"], "answer_start": [526, 526, 526, 526, 526]}, "prediction_text": "1884"}
{"answers": {"text": ["New Guinea", "German New Guinea", "German New Guinea", "German New Guinea", "German New Guinea"], "answer_start": [512, 505, 505, 505, 505]}, "prediction_text": "Friedrichsruh"}
{"answers": {"text": ["Hamburg merchants and traders", "Hamburg merchants and traders", "Hamburg merchants and traders", "Hamburg merchants and traders"], "answer_start": [360, 360, 360, 360]}, "prediction_text": "Hamburg merchants and traders"}
{"answers": {"text": ["Japan took part of Sakhalin Island", "Japan took part of Sakhalin Island from Russia", "Japan took part of Sakhalin Island from Russia", "Japan took part of Sakhalin Island from Russia", "Japan took part of Sakhalin Island from Russia"], "answer_start": [114, 114, 114, 114, 114]}, "prediction_text": "Japan took part of Sakhalin Island."}
{"answers": {"text": ["1894", "1894", "1894", "1894", "1894"], "answer_start": [38, 38, 38, 38, 38]}, "prediction_text": "1894"}
{"answers": {"text": ["Thailand", "Thailand", "Thailand", "Thailand", "Thailand"], "answer_start": [821, 821, 821, 821, 821]}, "prediction_text": "Thailand"}
{"answers": {"text": ["Manchuria", "Manchuria", "Manchuria", "Manchuria", "Manchuria"], "answer_start": [484, 484, 484, 484, 484]}, "prediction_text": "Manchuria"}
{"answers": {"text": ["China", "People\u2019s Republic of China", "the People\u2019s Republic of China", "People\u2019s Republic of China", "People\u2019s Republic of China"], "answer_start": [732, 711, 707, 711, 711]}, "prediction_text": "Soviet Union and China"}
{"answers": {"text": ["1932", "1932", "1932", "1932", "1932"], "answer_start": [496, 496, 496, 496, 496]}, "prediction_text": "1932"}
{"answers": {"text": ["Lenin", "Lenin", "Lenin", "Lenin", "Lenin"], "answer_start": [153, 153, 153, 153, 153]}, "prediction_text": "Lenin"}
{"answers": {"text": ["Eastern Europe", "Eastern Europe", "in areas its forces occupied in Eastern Europe", "1919\u201320", "Eastern Europe"], "answer_start": [670, 670, 638, 604, 670]}, "prediction_text": "Eastern Europe"}
{"answers": {"text": ["Bolshevik leaders", "Bolshevik leaders", "Bolshevik leaders", "Bolshevik leaders"], "answer_start": [0, 0, 0, 0]}, "prediction_text": "Bolshevik leaders"}
{"answers": {"text": ["a world revolution", "world revolution", "a world revolution", "a world revolution", "world revolution."], "answer_start": [90, 92, 90, 90, 92]}, "prediction_text": "A world revolution"}
{"answers": {"text": ["Lenin", "Lenin", "Lenin", "Lenin", "Lenin"], "answer_start": [110, 110, 110, 110, 110]}, "prediction_text": "Joseph Stalin"}
{"answers": {"text": ["Mao Zedong", "Mao Zedong", "Mao Zedong", "Mao Zedong", "Sultan Galiev and Vasyl Shakhrai"], "answer_start": [1519, 1519, 1519, 1519, 1817]}, "prediction_text": "Mao Zedong"}
{"answers": {"text": ["Nikita Khrushchev", "Nikita Khrushchev", "Nikita Khrushchev", "Nikita Khrushchev", "Khrushchev"], "answer_start": [751, 751, 751, 751, 758]}, "prediction_text": "Nikita Khrushchev"}
{"answers": {"text": ["socialism in one country", "socialism", "socialism", "socialism", "socialism in one country'"], "answer_start": [281, 281, 281, 281, 281]}, "prediction_text": "Socialism in one country"}
{"answers": {"text": ["mercantilism", "mercantilism", "mercantilism", "mercantilism", "mercantilism"], "answer_start": [38, 38, 38, 38, 38]}, "prediction_text": "Mercantilism"}
{"answers": {"text": ["1776", "1776", "1776", "1776", "1776"], "answer_start": [205, 205, 205, 205, 205]}, "prediction_text": "1776"}
{"answers": {"text": ["free trade", "free trade", "free trade", "free trade", "free trade"], "answer_start": [500, 500, 500, 500, 500]}, "prediction_text": "Free trade"}
{"answers": {"text": ["about 1820", "1820", "1820", "1820", "1820"], "answer_start": [424, 430, 430, 430, 430]}, "prediction_text": "About 1820"}
{"answers": {"text": ["1815", "1815", "1815", "1815", "1815"], "answer_start": [735, 735, 735, 735, 735]}, "prediction_text": "1815"}
{"answers": {"text": ["The British Empire", "British Empire", "The British", "British", "British"], "answer_start": [494, 498, 122, 498, 498]}, "prediction_text": "Britain"}
{"answers": {"text": ["pseudo-sciences", "pseudo-sciences", "pseudo-sciences", "British Empire", "pseudo"], "answer_start": [258, 258, 258, 498, 258]}, "prediction_text": "Social Darwinism and theories of race."}
{"answers": {"text": ["The British spirit of imperialism", "imperialism", "Social Darwinism", "imperialism"], "answer_start": [122, 144, 277, 144]}, "prediction_text": "British Empire"}
{"answers": {"text": ["Middle East", "Middle East", "the Middle East", "Africa", "Middle East."], "answer_start": [109, 109, 105, 66, 109]}, "prediction_text": "Africa"}
{"answers": {"text": ["the Monroe Doctrine", "through policies", "policies such as the Monroe Doctrine", "policies such as the Monroe Doctrine", "Monroe Doctrine"], "answer_start": [149, 124, 132, 132, 153]}, "prediction_text": "Theodore Roosevelt's interventionism and Wilson's mission to \"make the world safe for democracy\" changed all this."}
{"answers": {"text": ["interventionism", ".", "interventionism", "interventionism", "interventionism"], "answer_start": [268, 1200, 268, 268, 268]}, "prediction_text": "Monroe Doctrine"}
{"answers": {"text": ["a war erupted", "a war erupted", "war", "war", "war"], "answer_start": [727, 727, 729, 729, 729]}, "prediction_text": "American occupation caused deaths."}
{"answers": {"text": ["the Philippines", "Philippines", "Philippines", "Philippines", "Philippines"], "answer_start": [685, 689, 689, 689, 689]}, "prediction_text": "Philippines"}
{"answers": {"text": ["a \"racket\"", "racket", "racket", "a \"racket\"", "racket"], "answer_start": [979, 982, 982, 979, 982]}, "prediction_text": "A \"racket\""}
{"answers": {"text": ["Isiah Bowman", "Isiah Bowman", "Isiah Bowman", "Isiah Bowman", "Isiah Bowman"], "answer_start": [103, 103, 103, 103, 103]}, "prediction_text": "Isiah Bowman"}
{"answers": {"text": ["1917", "1917", "1917", "1917", "1917"], "answer_start": [208, 277, 208, 208, 208]}, "prediction_text": "1917"}
{"answers": {"text": ["American delegation from the Paris Peace Conference", "American delegation from the Paris Peace Conference", "the American delegation from the Paris Peace Conference", "American delegation from the Paris Peace Conference", "American delegation from the Paris Peace Conference"], "answer_start": [336, 336, 332, 336, 336]}, "prediction_text": "Isiah Bowman"}
{"answers": {"text": ["U.S authorship of a 'new world'", "allow for U.S authorship of a 'new world' which was to be characterized by geographical order", "allow for U.S authorship of a 'new world' which was to be characterized by geographical order", "allow for U.S authorship of a 'new world'", "U.S authorship of a 'new world'"], "answer_start": [459, 449, 449, 449, 459]}, "prediction_text": "A new world"}
{"answers": {"text": ["Wilson's geographer", "Wilson's geographer", "Wilson's geographer", "Wilson's geographer", "Wilson's geographer."], "answer_start": [623, 623, 623, 623, 623]}, "prediction_text": "Isiah Bowman"}
{"answers": {"text": ["internal strife", "internal strife", "internal strife", "internal strife", "internal strife"], "answer_start": [24, 24, 24, 24, 24]}, "prediction_text": "Internal strife between various people groups"}
{"answers": {"text": ["\"internal colonialism\"", "internal colonialism", "internal colonialism", "internal colonialism", "internal"], "answer_start": [560, 561, 561, 561, 116]}, "prediction_text": "\"internal colonialism\""}
{"answers": {"text": ["12 to 15 million", "12 to 15 million", "12 to 15 million", "12 to 15 million", "12 to 15 million"], "answer_start": [661, 661, 661, 661, 661]}, "prediction_text": "12 to 15 million"}
{"answers": {"text": ["the contemporary Orient", "the contemporary Orient", "the contemporary Orient", "contemporary Orient", "contemporary Orient, \""], "answer_start": [1213, 1213, 1213, 1217, 1217]}, "prediction_text": "Indigenous peoples and African-Americans."}
{"answers": {"text": ["1923", "1923", "1923", "1923", "1923"], "answer_start": [66, 66, 66, 66, 66]}, "prediction_text": "16th and 17th centuries"}
{"answers": {"text": ["Suleiman the Magnificent", "Suleiman the Magnificent", "Suleiman the Magnificent", "Suleiman the Magnificent", "Suleiman the Magnificent,"], "answer_start": [168, 168, 168, 168, 168]}, "prediction_text": "Suleiman the Magnificent"}
{"answers": {"text": ["32", "32", "32", "32", "32"], "answer_start": [425, 425, 425, 425, 425]}, "prediction_text": "32 provinces"}
{"answers": {"text": ["Europe", "Europe", "Europe", "Europe", "Europe"], "answer_start": [293, 293, 293, 293, 293]}, "prediction_text": "The Horn of Africa"}
{"answers": {"text": ["During the 16th and 17th centuries", "17th century", "the 16th and 17th centuries", "16th and 17th centuries", "16th and 17th centuries"], "answer_start": [72, 391, 79, 83, 83]}, "prediction_text": "16th and 17th centuries"}
{"answers": {"text": ["Istanbul", "Istanbul", "Istanbul", "Istanbul", "Istanbul"], "answer_start": [5, 5, 5, 5, 5]}, "prediction_text": "Istanbul"}
{"answers": {"text": ["Germany", "Germany", "Germany", "Germany", "Germany"], "answer_start": [358, 358, 358, 358, 358]}, "prediction_text": "Germany"}
{"answers": {"text": ["World War I", "creation of modern Balkan and Middle Eastern states", "the creation of modern Balkan and Middle Eastern states", "creation of modern Balkan and Middle Eastern states", "creation of modern Balkan and Middle Eastern states"], "answer_start": [493, 609, 605, 609, 609]}, "prediction_text": "dissolved in the aftermath of World War I."}
{"answers": {"text": ["Turkey", "Turkey", "Turkey", "Turkey", "Turkey"], "answer_start": [551, 551, 551, 551, 551]}, "prediction_text": "Turkey"}
{"answers": {"text": ["United Methodist Church", "United Methodist Church (UMC)", "United Methodist Church"], "answer_start": [4, 4, 4]}, "prediction_text": "United Methodist Church"}
{"answers": {"text": ["mainline Protestant Methodist denomination", "is a mainline Protestant Methodist denomination", "a mainline Protestant Methodist denomination"], "answer_start": [39, 34, 37]}, "prediction_text": "A mainline Protestant Methodist denomination."}
{"answers": {"text": ["1968", "mainline Protestant Methodist denomination", "1968"], "answer_start": [167, 39, 167]}, "prediction_text": "1968"}
{"answers": {"text": ["union of the Methodist Church (USA) and the Evangelical United Brethren Church", "John and Charles Wesley in England", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church"], "answer_start": [179, 316, 175]}, "prediction_text": "John and Charles Wesley"}
{"answers": {"text": ["Wesleyan", "orientation is decidedly Wesleyan", "Wesleyan"], "answer_start": [463, 438, 463]}, "prediction_text": "Wesleyan"}
{"answers": {"text": ["United Methodist Church", "The United Methodist Church", "The United Methodist Church"], "answer_start": [4, 0, 0]}, "prediction_text": "United Methodist Church"}
{"answers": {"text": ["80 million", "80 million adherents", "80 million"], "answer_start": [117, 117, 117]}, "prediction_text": "Approximately 80 million"}
{"answers": {"text": ["mainline Protestant denomination", "Protestant denomination", "mainline Protestant denomination"], "answer_start": [207, 216, 207]}, "prediction_text": "Protestant denomination"}
{"answers": {"text": ["3.6%", "3.6% of the U.S population, or", "3.6%"], "answer_start": [638, 638, 638]}, "prediction_text": "3.6%"}
{"answers": {"text": ["mid-18th century", "began in the mid-18th century within the Church of England.", "mid-18th century"], "answer_start": [73, 60, 73]}, "prediction_text": "Mid-18th century"}
{"answers": {"text": ["within the Church of England", "the Church of England.", "the Church of England"], "answer_start": [90, 97, 97]}, "prediction_text": "In the Church of England"}
{"answers": {"text": ["being methodical and exceptionally detailed in their Bible study", "They focused on Bible study, methodical study of scripture and living a holy life", "being methodical and exceptionally detailed in their Bible study, opinions and disciplined lifestyle."], "answer_start": [411, 245, 411]}, "prediction_text": "Methodists were methodical and detailed in their Bible study."}
{"answers": {"text": ["1735", "In 1735", "1735"], "answer_start": [3, 0, 3]}, "prediction_text": "1735"}
{"answers": {"text": ["colony of Georgia", "the colony of Georgia", "America"], "answer_start": [100, 96, 41]}, "prediction_text": "Georgia"}
{"answers": {"text": ["American Indians", "to the American Indians", "American Indians"], "answer_start": [76, 69, 76]}, "prediction_text": "American Indians"}
{"answers": {"text": ["salvation by God's grace", "plain, old, Bible Christianity\"", "salvation by God's grace"], "answer_start": [629, 421, 629]}, "prediction_text": "Salvation by God's grace"}
{"answers": {"text": ["American Revolution", "the American Revolution", "the American Revolution"], "answer_start": [94, 90, 90]}, "prediction_text": "American Revolution"}
{"answers": {"text": ["1784", "In 1784", "1784"], "answer_start": [231, 228, 231]}, "prediction_text": "1784"}
{"answers": {"text": ["Thomas Coke", "Thomas Coke", "Thomas Coke"], "answer_start": [390, 390, 390]}, "prediction_text": "Thomas Coke"}
{"answers": {"text": ["Lovely Lane Methodist Church", "held at the Lovely Lane Methodist Church", "Lovely Lane Methodist Church"], "answer_start": [736, 724, 736]}, "prediction_text": "Lovely Lane Methodist Church"}
{"answers": {"text": ["Lovely Lane Methodist Church", "Lovely Lane Methodist Church,", "Lovely Lane Methodist Church"], "answer_start": [736, 736, 736]}, "prediction_text": "Lovely Lane Methodist Church"}
{"answers": {"text": ["St. George's United Methodist Church", "St. George's United Methodist Church,", "St. George's United Methodist Church"], "answer_start": [0, 0, 0]}, "prediction_text": "St. George's United Methodist Church"}
{"answers": {"text": ["St. George's United Methodist Church", "St. George's United Methodist Church", "St. George's United Methodist Church"], "answer_start": [0, 0, 0]}, "prediction_text": "St. George's United Methodist Church"}
{"answers": {"text": ["1767", "congregation was founded in 1767,", "1767"], "answer_start": [252, 224, 252]}, "prediction_text": "1767"}
{"answers": {"text": ["sail loft on Dock Street", "meeting initially in a sail loft on Dock Street", "Dock Street"], "answer_start": [281, 258, 294]}, "prediction_text": "Dock Street"}
{"answers": {"text": ["1784", "the Methodist Episcopal Church was not founded until 1784.", "1784"], "answer_start": [553, 500, 553]}, "prediction_text": "1784"}
{"answers": {"text": ["Richard Allen and Absalom Jones", "Richard Allen", "Richard Allen and Absalom Jones"], "answer_start": [0, 0, 0]}, "prediction_text": "Richard Allen and Absalom Jones"}
{"answers": {"text": ["St. George's Church", "St. George's Church", "St. George's Church"], "answer_start": [123, 123, 123]}, "prediction_text": "St. George's Church"}
{"answers": {"text": ["1784", "1784", "1784"], "answer_start": [146, 146, 146]}, "prediction_text": "1784"}
{"answers": {"text": ["1830", "In 1830", "1830"], "answer_start": [160, 157, 160]}, "prediction_text": "1830"}
{"answers": {"text": ["issue of laity having a voice and vote in the administration of the church", "over the issue of laity having a voice and vote in the administration of the church", "over the issue of laity having a voice and vote in the administration of the church"], "answer_start": [249, 240, 240]}, "prediction_text": "Over slavery and bishops' power."}
{"answers": {"text": ["1844", "In 1844,", "1844"], "answer_start": [442, 439, 442]}, "prediction_text": "1844"}
{"answers": {"text": ["because of tensions over slavery and the power of bishops in the denomination", "because of tensions over slavery and the power of bishops in the denomination.", "tensions over slavery and the power of bishops in the denomination"], "answer_start": [532, 532, 543]}, "prediction_text": "Strictly for slavery and bishops' power."}
{"answers": {"text": ["April 23, 1968", "On April 23, 1968", "1968"], "answer_start": [3, 0, 13]}, "prediction_text": "April 23, 1968"}
{"answers": {"text": ["constituting General Conference in Dallas, Texas", "the constituting General Conference in Dallas, Texas.", "Dallas"], "answer_start": [233, 229, 268]}, "prediction_text": "Dallas, Texas"}
{"answers": {"text": ["Bishop Lloyd Christ Wicke", "Bishop Lloyd Christ", "Bishop Reuben H. Mueller"], "answer_start": [186, 186, 119]}, "prediction_text": "Bishop Lloyd Christ Wicke"}
{"answers": {"text": ["holy catholic (or universal) church", "the holy catholic (or universal) church", "holy catholic (or universal) church"], "answer_start": [65, 61, 65]}, "prediction_text": "Holy catholic church"}
{"answers": {"text": ["The Book of Discipline", ". The Book of Discipline", "Book of Discipline"], "answer_start": [243, 241, 247]}, "prediction_text": "Book of Discipline"}
{"answers": {"text": ["meaning that all who are truly believers in every age belong to the holy Church invisible", "meaning that all who are truly believers in every age belong to the holy Church invisible, while the United Methodist Church is a branch of the Church visible,", "all who are truly believers in every age belong to the holy Church invisible, while the United Methodist Church is a branch of the Church visible,"], "answer_start": [414, 414, 427]}, "prediction_text": "All believers belong to the holy Church invisible."}
{"answers": {"text": ["result of the American Revolution", "As a result of the American Revolution,", "the American Revolution"], "answer_start": [130, 125, 140]}, "prediction_text": "American Revolution"}
{"answers": {"text": ["Dr. Thomas Coke", "Dr. Thomas Coke", "Dr. Thomas Coke"], "answer_start": [317, 317, 317]}, "prediction_text": "Coke"}
{"answers": {"text": ["Thomas Vasey and Richard Whatcoat.", "Thomas Vasey and Richard Whatcoat", "Thomas Vasey and Richard Whatcoat"], "answer_start": [282, 282, 282]}, "prediction_text": "Thomas Vasey and Richard Whatcoat"}
{"answers": {"text": ["1968", "1968", "1968"], "answer_start": [529, 529, 529]}, "prediction_text": "1968"}
{"answers": {"text": ["John Wesley and Charles Wesley", "John Wesley and Charles Wesley", "John Wesley and Charles Wesley"], "answer_start": [316, 316, 316]}, "prediction_text": "John Wesley and Charles Wesley"}
{"answers": {"text": ["Albert C. Outler", "theologian Albert C. Outler", "Albert C. Outler"], "answer_start": [546, 535, 546]}, "prediction_text": "Albert C. Outler"}
{"answers": {"text": ["Albert C. Outler", "Albert C. Outler"], "answer_start": [546, 546]}, "prediction_text": "Albert C. Outler"}
{"answers": {"text": ["Prevenient grace", "Prevenient grace,", "Prevenient grace"], "answer_start": [0, 0, 0]}, "prediction_text": "Prevenient grace"}
{"answers": {"text": ["Prevenient grace", "God", "Prevenient grace"], "answer_start": [0, 225, 0]}, "prediction_text": "God's grace"}
{"answers": {"text": ["the grace that \"goes before\" us", "It is that power which enables us to love and motivates us to seek a relationship with God through Jesus Christ.", "that power which enables us to love and motivates us to seek a relationship with God through Jesus Christ."], "answer_start": [21, 78, 84]}, "prediction_text": "Power to love and seek God through Jesus Christ."}
{"answers": {"text": ["Prevenient grace", "sin", "sin"], "answer_start": [415, 249, 456]}, "prediction_text": "Sin before God"}
{"answers": {"text": ["Justifying Grace or Accepting Grace", "Justifying Grace or Accepting Grace", "Justifying Grace"], "answer_start": [0, 0, 0]}, "prediction_text": "Grace offered by God to all people."}
{"answers": {"text": ["justifying grace", "The justifying grace", "justifying grace"], "answer_start": [339, 335, 339]}, "prediction_text": "justifying grace"}
{"answers": {"text": ["conversion", "conversion", "conversion"], "answer_start": [494, 494, 494]}, "prediction_text": "Conversion"}
{"answers": {"text": ["conversion", "conversion, \"accepting Jesus as your personal Lord and Savior,\" or being \"born again", "justifying grace"], "answer_start": [494, 494, 460]}, "prediction_text": "New Birth"}
{"answers": {"text": ["New Birth", "John Wesley originally called this experience the New Birth.", "New Birth"], "answer_start": [631, 581, 631]}, "prediction_text": "New Birth"}
{"answers": {"text": ["grace of God which sustains the believers in the journey toward Christian Perfection", "is that grace of God which sustains the believers in the journey toward Christian Perfection", "that grace of God which sustains the believers in the journey toward Christian Perfection"], "answer_start": [26, 18, 21]}, "prediction_text": "Grace of God that sustains believers in the journey toward Christian Perfection."}
{"answers": {"text": ["Sanctifying Grace", "a genuine love of God with heart, soul, mind, and strength,", "Sanctifying Grace"], "answer_start": [0, 112, 0]}, "prediction_text": "Sanctifying Grace"}
{"answers": {"text": ["a genuine love of God with heart, soul, mind, and strength, and a genuine love of our neighbors as ourselves", "leading a Spirit-filled and Christ-like life aimed toward love", "a genuine love of God with heart, soul, mind"], "answer_start": [112, 272, 112]}, "prediction_text": "A genuine love of God with heart, soul, mind, and strength."}
{"answers": {"text": ["Christian Perfection", "Christian Perfection", "Christian Perfection"], "answer_start": [90, 90, 90]}, "prediction_text": "Sanctifying Grace"}
{"answers": {"text": ["Wesleyan theology", "Wesleyan theology", "Wesleyan theology"], "answer_start": [0, 0, 0]}, "prediction_text": "Wesleyan theology"}
{"answers": {"text": ["prima scriptura", "Wesleyan theology s", "prima scriptura"], "answer_start": [383, 0, 383]}, "prediction_text": "Prima scriptura"}
{"answers": {"text": ["UMC", "the UMC", "the UMC"], "answer_start": [726, 722, 722]}, "prediction_text": "United Methodist Church"}
{"answers": {"text": ["Book of Discipline", "Book of Discipline", "The Book of Discipline"], "answer_start": [619, 619, 615]}, "prediction_text": "The United Methodist Church states that it is at once \"catholic, evangelical, and reformed.\""}
{"answers": {"text": ["2008", "2008", "2008"], "answer_start": [604, 604, 604]}, "prediction_text": "2008 General Conference"}
{"answers": {"text": ["pro-choice", "pro-choice", "pro-choice"], "answer_start": [502, 502, 502]}, "prediction_text": "Pro-life"}
{"answers": {"text": ["Religious Coalition for Reproductive Choice", "Religious Coalition for Reproductive Choice.", "the Religious Coalition for Reproductive Choice"], "answer_start": [552, 552, 548]}, "prediction_text": "Religious Coalition for Reproductive Choice"}
{"answers": {"text": ["The General Board of Church and Society, and the United Methodist Women", "two official bodies of the United Methodist Church", "The General Board of Church and Society, and the United Methodist Women"], "answer_start": [544, 410, 544]}, "prediction_text": "General Board of Church and Society, United Methodist Women"}
{"answers": {"text": ["all women", "unacceptable pregnancy. In", "women"], "answer_start": [822, 166, 826]}, "prediction_text": "All women"}
{"answers": {"text": ["the mother", "supportive ministry with all women,", "the mother, for whom devastating damage may result from an unacceptable pregnancy"], "answer_start": [107, 797, 107]}, "prediction_text": "Mother"}
{"answers": {"text": ["Taskforce of United Methodists on Abortion and Sexuality (", "United Methodists on Abortion and Sexuality (TUMAS)", "Members of the United Methodist Church"], "answer_start": [103, 116, 0]}, "prediction_text": "Taskforce of United Methodist Church on Abortion and Sexuality"}
{"answers": {"text": ["2012", "2012", "2012"], "answer_start": [383, 383, 383]}, "prediction_text": "May 2012"}
{"answers": {"text": ["Rev. Paul T. Stallsworth", "Rev. Paul T. Stallsworth", "Rev. Paul T. Stallsworth"], "answer_start": [507, 507, 507]}, "prediction_text": "Rev. Paul Stallsworth"}
{"answers": {"text": ["temperance movement", "temperance movement.", "the temperance movement"], "answer_start": [53, 53, 49]}, "prediction_text": "The temperance movement"}
{"answers": {"text": ["2011 and 2012", "in 2011 and 2012", "2011 and 2012"], "answer_start": [784, 781, 784]}, "prediction_text": "2011 and 2012."}
{"answers": {"text": ["The Use of Money", "The Use of Money,", "\"The Use of Money,\""], "answer_start": [148, 148, 147]}, "prediction_text": "\"The Use of Money\""}
{"answers": {"text": ["unfermented grape juice", "uses unfermented grape juice", "unfermented grape juice"], "answer_start": [548, 543, 548]}, "prediction_text": "Unfermented grape juice"}
{"answers": {"text": ["capital punishment", "capital punishment", "capital punishment"], "answer_start": [75, 75, 75]}, "prediction_text": "Capital punishment"}
{"answers": {"text": ["John 8:7.", "John 8:7", "John 8:7"], "answer_start": [555, 555, 555]}, "prediction_text": "John 8:7"}
{"answers": {"text": ["Matthew 5:38-39", "Matthew 5:38-39", "Matthew 5:38-39"], "answer_start": [504, 504, 504]}, "prediction_text": "Matthew 5:38-39"}
{"answers": {"text": ["The General Conference", "The General Conference of the United Methodist Church", "The General Conference"], "answer_start": [565, 565, 565]}, "prediction_text": "Oppose capital punishment"}
{"answers": {"text": ["same-sex unions", "prohibits the celebration of same-sex unions.", "same-sex"], "answer_start": [70, 41, 70]}, "prediction_text": "Same-sex unions"}
{"answers": {"text": ["1999", "1999", "1999"], "answer_start": [161, 161, 161]}, "prediction_text": "1999"}
{"answers": {"text": ["2016", "2016", "2016"], "answer_start": [781, 781, 781]}, "prediction_text": "2016"}
{"answers": {"text": ["Connectional Table", "the Connectional Table", "the Connectional Table"], "answer_start": [428, 424, 424]}, "prediction_text": "Connectional Table"}
{"answers": {"text": ["LGBT", "LGBT community", "LGBT community"], "answer_start": [380, 380, 380]}, "prediction_text": "LGBT community"}
{"answers": {"text": ["same-gender marriages with resolutions", "permit ministers to officiate same-sex weddings", "same-gender marriages"], "answer_start": [724, 551, 724]}, "prediction_text": "Same-gender marriages"}
{"answers": {"text": ["1987", "1987", "1987"], "answer_start": [3, 3, 3]}, "prediction_text": "1987"}
{"answers": {"text": ["2005", "2005", "2005"], "answer_start": [150, 150, 150]}, "prediction_text": "2005"}
{"answers": {"text": ["Baltimore-Washington Conference of the UMC", "The Baltimore-Washington Conference of the UMC", "The Baltimore-Washington Conference of the UMC"], "answer_start": [953, 949, 949]}, "prediction_text": "Baltimore-Washington Conference"}
{"answers": {"text": ["conscription", "conscription", "conscription"], "answer_start": [36, 36, 36]}, "prediction_text": "Conscription"}
{"answers": {"text": ["the way of military action", "persons who conscientiously oppose all war", "military action"], "answer_start": [592, 162, 603]}, "prediction_text": "Military action, nor the way of inaction."}
{"answers": {"text": ["all war", "war", "war"], "answer_start": [197, 201, 201]}, "prediction_text": "War or any particular war"}
{"answers": {"text": ["Christ's message and teachings", "is incompatible with Christ's message and teachings.", "Christ's message and teachings"], "answer_start": [68, 47, 68]}, "prediction_text": "Christ's message and teachings."}
{"answers": {"text": ["instrument of national foreign policy", "national foreign policy", "war"], "answer_start": [140, 154, 130]}, "prediction_text": "National foreign policy"}
{"answers": {"text": ["general and complete disarmament", "evils as genocide, brutal suppression of human rights, and unprovoked international aggression", "general and complete disarmament"], "answer_start": [845, 242, 845]}, "prediction_text": "General and complete disarmament."}
{"answers": {"text": ["The Sexual Ethics Task Force of The United Methodist Church", "The Sexual Ethics Task Force of The United Methodist Church", "The Sexual Ethics Task Force of The United Methodist Church"], "answer_start": [195, 195, 195]}, "prediction_text": "Sexual Ethics Task Force"}
{"answers": {"text": ["violence, degradation, exploitation, and coercion", "about violence, degradation, exploitation, and coercion\"", "violence, degradation, exploitation, and coercion"], "answer_start": [63, 57, 63]}, "prediction_text": "Violence, degradation, exploitation, and coercion."}
{"answers": {"text": ["girls and women", "relationships with parishioners and family, and their perceptions of girls and women.\"", "girls and women"], "answer_start": [536, 467, 536]}, "prediction_text": "Girls and women"}
{"answers": {"text": ["IVF", "created for IVF that remain after the procreative efforts have ceased,", "research"], "answer_start": [69, 57, 285]}, "prediction_text": "IVF"}
{"answers": {"text": ["stem cells", "stem cells", "stem cells"], "answer_start": [485, 485, 485]}, "prediction_text": "Adult stem cells"}
{"answers": {"text": ["research", "sake of research", "research"], "answer_start": [377, 369, 377]}, "prediction_text": "Research"}
{"answers": {"text": ["Sunday Service of the Methodists in North America", "Sunday Service of the Methodists in North America", "the Sunday Service of the Methodists in North America"], "answer_start": [402, 402, 398]}, "prediction_text": "Sunday Service of the Methodists"}
{"answers": {"text": ["When the Methodists in America were separated from the Church of England", "When the Methodists in America were separated from the Church of England,", "When the Methodists in America were separated from the Church of England"], "answer_start": [241, 241, 241]}, "prediction_text": "In America"}
{"answers": {"text": ["The Book of Common Prayer", "Book of Common Prayer", "The Book of Common Prayer"], "answer_start": [365, 369, 365]}, "prediction_text": "The Book of Common Prayer"}
{"answers": {"text": ["Africa", "The United Methodist Church in Africa.", "Africa"], "answer_start": [346, 315, 346]}, "prediction_text": "Africa"}
{"answers": {"text": ["Book of Common Prayer", "United Methodist Book of Worship", "Book of Common Prayer."], "answer_start": [750, 643, 750]}, "prediction_text": "Anglican tradition's Book of Common Prayer"}
{"answers": {"text": ["anointing with oil", "anointing with oil.", "anointing with oil"], "answer_start": [404, 404, 404]}, "prediction_text": "Anointing with oil"}
{"answers": {"text": ["Methodist institutions", "Methodist institutions", "Methodist institutions"], "answer_start": [0, 0, 0]}, "prediction_text": "Methodist institutions"}
{"answers": {"text": ["William Booth", "William Booth", "William Booth"], "answer_start": [528, 528, 528]}, "prediction_text": "William Booth"}
{"answers": {"text": ["John Wesley", "John Wesley", "John Wesley"], "answer_start": [612, 612, 612]}, "prediction_text": "John Wesley"}
{"answers": {"text": ["United Methodist Church", "The United Methodist Church", "The United Methodist Church"], "answer_start": [4, 0, 0]}, "prediction_text": "United Methodist Church"}
{"answers": {"text": ["General Conference", "General Conference a", "the General Conference"], "answer_start": [91, 91, 87]}, "prediction_text": "General Conference"}
{"answers": {"text": ["The Book of Discipline", "The Book of Discipline", "The Book of Discipline"], "answer_start": [279, 279, 279]}, "prediction_text": "The Book of Discipline"}
{"answers": {"text": ["General Conference", "General Conference", "the General Conference"], "answer_start": [91, 91, 87]}, "prediction_text": "General Conference"}
{"answers": {"text": ["every four years", "every four years (quadrennium).", "every four years"], "answer_start": [211, 211, 211]}, "prediction_text": "Every four years"}
{"answers": {"text": ["five", "The United States is divided into five jurisdictions", "five"], "answer_start": [153, 119, 153]}, "prediction_text": "Five jurisdictions"}
{"answers": {"text": ["seven", "seven central conferences: Africa, Congo, West Africa, Central & Southern Europe, Germany, Northern Europe and the Philippines.", "seven"], "answer_start": [296, 296, 296]}, "prediction_text": "Seven central conferences"}
{"answers": {"text": ["to elect and appoint bishops", "to elect and appoint bishops", "elect and appoint bishops"], "answer_start": [489, 489, 492]}, "prediction_text": "Elect and appoint bishops"}
{"answers": {"text": ["bishops", "bishops", "bishops"], "answer_start": [510, 510, 510]}, "prediction_text": "Episcopal Areas"}
{"answers": {"text": ["Episcopal Areas", "Episcopal Areas,", "Episcopal Areas"], "answer_start": [586, 586, 586]}, "prediction_text": "Africa, Congo, West Africa, Central & Southern Europe"}
{"answers": {"text": ["Mission Council", "the Mission Council (usually consisting of church bishops)", "the Mission Council"], "answer_start": [60, 56, 56]}, "prediction_text": "Mission Council of the South Central Jurisdiction"}
{"answers": {"text": ["church bishops", "church bishops)", "church bishops"], "answer_start": [99, 99, 99]}, "prediction_text": "Church bishops"}
{"answers": {"text": ["36", "36 acres", "36"], "answer_start": [314, 314, 314]}, "prediction_text": "36 acres"}
{"answers": {"text": ["for the George W. Bush Presidential Library", "the George W. Bush Presidential Library", "the George W. Bush Presidential Library"], "answer_start": [369, 373, 373]}, "prediction_text": "For the George W. Bush Presidential Library"}
{"answers": {"text": ["Southern Methodist University", "Southern Methodist University"], "answer_start": [339, 339]}, "prediction_text": "Southern Methodist University"}
{"answers": {"text": ["nine", "nine members,", "nine"], "answer_start": [78, 78, 78]}, "prediction_text": "Nine members"}
{"answers": {"text": ["Judicial Council", "The Judicial Council", "The Judicial Council"], "answer_start": [4, 0, 0]}, "prediction_text": "The Judicial Council"}
{"answers": {"text": ["eight-year term", "eight-year term", "eight-year"], "answer_start": [156, 156, 156]}, "prediction_text": "Eight years"}
{"answers": {"text": ["twice a year", "meets twice a year at", "every eight years"], "answer_start": [766, 760, 213]}, "prediction_text": "Twice a year"}
{"answers": {"text": ["various locations throughout the world", "at various locations throughout the world.", "various locations throughout the world"], "answer_start": [782, 779, 782]}, "prediction_text": "At various locations throughout the world."}
{"answers": {"text": ["The Annual Conference", "synod", "The Annual Conference"], "answer_start": [0, 120, 0]}, "prediction_text": "Annual Conference"}
{"answers": {"text": ["geographical area it covers as well as the frequency of meeting", "geographical area it covers as well as the frequency of meeting. Clergy are members of their Annual Conference rather than of any local congregation,", "the geographical area it covers"], "answer_start": [316, 316, 312]}, "prediction_text": "The geographical area it covers"}
{"answers": {"text": ["their Annual Conference", "Annual Conference", "their Annual Conference"], "answer_start": [403, 409, 403]}, "prediction_text": "Annual Conference"}
{"answers": {"text": ["The Book of Discipline", "The Book of Discipline", "The Book of Discipline"], "answer_start": [0, 0, 0]}, "prediction_text": "Book of Discipline"}
{"answers": {"text": ["three", "three members", "three"], "answer_start": [233, 233, 233]}, "prediction_text": "Three members"}
{"answers": {"text": ["nine", "no more than nine members", "nine"], "answer_start": [264, 251, 264]}, "prediction_text": "Three members"}
{"answers": {"text": ["church conference", "church conference", "The church conference"], "answer_start": [648, 648, 644]}, "prediction_text": "Annual meeting of all the officers of the church."}
{"answers": {"text": ["church conference", "church conference", "The church conference"], "answer_start": [648, 648, 644]}, "prediction_text": "Church conference"}
{"answers": {"text": ["one hundred", "one hundred colleges and universities", "around one hundred"], "answer_start": [189, 189, 182]}, "prediction_text": "Around one hundred colleges and universities"}
{"answers": {"text": ["three hundred sixty", "three hundred sixty schools and institutions overseas.", "three hundred"], "answer_start": [562, 562, 562]}, "prediction_text": "Three hundred sixty schools and institutions"}
{"answers": {"text": ["International Association of Methodist-related Schools, Colleges, and Universities", "members of the International Association of Methodist-related Schools, Colleges, and Universities. The church operates three hundred sixty scho", "the International Association of Methodist-related Schools, Colleges, and Universities"], "answer_start": [458, 443, 454]}, "prediction_text": "International Association of Methodist-related Schools, Colleges, and Universities"}
{"answers": {"text": ["John Wesley", "John Wesley,", "John Wesley"], "answer_start": [44, 44, 44]}, "prediction_text": "John Wesley"}
{"answers": {"text": ["pastors", "appointed to various ministries.", "pastors"], "answer_start": [510, 338, 510]}, "prediction_text": "pastors"}
{"answers": {"text": ["Annual Conference Order of Elders", "a member of their Annual Conference Order of Elders.", "Annual Conference Order of Elders"], "answer_start": [898, 880, 898]}, "prediction_text": "Annual Conference Order of Elders"}
{"answers": {"text": ["Annual Conference Order of Deacons", "Annual Conference Order of Deacons", "Annual Conference Order of Deacons"], "answer_start": [994, 994, 994]}, "prediction_text": "Their Annual Conference Order of Deacons."}
{"answers": {"text": ["Annual Conference Cabinet", "All clergy appointments a", "the Annual Conference Cabinet"], "answer_start": [96, 0, 92]}, "prediction_text": "The Annual Conference Cabinet"}
{"answers": {"text": ["one year at a time", "one year at a time,", "one year"], "answer_start": [526, 526, 526]}, "prediction_text": "One year at a time"}
{"answers": {"text": ["bishop has read the appointments at the session of the Annual Conference", "Until the bishop has read the appointments at the session of the Annual Conference,", "the bishop has read the appointments at the session of the Annual Conference"], "answer_start": [282, 272, 278]}, "prediction_text": "The bishop reads the appointments"}
{"answers": {"text": ["Elders", "Elders", "Elders"], "answer_start": [0, 0, 0]}, "prediction_text": "Elders"}
{"answers": {"text": ["the local church", "bishop", "the local church"], "answer_start": [171, 68, 171]}, "prediction_text": "Church authorities"}
{"answers": {"text": ["2\u20133 years", "2\u20133 years as provisional Elders prior to their ordination.", "2\u20133 years"], "answer_start": [570, 570, 570]}, "prediction_text": "2\u20133 years"}
{"answers": {"text": ["District Superintendents", "ordained by a bishop", "District Superintendents"], "answer_start": [467, 54, 467]}, "prediction_text": "District Superintendents"}
{"answers": {"text": ["2\u20133 years", "Deacons serve a term of 2\u20133 years as provisional deacons prior to their ordination.", "2\u20133 years"], "answer_start": [670, 646, 670]}, "prediction_text": "2\u20133 years"}
{"answers": {"text": ["Deacons", "Deacons", "Deacons"], "answer_start": [318, 318, 318]}, "prediction_text": "Deacons"}
{"answers": {"text": ["Deacons", "Deacons", "Deacons"], "answer_start": [479, 479, 479]}, "prediction_text": "Deacons assist elders in the sacraments of Holy Communion and Baptism."}
{"answers": {"text": ["granted sacramental authority", "granted sacramental authority", "sacramental authority"], "answer_start": [561, 561, 569]}, "prediction_text": "Sacramental authority"}
{"answers": {"text": ["1996", "1996", "1996"], "answer_start": [7, 7, 7]}, "prediction_text": "1996"}
{"answers": {"text": ["The provisional elder/deacon", "The provisional elder/deacon", "The provisional elder/deacon"], "answer_start": [227, 227, 227]}, "prediction_text": "provisional elder"}
{"answers": {"text": ["1996 General Conference", "1996 General Conference the", "the ordination order of transitional deacon was abolished"], "answer_start": [7, 7, 31]}, "prediction_text": "Ordination order abolished"}
{"answers": {"text": ["Licensed Local Pastor", "'Licensed Local Pastor", "'Licensed Local Pastor"], "answer_start": [913, 912, 912]}, "prediction_text": "Local Pastor"}
{"answers": {"text": ["licensed local pastor", "five-year course of s", "licensed local pastor"], "answer_start": [1073, 1352, 1073]}, "prediction_text": "Local pastors"}
{"answers": {"text": ["five", "five-year course of study at an", "five-year"], "answer_start": [1352, 1352, 1352]}, "prediction_text": "Five years"}
{"answers": {"text": ["Associate Membership", "Associate Membership", "Associate Membership"], "answer_start": [1625, 1625, 1625]}, "prediction_text": "Associate Membership"}
{"answers": {"text": ["Baptized Members", "Baptized Members", "Baptized Members"], "answer_start": [70, 70, 70]}, "prediction_text": "Professing Members"}
{"answers": {"text": ["confirmation and sometimes the profession of faith", "through confirmation and sometimes the profession of faith.", "confirmation"], "answer_start": [257, 249, 257]}, "prediction_text": "Baptized Members become Professing Members through confirmation and sometimes the profession of faith."}
{"answers": {"text": ["transfer from another Christian denomination", "through confirmation and sometimes the profession of faith.", "the profession of faith"], "answer_start": [511, 249, 284]}, "prediction_text": "Through transfer"}
{"answers": {"text": ["Baptism", "Baptism", "Baptism"], "answer_start": [45, 45, 45]}, "prediction_text": "Baptism"}
{"answers": {"text": ["confirmation and membership preparation classes", "In confirmation and membership preparation classes,", "confirmation and membership preparation classes"], "answer_start": [591, 588, 591]}, "prediction_text": "Through confirmation and membership preparation classes."}
{"answers": {"text": ["The Book of Discipline", "The Book of Discipline", "The Book of Discipline of the United Methodist Church"], "answer_start": [80, 401, 80]}, "prediction_text": "Book of Discipline"}
{"answers": {"text": ["Church and the Methodist-Christian theological tradition", "learn about Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Church and the Methodist-Christian theological tradition"], "answer_start": [661, 649, 661]}, "prediction_text": "Church and Methodist-Christian theological tradition"}
{"answers": {"text": ["lay servants", "lay servants"], "answer_start": [270, 270]}, "prediction_text": "Local church lay servants"}
{"answers": {"text": ["they must be recommended by their pastor and Church Council or Charge Conference, and complete the basic course for lay servant", "they must be recommended by their pastor and Church Council or Charge Conference, and complete the basic course for lay servant", "recommended by their pastor and Church Council or Charge Conference, and complete the basic course for lay servant"], "answer_start": [541, 541, 554]}, "prediction_text": "They must be recommended by their pastor and Church Council or Charge Conference."}
{"answers": {"text": ["annually", "Each year", "Each year"], "answer_start": [1064, 670, 670]}, "prediction_text": "Every three years"}
{"answers": {"text": ["at least one advanced course every three years", "complete the basic course and one advanced lay servant course,", "one advanced course every three years"], "answer_start": [1097, 896, 1106]}, "prediction_text": "One advanced course every three years."}
{"answers": {"text": ["United Methodist Church", "The United Methodist Church is", "The United Methodist Church"], "answer_start": [4, 0, 0]}, "prediction_text": "United Methodist Church"}
{"answers": {"text": ["observer status", "it voted to seek observer status", "observer"], "answer_start": [357, 340, 357]}, "prediction_text": "Observer status"}
{"answers": {"text": ["blurring of theological and confessional differences in the interests of unity", "\"blurring of theological and confessional differences in the interests of unity", "the \"blurring of theological and confessional differences in the interests of unity.\""], "answer_start": [564, 563, 559]}, "prediction_text": "Blurring of theological and confessional differences"}
{"answers": {"text": ["2000", "2000", "2000"], "answer_start": [335, 335, 335]}, "prediction_text": "2000"}
{"answers": {"text": ["May 2012", "May 2012", "2012"], "answer_start": [379, 379, 383]}, "prediction_text": "May 2012"}
{"answers": {"text": ["1985", "since 1985", "1985"], "answer_start": [38, 32, 38]}, "prediction_text": "1985"}
{"answers": {"text": ["11 million", "about 11 million members in nearly 42,000 congregations", "11 million"], "answer_start": [213, 207, 213]}, "prediction_text": "About 11 million"}
{"answers": {"text": ["42,000", "42,000 congregations", "42,000"], "answer_start": [242, 242, 242]}, "prediction_text": "About 11 million"}
{"answers": {"text": ["8 million", "8 million", "8 million"], "answer_start": [355, 355, 355]}, "prediction_text": "About 8 million"}
{"answers": {"text": ["34,000", "34,000 congregations", "34,000"], "answer_start": [381, 381, 381]}, "prediction_text": "About 8 million"}
{"answers": {"text": ["Texas", "Texas", "Texas"], "answer_start": [473, 473, 473]}, "prediction_text": "Texas"}
{"answers": {"text": ["11.4 million", "11.4 million", "11.4 million"], "answer_start": [85, 85, 85]}, "prediction_text": "11.4 million"}
{"answers": {"text": ["7.9 million", "7.9 million in the U.S", "7.9 million"], "answer_start": [110, 110, 110]}, "prediction_text": "11.4 million"}
{"answers": {"text": ["3.5 million", "3.5 million", "3.5 million"], "answer_start": [138, 138, 138]}, "prediction_text": "3.5 million"}
{"answers": {"text": ["Wesleyan Holiness Consortium", "Wesleyan Holiness Consortium", "Wesleyan Holiness Consortium"], "answer_start": [32, 32, 32]}, "prediction_text": "Wesleyan Holiness Consortium"}
{"answers": {"text": ["World Methodist Council", "World Methodist Council", "World Methodist Council"], "answer_start": [162, 162, 162]}, "prediction_text": "World Methodist Council"}
{"answers": {"text": ["July 18, 2006", "On July 18, 2006", "July 18, 2006"], "answer_start": [324, 321, 324]}, "prediction_text": "July 18, 2006"}
{"answers": {"text": ["1754\u20131763", "1754\u20131763", "1754\u20131763", "1754\u20131763", "1754\u20131763"], "answer_start": [27, 27, 27, 27, 27]}, "prediction_text": "1754\u20131763"}
{"answers": {"text": ["colonies of British America and New France", "colonies of British America and New France", "British America and New France", "British America and New France", "the colonies of British America and New France"], "answer_start": [135, 135, 147, 147, 131]}, "prediction_text": "The colonies of British America and New France"}
{"answers": {"text": ["roughly 60,000 European settlers", "60,000", "60,000", "60,000", "60,000 European settlers"], "answer_start": [395, 403, 403, 403, 403]}, "prediction_text": "Approximately 60,000"}
{"answers": {"text": ["2 million", "2 million", "2 million", "2 million", "2 million"], "answer_start": [443, 443, 443, 443, 443]}, "prediction_text": "2 million"}
{"answers": {"text": ["primarily along the frontiers between New France and the British colonies", "between New France and the British colonies", "frontiers between New France and the British colonies", "along the frontiers", "Virginia in the South to Nova Scotia in the North"], "answer_start": [19, 49, 39, 29, 99]}, "prediction_text": "North and South"}
{"answers": {"text": ["dispute over control of the confluence of the Allegheny and Monongahela rivers, called the Forks of the Ohio", "dispute over control of the confluence of the Allegheny and Monongahela rivers", "dispute over control of the confluence of the Allegheny and Monongahela rivers", "dispute over control", "a dispute over control of the confluence of the Allegheny and Monongahela rivers"], "answer_start": [166, 166, 166, 166, 164]}, "prediction_text": "Battle of Jumonville Glen"}
{"answers": {"text": ["Battle of Jumonville Glen in May 1754,", "May 1754", "May 1754", "May 1754", "May 1754"], "answer_start": [400, 429, 429, 429, 429]}, "prediction_text": "May 1754"}
{"answers": {"text": ["1755", "1755", "1755", "1755", "1755"], "answer_start": [3, 3, 3, 3, 3]}, "prediction_text": "1755"}
{"answers": {"text": ["disaster; he was defeated in the Battle of the Monongahela", "disaster", "was a disaster", "he was defeated", "None succeeded"], "answer_start": [223, 223, 217, 233, 170]}, "prediction_text": "He was defeated."}
{"answers": {"text": ["combination of poor management, internal divisions, and effective Canadian scouts, French regular forces, and Indian warrior allies", "poor management, internal divisions, and effective Canadian scouts, French regular forces, and Indian warrior allies", "a combination of poor management, internal divisions, and effective Canadian scouts, French regular forces, and Indian warrior allies", "poor management, internal divisions, and effective Canadian scouts", "a combination of poor management, internal divisions, and effective Canadian scouts"], "answer_start": [439, 454, 437, 454, 437]}, "prediction_text": "Poor management, internal divisions, and effective Canadian scouts."}
{"answers": {"text": ["Fort Beaus\u00e9jour", "Fort Beaus\u00e9jour", "Fort Beaus\u00e9jour", "Fort Beaus\u00e9jour", "Fort Beaus\u00e9jour"], "answer_start": [602, 602, 602, 602, 602]}, "prediction_text": "Fort Beaus\u00e9jour"}
{"answers": {"text": ["expulsion of the Acadians", "expulsion of the Acadians", "deportation", "expulsion", "deportation"], "answer_start": [700, 700, 742, 700, 742]}, "prediction_text": "Orders for the expulsion were given by William Shirley, Commander-in-Chief, North America."}
{"answers": {"text": ["William Pitt", "William Pitt", "William Pitt", "William Pitt", "William Pitt"], "answer_start": [235, 235, 235, 235, 235]}, "prediction_text": "William Pitt"}
{"answers": {"text": ["unwilling to risk large convoys to aid the limited forces it had in New France", "limited forces", "significantly increased", "France was unwilling to risk large convoys to aid the limited forces it had in New France"], "answer_start": [359, 402, 266, 348]}, "prediction_text": "France was unwilling to risk large convoys."}
{"answers": {"text": ["against Prussia and its allies in the European theatre of the war.", "Prussia", "against Prussia and its allies", "European theatre", "Prussia"], "answer_start": [470, 478, 470, 508, 478]}, "prediction_text": "European theatre of the war"}
{"answers": {"text": ["Sainte Foy in Quebec", "Sainte Foy", "Sainte Foy in Quebec", "Sainte Foy", "Sainte Foy"], "answer_start": [761, 761, 761, 761, 761]}, "prediction_text": "At Sainte Foy"}
{"answers": {"text": ["territory east of the Mississippi to Great Britain", "France", "territory east of the Mississippi", "east of the Mississippi", "territory east of the Mississippi"], "answer_start": [113, 96, 113, 123, 113]}, "prediction_text": "French Louisiana"}
{"answers": {"text": ["French Louisiana west of the Mississippi River (including New Orleans) to its ally Spain", "French Louisiana", "French Louisiana west of the Mississippi River (including New Orleans)", "Louisiana west of the Mississippi River", "French Louisiana west of the Mississippi River (including New Orleans)"], "answer_start": [174, 174, 174, 181, 174]}, "prediction_text": "French Louisiana"}
{"answers": {"text": ["confirming Britain's position as the dominant colonial power in eastern North America", "confirming Britain's position as the dominant colonial power in eastern North America", "confirming Britain's position as the dominant colonial power in eastern North America", "dominant colonial power", "confirming Britain's position as the dominant colonial power in eastern North America"], "answer_start": [504, 504, 504, 541, 504]}, "prediction_text": "Britain's position as dominant colonial power"}
{"answers": {"text": ["1740s", "1740s", "1740s", "1740s", "1740s"], "answer_start": [219, 219, 219, 219, 219]}, "prediction_text": "1740s"}
{"answers": {"text": ["Indians fought on both sides of the conflict, and that this was part of the Seven Years' War", "Indians fought on both sides of the conflict", "obscures the fact that Indians fought on both sides of the conflict, and that this was part of the Seven Years' War", "Seven Years' War", "it obscures the fact that Indians fought on both sides of the conflict"], "answer_start": [461, 461, 438, 537, 435]}, "prediction_text": "Part of the Seven Years' War"}
{"answers": {"text": ["much larger conflict between France and Great Britain", "conflict between France and Great Britain", "in King George's reign", "conflict between France and Great Britain", "a much larger conflict between France and Great Britain"], "answer_start": [557, 569, 265, 569, 555]}, "prediction_text": "A larger conflict between France and Great Britain."}
{"answers": {"text": ["Fourth Intercolonial War and the Great War for the Empire", "Fourth Intercolonial War and the Great War for the Empire", "Fourth Intercolonial War and the Great War for the Empire", "Fourth Intercolonial War and the Great War for the Empire", "the Fourth Intercolonial War and the Great War for the Empire"], "answer_start": [760, 760, 760, 760, 756]}, "prediction_text": "Fourth Intercolonial War, Great War for the Empire"}
{"answers": {"text": ["declaration of war in 1756 to the signing of the peace treaty in 1763", "1756 to the signing of the peace treaty in 1763", "1756 to the signing of the peace treaty in 1763", "1756 to the signing of the peace treaty in 1763", "the official declaration of war in 1756 to the signing of the peace treaty in 1763"], "answer_start": [228, 250, 250, 250, 215]}, "prediction_text": "Six years"}
{"answers": {"text": ["six years", "six years", "six years", "six years", "six years"], "answer_start": [450, 450, 450, 450, 450]}, "prediction_text": "Six years"}
{"answers": {"text": ["1760", "1760", "1760", "1760", "1760"], "answer_start": [534, 534, 534, 534, 534]}, "prediction_text": "1760"}
{"answers": {"text": ["Battle of Jumonville Glen", "Battle of Jumonville Glen", "Jumonville Glen", "Battle of Jumonville Glen", "Battle of Jumonville Glen"], "answer_start": [470, 470, 480, 470, 470]}, "prediction_text": "Battle of Jumonville Glen"}
{"answers": {"text": ["about 75,000", "75,000", "75,000", "75,000", "75,000"], "answer_start": [31, 37, 37, 37, 37]}, "prediction_text": "About 75,000"}
{"answers": {"text": ["heavily concentrated along the St. Lawrence River valley, with some also in Acadia", "along the St. Lawrence River valley", "St. Lawrence River valley", "along the St. Lawrence River valley"], "answer_start": [52, 73, 83, 73]}, "prediction_text": "St. Lawrence River valley"}
{"answers": {"text": ["St. Lawrence and Mississippi watersheds, did business with local tribes, and often married Indian women", "St. Lawrence and Mississippi watersheds", "throughout the St. Lawrence and Mississippi watersheds", "St. Lawrence and Mississippi", "the St. Lawrence and Mississippi watersheds"], "answer_start": [480, 480, 465, 480, 476]}, "prediction_text": "St. Lawrence River valley"}
{"answers": {"text": ["20 to 1", "20 to 1", "20 to 1", "20 to 1", "20 to 1"], "answer_start": [40, 40, 40, 40, 40]}, "prediction_text": "20 to 1"}
{"answers": {"text": ["from Nova Scotia and Newfoundland in the north, to Georgia in the south", "eastern coast of the continent", "eastern coast of the continent,", "eastern coast", "from Nova Scotia and Newfoundland in the north, to Georgia in the south"], "answer_start": [136, 104, 104, 104, 136]}, "prediction_text": "In the interior"}
{"answers": {"text": ["along the coast, the settlements were growing into the interior", "along the coast", "along the coast", "along the coast", "along the coast"], "answer_start": [426, 426, 426, 426, 426]}, "prediction_text": "Along the coast"}
{"answers": {"text": ["native tribes", "native tribes", "native tribes", "native tribes", "native tribes"], "answer_start": [69, 69, 69, 69, 69]}, "prediction_text": "Native tribes"}
{"answers": {"text": ["Mi'kmaq and the Abenaki", "Mi'kmaq and the Abenaki", "the Mi'kmaq and the Abenaki", "Mi'kmaq and the Abenaki", "the Mi'kmaq and the Abenaki"], "answer_start": [102, 102, 98, 102, 98]}, "prediction_text": "Mi'kmaq and Abenaki"}
{"answers": {"text": ["present-day Upstate New York and the Ohio Country", "present-day Upstate New York and the Ohio Country", "Upstate New York and the Ohio Country", "New York and the Ohio", "Upstate New York and the Ohio Country"], "answer_start": [353, 353, 365, 373, 365]}, "prediction_text": "Upstate New York"}
{"answers": {"text": ["Iroquois rule, and were limited by them in authority to make agreements", "Iroquois", "Iroquois", "Iroquois", "Iroquois"], "answer_start": [565, 565, 565, 565, 565]}, "prediction_text": "Iroquois rule"}
{"answers": {"text": ["Catawba, Muskogee-speaking Creek and Choctaw", "Catawba", "Catawba", "Catawba", "Catawba"], "answer_start": [70, 70, 70, 70, 70]}, "prediction_text": "Catawba, Muskogee-speaking Creek, Choctaw, Cherokee."}
{"answers": {"text": ["western portions of the Great Lakes region", "Great Lakes", "tribes in western portions of the Great Lakes region", "western portions of the Great Lakes", "western portions of the Great Lakes region"], "answer_start": [257, 281, 247, 257, 257]}, "prediction_text": "Western portions of the Great Lakes region"}
{"answers": {"text": ["Iroquois Six Nations, and also by the Cherokee", "Iroquois Six Nations, and also by the Cherokee", "Iroquois Six Nations, and also by the Cherokee", "Iroquois", "the Iroquois Six Nations"], "answer_start": [493, 493, 493, 493, 489]}, "prediction_text": "Creek and Cherokee"}
{"answers": {"text": ["no French regular army troops were stationed in North America", "no French regular army troops were stationed in North America", "no French regular army troops were stationed in North America,", "no French regular army", "no French regular army troops were stationed in North America"], "answer_start": [25, 25, 25, 25, 25]}, "prediction_text": "No French regular army troops were stationed in North America."}
{"answers": {"text": ["few British troops", "few", "few", "not have any standing forces", "few British troops"], "answer_start": [92, 92, 92, 479, 92]}, "prediction_text": "About 3,000 troops"}
{"answers": {"text": ["mustered local militia companies, generally ill trained and available only for short periods, to deal with native threats, but did not have any standing forces.", "local militia companies", "local militia companies", "militia support", "local militia companies"], "answer_start": [348, 357, 357, 297, 357]}, "prediction_text": "About 3,000 troupes de la marine"}
{"answers": {"text": ["about 3,000 miles (4,800 km) between June and November 1749.", "about 3,000 miles", "3,000 miles", "3,000 miles", "3,000 miles"], "answer_start": [110, 110, 116, 116, 116]}, "prediction_text": "About 3,000 miles (4,800 km)"}
{"answers": {"text": ["200 Troupes de la marine and 30 Indians", "C\u00e9loron", "200 Troupes de la marine and 30 Indians", "200 Troupes de la marine and 30 Indians", "200 Troupes de la marine and 30 Indians"], "answer_start": [46, 511, 46, 46, 46]}, "prediction_text": "About 200 Troupes de la marine"}
{"answers": {"text": ["British merchants or fur-traders, C\u00e9loron informed them of the French claims on the territory and told them to leave.", "told them to leave", "Whenever he encountered British merchants or fur-traders, C\u00e9loron informed them of the French claims on the territory and told them to leave.", "buried lead plates", "Whenever he encountered British merchants or fur-traders, C\u00e9loron informed them of the French claims on the territory and told them to leave"], "answer_start": [614, 712, 590, 519, 590]}, "prediction_text": "C\u00e9loron handled business on the trip."}
{"answers": {"text": ["informed C\u00e9loron that they owned the Ohio Country and that they would trade with the British regardless of the French", "informed C\u00e9loron that they owned the Ohio Country and that they would trade with the British", "they owned the Ohio Country", "they owned the Ohio Country and that they would trade with the British regardless of the French"], "answer_start": [80, 80, 102, 102]}, "prediction_text": "They informed C\u00e9loron that they owned the Ohio Country."}
{"answers": {"text": ["village of Pickawillany", "village of Pickawillany", "village of Pickawillany", "Pickawillany", "village of Pickawillany"], "answer_start": [329, 329, 329, 340, 329]}, "prediction_text": "Pickawillany, the home of the Miami chief."}
{"answers": {"text": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British", "C\u00e9loron threatened \"Old Briton\" with severe consequences", "threatened \"Old Briton\" with severe consequences", "threatened", "C\u00e9loron threatened \"Old Briton\""], "answer_start": [413, 405, 413, 413, 405]}, "prediction_text": "C\u00e9loron threatened \"Old Briton\" with severe consequences if he continued to trade with the British."}
{"answers": {"text": ["ignored the warning.", "ignored the warning", "ignored the warning", "ignored the warning", "\"Old Briton\" ignored the warning"], "answer_start": [518, 518, 518, 518, 505]}, "prediction_text": "He ignored C\u00e9loron's threat."}
{"answers": {"text": ["very badly disposed towards the French, and are entirely devoted to the English", "very badly disposed towards the French", "are very badly disposed towards the French, and are entirely devoted to the English", "what way they could be brought back", "very badly disposed towards the French"], "answer_start": [110, 110, 106, 207, 110]}, "prediction_text": "He wrote, \"All I can say is that the Natives of these localities are very badly disposed towards the French, and are entirely devoted to the English. I don't know in what way they could be brought back.\""}
{"answers": {"text": ["proposing that action be taken", "each side proposing that action be taken", "proposing that action be taken", "each side proposing that action be taken"], "answer_start": [379, 369, 379, 369]}, "prediction_text": "They were very concerned."}
{"answers": {"text": ["British colonists would not be safe as long as the French were present", "British colonists would not be safe", "British colonists would not be safe as long as the French were present", "British colonists would not be safe", "forceful"], "answer_start": [532, 532, 532, 532, 509]}, "prediction_text": "Strongly forceful"}
{"answers": {"text": ["1749", "1749", "1749", "1749", "1749"], "answer_start": [3, 3, 3, 3, 3]}, "prediction_text": "1749"}
{"answers": {"text": ["Ohio Company of Virginia", "Ohio Company of Virginia", "Ohio Company of Virginia", "Ohio Company of Virginia", "Ohio Company"], "answer_start": [48, 48, 48, 48, 48]}, "prediction_text": "Ohio Company of Virginia"}
{"answers": {"text": ["Christopher Gist", "Christopher Gist", "Christopher Gist", "Christopher Gist", "Christopher Gist"], "answer_start": [393, 393, 393, 393, 393]}, "prediction_text": "Christopher Gist"}
{"answers": {"text": ["Treaty of Logstown", "1752 Treaty of Logstown", "1752 Treaty of Logstown", "Treaty of Logstown", "Treaty of Logstown"], "answer_start": [572, 567, 567, 572, 572]}, "prediction_text": "Treaty of Logstown"}
{"answers": {"text": ["mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "mouth of the Monongahela River", "mouth of the Monongahela River", "Pittsburgh, Pennsylvania", "the mouth of the Monongahela River"], "answer_start": [764, 764, 764, 820, 760]}, "prediction_text": "At the mouth of the Monongahela River"}
{"answers": {"text": ["King George's War", "King George's War", "King George's War", "King George's War"], "answer_start": [77, 77, 77, 77]}, "prediction_text": "North American theater"}
{"answers": {"text": ["1748 with the signing of the Treaty of Aix-la-Chapelle", "signing of the Treaty of Aix-la-Chapelle", "signing of the Treaty of Aix-la-Chapelle", "1748", "the Treaty of Aix-la-Chapelle"], "answer_start": [114, 128, 128, 114, 139]}, "prediction_text": "Treaty of Aix-la-Chapelle ended the War of the Austrian Succession."}
{"answers": {"text": ["conflicting territorial claims between British and French", "conflicting territorial claims between British and French colonies in North America", "conflicting territorial claims between British and French colonies in North America", "conflicting territorial claims", "The issues of conflicting territorial claims between British and French colonies"], "answer_start": [248, 248, 248, 248, 234]}, "prediction_text": "conflicting territorial claims"}
{"answers": {"text": ["Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides", "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides", "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides.", "claimed by both sides", "Frontiers from between Nova Scotia and Acadia in the north, to the Ohio Country in the south, were claimed by both sides"], "answer_start": [405, 405, 405, 504, 405]}, "prediction_text": "The disputes continued."}
{"answers": {"text": ["Marquis de la Jonqui\u00e8re", "Marquis de la Jonqui\u00e8re", "Marquis de la Jonqui\u00e8re", "Marquis de la Jonqui\u00e8re", "Marquis de la Jonqui\u00e8re"], "answer_start": [55, 55, 55, 55, 55]}, "prediction_text": "Marquis de la Jonqui\u00e8re"}
{"answers": {"text": ["300 men, including French-Canadians and warriors of the Ottawa", "300", "300 men", "300", "300 men"], "answer_start": [486, 486, 486, 486, 486]}, "prediction_text": "300 men"}
{"answers": {"text": ["punish the Miami people of Pickawillany for not following C\u00e9loron's orders to cease trading with the British", "punish the Miami people of Pickawillany", "punish the Miami people of Pickawillany for not following C\u00e9loron's orders", "punish the Miami people", "to punish the Miami people of Pickawillany"], "answer_start": [571, 571, 571, 571, 568]}, "prediction_text": "Punish the Miami people for not following C\u00e9loron's orders."}
{"answers": {"text": ["capturing three traders and killing 14 people of the Miami nation, including Old Briton", "capturing three traders and killing 14 people of the Miami nation", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "capturing three traders and killing 14 people", "capturing three traders and killing 14 people of the Miami nation"], "answer_start": [759, 759, 759, 759, 759]}, "prediction_text": "C\u00e9loron's orders were not followed."}
{"answers": {"text": ["Paul Marin de la Malgue", "Paul Marin de la Malgue", "Paul Marin de la Malgue", "Paul Marin de la Malgue", "Paul Marin de la Malgue"], "answer_start": [23, 23, 23, 23, 23]}, "prediction_text": "Paul Marin de la Malgue"}
{"answers": {"text": ["Fort Presque Isle (near present-day Erie, Pennsylvania", "Fort Presque Isle", "near present-day Erie, Pennsylvania", "Fort Presque Isle", "near present-day Erie, Pennsylvania"], "answer_start": [425, 425, 444, 425, 444]}, "prediction_text": "Lake Erie's south shore"}
{"answers": {"text": ["Fort Le Boeuf (present-day Waterford, Pennsylvania", "Fort Le Boeuf", "present-day Waterford, Pennsylvania", "Fort Le Boeuf", "present-day Waterford, Pennsylvania"], "answer_start": [600, 600, 615, 600, 615]}, "prediction_text": "Fort Le Boeuf"}
{"answers": {"text": ["protect the King's land in the Ohio Valley from the British", "protect the King's land in the Ohio Valley from the British", "to protect the King's land in the Ohio Valley from the British", "protect the King's land in the Ohio Valley", "he moved south, he drove off or captured British traders"], "answer_start": [142, 142, 139, 142, 707]}, "prediction_text": "Protect the King's land in the Ohio Valley."}
{"answers": {"text": ["Tanaghrisson", "Tanaghrisson", "Tanaghrisson", "Tanaghrisson", "the Mingo"], "answer_start": [809, 809, 809, 809, 834]}, "prediction_text": "Tanaghrisson"}
{"answers": {"text": ["British Superintendent for Indian Affairs in the New York region and beyond", "British Superintendent for Indian Affairs", "British Superintendent for Indian Affairs in the New York region and beyond", "British Superintendent for Indian Affairs", "British Superintendent for Indian Affairs"], "answer_start": [83, 83, 83, 83, 83]}, "prediction_text": "Superintendent for Indian Affairs in New York"}
{"answers": {"text": ["Warraghiggey, meaning \"He who does great things.\"", "Warraghiggey", "Warraghiggey", "Warraghiggey", "Warraghiggey"], "answer_start": [197, 197, 197, 197, 197]}, "prediction_text": "Warraghiggey"}
{"answers": {"text": ["colonel of the Iroquois", "He who does great things", "He who does great things.", "honorary member of the Iroquois Confederacy", "Warraghiggey"], "answer_start": [384, 220, 220, 299, 197]}, "prediction_text": "Colonel of the Western New York Militia"}
{"answers": {"text": ["Mohawk Chief Hendrick", "Mohawk Chief Hendrick", "Mohawk Chief Hendrick", "Chief Hendrick", "Chief Hendrick"], "answer_start": [588, 588, 588, 595, 595]}, "prediction_text": "Mohawk Chief Hendrick"}
{"answers": {"text": ["Ohio Company", "Ohio Company", "Ohio Company,", "Ohio Company", "the Ohio Company"], "answer_start": [61, 61, 61, 61, 57]}, "prediction_text": "Ohio Company"}
{"answers": {"text": ["Major George Washington", "George Washington", "Major George Washington", "George Washington", "Major George Washington"], "answer_start": [232, 238, 232, 238, 232]}, "prediction_text": "Major George Washington"}
{"answers": {"text": ["Jacob Van Braam as an interpreter; Christopher Gist, a company surveyor working in the area; and a few Mingo led by Tanaghrisson", "Jacob Van Braam", "Jacob Van Braam", "Jacob Van Braam"], "answer_start": [440, 440, 440, 440]}, "prediction_text": "Jacob Van Braam"}
{"answers": {"text": ["December 12", "December 12", "December 12", "December 12", "December 12"], "answer_start": [573, 573, 573, 573, 573]}, "prediction_text": "December 12, 1753"}
{"answers": {"text": ["Jacques Legardeur de Saint-Pierre", "Jacques Legardeur de Saint-Pierre", "Jacques Legardeur de Saint-Pierre", "Jacques Legardeur de Saint-Pierre", "Jacques Legardeur de Saint-Pierre"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Jacques Legardeur de Saint-Pierre"}
{"answers": {"text": ["Dinwiddie demanding an immediate French withdrawal from the Ohio Country", "Dinwiddie", "from Dinwiddie demanding an immediate French withdrawal from the Ohio Country", "immediate French withdrawal", "the letter from Dinwiddie"], "answer_start": [231, 231, 226, 254, 215]}, "prediction_text": "Letter from Dinwiddie"}
{"answers": {"text": ["As to the Summons you send me to retire, I do not think myself obliged to obey it.", "said, \"As to the Summons you send me to retire, I do not think myself obliged to obey it.\"", "\"As to the Summons you send me to retire, I do not think myself obliged to obey it.\"", "I do not think myself obliged to obey", "\"As to the Summons you send me to retire, I do not think myself obliged to obey it.\""], "answer_start": [325, 318, 324, 366, 324]}, "prediction_text": "He said, \"As to the Summons you send me to retire, I do not think myself obliged to obey it.\""}
{"answers": {"text": ["France's claim to the region was superior to that of the British", "Sieur de La Salle had explored the Ohio Country nearly a century earlier", "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier.", "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country", "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier"], "answer_start": [433, 527, 505, 505, 505]}, "prediction_text": "Superiority to British"}
{"answers": {"text": ["Contrec\u0153ur led 500 men south from Fort Venango on April 5, 1754", "40", "40", "additional French forces", "40 men"], "answer_start": [334, 65, 65, 215, 65]}, "prediction_text": "500 men"}
{"answers": {"text": ["early months of 1754", "1754", "1754", "1754", "1754"], "answer_start": [120, 136, 136, 136, 136]}, "prediction_text": "Early 1754"}
{"answers": {"text": ["Fort Duquesne.", "Fort Duquesne", "Fort Duquesne", "Fort Duquesne", "Fort Duquesne"], "answer_start": [586, 586, 586, 586, 586]}, "prediction_text": "Fort Duquesne"}
{"answers": {"text": ["with Tanaghrisson and his party, surprised the Canadians on May 28 in what became known as the Battle of Jumonville Glen", "killed many of the Canadians", "surprised the Canadians on May 28", "Battle of Jumonville Glen", "surprised the Canadians on May 28"], "answer_start": [366, 493, 399, 461, 399]}, "prediction_text": "Surprised the Canadians on May 28."}
{"answers": {"text": ["killed many of the Canadians, including their commanding officer, Joseph Coulon de Jumonville", "many of the Canadians, including their commanding officer, Joseph Coulon de Jumonville", "Canadians, including their commanding officer", "many of the Canadians, including their commanding officer, Joseph Coulon de Jumonville"], "answer_start": [493, 500, 512, 500]}, "prediction_text": "Many Canadian soldiers were killed."}
{"answers": {"text": ["regain authority over his own people. They had been inclined to support the French, with whom they had long trading relationships", "gain the support of the British and regain authority over his own people", "had promised", "regain authority over his own people", "to gain the support of the British and regain authority over his own people"], "answer_start": [763, 727, 195, 763, 724]}, "prediction_text": "To regain authority over his people."}
{"answers": {"text": ["dislodge the French", "dislodge the French", "dislodge the French", "dislodge the French"], "answer_start": [186, 186, 186, 186]}, "prediction_text": "To dislodge French forces"}
{"answers": {"text": ["plans leaked to France well before Braddock's departure", "before Braddock's departure", "well before Braddock's departure for North America", "before Braddock's departure", "well before Braddock's departure for North America"], "answer_start": [301, 329, 324, 329, 324]}, "prediction_text": "August 1755"}
{"answers": {"text": ["dispatched six regiments to New France under the command of Baron Dieskau in 1755.", "dispatched six regiments to New France", "dispatched six regiments to New France under the command of Baron Dieskau in 1755", "six regiments to New France", "dispatched six regiments to New France"], "answer_start": [403, 403, 403, 414, 403]}, "prediction_text": "Sent out fleet"}
{"answers": {"text": ["blockade French ports, sent out their fleet in February 1755", "blockade French ports", "blockade French ports", "blockade French ports", "blockade French ports"], "answer_start": [512, 512, 512, 512, 512]}, "prediction_text": "British military plans against French."}
{"answers": {"text": ["Albany Congress", "Albany Congress", "the opening of hostilities", "Albany Congress", "Albany Congress"], "answer_start": [93, 93, 41, 93, 93]}, "prediction_text": "A unified front in trade and negotiations."}
{"answers": {"text": ["formalize a unified front in trade and negotiations with various Indians, since allegiance of the various tribes and nations was seen to be pivotal", "formalize a unified front in trade and negotiations with various Indians", "formalize a unified front in trade and negotiations with various Indians", "unified front in trade and negotiations with various Indians", "to formalize a unified front in trade and negotiations with various Indians"], "answer_start": [165, 165, 165, 177, 162]}, "prediction_text": "formalized a unified front in trade and negotiations."}
{"answers": {"text": ["The plan that the delegates agreed to was never ratified by the colonial legislatures nor approved of by the crown", "was never ratified", "never ratified", "never ratified", "The plan that the delegates agreed to was never ratified"], "answer_start": [359, 397, 401, 401, 359]}, "prediction_text": "Yes, formalized."}
{"answers": {"text": ["format of the congress and many specifics of the plan became the prototype for confederation during the War of Independence", "became the prototype for confederation during the War of Independence", "became the prototype for confederation during the War of Independence", "prototype for confederation", "became the prototype for confederation during the War of Independence"], "answer_start": [493, 547, 547, 558, 547]}, "prediction_text": "formalized a unified front in trade and negotiations."}
{"answers": {"text": ["Braddock (with George Washington as one of his aides) led about 1,500 army troops", "Braddock", "Braddock (with George Washington", "Braddock", "Braddock"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "George Washington"}
{"answers": {"text": ["The expedition was a disaster", "disaster", "was a disaster", "disaster", "The expedition was a disaster"], "answer_start": [158, 179, 173, 179, 158]}, "prediction_text": "A disaster"}
{"answers": {"text": ["Approximately 1,000 British soldiers were killed or injured.", "Approximately 1,000", "1,000 British soldiers", "1,000", "1,000 British soldiers"], "answer_start": [330, 330, 344, 344, 344]}, "prediction_text": "Approximately 1,000 British soldiers were killed or injured."}
{"answers": {"text": ["Washington and Thomas Gage", "George Washington", "Washington and Thomas Gage", "Washington and Thomas Gage", "George Washington"], "answer_start": [530, 432, 530, 530, 432]}, "prediction_text": "Washington and Gage"}
{"answers": {"text": ["Shirley and Johnson.", "British", "British war plans", "British war plans", "Shirley and Johnson"], "answer_start": [81, 34, 34, 34, 81]}, "prediction_text": "Shirley's activities"}
{"answers": {"text": ["efforts to fortify Oswego were bogged down in logistical difficulties, exacerbated by Shirley's inexperience", "logistical", "logistical difficulties", "logistical", "logistical"], "answer_start": [112, 158, 158, 158, 158]}, "prediction_text": "logistical difficulties"}
{"answers": {"text": ["planned to attack Fort Niagara", "Fort Niagara", "Fort Niagara", "Fort Niagara"], "answer_start": [372, 390, 390, 390]}, "prediction_text": "At Fort Niagara"}
{"answers": {"text": ["garrisons", "garrisons", "garrisons", "garrisons"], "answer_start": [432, 432, 432, 432]}, "prediction_text": "Garrisons"}
{"answers": {"text": ["Marquis de Vaudreuil.", "Marquis de Vaudreuil", "the Marquis de Vaudreuil", "Marquis de Vaudreuil", "Marquis de Vaudreuil"], "answer_start": [106, 106, 102, 106, 106]}, "prediction_text": "Marquis de Vaudreuil"}
{"answers": {"text": ["sent Dieskau to Fort St. Fr\u00e9d\u00e9ric to meet that threat", "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric", "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric", "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric", "sent Dieskau to Fort St. Fr\u00e9d\u00e9ric"], "answer_start": [367, 367, 367, 367, 367]}, "prediction_text": "Vaudreuil sent Dieskau to lead the defenses at Frontenac against Shirley's expected attack."}
{"answers": {"text": ["inconclusively, with both sides withdrawing from the field", "The battle ended inconclusively", "ended inconclusively", "both sides withdrawing from the field", "The battle ended inconclusively"], "answer_start": [755, 738, 749, 776, 738]}, "prediction_text": "The French won the battle of Lake George."}
{"answers": {"text": ["Fort William Henry", "Fort William Henry", "Fort William Henry", "Fort William Henry", "Fort William Henry"], "answer_start": [844, 844, 844, 844, 844]}, "prediction_text": "At Fort William Henry"}
{"answers": {"text": ["Ticonderoga Point,", "Ticonderoga Point", "Ticonderoga Point", "Ticonderoga Point", "Ticonderoga Point"], "answer_start": [891, 891, 891, 891, 891]}, "prediction_text": "Ticonderoga Point"}
{"answers": {"text": ["Colonel Monckton", "Colonel Monckton", "Colonel Monckton", "Colonel Monckton", "British"], "answer_start": [0, 0, 0, 0, 30]}, "prediction_text": "Colonel Monckton"}
{"answers": {"text": ["deportation of the French-speaking Acadian population from the area.", "deportation of the French-speaking Acadian population from the area", "captured Fort Beaus\u00e9jour", "captured Fort Beaus\u00e9jour", "the deportation of the French-speaking Acadian population"], "answer_start": [263, 263, 57, 57, 259]}, "prediction_text": "Colonel Monckton's forces cut supplies to Louisbourg."}
{"answers": {"text": ["Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757", "Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757", "deportation of the French-speaking Acadian population from the area", "Petitcodiac in 1755 and at Bloody Creek", "Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757"], "answer_start": [949, 949, 263, 949, 949]}, "prediction_text": "At Petitcodiac, at Bloody Creek, and at \u00cele Saint-Jean."}
{"answers": {"text": ["William Shirley", "William Shirley", "William Shirley", "William Shirley", "William Shirley"], "answer_start": [33, 33, 33, 33, 33]}, "prediction_text": "William Shirley"}
{"answers": {"text": ["Albany", "meeting in Albany in December 1755", "Albany", "Albany in December 1755", "a meeting in Albany"], "answer_start": [117, 106, 117, 117, 104]}, "prediction_text": "Albany"}
{"answers": {"text": ["capture Niagara, Crown Point and Duquesne, he proposed attacks on Fort Frontenac on the north shore of Lake Ontario", "Fort Frontenac", "Fort Frontenac", "Fort Frontenac", "Fort Frontenac"], "answer_start": [213, 279, 279, 279, 279]}, "prediction_text": "Fort Frontenac, Duquesne, and the Chaudi\u00e8re River."}
{"answers": {"text": ["through the wilderness of the Maine district and down the Chaudi\u00e8re River to attack the city of Quebec", "wilderness of the Maine district and down the Chaudi\u00e8re River", "the wilderness of the Maine district", "Maine", "the wilderness of the Maine district and down the Chaudi\u00e8re River"], "answer_start": [347, 359, 355, 377, 355]}, "prediction_text": "Maine district"}
{"answers": {"text": ["Major General James Abercrombie", "Lord Loudoun", "Major General James Abercrombie", "Major General James Abercrombie", "Major General James Abercrombie"], "answer_start": [63, 44, 63, 63, 63]}, "prediction_text": "Major General James Abercrombie"}
{"answers": {"text": ["Major General Louis-Joseph de Montcalm", "Major General Louis-Joseph de Montcalm", "Lord Loudoun", "Major General Louis-Joseph de Montcalm", "Major General Louis-Joseph de Montcalm"], "answer_start": [305, 305, 44, 305, 305]}, "prediction_text": "Major General Louis-Joseph de Montcalm"}
{"answers": {"text": ["May 18, 1756", "May 18, 1756", "May 18, 1756", "May 18, 1756", "May 18, 1756"], "answer_start": [525, 525, 525, 525, 525]}, "prediction_text": "May 18, 1756"}
{"answers": {"text": ["Oneida Carry", "Oneida Carry", "forts Shirley had erected at the Oneida Carry", "Oneida Carry", "Oneida Carry"], "answer_start": [323, 323, 290, 323, 323]}, "prediction_text": "Oneida Carry"}
{"answers": {"text": ["Battle of Fort Bull", "Battle of Fort Bull", "Battle of Fort Bull", "Battle of Fort Bull", "March Battle of Fort Bull"], "answer_start": [350, 350, 350, 350, 344]}, "prediction_text": "The British supply chain was weakened."}
{"answers": {"text": ["45,000 pounds", "45,000 pounds", "45,000 pounds", "45,000 pounds", "45,000 pounds"], "answer_start": [448, 448, 448, 448, 448]}, "prediction_text": "45,000 pounds"}
{"answers": {"text": ["hopes for campaigns on Lake Ontario, and endangered the Oswego garrison", "campaigns on Lake Ontario, and endangered the Oswego garrison", "campaigns on Lake Ontario", "campaigns on Lake Ontario", "hopes for campaigns on Lake Ontario"], "answer_start": [502, 512, 512, 512, 502]}, "prediction_text": "British hopes for campaigns"}
{"answers": {"text": ["Abercrombie", "Abercrombie", "Abercrombie", "Abercrombie", "Abercrombie"], "answer_start": [80, 80, 80, 80, 80]}, "prediction_text": "Montcalm"}
{"answers": {"text": ["Ticonderoga", "Ticonderoga", "Ticonderoga", "Ticonderoga", "Ticonderoga"], "answer_start": [334, 334, 334, 334, 334]}, "prediction_text": "Ticonderoga"}
{"answers": {"text": ["Oswego", "Oswego", "Oswego", "Oswego", "Oswego"], "answer_start": [493, 493, 493, 493, 493]}, "prediction_text": "Ticonderoga"}
{"answers": {"text": ["disposition of prisoners' personal effects", "the disposition of prisoners' personal effects", "about the disposition of prisoners' personal effects", "disposition of prisoners' personal effects", "the disposition of prisoners' personal effects"], "answer_start": [592, 588, 582, 592, 588]}, "prediction_text": "Disagreement about prisoners' personal effects"}
{"answers": {"text": ["attack on New France's capital, Quebec", "an attack on New France's capital, Quebec", "an attack on New France's capital, Quebec", "one major operation", "an attack on New France's capital, Quebec"], "answer_start": [106, 103, 103, 73, 103]}, "prediction_text": "An attack on New France's capital, Quebec."}
{"answers": {"text": ["to distract Montcalm", "distract Montcalm", "distract Montcalm", "distract Montcalm", "to distract Montcalm"], "answer_start": [192, 195, 195, 195, 192]}, "prediction_text": "Stabilizing Montcalm's position"}
{"answers": {"text": ["William Pitt", "William Pitt", "William Pitt", "William Pitt", "William Pitt"], "answer_start": [287, 287, 287, 287, 287]}, "prediction_text": "William Pitt"}
{"answers": {"text": ["returned to New York amid news that a massacre had occurred at Fort William Henry.", "returned to New York", "returned to New York", "returned to New York", "returned to New York"], "answer_start": [685, 685, 685, 685, 685]}, "prediction_text": "Returned to New York"}
{"answers": {"text": ["French irregular forces (Canadian scouts and Indians)", "French irregular forces", "French irregular forces", "French irregular forces", "French irregular forces"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "French irregular forces"}
{"answers": {"text": ["Lake George", "Lake George", "Lake George", "Lake George", "Lake George"], "answer_start": [255, 255, 255, 255, 255]}, "prediction_text": "Lake George"}
{"answers": {"text": ["attacked the British column, killing and capturing several hundred men, women, children, and slaves.", "attacked the British column", "attacked the British column", "attacked the British", "attacked the British column"], "answer_start": [564, 564, 564, 564, 564]}, "prediction_text": "attacked British column"}
{"answers": {"text": ["British blockade of the French coastline limited French shipping.", "British blockade of the French coastline", "British blockade of the French coastline", "British blockade of the French coastline", "British blockade"], "answer_start": [65, 65, 65, 65, 65]}, "prediction_text": "British blockade"}
{"answers": {"text": ["poor harvest", "allegedly corrupt machinations of Fran\u00e7ois Bigot", "poor harvest in 1757", "poor harvest in 1757", "a poor harvest"], "answer_start": [188, 238, 188, 188, 186]}, "prediction_text": "Corruption and inflated prices."}
{"answers": {"text": ["St. Lawrence, with primary defenses at Carillon, Quebec, and Louisbourg,", "St. Lawrence", "St. Lawrence", "St. Lawrence", "the defense of the St. Lawrence"], "answer_start": [873, 873, 873, 873, 854]}, "prediction_text": "Montcalm's focus was on New France."}
{"answers": {"text": ["British failures in North America, combined with other failures in the European theater", "British failures in North America, combined with other failures in the European theater", "British failures in North America, combined with other failures in the Europe", "failures in North America", "British failures in North America"], "answer_start": [4, 4, 4, 12, 4]}, "prediction_text": "Other failures in the European theater."}
{"answers": {"text": ["Loudoun", "Duke of Cumberland", "Loudoun", "Pitt", "Newcastle"], "answer_start": [363, 173, 363, 207, 123]}, "prediction_text": "Pitt"}
{"answers": {"text": ["three major offensive actions involving large numbers of regular troops", "three major offensive actions", "three major offensive actions", "three major offensive actions", "three major offensive actions"], "answer_start": [481, 481, 481, 481, 481]}, "prediction_text": "Three major offensive actions"}
{"answers": {"text": ["Two of the expeditions were successful, with Fort Duquesne and Louisbourg", "Two", "Two", "Two", "Two"], "answer_start": [641, 641, 641, 641, 641]}, "prediction_text": "Two successful expeditions"}
{"answers": {"text": ["3,600", "3,60", "3,600", "3,600", "3,600"], "answer_start": [102, 102, 102, 102, 102]}, "prediction_text": "3,600 Frenchmen"}
{"answers": {"text": ["18,000 regulars, militia and Native American allies", "18,000", "18,000", "18,000", "18,000"], "answer_start": [174, 174, 174, 174, 174]}, "prediction_text": "3,600 troops"}
{"answers": {"text": ["sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac", "successfully destroyed Fort Frontenac", "destroyed Fort Frontenac", "destroyed Fort Frontenac", "destroyed Fort Frontenac"], "answer_start": [360, 403, 416, 416, 416]}, "prediction_text": "He saved something from disaster."}
{"answers": {"text": ["recalled and replaced by Jeffery Amherst, victor at Louisbourg.", "Abercrombie was recalled and replaced", "was recalled and replaced by Jeffery Amherst", "recalled and replaced", "Abercrombie was recalled and replaced by Jeffery Amherst,"], "answer_start": [557, 541, 553, 557, 541]}, "prediction_text": "Abercrombie saved something from disaster."}
{"answers": {"text": ["invasion of Britain, to draw British resources away from North America and the European mainland", "invasion of Britain", "an invasion of Britain", "invasion of Britain", "an invasion of Britain"], "answer_start": [175, 175, 172, 175, 172]}, "prediction_text": "Invasion of Britain"}
{"answers": {"text": ["The invasion failed both militarily and politically, as Pitt again planned significant campaigns against New France", "failed", "invasion failed", "failed", "The invasion failed both militarily and politically"], "answer_start": [273, 286, 277, 286, 273]}, "prediction_text": "Failed militarily and politically."}
{"answers": {"text": ["Lagos and Quiberon Bay.", "battles at Lagos and Quiberon Bay", "Lagos and Quiberon Bay", "Lagos and Quiberon Bay", "Lagos and Quiberon Bay"], "answer_start": [505, 494, 505, 505, 505]}, "prediction_text": "Lagos and Quiberon Bay"}
{"answers": {"text": ["James Wolfe", "James Wolfe", "James Wolfe", "James Wolfe", "James Wolfe"], "answer_start": [116, 116, 116, 116, 116]}, "prediction_text": "Montcalm defeated British commander, James Wolfe."}
{"answers": {"text": ["cut off the French frontier forts further to the west and south", "successfully cut off the French frontier forts further to the west and south", "cut off the French frontier forts", "cut off the French frontier forts", "successfully cut off the French frontier forts"], "answer_start": [254, 241, 254, 254, 241]}, "prediction_text": "Cut French frontier further to the west and south."}
{"answers": {"text": ["Battle of Sainte-Foy", "Battle of Sainte-Foy", "Sainte-Foy", "Battle of Sainte-Foy", "Battle of Sainte-Foy"], "answer_start": [405, 405, 415, 405, 405]}, "prediction_text": "Battle of Sainte-Foy"}
{"answers": {"text": ["naval Battle of the Restigouche", "Battle of the Restigouche", "Battle of the Restigouche", "Battle of the Restigouche", "Battle of the Restigouche"], "answer_start": [502, 508, 508, 508, 508]}, "prediction_text": "Battle of the Restigouche"}
{"answers": {"text": ["Governor Vaudreuil", "Governor Vaudreuil", "Governor Vaudreuil", "Governor Vaudreuil", "Governor Vaudreuil"], "answer_start": [55, 55, 55, 55, 55]}, "prediction_text": "Governor Vaudreuil"}
{"answers": {"text": ["freedom to continue worshiping in their Roman Catholic tradition, continued ownership of their property,", "French residents who chose to remain in the colony would be given freedom", "continue worshiping in their Roman Catholic tradition, continued ownership of their property, and the right to remain undisturbed", "French residents who chose to remain in the colony would be given freedom"], "answer_start": [247, 181, 258, 181]}, "prediction_text": "For French residents to remain in the colony"}
{"answers": {"text": ["General Amherst.", "General Amherst", "General Amherst", "Amherst", "Amherst"], "answer_start": [119, 119, 119, 127, 127]}, "prediction_text": "Governor Vaudreuil"}
{"answers": {"text": ["signing of the Treaty of Paris on 10 February 1763", "10 February 1763", "10 February 1763", "10 February 1763", "10 February 1763"], "answer_start": [51, 85, 85, 85, 85]}, "prediction_text": "10 February 1763"}
{"answers": {"text": ["Treaty of Hubertusburg on 15 February 1763", "15 February 1763", "15 February 1763", "15 February 1763", "15 February 1763"], "answer_start": [178, 204, 204, 204, 204]}, "prediction_text": "1763 (Treaty of Hubertusburg)"}
{"answers": {"text": ["continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique", "surrendering either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique", "either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique,", "its continental North American possessions east of the Mississippi or the Caribbean islands", "surrendering either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique"], "answer_start": [287, 263, 276, 283, 263]}, "prediction_text": "East of the Mississippi or the Caribbean islands."}
{"answers": {"text": ["value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "They viewed the economic value of the Caribbean islands' sugar cane to be greater", "value of the Caribbean islands' sugar", "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent"], "answer_start": [659, 634, 634, 659, 634]}, "prediction_text": "To retain Saint Pierre and Miquelon."}
{"answers": {"text": ["80,000", "80,000", "80,000", "80,000", "80,000"], "answer_start": [86, 86, 86, 86, 86]}, "prediction_text": "Approximately 80,000"}
{"answers": {"text": ["1755", "1755", "1755", "1755", "1755"], "answer_start": [186, 186, 186, 186, 186]}, "prediction_text": "1755"}
{"answers": {"text": ["throughout its North American provinces", "throughout its North American provinces", "North American provinces", "North American provinces", "its North American provinces"], "answer_start": [315, 315, 330, 330, 326]}, "prediction_text": "North American provinces"}
{"answers": {"text": ["New Orleans", "New Orleans", "New Orleans", "New Orleans", "New Orleans"], "answer_start": [640, 398, 398, 640, 398]}, "prediction_text": "New Orleans"}
{"answers": {"text": ["King George III", "King George III", "King George III", "King George III", "King George III"], "answer_start": [22, 22, 22, 22, 22]}, "prediction_text": "King George III"}
{"answers": {"text": ["outlined the division and administration of the newly conquered territory", "outlined the division and administration of the newly conquered territory", "division and administration of the newly conquered territory", "division and administration", "the division and administration of the newly conquered territory"], "answer_start": [102, 102, 115, 115, 111]}, "prediction_text": "Divided and administered territory"}
{"answers": {"text": ["west of the Appalachian Mountains", "lands west of the Appalachian Mountains", "west of the Appalachian Mountains", "west of the Appalachian Mountains", "west of the Appalachian Mountains"], "answer_start": [345, 339, 345, 345, 345]}, "prediction_text": "West of the Appalachian Mountains"}
{"answers": {"text": ["Most went to Cuba,", "Most went to Cuba", "Cuba", "Cuba", "Cuba"], "answer_start": [831, 831, 844, 844, 844]}, "prediction_text": "Cuba"}
{"answers": {"text": ["military roads to the area by Braddock and Forbes", "construction of military roads to the area by Braddock and Forbes", "the construction of military roads to the area", "military roads to the area", "the construction of military roads"], "answer_start": [304, 288, 284, 304, 284]}, "prediction_text": "Construction of military roads"}
{"answers": {"text": ["1769", "1769", "1769", "1769", "1769"], "answer_start": [443, 443, 443, 443, 443]}, "prediction_text": "1769"}
{"answers": {"text": ["Choctaw and the Creek", "tribes that did not want to do business with the British", "Choctaw and the Creek", "Choctaw and the Creek"], "answer_start": [646, 553, 646, 646]}, "prediction_text": "Spanish Catholic population"}
{"answers": {"text": ["disappearance of a strong ally and counterweight to British expansion, leading to their ultimate dispossession", "disappearance of a strong ally and counterweight to British expansion", "elimination of French power", "."], "answer_start": [88, 88, 33, 985]}, "prediction_text": "The elimination of French power in North America."}
{"answers": {"text": ["force", "force", "the concept of force", "the concept of force", "force", "force"], "answer_start": [46, 46, 31, 31, 46, 46]}, "prediction_text": "Force"}
{"answers": {"text": ["fundamental error", "A fundamental error", "A fundamental error", "A fundamental error", "A fundamental error", "A fundamental error"], "answer_start": [387, 385, 385, 385, 385, 385]}, "prediction_text": "Belief in force required constant velocity."}
{"answers": {"text": ["Sir Isaac Newton", "Sir Isaac Newton", "Sir Isaac Newton", "Sir Isaac Newton", "Sir Isaac Newton", "Sir Isaac Newton"], "answer_start": [654, 654, 654, 654, 654, 654]}, "prediction_text": "Galileo Galilei"}
{"answers": {"text": ["nearly three hundred years", "nearly three hundred years", "nearly three hundred years", "nearly three hundred years", "nearly three hundred years", "three hundred years"], "answer_start": [727, 727, 727, 727, 727, 734]}, "prediction_text": "Nearly three hundred years"}
{"answers": {"text": ["Einstein", "Einstein", "Einstein", "Einstein", "Einstein", "Einstein"], "answer_start": [782, 782, 782, 782, 782, 782]}, "prediction_text": "Sir Isaac Newton"}
{"answers": {"text": ["Standard Model", "Standard Model", "Standard Model", "Standard Model", "a Standard Model", "a Standard Model"], "answer_start": [149, 149, 149, 149, 147, 147]}, "prediction_text": "Standard Model"}
{"answers": {"text": ["gauge bosons", "gauge bosons", "gauge bosons", "gauge bosons", "gauge bosons", "gauge bosons"], "answer_start": [281, 281, 281, 281, 281, 281]}, "prediction_text": "gauge bosons"}
{"answers": {"text": ["strong", "strong", "strong,", "strong", "strong", "strong, electromagnetic"], "answer_start": [444, 444, 444, 444, 444, 444]}, "prediction_text": "Weak and electromagnetic forces"}
{"answers": {"text": ["gravitational", "gravitational", "gravitational", "gravitational", "gravitational", "gravitational"], "answer_start": [479, 479, 479, 479, 479, 479]}, "prediction_text": "Stronger electromagnetism"}
{"answers": {"text": ["electroweak interaction", "a more fundamental electroweak interaction", "more fundamental electroweak interaction.", "a more fundamental electroweak interaction", "fundamental electroweak interaction."], "answer_start": [665, 646, 648, 646, 653]}, "prediction_text": "A more fundamental electroweak interaction."}
{"answers": {"text": ["Aristotle", "Aristotle", "Aristotle", "Aristotle", "Aristotle", "Aristotle"], "answer_start": [0, 0, 0, 0, 0, 0]}, "prediction_text": "Aristotle"}
{"answers": {"text": ["Aristotelian cosmology", "Aristotelian cosmology", "Aristotelian cosmology", "Aristotelian cosmology", "cosmology", "Aristotelian cosmology"], "answer_start": [95, 95, 95, 95, 108, 95]}, "prediction_text": "Aristotelian cosmology"}
{"answers": {"text": ["four", "four", "four", "four", "four", "four"], "answer_start": [173, 173, 173, 173, 173, 173]}, "prediction_text": "Four elements"}
{"answers": {"text": ["on the ground", "ground", "heavy bodies to fall", "on the ground", "on the ground", "on the ground"], "answer_start": [381, 388, 540, 381, 381, 381]}, "prediction_text": "At the ground"}
{"answers": {"text": ["unnatural", "unnatural", "natural motion", "unnatural", "continued application of a force", "unnatural"], "answer_start": [598, 598, 577, 598, 641, 598]}, "prediction_text": "Natural motion"}
{"answers": {"text": ["17th century", "17th century", "17th century", "the 17th century", "17th century", "17th century"], "answer_start": [80, 80, 80, 76, 80, 80]}, "prediction_text": "17th century work of Galileo Galilei"}
{"answers": {"text": ["Galileo Galilei", "Galileo Galilei", "Galileo Galilei", "Galileo Galilei,", "Galileo Galilei", "Galileo Galilei"], "answer_start": [101, 101, 101, 101, 101, 101]}, "prediction_text": "Galileo Galilei"}
{"answers": {"text": ["impetus", "innate force of impetus", "gravity", "an innate force of impetus", "innate force of impetus", "innate force of impetus"], "answer_start": [220, 204, 447, 201, 204, 204]}, "prediction_text": "An innate force of impetus"}
{"answers": {"text": ["Galileo", "Galileo", "Galileo Galilei", "Galileo", "Galileo", "Galileo"], "answer_start": [229, 229, 101, 229, 229, 229]}, "prediction_text": "Galileo Galilei"}
{"answers": {"text": ["friction", "friction", "gravity", "friction", "friction", "force"], "answer_start": [589, 589, 447, 589, 589, 570]}, "prediction_text": "Gravity"}
{"answers": {"text": ["Newton", "Newton's", "Newton's", "Newton's", "Newton's"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Newton's First Law of Motion"}
{"answers": {"text": ["lack of net force", "lack of net force", "constant velocity was associated with a lack of net force", "constant velocity was associated with a lack of net force", "lack of net force"], "answer_start": [252, 252, 212, 212, 252]}, "prediction_text": "Newton's First Law of Motion"}
{"answers": {"text": ["Newton", "Newton", "Newton", "Newton", "Newton"], "answer_start": [319, 319, 319, 319, 319]}, "prediction_text": "Newton"}
{"answers": {"text": ["Newton's First", "first law", "Newton's First Law", "First Law", "Newton's First Law"], "answer_start": [737, 526, 737, 746, 737]}, "prediction_text": "Newton's First Law of Motion"}
{"answers": {"text": ["the same", "a Galilean transformation", "Galilean transformation", "the laws of physics are the same in every inertial frame of reference", "the same in every inertial frame of reference"], "answer_start": [1065, 1146, 1148, 1041, 1065]}, "prediction_text": "Newton's First Law of Motion and rest."}
{"answers": {"text": ["laws of physics", "the laws of physics", "the laws of physics", "the laws of physics", "the laws of physics"], "answer_start": [78, 74, 74, 74, 74]}, "prediction_text": "Laws of physics do not change."}
{"answers": {"text": ["parabolic", "parabolic path", "a curving parabolic path", "curving parabolic path", "curving parabolic path"], "answer_start": [411, 411, 401, 403, 403]}, "prediction_text": "Curving parabolic path"}
{"answers": {"text": ["at rest", "at rest", "rest", "the vehicle and everything inside of it is at rest:"], "answer_start": [770, 770, 773, 727]}, "prediction_text": "Outside world"}
{"answers": {"text": ["Inertia", "Inertia", "Inertia", "Inertia", "Inertia"], "answer_start": [1067, 1067, 1067, 1067, 1067]}, "prediction_text": "It applies equally well to constant velocity motion as it does to rest."}
{"answers": {"text": ["inertia", "inertia", "inertia", "inertia", "inertia"], "answer_start": [15, 15, 15, 15, 15]}, "prediction_text": "inertia"}
{"answers": {"text": ["rotational inertia of planet", "rotational inertia of planet Earth", "rotational inertia", "rotational inertia", "The rotational inertia of planet Earth"], "answer_start": [197, 197, 197, 197, 193]}, "prediction_text": "Rotational inertia"}
{"answers": {"text": ["Albert Einstein", "Albert Einstein", "Albert Einstein", "Albert Einstein", "Albert Einstein"], "answer_start": [309, 309, 309, 309, 309]}, "prediction_text": "Albert Einstein"}
{"answers": {"text": ["weightlessness", "weightlessness", "weightlessness", "weightlessness", "weightlessness"], "answer_start": [602, 602, 602, 602, 602]}, "prediction_text": "Weightlessness"}
{"answers": {"text": ["principle of equivalence", "principle of equivalence", "principle of equivalence", "principle of equivalence", "principle of equivalence"], "answer_start": [1062, 1062, 1062, 1062, 1062]}, "prediction_text": "The principle of inertia"}
{"answers": {"text": ["Newton's Second Law", "Newton's Second Law", "Newton's Second Law", "Newton's Second Law", "Newton's Second Law"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Newton's Second Law"}
{"answers": {"text": ["kinematic", "kinematic measurements", "kinematic", "kinematic", "kinematic"], "answer_start": [174, 174, 174, 174, 174]}, "prediction_text": "Reference frame analysis"}
{"answers": {"text": ["General relativity", "General relativity", "General relativity", "General relativity", "General relativity"], "answer_start": [385, 385, 385, 385, 385]}, "prediction_text": "Mass and space-time"}
{"answers": {"text": ["General relativity", "coherent theory of quantum gravity", "General relativity", "General relativity"], "answer_start": [385, 469, 385, 385]}, "prediction_text": "A coherent theory of quantum gravity."}
{"answers": {"text": ["fixed", "an equality", "fixed", "fixed", "unclear"], "answer_start": [760, 701, 760, 760, 511]}, "prediction_text": "Space-time and mass"}
{"answers": {"text": ["Newton's Third", "Newton's Third Law", "Newton's Third Law", "Newton's Third Law", "Newton's Third Law"], "answer_start": [0, 0, 0, 0, 0]}, "prediction_text": "Newton's Third Law"}
{"answers": {"text": ["Newton's Third", "The third law", "The third law", "Newton's Third Law", "Newton's Third Law"], "answer_start": [0, 135, 135, 0, 0]}, "prediction_text": "Newton's Third Law"}
{"answers": {"text": ["unidirectional", "unidirectional force", "unidirectional force", "unidirectional", "unidirectional force"], "answer_start": [264, 264, 264, 264, 264]}, "prediction_text": "Unidirectional force or force that acts on only one body."}
{"answers": {"text": ["magnitude", "action-reaction", "the action-reaction law", "equal in magnitude"], "answer_start": [456, 534, 530, 447]}, "prediction_text": "F and \u2212F are equal in magnitude and opposite in direction."}
{"answers": {"text": ["center of mass", "center of mass", "the center of mass", "the center of mass", "the center of mass"], "answer_start": [421, 421, 417, 417, 417]}, "prediction_text": "Center of mass experiences acceleration."}
{"answers": {"text": ["closed", "closed system", "closed system of particles", "a closed system of particles", "a closed system"], "answer_start": [21, 21, 21, 19, 19]}, "prediction_text": "Closed system of particles"}
{"answers": {"text": ["mass of the system", "mass of the system", "the mass of the system", "the mass of the system", "mass of the system"], "answer_start": [535, 535, 531, 531, 535]}, "prediction_text": "Mass of system"}
{"answers": {"text": ["intuitive understanding", "an intuitive understanding", "an intuitive understanding", "intuitive understanding", "an intuitive understanding"], "answer_start": [67, 64, 64, 67, 64]}, "prediction_text": "An intuitive understanding"}
{"answers": {"text": ["standard measurement scale", "precise operational definitions", "precise operational definitions", "precise operational definitions", "precise operational definitions"], "answer_start": [319, 224, 224, 224, 224]}, "prediction_text": "precise operational definitions"}
{"answers": {"text": ["Newtonian mechanics", "Newtonian mechanics", "Newtonian mechanics", "Newtonian mechanics", "Newtonian mechanics"], "answer_start": [500, 500, 500, 500, 500]}, "prediction_text": "Newtonian mechanics"}
{"answers": {"text": ["experimentation", "Through experimentation", "Through experimentation", "Through experimentation", "experimentation"], "answer_start": [355, 347, 347, 347, 355]}, "prediction_text": "Through experimentation"}
{"answers": {"text": ["vector quantities", "vector quantities", "vector quantities", "\"vector quantities\"", "dependent upon how strong"], "answer_start": [159, 159, 159, 158, 52]}, "prediction_text": "Vector quantities"}
{"answers": {"text": ["denoted scalar quantities", "scalar quantities", "denoted scalar quantities", "scalar quantities", "scalar quantities"], "answer_start": [300, 308, 300, 308, 308]}, "prediction_text": "Force quantities"}
{"answers": {"text": ["Associating forces with vectors", "Associating forces with vectors", "Associating forces with vectors", "Associating forces with vectors", "know both the magnitude and the direction of both forces to calculate the result"], "answer_start": [1188, 1188, 1188, 1188, 430]}, "prediction_text": "Associating forces with vectors avoids problems."}
{"answers": {"text": ["ambiguous", "ambiguous", "ambiguous", "ambiguous", "ambiguous"], "answer_start": [598, 598, 598, 598, 598]}, "prediction_text": "ambiguous"}
{"answers": {"text": ["Associating forces with vectors", "Associating forces with vectors", "adding the two force magnitudes or subtracting one from the other", "knowing the direction of the forces", "it is impossible"], "answer_start": [1188, 1188, 1121, 1019, 772]}, "prediction_text": "Using both forces' magnitudes."}
{"answers": {"text": ["static equilibrium", "static equilibrium", "conditions of static equilibrium", "static equilibrium", "static equilibrium"], "answer_start": [77, 77, 63, 77, 77]}, "prediction_text": "Static equilibrium"}
{"answers": {"text": ["magnitude and direction", "magnitude and direction", "magnitude and direction", "magnitude and direction", "magnitude and direction"], "answer_start": [248, 248, 248, 248, 248]}, "prediction_text": "Magnitudes and direction."}
{"answers": {"text": ["net force", "net force", "the resultant (also called the net force)", "net force", "net force"], "answer_start": [366, 366, 335, 366, 366]}, "prediction_text": "The resultant force is equal in magnitude and direction to the transversal of the parallelogram."}
{"answers": {"text": ["respective lines of application", "respective lines of application", "their respective lines of application", "their respective lines of application", "their effects on the motion of the body"], "answer_start": [863, 863, 857, 857, 942]}, "prediction_text": "Line of application"}
{"answers": {"text": ["parallelogram", "parallelogram", "parallelogram", "parallelogram", "parallelogram"], "answer_start": [506, 506, 413, 625, 413]}, "prediction_text": "parallelogram"}
{"answers": {"text": ["independent components", "independent components", "independent components", "independent components"], "answer_start": [57, 57, 57, 57]}, "prediction_text": "Orthogonal basis vectors"}
{"answers": {"text": ["two", "two", "two", "two"], "answer_start": [177, 177, 177, 177]}, "prediction_text": "Two forces"}
{"answers": {"text": ["the original force", "the original force", "the original force", "the original force"], "answer_start": [292, 292, 292, 292]}, "prediction_text": "The original force is split into two forces."}
{"answers": {"text": ["orthogonal", "uniquely determined", "orthogonal components", "orthogonal components"], "answer_start": [497, 557, 497, 497]}, "prediction_text": "Orthogonal components"}
{"answers": {"text": ["three-dimensional", "three-dimensional", "three-dimensional", "three-dimensional"], "answer_start": [1134, 1134, 1134, 1134]}, "prediction_text": "Three-dimensional force vectors."}
{"answers": {"text": ["static friction", "static friction", "friction", "static friction", "applied force"], "answer_start": [147, 147, 154, 147, 119]}, "prediction_text": "Static friction"}
{"answers": {"text": ["static friction", "static friction", "static friction", "static friction", "static friction"], "answer_start": [147, 147, 147, 147, 147]}, "prediction_text": "Static friction"}
{"answers": {"text": ["applied", "applied force", "applied force", "applied force", "applied"], "answer_start": [297, 119, 297, 297, 297]}, "prediction_text": "applied force"}
{"answers": {"text": ["applied force", "applied force", "applied force", "applied force", "applied force"], "answer_start": [403, 403, 403, 403, 403]}, "prediction_text": "Attracts static friction"}
{"answers": {"text": ["forces", "static equilibrium", "forces", "force of gravity", "forces"], "answer_start": [75, 2, 75, 225, 75]}, "prediction_text": "Forces between objects of constant density."}
{"answers": {"text": ["spring reaction force", "spring reaction force", "the force of gravity", "spring reaction", "spring reaction force"], "answer_start": [299, 299, 221, 299, 299]}, "prediction_text": "\"Spring reaction force\""}
{"answers": {"text": ["gravity", "object's weight", "spring reaction force", "the object's weight", "the object's weight"], "answer_start": [234, 340, 299, 336, 336]}, "prediction_text": "The object's weight"}
{"answers": {"text": ["gravity", "gravity", "the force of gravity", "force of gravity", "the force of gravity"], "answer_start": [439, 439, 426, 430, 426]}, "prediction_text": "Archimedes' principle"}
{"answers": {"text": ["Isaac Newton", "Isaac Newton", "Isaac Newton", "Isaac Newton", "Isaac Newton"], "answer_start": [757, 757, 757, 757, 757]}, "prediction_text": "Isaac Newton"}
{"answers": {"text": ["Galileo", "Galileo", "Galileo", "Galileo", "Galileo"], "answer_start": [43, 43, 43, 43, 43]}, "prediction_text": "Galileo"}
{"answers": {"text": ["rest", "rest", "rest", "rest", "rest"], "answer_start": [354, 354, 354, 354, 354]}, "prediction_text": "Rest"}
{"answers": {"text": ["Galileo", "Aristotle's", "Aristotle", "Aristotle", "Aristotle's"], "answer_start": [272, 381, 381, 381, 381]}, "prediction_text": "Aristotle"}
{"answers": {"text": ["behind the foot of the mast", "straight down", "behind the foot of the mast", "behind the foot of the mast", "behind the foot of the mast of a moving ship"], "answer_start": [869, 753, 869, 869, 869]}, "prediction_text": "Behind the foot of the mast."}
{"answers": {"text": ["foot of the mast", "the foot of the mast", "at the foot of the mast", "at the foot of the mast", "at the foot of the mast"], "answer_start": [1003, 999, 996, 996, 996]}, "prediction_text": "Behind the foot of the mast."}
{"answers": {"text": ["dynamic equilibrium", "dynamic equilibrium", "dynamic equilibrium", "dynamic equilibrium", "dynamic equilibrium"], "answer_start": [17, 17, 17, 17, 17]}, "prediction_text": "A force is applied."}
{"answers": {"text": ["kinetic friction force", "kinetic friction force", "kinetic friction force", "kinetic friction", "kinetic friction force"], "answer_start": [189, 189, 189, 189, 189]}, "prediction_text": "kinetic friction"}
{"answers": {"text": ["kinetic friction", "object started with a non-zero velocity", "kinetic friction", "kinetic friction"], "answer_start": [470, 293, 470, 470]}, "prediction_text": "applied force"}
{"answers": {"text": ["Aristotle", "Aristotle", "Aristotle", "Aristotle", "Aristotle"], "answer_start": [381, 381, 381, 381, 381]}, "prediction_text": "Aristotle"}
{"answers": {"text": ["Schr\u00f6dinger", "Newtonian equations", "the Schr\u00f6dinger equation", "Schr\u00f6dinger", "Schr\u00f6dinger equation"], "answer_start": [178, 210, 174, 178, 178]}, "prediction_text": "Schr\u00f6dinger equation"}
{"answers": {"text": ["Newtonian", "Newtonian equations", "Newtonian equations.", "Newtonian", "Newtonian equations"], "answer_start": [210, 210, 210, 210, 210]}, "prediction_text": "Schr\u00f6dinger equation"}
{"answers": {"text": ["classical position variables", "classical position variables", "classical position variables", "classical position variables", "classical position variables"], "answer_start": [544, 544, 544, 544, 544]}, "prediction_text": "Classical position variables"}
{"answers": {"text": ["quantized", "operators", "quantized", "quantized", "quantized"], "answer_start": [309, 90, 309, 309, 309]}, "prediction_text": "Quantized results"}
{"answers": {"text": ["force", "force", "force", "force", "The notion \"force\""], "answer_start": [12, 12, 12, 12, 0]}, "prediction_text": "Force"}
{"answers": {"text": ["spin", "spin", "spin", "spin", "the \"spin"], "answer_start": [220, 220, 220, 220, 215]}, "prediction_text": "\"spin\""}
{"answers": {"text": ["Pauli", "Pauli principle", "Pauli principle", "Pauli", "Pauli"], "answer_start": [244, 244, 244, 244, 244]}, "prediction_text": "They exclude each other from their places."}
{"answers": {"text": ["spin", "value of the spin", "the value of the spin", "the spin", "value of the spin,"], "answer_start": [333, 320, 316, 329, 320]}, "prediction_text": "On the spin value"}
{"answers": {"text": ["antiparallel", "antiparallel spins", "antisymmetric", "antiparallel", "antiparallel"], "answer_start": [668, 668, 540, 668, 668]}, "prediction_text": "Antisymmetric"}
{"answers": {"text": ["parallel", "antisymmetric", "symmetric", "parallel", "symmetric"], "answer_start": [494, 540, 464, 494, 464]}, "prediction_text": "Antisymmetric"}
{"answers": {"text": ["mathematical by-product", "mathematical by-product of exchange", "a mathematical by-product of exchange of momentum", "mathematical by-product of exchange"], "answer_start": [88, 88, 86, 88]}, "prediction_text": "As a mathematical by-product of exchange of momentum-carrying gauge bosons."}
{"answers": {"text": ["force", "4-momentum in relativity and momentum of virtual particles in quantum electrodynamics", "force"], "answer_start": [249, 317, 249]}, "prediction_text": "Force is a redundant concept arising from momentum conservation."}
{"answers": {"text": ["conservation of momentum", "conservation of momentum", "conservation of momentum", "the currently known fundamental forces"], "answer_start": [409, 409, 409, 580]}, "prediction_text": "Conservation of momentum"}
{"answers": {"text": ["Feynman", "Feynman diagrams", "Feynman"], "answer_start": [1199, 1199, 1199]}, "prediction_text": "Feynman diagrams"}
{"answers": {"text": ["straight", "straight line", "straight", "straight"], "answer_start": [1280, 1280, 1280, 1280]}, "prediction_text": "Wavy lines"}
{"answers": {"text": ["four", "four", "four", "four"], "answer_start": [47, 47, 47, 47]}, "prediction_text": "Four fundamental interactions"}
{"answers": {"text": ["strong and weak", "strong and weak forces", "strong and weak", "strong and weak forces"], "answer_start": [82, 82, 82, 82]}, "prediction_text": "Strong and weak forces"}
{"answers": {"text": ["electromagnetic", "electromagnetic force", "electromagnetic"], "answer_start": [277, 277, 277]}, "prediction_text": "The electromagnetic force"}
{"answers": {"text": ["masses", "masses", "masses", "masses"], "answer_start": [371, 371, 371, 371]}, "prediction_text": "masses"}
{"answers": {"text": ["Pauli exclusion principle", "the Pauli exclusion principle", "the Pauli exclusion principle", "Pauli exclusion principle"], "answer_start": [575, 571, 571, 575]}, "prediction_text": "Exclusion Principle"}
{"answers": {"text": ["Isaac Newton", "Isaac Newton", "Isaac Newton", "Isaac Newton"], "answer_start": [125, 125, 125, 125]}, "prediction_text": "Michael Faraday and James Clerk Maxwell"}
{"answers": {"text": ["20th", "the 20th century", "20th", "20th"], "answer_start": [479, 475, 479, 479]}, "prediction_text": "20th century"}
{"answers": {"text": ["unification", "unification models", "unification", "unification"], "answer_start": [1457, 1457, 1457, 1457]}, "prediction_text": "String theory"}
{"answers": {"text": ["self-consistent unification", "self-consistent unification models", "self-consistent unification", "self-consistent unification models that would combine all four fundamental interactions"], "answer_start": [1441, 1441, 1441, 1441]}, "prediction_text": "String theory"}
{"answers": {"text": ["Isaac Newton", "Isaac Newton", "Isaac Newton", "Isaac Newton"], "answer_start": [83, 83, 83, 83]}, "prediction_text": "Isaac Newton"}
{"answers": {"text": ["Galileo", "Galileo", "Galileo", "Galileo"], "answer_start": [233, 233, 233, 233]}, "prediction_text": "Isaac Newton"}
{"answers": {"text": ["about 9.81 meters per second squared", "about 9.81 meters per second squared", "about 9.81 meters per second", "9.81 meters per second"], "answer_start": [555, 555, 555, 561]}, "prediction_text": "At a constant rate"}
{"answers": {"text": ["sea level", "sea level", "sea level", "from sea level"], "answer_start": [624, 624, 624, 619]}, "prediction_text": "From sea level"}
{"answers": {"text": ["force of gravity", "the force of gravity on an object", "force of gravity", "force of gravity"], "answer_start": [746, 742, 746, 746]}, "prediction_text": "The force of gravity on an object at the Earth's surface is directly proportional to its mass."}
{"answers": {"text": ["at larger distances.", "at larger distances", "at larger distances", "at larger distances"], "answer_start": [87, 87, 87, 87]}, "prediction_text": "At larger distances."}
{"answers": {"text": ["the Moon", "the mass () and the radius () of the Earth", "force of gravity", "the same force of gravity if the acceleration due to gravity decreased as an inverse square law."], "answer_start": [166, 475, 222, 213]}, "prediction_text": "Same force of gravity"}
{"answers": {"text": ["mass", "the mass of the attracting body", "the mass of the attracting body", "the mass of the attracting body"], "answer_start": [395, 391, 391, 391]}, "prediction_text": "Mass of attracting body"}
{"answers": {"text": ["radius () of the Earth", "the radius () of the Earth", "radius"], "answer_start": [495, 491, 495]}, "prediction_text": "Gravitational acceleration formula"}
{"answers": {"text": ["Newton's Universal Gravitation Constant,", "dimensional constant", "a dimensional constant", "a dimensional constant"], "answer_start": [134, 20, 18, 18]}, "prediction_text": "A dimensional constant"}
{"answers": {"text": ["Henry Cavendish", "Henry Cavendish", "Henry Cavendish", "Henry Cavendish"], "answer_start": [245, 245, 245, 245]}, "prediction_text": "Henry Cavendish"}
{"answers": {"text": ["1798", "1798", "1798", "1798"], "answer_start": [236, 236, 236, 236]}, "prediction_text": "1798"}
{"answers": {"text": ["Newton", "Newton", "Newton", "Newton"], "answer_start": [492, 643, 492, 492]}, "prediction_text": "Henry Cavendish"}
{"answers": {"text": ["Mercury", "Mercury", "Mercury", "Mercury"], "answer_start": [36, 36, 36, 36]}, "prediction_text": "Venus"}
{"answers": {"text": ["Vulcan", "Vulcan", "Vulcan", "Vulcan"], "answer_start": [170, 170, 170, 170]}, "prediction_text": "Vulcan"}
{"answers": {"text": ["theory of general relativity", "theory of general relativity (GR)", "general relativity", "general relativity"], "answer_start": [324, 324, 334, 334]}, "prediction_text": "Newton's Theory of Gravity"}
{"answers": {"text": ["Albert Einstein", "Albert Einstein", "Albert Einstein", "Albert Einstein"], "answer_start": [293, 293, 293, 293]}, "prediction_text": "Albert Einstein"}
{"answers": {"text": ["Albert Einstein", "Albert Einstein", "Albert Einstein", "Albert Einstein"], "answer_start": [293, 293, 293, 293]}, "prediction_text": "Albert Einstein"}
{"answers": {"text": ["general relativity", "general relativity", "general relativity", "general relativity"], "answer_start": [24, 24, 24, 24]}, "prediction_text": "General relativity"}
{"answers": {"text": ["ballistic trajectory", "path between two space-time events", "straight lines", "the shortest space-time path between two space-time events."], "answer_start": [716, 322, 244, 298]}, "prediction_text": "Space-time path in space"}
{"answers": {"text": ["gravitational force", "gravitational force", "gravitational force", "gravitational force"], "answer_start": [1117, 1117, 1117, 1117]}, "prediction_text": "Gravitational force"}
{"answers": {"text": ["global", "a global sense", "in space", "the perspective of the object"], "answer_start": [498, 496, 685, 363]}, "prediction_text": "In a global sense."}
{"answers": {"text": ["electric current", "electric current", "electric current", "electric current"], "answer_start": [36, 36, 36, 36]}, "prediction_text": "Time rate of change of electric charge"}
{"answers": {"text": ["unified electromagnetic", "unified electromagnetic force", "electromagnetic", "unified electromagnetic force"], "answer_start": [294, 294, 302, 294]}, "prediction_text": "Magnetism"}
{"answers": {"text": ["Lorentz's Law", "Lorentz's Law", "Lorentz's Law", "Lorentz's Law"], "answer_start": [139, 139, 139, 139]}, "prediction_text": "Lorentz's Law"}
{"answers": {"text": ["electrostatic force", "the electrostatic force (due to the electric field) and the magnetic force (due to the magnetic field).", "electrostatic force (due to the electric field) and the magnetic force", "the electrostatic force (due to the electric field) and the magnetic force"], "answer_start": [389, 385, 389, 385]}, "prediction_text": "The electrostatic force and the magnetic force."}
{"answers": {"text": ["James Clerk Maxwell", "James Clerk Maxwell", "James Clerk Maxwell", "James Clerk Maxwell"], "answer_start": [88, 88, 88, 88]}, "prediction_text": "James Clerk Maxwell"}
{"answers": {"text": ["1864", "1864", "1864", "1864"], "answer_start": [78, 78, 78, 78]}, "prediction_text": "1864"}
{"answers": {"text": ["20", "20", "20", "20"], "answer_start": [159, 159, 159, 159]}, "prediction_text": "20 scalar equations"}
{"answers": {"text": ["4", "4", "4", "4"], "answer_start": [215, 215, 215, 215]}, "prediction_text": "4 vector equations"}
{"answers": {"text": ["Maxwell", "James Clerk Maxwell", "Maxwell", "Maxwell"], "answer_start": [444, 88, 444, 444]}, "prediction_text": "James Clerk Maxwell"}
{"answers": {"text": ["electromagnetic theory", "electromagnetic theory", "electromagnetic theory", "electromagnetic theory"], "answer_start": [33, 33, 33, 33]}, "prediction_text": "Using quantum mechanics"}
{"answers": {"text": ["quantum mechanics", "quantum mechanics", "quantum mechanics", "the work of leading theoretical physicists"], "answer_start": [283, 283, 283, 186]}, "prediction_text": "Quantum mechanics"}
{"answers": {"text": ["quantum electrodynamics", "quantum electrodynamics (or QED)", "quantum electrodynamics", "quantum electrodynamics"], "answer_start": [370, 370, 370, 370]}, "prediction_text": "Quantum electrodynamics (QED)"}
{"answers": {"text": ["photons", "photons", "photons", "photons"], "answer_start": [501, 501, 501, 501]}, "prediction_text": "photons"}
{"answers": {"text": ["quantum electrodynamics", "quantum electrodynamics", "quantum electrodynamics", "quantum electrodynamics"], "answer_start": [370, 370, 370, 370]}, "prediction_text": "Quantum Electrodynamics"}
{"answers": {"text": ["repulsion of like charges", "repulsion of like charges under the influence of the electromagnetic force", "repulsion of like charges", "the repulsion of like charges under the influence of the electromagnetic force"], "answer_start": [90, 90, 90, 86]}, "prediction_text": "Pauli exclusion principle"}
{"answers": {"text": ["the Pauli exclusion principle", "the Pauli exclusion principle", "Pauli exclusion principle", "Pauli exclusion principle"], "answer_start": [218, 218, 222, 222]}, "prediction_text": "Pauli exclusion principle"}
{"answers": {"text": ["energy", "energy", "energy", "energy"], "answer_start": [579, 579, 579, 579]}, "prediction_text": "Energy"}
{"answers": {"text": ["as a structural force", "as a structural force", "a structural force", "macroscopically as a structural force"], "answer_start": [657, 657, 660, 641]}, "prediction_text": "Through electron mass and Pauli exclusion."}
{"answers": {"text": ["repulsion of like charges", "repulsion of like charges under the influence of the electromagnetic force", "repulsion of like charges", "the repulsion of like charges under the influence of the electromagnetic force"], "answer_start": [90, 90, 90, 86]}, "prediction_text": "Pauli exclusion principle"}
{"answers": {"text": ["the Pauli exclusion principle", "the Pauli exclusion principle", "Pauli exclusion principle", "Pauli exclusion principle"], "answer_start": [218, 218, 222, 222]}, "prediction_text": "Pauli exclusion principle"}
{"answers": {"text": ["energy", "energy", "energy", "energy"], "answer_start": [579, 539, 579, 579]}, "prediction_text": "Energy"}
{"answers": {"text": ["as a structural force", "as a structural force", "a structural force", "macroscopically as a structural force"], "answer_start": [657, 657, 660, 641]}, "prediction_text": "Through electron mass and Pauli exclusion."}
{"answers": {"text": ["elementary particles", "elementary particles", "elementary particles", "elementary particles"], "answer_start": [41, 41, 41, 41]}, "prediction_text": "elementary particles"}
{"answers": {"text": ["residual of the force", "residual of the force", "nucleons in atomic nuclei", "a residual of the force"], "answer_start": [74, 74, 182, 72]}, "prediction_text": "Force acts between nucleons."}
{"answers": {"text": ["nuclear", "nuclear force.", "nuclear", "nuclear force"], "answer_start": [216, 216, 216, 216]}, "prediction_text": "Nuclear force"}
{"answers": {"text": ["as gluons", "as gluons", "as gluons", "as gluons"], "answer_start": [282, 282, 282, 282]}, "prediction_text": "Through gluons"}
{"answers": {"text": ["color confinement", "color confinement", "color confinement", "color confinement"], "answer_start": [564, 564, 564, 564]}, "prediction_text": "Color confinement"}
{"answers": {"text": ["weak force", "weak force", "weak force", "weak force"], "answer_start": [4, 4, 4, 4]}, "prediction_text": "Beta decay and radioactivity."}
{"answers": {"text": ["beta decay", "beta decay (of neutrons in atomic nuclei)", "beta decay", "beta decay"], "answer_start": [95, 95, 95, 95]}, "prediction_text": "Beta decay"}
{"answers": {"text": ["radioactivity", "radioactivity", "radioactivity", "radioactivity"], "answer_start": [156, 156, 156, 156]}, "prediction_text": "Beta decay is a strong force effect."}
{"answers": {"text": ["1013", "1013", "1013", "1013"], "answer_start": [241, 241, 241, 241]}, "prediction_text": "1013 times less"}
{"answers": {"text": ["approximately 1015 kelvins", "in excess of approximately 1015 kelvins", "1015 kelvins", "in excess of approximately 1015 kelvins"], "answer_start": [514, 501, 528, 501]}, "prediction_text": "At approximately 1015 kelvins."}
{"answers": {"text": ["normal force", "normal force", "normal force", "normal force"], "answer_start": [4, 4, 4, 4]}, "prediction_text": "Pauli repulsion"}
{"answers": {"text": ["Pauli repulsion", "Pauli repulsion", "Pauli repulsion", "Pauli repulsion"], "answer_start": [127, 127, 127, 127]}, "prediction_text": "Pauli repulsion occurs."}
{"answers": {"text": ["fermionic nature of electrons", "fermionic nature of electrons", "fermionic nature of electrons", "fermionic nature of electrons"], "answer_start": [151, 151, 151, 151]}, "prediction_text": "Fermionic nature of electrons"}
{"answers": {"text": ["normal", "normal force", "normal force", "normal force"], "answer_start": [298, 298, 298, 298]}, "prediction_text": "Pauli repulsion"}
{"answers": {"text": ["ideal strings", "ideal strings that are massless", "ideal strings that are massless", "ideal strings that are massless, frictionless, unbreakable, and unstretchable"], "answer_start": [36, 36, 36, 36]}, "prediction_text": "Ideal strings and ideal pulleys."}
{"answers": {"text": ["ideal pulleys", "ideal pulleys", "ideal pulleys", "ideal pulleys"], "answer_start": [141, 141, 141, 141]}, "prediction_text": "Ideal pulleys"}
{"answers": {"text": ["action-reaction pairs", "instantaneously in action-reaction pairs", "in action-reaction pairs", "instantaneously in action-reaction pairs"], "answer_start": [269, 250, 266, 250]}, "prediction_text": "Ideal strings transmit tesion forces."}
{"answers": {"text": ["conservation of mechanical energy", "conservation of mechanical energy", "the tension force on a load can be multiplied", "tension force on a load can be multiplied"], "answer_start": [997, 997, 623, 627]}, "prediction_text": "Conservation of mechanical energy"}
{"answers": {"text": ["movable pulleys", "connecting the same string multiple times to the same object through the use of a set-up that uses movable pulleys,", "every string", "connecting the same string multiple times to the same object through the use of a set-up that uses movable pulleys"], "answer_start": [606, 507, 674, 507]}, "prediction_text": "A set-up that uses movable pulleys."}
{"answers": {"text": ["idealized point particles", "idealized point particles rather than three-dimensional objects", "idealized point particles", "idealized point particles"], "answer_start": [100, 100, 100, 100]}, "prediction_text": "Idealized point particles"}
{"answers": {"text": ["three-dimensional objects", "three-dimensional objects", "three-dimensional objects"], "answer_start": [138, 138, 138]}, "prediction_text": "Matter's extended structure and forces."}
{"answers": {"text": ["extended", "extended", "extended"], "answer_start": [530, 530, 530]}, "prediction_text": "Extended fluids"}
{"answers": {"text": ["other parts", "other parts of an object", "other parts of an object", "other parts of an object"], "answer_start": [276, 276, 276, 276]}, "prediction_text": "Other parts of an object"}
{"answers": {"text": ["extended structure", "extended structure", "extended structure", "extended structure and forces that act on one part of an object might affect other parts of an object"], "answer_start": [199, 199, 199, 199]}, "prediction_text": "Structures and forces"}
{"answers": {"text": ["stress tensor", "stress tensor", "deformations", "The stress tensor"], "answer_start": [376, 376, 434, 372]}, "prediction_text": "Deformations and compressions."}
{"answers": {"text": ["pressure terms", "stress tensor", "pressure terms associated with forces that act normal to the cross-sectional area (the matrix diagonals of the tensor) as well as shear terms"], "answer_start": [132, 376, 132]}, "prediction_text": "Pressure terms and shear terms."}
{"answers": {"text": ["pressure terms", "matrix diagonals of the tensor)", "pressure terms"], "answer_start": [132, 219, 132]}, "prediction_text": "Pressure terms"}
{"answers": {"text": ["formalism", "the relevant cross-sectional area for the volume for which the stress-tensor is being calculated", "formalism", "This formalism"], "answer_start": [113, 10, 113, 108]}, "prediction_text": "Pressure terms associated with forces that act normal to the cross-sectional area."}
{"answers": {"text": ["rotational equivalent for position", "rotation", "rotational inertia", "angle is the rotational equivalent for position"], "answer_start": [77, 14, 242, 64]}, "prediction_text": "Torque is the rotation equivalent of angular momentum."}
{"answers": {"text": ["unbalanced torque", "unbalanced torque", "unbalanced torque", "an unbalanced torque"], "answer_start": [346, 346, 346, 343]}, "prediction_text": "Unbalanced torque"}
{"answers": {"text": ["Newton's Second Law of Motion", "Newton's Second Law of Motion", "Newton's Second Law of Motion", "Newton's Second Law of Motion"], "answer_start": [375, 375, 375, 375]}, "prediction_text": "Newton's Second Law of Motion"}
{"answers": {"text": ["toward the center of the curving path", "center of the curving path.", "the center of the curving path", "directed toward the center of the curving path"], "answer_start": [291, 302, 298, 282]}, "prediction_text": "In the direction of the velocity vector."}
{"answers": {"text": ["perpendicular", "perpendicular", "perpendicular", "perpendicular"], "answer_start": [346, 346, 346, 346]}, "prediction_text": "In relation to vectors of velocity."}
{"answers": {"text": ["centripetal", "unbalanced centripetal force", "unbalanced centripetal force", "centripetal"], "answer_start": [837, 224, 224, 837]}, "prediction_text": "Unbalanced force"}
{"answers": {"text": ["radial", "radial (centripetal) force", "radial", "radial"], "answer_start": [829, 829, 829, 829]}, "prediction_text": "radial force"}
{"answers": {"text": ["tangential force", "tangential force", "tangential force", "tangential force"], "answer_start": [729, 729, 729, 729]}, "prediction_text": "The unbalanced force"}
{"answers": {"text": ["kinetic", "kinetic", "kinetic", "kinetic"], "answer_start": [127, 127, 127, 127]}, "prediction_text": "kinetic or potential forms"}
{"answers": {"text": ["potential", "potential", "potential", "potential"], "answer_start": [138, 138, 138, 138]}, "prediction_text": "Potential energy"}
{"answers": {"text": ["net mechanical energy", "net mechanical energy", "net mechanical energy", "net mechanical energy"], "answer_start": [196, 196, 196, 196]}, "prediction_text": "Energy is conserved."}
{"answers": {"text": ["difference in potential energy", "the difference in potential energy", "the difference in potential energy", "the difference in potential energy between two different locations in space"], "answer_start": [330, 326, 326, 326]}, "prediction_text": "Potential energy"}
{"answers": {"text": ["artifact", "artifact of the potential field", "an artifact"], "answer_start": [434, 434, 431]}, "prediction_text": "Conservative force"}
{"answers": {"text": ["forces", "forces as being due to gradient of potentials", "forces", "forces as being due to gradient of potentials"], "answer_start": [58, 58, 58, 58]}, "prediction_text": "Force models as arising from macroscopic statistical average of microstates."}
{"answers": {"text": ["gradient of potentials", "macrophysical considerations that yield forces as arising from a macroscopic statistical average of microstates", "gradient of potentials.", "gradient of potentials"], "answer_start": [81, 126, 81, 81]}, "prediction_text": "Macrophysical considerations"}
{"answers": {"text": ["friction", "friction", "friction", "friction"], "answer_start": [252, 252, 252, 252]}, "prediction_text": "Force models"}
{"answers": {"text": ["Nonconservative", "Nonconservative forces other than friction", "Nonconservative", "Nonconservative forces"], "answer_start": [430, 430, 430, 430]}, "prediction_text": "Nonconservative forces"}
{"answers": {"text": ["statistical mechanics", "statistical mechanics", "detailed", "detailed treatment with statistical mechanics"], "answer_start": [134, 134, 110, 110]}, "prediction_text": "Statistical mechanics"}
{"answers": {"text": ["nonconservative forces", "internal energies of the system", "nonconservative forces", "nonconservative forces"], "answer_start": [188, 229, 188, 188]}, "prediction_text": "Nonconservative forces change energy transformations."}
{"answers": {"text": ["nonconservative forces", "nonconservative forces", "nonconservative forces", "nonconservative forces"], "answer_start": [188, 188, 188, 188]}, "prediction_text": "Nonconservative forces"}
{"answers": {"text": ["Second", "Second law of thermodynamics", "Second law", "Second"], "answer_start": [331, 331, 331, 331]}, "prediction_text": "entropy increases"}
{"answers": {"text": ["nonconservative forces", "nonconservative forces", "nonconservative forces", "nonconservative forces"], "answer_start": [361, 361, 361, 361]}, "prediction_text": "Nonconservative forces"}
{"answers": {"text": ["kilogram-force", "pound-force", "kilogram-force (kgf)", "kilogram-force", "the kilogram-force ("], "answer_start": [82, 4, 82, 82, 78]}, "prediction_text": "kilogram-force (kgf)"}
{"answers": {"text": ["kilopond", "kilopond", "kilopond", "kilopond", "kilopond"], "answer_start": [114, 114, 114, 114, 114]}, "prediction_text": "kilopond"}
{"answers": {"text": ["slug", "metric slug", "metric slug", "metric slug", "the metric slug"], "answer_start": [274, 267, 267, 267, 263]}, "prediction_text": "The metric slug (sometimes mug or hyl)"}
{"answers": {"text": ["kip", "kip", "kip", "kip", "kip"], "answer_start": [712, 712, 712, 712, 712]}, "prediction_text": "metric slug"}
{"answers": {"text": ["sth\u00e8ne", "sth\u00e8ne", "sth\u00e8ne", "sth\u00e8ne", "sth\u00e8ne"], "answer_start": [665, 665, 665, 665, 665]}, "prediction_text": "kilogram-force (kgf)"}
